<!DOCTYPE html><html lang="en-us" dir="ltr"> <head><script async src="https://ot.www.cloudflare.com/public/vendor/onetrust/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" data-domain-script="b1e05d49-f072-4bae-9116-bdb78af15448"></script><meta name="HandheldFriendly" content="True"><meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="baidu-site-verification" content="KeThzeyMOr"><meta name="baidu-site-verification" content="code-NIlrS7gNhx"><meta charset="UTF-8"><meta name="description" content="Get the latest news on how products at Cloudflare are built, technologies used, and open positions to join the teams helping to build a better Internet."><title>Outage</title><meta name="title" content="Outage"><meta name="msvalidate.01" content="CF295E1604697F9CAD18B5A232E871F6"><meta class="swiftype" name="language" data-type="string" content="en"><script src="/static/z/i.js" type="text/javascript" referrerpolicy="origin"></script><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/favicon-32x32.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-32x32.png"><link rel="mask-icon" href="/images/favicon-32x32.png" color="#f78100"><link rel="stylesheet" href="/themes/ashes.min.css"><link rel="sitemap" href="/sitemap.xml"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" content="#ffffff"><link rel="canonical" href="https://blog.cloudflare.com/tag/outage/"><link rel="alternate" type="application/rss+xml" title="Cloudflare Outage RSS Feed" href="/tag/outage/rss"><link rel="alternate" hreflang="en-us" href="https://blog.cloudflare.com/tag/outage/"><link rel="alternate" hreflang="de-de" href="https://blog.cloudflare.com/de-de/tag/outage/"><link rel="alternate" hreflang="es-es" href="https://blog.cloudflare.com/es-es/tag/outage/"><link rel="alternate" hreflang="fr-fr" href="https://blog.cloudflare.com/fr-fr/tag/outage/"><link rel="alternate" hreflang="it-it" href="https://blog.cloudflare.com/it-it/tag/outage/"><link rel="alternate" hreflang="ja-jp" href="https://blog.cloudflare.com/ja-jp/tag/outage/"><link rel="alternate" hreflang="ko-kr" href="https://blog.cloudflare.com/ko-kr/tag/outage/"><link rel="alternate" hreflang="zh-tw" href="https://blog.cloudflare.com/zh-tw/tag/outage/"><link rel="alternate" hreflang="zh-cn" href="https://blog.cloudflare.com/zh-cn/tag/outage/"><link rel="alternate" hreflang="pt-br" href="https://blog.cloudflare.com/pt-br/tag/outage/"><link rel="alternate" hreflang="ru-ru" href="https://blog.cloudflare.com/ru-ru/tag/outage/"><link rel="alternate" hreflang="id-id" href="https://blog.cloudflare.com/id-id/tag/outage/"><link rel="alternate" hreflang="th-th" href="https://blog.cloudflare.com/th-th/tag/outage/"><link rel="alternate" hreflang="vi-vn" href="https://blog.cloudflare.com/vi-vn/tag/outage/"><link rel="alternate" hreflang="nl-nl" href="https://blog.cloudflare.com/nl-nl/tag/outage/"><!-- General Meta Tags --><meta property="article:publisher" content="https://www.facebook.com/cloudflare"><!-- Facebook Meta Tags --><meta property="og:site_name" content="The Cloudflare Blog"><meta property="og:type" content="website"><meta property="og:title" content="The Cloudflare Blog: Outage"><meta property="og:description" content="Collection of Cloudflare blog posts tagged 'Outage'"><meta property="og:url" content="https://blog.cloudflare.com/tag/outage/"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="628"><!-- Twitter/X Meta Tags --><meta name="twitter:title" content="The Cloudflare Blog: Outage"><meta name="twitter:description" content="Collection of Cloudflare blog posts tagged 'Outage'"><meta name="twitter:url" content="https://blog.cloudflare.com/tag/outage/"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@cloudflare"><meta property="og:image"><meta name="twitter:image"><link rel="stylesheet" href="/_astro/index.DAblDsYO.css"></head><style>astro-island,astro-slot,astro-static-slot{display:contents}</style><script>(()=>{var e=async t=>{await(await t())()};(self.Astro||(self.Astro={})).only=e;window.dispatchEvent(new Event("astro:only"));})();;(()=>{var A=Object.defineProperty;var g=(i,o,a)=>o in i?A(i,o,{enumerable:!0,configurable:!0,writable:!0,value:a}):i[o]=a;var d=(i,o,a)=>g(i,typeof o!="symbol"?o+"":o,a);{let i={0:t=>m(t),1:t=>a(t),2:t=>new RegExp(t),3:t=>new Date(t),4:t=>new Map(a(t)),5:t=>new Set(a(t)),6:t=>BigInt(t),7:t=>new URL(t),8:t=>new Uint8Array(t),9:t=>new Uint16Array(t),10:t=>new Uint32Array(t),11:t=>1/0*t},o=t=>{let[l,e]=t;return l in i?i[l](e):void 0},a=t=>t.map(o),m=t=>typeof t!="object"||t===null?t:Object.fromEntries(Object.entries(t).map(([l,e])=>[l,o(e)]));class y extends HTMLElement{constructor(){super(...arguments);d(this,"Component");d(this,"hydrator");d(this,"hydrate",async()=>{var b;if(!this.hydrator||!this.isConnected)return;let e=(b=this.parentElement)==null?void 0:b.closest("astro-island[ssr]");if(e){e.addEventListener("astro:hydrate",this.hydrate,{once:!0});return}let c=this.querySelectorAll("astro-slot"),n={},h=this.querySelectorAll("template[data-astro-template]");for(let r of h){let s=r.closest(this.tagName);s!=null&&s.isSameNode(this)&&(n[r.getAttribute("data-astro-template")||"default"]=r.innerHTML,r.remove())}for(let r of c){let s=r.closest(this.tagName);s!=null&&s.isSameNode(this)&&(n[r.getAttribute("name")||"default"]=r.innerHTML)}let p;try{p=this.hasAttribute("props")?m(JSON.parse(this.getAttribute("props"))):{}}catch(r){let s=this.getAttribute("component-url")||"<unknown>",v=this.getAttribute("component-export");throw v&&(s+=` (export ${v})`),console.error(`[hydrate] Error parsing props for component ${s}`,this.getAttribute("props"),r),r}let u;await this.hydrator(this)(this.Component,p,n,{client:this.getAttribute("client")}),this.removeAttribute("ssr"),this.dispatchEvent(new CustomEvent("astro:hydrate"))});d(this,"unmount",()=>{this.isConnected||this.dispatchEvent(new CustomEvent("astro:unmount"))})}disconnectedCallback(){document.removeEventListener("astro:after-swap",this.unmount),document.addEventListener("astro:after-swap",this.unmount,{once:!0})}connectedCallback(){if(!this.hasAttribute("await-children")||document.readyState==="interactive"||document.readyState==="complete")this.childrenConnectedCallback();else{let e=()=>{document.removeEventListener("DOMContentLoaded",e),c.disconnect(),this.childrenConnectedCallback()},c=new MutationObserver(()=>{var n;((n=this.lastChild)==null?void 0:n.nodeType)===Node.COMMENT_NODE&&this.lastChild.nodeValue==="astro:end"&&(this.lastChild.remove(),e())});c.observe(this,{childList:!0}),document.addEventListener("DOMContentLoaded",e)}}async childrenConnectedCallback(){let e=this.getAttribute("before-hydration-url");e&&await import(e),this.start()}async start(){let e=JSON.parse(this.getAttribute("opts")),c=this.getAttribute("client");if(Astro[c]===void 0){window.addEventListener(`astro:${c}`,()=>this.start(),{once:!0});return}try{await Astro[c](async()=>{let n=this.getAttribute("renderer-url"),[h,{default:p}]=await Promise.all([import(this.getAttribute("component-url")),n?import(n):()=>()=>{}]),u=this.getAttribute("component-export")||"default";if(!u.includes("."))this.Component=h[u];else{this.Component=h;for(let f of u.split("."))this.Component=this.Component[f]}return this.hydrator=p,this.hydrate},e,this)}catch(n){console.error(`[astro-island] Error hydrating ${this.getAttribute("component-url")}`,n)}}attributeChangedCallback(){this.hydrate()}}d(y,"observedAttributes",["props"]),customElements.get("astro-island")||customElements.define("astro-island",y)}})();</script><astro-island uid="tWjgj" component-url="/_astro/GoogleAnalytics.o7SaAFZX.js" component-export="GoogleAnalytics" renderer-url="/_astro/client.DLO1yDVm.js" props="{&quot;title&quot;:[0,&quot;Outage&quot;],&quot;canonical&quot;:[0,&quot;https://blog.cloudflare.com/tag/outage&quot;],&quot;info&quot;:[0],&quot;tagInfo&quot;:[0,{&quot;id&quot;:[0,&quot;4yliZlpBPZpOwBDZzo1tTh&quot;],&quot;slug&quot;:[0,&quot;outage&quot;],&quot;url&quot;:[0,&quot;https://blog.cloudflare.com/outage&quot;],&quot;name&quot;:[0,&quot;Outage&quot;],&quot;visibility&quot;:[0,&quot;public&quot;],&quot;feature_image&quot;:[0,&quot;&quot;],&quot;publicly_index&quot;:[0,true]}],&quot;authorInfo&quot;:[0],&quot;translatedPosts&quot;:[1,[]]}" ssr client="only" opts="{&quot;name&quot;:&quot;GoogleAnalytics&quot;,&quot;value&quot;:&quot;react&quot;}"></astro-island><script>(()=>{var l=(n,t)=>{let i=async()=>{await(await n())()},e=typeof t.value=="object"?t.value:void 0,s={timeout:e==null?void 0:e.timeout};"requestIdleCallback"in window?window.requestIdleCallback(i,s):setTimeout(i,s.timeout||200)};(self.Astro||(self.Astro={})).idle=l;window.dispatchEvent(new Event("astro:idle"));})();</script><astro-island uid="18lW62" prefix="r8" component-url="/_astro/Navigation.JWiNRNo9.js" component-export="Navigation" renderer-url="/_astro/client.DLO1yDVm.js" props="{&quot;title&quot;:[0,&quot;The Cloudflare Blog&quot;],&quot;logo&quot;:[0,&quot;//images.ctfassets.net/zkvhlag99gkb/69RwBidpiEHCDZ9rFVVk7T/092507edbed698420b89658e5a6d5105/CF_logo_stacked_blktype.png&quot;],&quot;pagesStore&quot;:[0,{&quot;page&quot;:[0,&quot;Tag&quot;],&quot;slug&quot;:[0,&quot;outage&quot;],&quot;translationsAvailable&quot;:[1,[[0,&quot;de-de&quot;],[0,&quot;es-es&quot;],[0,&quot;fr-fr&quot;],[0,&quot;it-it&quot;],[0,&quot;ja-jp&quot;],[0,&quot;ko-kr&quot;],[0,&quot;zh-tw&quot;],[0,&quot;zh-cn&quot;],[0,&quot;pt-br&quot;],[0,&quot;ru-ru&quot;],[0,&quot;id-id&quot;],[0,&quot;th-th&quot;],[0,&quot;vi-vn&quot;],[0,&quot;nl-nl&quot;]]],&quot;navData&quot;:[1,[[0,{&quot;metadata&quot;:[0,{&quot;tags&quot;:[1,[]],&quot;concepts&quot;:[1,[]]}],&quot;sys&quot;:[0,{&quot;space&quot;:[0,{&quot;sys&quot;:[0,{&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;Space&quot;],&quot;id&quot;:[0,&quot;zkvhlag99gkb&quot;]}]}],&quot;id&quot;:[0,&quot;6Foe3R8of95cWVnQwe5Toi&quot;],&quot;type&quot;:[0,&quot;Entry&quot;],&quot;createdAt&quot;:[0,&quot;2024-10-09T22:44:28.803Z&quot;],&quot;updatedAt&quot;:[0,&quot;2025-06-17T05:04:39.288Z&quot;],&quot;environment&quot;:[0,{&quot;sys&quot;:[0,{&quot;id&quot;:[0,&quot;master&quot;],&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;Environment&quot;]}]}],&quot;publishedVersion&quot;:[0,153],&quot;revision&quot;:[0,44],&quot;contentType&quot;:[0,{&quot;sys&quot;:[0,{&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;ContentType&quot;],&quot;id&quot;:[0,&quot;blogTag&quot;]}]}],&quot;locale&quot;:[0,&quot;en-US&quot;]}],&quot;fields&quot;:[0,{&quot;entryTitle&quot;:[0,&quot;AI&quot;],&quot;name&quot;:[0,&quot;AI&quot;],&quot;slug&quot;:[0,&quot;ai&quot;],&quot;featured&quot;:[0,true],&quot;publiclyIndex&quot;:[0,true]}]}],[0,{&quot;metadata&quot;:[0,{&quot;tags&quot;:[1,[]],&quot;concepts&quot;:[1,[]]}],&quot;sys&quot;:[0,{&quot;space&quot;:[0,{&quot;sys&quot;:[0,{&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;Space&quot;],&quot;id&quot;:[0,&quot;zkvhlag99gkb&quot;]}]}],&quot;id&quot;:[0,&quot;4HIPcb68qM0e26fIxyfzwQ&quot;],&quot;type&quot;:[0,&quot;Entry&quot;],&quot;createdAt&quot;:[0,&quot;2024-10-09T19:43:21.536Z&quot;],&quot;updatedAt&quot;:[0,&quot;2025-05-19T05:03:04.375Z&quot;],&quot;environment&quot;:[0,{&quot;sys&quot;:[0,{&quot;id&quot;:[0,&quot;master&quot;],&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;Environment&quot;]}]}],&quot;publishedVersion&quot;:[0,135],&quot;revision&quot;:[0,46],&quot;contentType&quot;:[0,{&quot;sys&quot;:[0,{&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;ContentType&quot;],&quot;id&quot;:[0,&quot;blogTag&quot;]}]}],&quot;locale&quot;:[0,&quot;en-US&quot;]}],&quot;fields&quot;:[0,{&quot;entryTitle&quot;:[0,&quot;Developers&quot;],&quot;name&quot;:[0,&quot;Developers&quot;],&quot;slug&quot;:[0,&quot;developers&quot;],&quot;featured&quot;:[0,true]}]}],[0,{&quot;metadata&quot;:[0,{&quot;tags&quot;:[1,[]],&quot;concepts&quot;:[1,[]]}],&quot;sys&quot;:[0,{&quot;space&quot;:[0,{&quot;sys&quot;:[0,{&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;Space&quot;],&quot;id&quot;:[0,&quot;zkvhlag99gkb&quot;]}]}],&quot;id&quot;:[0,&quot;5kZtWqjqa7aOUoZr8NFGwI&quot;],&quot;type&quot;:[0,&quot;Entry&quot;],&quot;createdAt&quot;:[0,&quot;2024-10-09T19:43:26.040Z&quot;],&quot;updatedAt&quot;:[0,&quot;2025-04-30T14:03:57.409Z&quot;],&quot;environment&quot;:[0,{&quot;sys&quot;:[0,{&quot;id&quot;:[0,&quot;master&quot;],&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;Environment&quot;]}]}],&quot;publishedVersion&quot;:[0,142],&quot;revision&quot;:[0,43],&quot;contentType&quot;:[0,{&quot;sys&quot;:[0,{&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;ContentType&quot;],&quot;id&quot;:[0,&quot;blogTag&quot;]}]}],&quot;locale&quot;:[0,&quot;en-US&quot;]}],&quot;fields&quot;:[0,{&quot;entryTitle&quot;:[0,&quot;Cloudflare Radar&quot;],&quot;name&quot;:[0,&quot;Radar&quot;],&quot;slug&quot;:[0,&quot;cloudflare-radar&quot;],&quot;featured&quot;:[0,true]}]}],[0,{&quot;metadata&quot;:[0,{&quot;tags&quot;:[1,[]],&quot;concepts&quot;:[1,[]]}],&quot;sys&quot;:[0,{&quot;space&quot;:[0,{&quot;sys&quot;:[0,{&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;Space&quot;],&quot;id&quot;:[0,&quot;zkvhlag99gkb&quot;]}]}],&quot;id&quot;:[0,&quot;6QktrXeEFcl4e2dZUTZVGl&quot;],&quot;type&quot;:[0,&quot;Entry&quot;],&quot;createdAt&quot;:[0,&quot;2024-10-09T19:43:20.198Z&quot;],&quot;updatedAt&quot;:[0,&quot;2025-04-09T11:02:56.665Z&quot;],&quot;environment&quot;:[0,{&quot;sys&quot;:[0,{&quot;id&quot;:[0,&quot;master&quot;],&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;Environment&quot;]}]}],&quot;publishedVersion&quot;:[0,68],&quot;revision&quot;:[0,28],&quot;contentType&quot;:[0,{&quot;sys&quot;:[0,{&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;ContentType&quot;],&quot;id&quot;:[0,&quot;blogTag&quot;]}]}],&quot;locale&quot;:[0,&quot;en-US&quot;]}],&quot;fields&quot;:[0,{&quot;entryTitle&quot;:[0,&quot;Product News&quot;],&quot;name&quot;:[0,&quot;Product News&quot;],&quot;slug&quot;:[0,&quot;product-news&quot;],&quot;featured&quot;:[0,true]}]}],[0,{&quot;metadata&quot;:[0,{&quot;tags&quot;:[1,[]],&quot;concepts&quot;:[1,[]]}],&quot;sys&quot;:[0,{&quot;space&quot;:[0,{&quot;sys&quot;:[0,{&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;Space&quot;],&quot;id&quot;:[0,&quot;zkvhlag99gkb&quot;]}]}],&quot;id&quot;:[0,&quot;6Mp7ouACN2rT3YjL1xaXJx&quot;],&quot;type&quot;:[0,&quot;Entry&quot;],&quot;createdAt&quot;:[0,&quot;2024-10-09T19:42:46.231Z&quot;],&quot;updatedAt&quot;:[0,&quot;2025-04-09T11:02:54.136Z&quot;],&quot;environment&quot;:[0,{&quot;sys&quot;:[0,{&quot;id&quot;:[0,&quot;master&quot;],&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;Environment&quot;]}]}],&quot;publishedVersion&quot;:[0,134],&quot;revision&quot;:[0,41],&quot;contentType&quot;:[0,{&quot;sys&quot;:[0,{&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;ContentType&quot;],&quot;id&quot;:[0,&quot;blogTag&quot;]}]}],&quot;locale&quot;:[0,&quot;en-US&quot;]}],&quot;fields&quot;:[0,{&quot;entryTitle&quot;:[0,&quot;Security&quot;],&quot;name&quot;:[0,&quot;Security&quot;],&quot;slug&quot;:[0,&quot;security&quot;],&quot;featured&quot;:[0,true]}]}],[0,{&quot;metadata&quot;:[0,{&quot;tags&quot;:[1,[]],&quot;concepts&quot;:[1,[]]}],&quot;sys&quot;:[0,{&quot;space&quot;:[0,{&quot;sys&quot;:[0,{&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;Space&quot;],&quot;id&quot;:[0,&quot;zkvhlag99gkb&quot;]}]}],&quot;id&quot;:[0,&quot;16yk8DVbNNifxov5cWvAov&quot;],&quot;type&quot;:[0,&quot;Entry&quot;],&quot;createdAt&quot;:[0,&quot;2024-10-09T19:56:23.848Z&quot;],&quot;updatedAt&quot;:[0,&quot;2025-04-07T23:03:54.104Z&quot;],&quot;environment&quot;:[0,{&quot;sys&quot;:[0,{&quot;id&quot;:[0,&quot;master&quot;],&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;Environment&quot;]}]}],&quot;publishedVersion&quot;:[0,65],&quot;revision&quot;:[0,29],&quot;contentType&quot;:[0,{&quot;sys&quot;:[0,{&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;ContentType&quot;],&quot;id&quot;:[0,&quot;blogTag&quot;]}]}],&quot;locale&quot;:[0,&quot;en-US&quot;]}],&quot;fields&quot;:[0,{&quot;entryTitle&quot;:[0,&quot;Policy &amp; Legal&quot;],&quot;name&quot;:[0,&quot;Policy &amp; Legal&quot;],&quot;slug&quot;:[0,&quot;policy&quot;],&quot;featured&quot;:[0,true]}]}],[0,{&quot;metadata&quot;:[0,{&quot;tags&quot;:[1,[]],&quot;concepts&quot;:[1,[]]}],&quot;sys&quot;:[0,{&quot;space&quot;:[0,{&quot;sys&quot;:[0,{&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;Space&quot;],&quot;id&quot;:[0,&quot;zkvhlag99gkb&quot;]}]}],&quot;id&quot;:[0,&quot;J61Eszqn98amrYHq4IhTx&quot;],&quot;type&quot;:[0,&quot;Entry&quot;],&quot;createdAt&quot;:[0,&quot;2024-10-09T19:43:46.068Z&quot;],&quot;updatedAt&quot;:[0,&quot;2025-04-07T23:03:53.720Z&quot;],&quot;environment&quot;:[0,{&quot;sys&quot;:[0,{&quot;id&quot;:[0,&quot;master&quot;],&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;Environment&quot;]}]}],&quot;publishedVersion&quot;:[0,136],&quot;revision&quot;:[0,44],&quot;contentType&quot;:[0,{&quot;sys&quot;:[0,{&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;ContentType&quot;],&quot;id&quot;:[0,&quot;blogTag&quot;]}]}],&quot;locale&quot;:[0,&quot;en-US&quot;]}],&quot;fields&quot;:[0,{&quot;entryTitle&quot;:[0,&quot;Zero Trust&quot;],&quot;name&quot;:[0,&quot;Zero Trust&quot;],&quot;slug&quot;:[0,&quot;zero-trust&quot;],&quot;featured&quot;:[0,true]}]}],[0,{&quot;metadata&quot;:[0,{&quot;tags&quot;:[1,[]],&quot;concepts&quot;:[1,[]]}],&quot;sys&quot;:[0,{&quot;space&quot;:[0,{&quot;sys&quot;:[0,{&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;Space&quot;],&quot;id&quot;:[0,&quot;zkvhlag99gkb&quot;]}]}],&quot;id&quot;:[0,&quot;48r7QV00gLMWOIcM1CSDRy&quot;],&quot;type&quot;:[0,&quot;Entry&quot;],&quot;createdAt&quot;:[0,&quot;2024-10-09T19:54:22.790Z&quot;],&quot;updatedAt&quot;:[0,&quot;2025-04-07T23:03:52.422Z&quot;],&quot;environment&quot;:[0,{&quot;sys&quot;:[0,{&quot;id&quot;:[0,&quot;master&quot;],&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;Environment&quot;]}]}],&quot;publishedVersion&quot;:[0,66],&quot;revision&quot;:[0,28],&quot;contentType&quot;:[0,{&quot;sys&quot;:[0,{&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;ContentType&quot;],&quot;id&quot;:[0,&quot;blogTag&quot;]}]}],&quot;locale&quot;:[0,&quot;en-US&quot;]}],&quot;fields&quot;:[0,{&quot;entryTitle&quot;:[0,&quot;Speed &amp; Reliability&quot;],&quot;name&quot;:[0,&quot;Speed &amp; Reliability&quot;],&quot;slug&quot;:[0,&quot;speed-and-reliability&quot;],&quot;featured&quot;:[0,true]}]}],[0,{&quot;metadata&quot;:[0,{&quot;tags&quot;:[1,[]],&quot;concepts&quot;:[1,[]]}],&quot;sys&quot;:[0,{&quot;space&quot;:[0,{&quot;sys&quot;:[0,{&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;Space&quot;],&quot;id&quot;:[0,&quot;zkvhlag99gkb&quot;]}]}],&quot;id&quot;:[0,&quot;4g8tPriKOAUwdUT4jNPebe&quot;],&quot;type&quot;:[0,&quot;Entry&quot;],&quot;createdAt&quot;:[0,&quot;2024-10-09T19:46:40.927Z&quot;],&quot;updatedAt&quot;:[0,&quot;2025-04-07T23:03:51.235Z&quot;],&quot;environment&quot;:[0,{&quot;sys&quot;:[0,{&quot;id&quot;:[0,&quot;master&quot;],&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;Environment&quot;]}]}],&quot;publishedVersion&quot;:[0,77],&quot;revision&quot;:[0,29],&quot;contentType&quot;:[0,{&quot;sys&quot;:[0,{&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;ContentType&quot;],&quot;id&quot;:[0,&quot;blogTag&quot;]}]}],&quot;locale&quot;:[0,&quot;en-US&quot;]}],&quot;fields&quot;:[0,{&quot;entryTitle&quot;:[0,&quot;Life at Cloudflare&quot;],&quot;name&quot;:[0,&quot;Life at Cloudflare&quot;],&quot;slug&quot;:[0,&quot;life-at-cloudflare&quot;],&quot;featured&quot;:[0,true]}]}],[0,{&quot;metadata&quot;:[0,{&quot;tags&quot;:[1,[]],&quot;concepts&quot;:[1,[]]}],&quot;sys&quot;:[0,{&quot;space&quot;:[0,{&quot;sys&quot;:[0,{&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;Space&quot;],&quot;id&quot;:[0,&quot;zkvhlag99gkb&quot;]}]}],&quot;id&quot;:[0,&quot;V86khSc459Yi1AhTlvtY7&quot;],&quot;type&quot;:[0,&quot;Entry&quot;],&quot;createdAt&quot;:[0,&quot;2024-10-09T19:46:53.657Z&quot;],&quot;updatedAt&quot;:[0,&quot;2025-02-04T17:12:59.473Z&quot;],&quot;environment&quot;:[0,{&quot;sys&quot;:[0,{&quot;id&quot;:[0,&quot;master&quot;],&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;Environment&quot;]}]}],&quot;publishedVersion&quot;:[0,57],&quot;revision&quot;:[0,21],&quot;contentType&quot;:[0,{&quot;sys&quot;:[0,{&quot;type&quot;:[0,&quot;Link&quot;],&quot;linkType&quot;:[0,&quot;ContentType&quot;],&quot;id&quot;:[0,&quot;blogTag&quot;]}]}],&quot;locale&quot;:[0,&quot;en-US&quot;]}],&quot;fields&quot;:[0,{&quot;entryTitle&quot;:[0,&quot;Partners&quot;],&quot;name&quot;:[0,&quot;Partners&quot;],&quot;slug&quot;:[0,&quot;partners&quot;],&quot;featured&quot;:[0,true]}]}]]]}],&quot;locale&quot;:[0,&quot;en-us&quot;],&quot;translations&quot;:[0,{&quot;posts.by&quot;:[0,&quot;By&quot;],&quot;footer.gdpr&quot;:[0,&quot;GDPR&quot;],&quot;lang_blurb1&quot;:[0,&quot;This post is also available in {lang1}.&quot;],&quot;lang_blurb2&quot;:[0,&quot;This post is also available in {lang1} and {lang2}.&quot;],&quot;lang_blurb3&quot;:[0,&quot;This post is also available in {lang1}, {lang2} and {lang3}.&quot;],&quot;footer.press&quot;:[0,&quot;Press&quot;],&quot;header.title&quot;:[0,&quot;The Cloudflare Blog&quot;],&quot;search.clear&quot;:[0,&quot;Clear&quot;],&quot;search.filter&quot;:[0,&quot;Filter&quot;],&quot;search.source&quot;:[0,&quot;Source&quot;],&quot;footer.careers&quot;:[0,&quot;Careers&quot;],&quot;footer.company&quot;:[0,&quot;Company&quot;],&quot;footer.support&quot;:[0,&quot;Support&quot;],&quot;footer.the_net&quot;:[0,&quot;theNet&quot;],&quot;search.filters&quot;:[0,&quot;Filters&quot;],&quot;footer.our_team&quot;:[0,&quot;Our team&quot;],&quot;footer.webinars&quot;:[0,&quot;Webinars&quot;],&quot;page.more_posts&quot;:[0,&quot;More posts&quot;],&quot;posts.time_read&quot;:[0,&quot;{time} min read&quot;],&quot;search.language&quot;:[0,&quot;Language&quot;],&quot;footer.community&quot;:[0,&quot;Community&quot;],&quot;footer.resources&quot;:[0,&quot;Resources&quot;],&quot;footer.solutions&quot;:[0,&quot;Solutions&quot;],&quot;footer.trademark&quot;:[0,&quot;Trademark&quot;],&quot;header.subscribe&quot;:[0,&quot;Subscribe&quot;],&quot;footer.compliance&quot;:[0,&quot;Compliance&quot;],&quot;footer.free_plans&quot;:[0,&quot;Free plans&quot;],&quot;footer.impact_ESG&quot;:[0,&quot;Impact/ESG&quot;],&quot;posts.follow_on_X&quot;:[0,&quot;Follow on X&quot;],&quot;footer.help_center&quot;:[0,&quot;Help center&quot;],&quot;footer.network_map&quot;:[0,&quot;Network Map&quot;],&quot;header.please_wait&quot;:[0,&quot;Please Wait&quot;],&quot;page.related_posts&quot;:[0,&quot;Related posts&quot;],&quot;search.result_stat&quot;:[0,&quot;Results &lt;strong&gt;{search_range}&lt;/strong&gt; of &lt;strong&gt;{search_total}&lt;/strong&gt; for &lt;strong&gt;{search_keyword}&lt;/strong&gt;&quot;],&quot;footer.case_studies&quot;:[0,&quot;Case Studies&quot;],&quot;footer.connect_2024&quot;:[0,&quot;Connect 2024&quot;],&quot;footer.terms_of_use&quot;:[0,&quot;Terms of Use&quot;],&quot;footer.white_papers&quot;:[0,&quot;White Papers&quot;],&quot;footer.cloudflare_tv&quot;:[0,&quot;Cloudflare TV&quot;],&quot;footer.community_hub&quot;:[0,&quot;Community Hub&quot;],&quot;footer.compare_plans&quot;:[0,&quot;Compare plans&quot;],&quot;footer.contact_sales&quot;:[0,&quot;Contact Sales&quot;],&quot;header.contact_sales&quot;:[0,&quot;Contact Sales&quot;],&quot;header.email_address&quot;:[0,&quot;Email Address&quot;],&quot;page.error.not_found&quot;:[0,&quot;Page not found&quot;],&quot;footer.developer_docs&quot;:[0,&quot;Developer docs&quot;],&quot;footer.privacy_policy&quot;:[0,&quot;Privacy Policy&quot;],&quot;footer.request_a_demo&quot;:[0,&quot;Request a demo&quot;],&quot;page.continue_reading&quot;:[0,&quot;Continue reading&quot;],&quot;footer.analysts_report&quot;:[0,&quot;Analyst reports&quot;],&quot;footer.for_enterprises&quot;:[0,&quot;For enterprises&quot;],&quot;footer.getting_started&quot;:[0,&quot;Getting Started&quot;],&quot;footer.learning_center&quot;:[0,&quot;Learning Center&quot;],&quot;footer.project_galileo&quot;:[0,&quot;Project Galileo&quot;],&quot;pagination.newer_posts&quot;:[0,&quot;Newer Posts&quot;],&quot;pagination.older_posts&quot;:[0,&quot;Older Posts&quot;],&quot;posts.social_buttons.x&quot;:[0,&quot;Discuss on X&quot;],&quot;search.icon_aria_label&quot;:[0,&quot;Search&quot;],&quot;search.source_location&quot;:[0,&quot;Source/Location&quot;],&quot;footer.about_cloudflare&quot;:[0,&quot;About Cloudflare&quot;],&quot;footer.athenian_project&quot;:[0,&quot;Athenian Project&quot;],&quot;footer.become_a_partner&quot;:[0,&quot;Become a partner&quot;],&quot;footer.cloudflare_radar&quot;:[0,&quot;Cloudflare Radar&quot;],&quot;footer.network_services&quot;:[0,&quot;Network services&quot;],&quot;footer.trust_and_safety&quot;:[0,&quot;Trust &amp; Safety&quot;],&quot;header.get_started_free&quot;:[0,&quot;Get Started Free&quot;],&quot;page.search.placeholder&quot;:[0,&quot;Search Cloudflare&quot;],&quot;footer.cloudflare_status&quot;:[0,&quot;Cloudflare Status&quot;],&quot;footer.cookie_preference&quot;:[0,&quot;Cookie Preferences&quot;],&quot;header.valid_email_error&quot;:[0,&quot;Must be valid email.&quot;],&quot;search.result_stat_empty&quot;:[0,&quot;Results &lt;strong&gt;{search_range}&lt;/strong&gt; of &lt;strong&gt;{search_total}&lt;/strong&gt;&quot;],&quot;footer.connectivity_cloud&quot;:[0,&quot;Connectivity cloud&quot;],&quot;footer.developer_services&quot;:[0,&quot;Developer services&quot;],&quot;footer.investor_relations&quot;:[0,&quot;Investor relations&quot;],&quot;page.not_found.error_code&quot;:[0,&quot;Error Code: 404&quot;],&quot;search.autocomplete_title&quot;:[0,&quot;Insert a query. Press enter to send&quot;],&quot;footer.logos_and_press_kit&quot;:[0,&quot;Logos &amp; press kit&quot;],&quot;footer.application_services&quot;:[0,&quot;Application services&quot;],&quot;footer.get_a_recommendation&quot;:[0,&quot;Get a recommendation&quot;],&quot;posts.social_buttons.reddit&quot;:[0,&quot;Discuss on Reddit&quot;],&quot;footer.sse_and_sase_services&quot;:[0,&quot;SSE and SASE services&quot;],&quot;page.not_found.outdated_link&quot;:[0,&quot;You may have used an outdated link, or you may have typed the address incorrectly.&quot;],&quot;footer.report_security_issues&quot;:[0,&quot;Report Security Issues&quot;],&quot;page.error.error_message_page&quot;:[0,&quot;Sorry, we can&#39;t find the page you are looking for.&quot;],&quot;header.subscribe_notifications&quot;:[0,&quot;Subscribe to receive notifications of new posts:&quot;],&quot;footer.cloudflare_for_campaigns&quot;:[0,&quot;Cloudflare for Campaigns&quot;],&quot;header.subscription_confimation&quot;:[0,&quot;Subscription confirmed. Thank you for subscribing!&quot;],&quot;posts.social_buttons.hackernews&quot;:[0,&quot;Discuss on Hacker News&quot;],&quot;footer.diversity_equity_inclusion&quot;:[0,&quot;Diversity, equity &amp; inclusion&quot;],&quot;footer.critical_infrastructure_defense_project&quot;:[0,&quot;Critical Infrastructure Defense Project&quot;]}]}" ssr client="idle" opts="{&quot;name&quot;:&quot;NavigationComponent&quot;,&quot;value&quot;:true}" await-children><header class="flex flex-row flex-wrap justify-between items-flex-end mw8 center mv3 pl3 pr1"><div class="w-100 flex items-flex-end justify-between justify-start-l"><div class="w-100 tr flex justify-end"><div class="flex justify-between items-center"><span class="dn di-l pr1"><a href="https://dash.cloudflare.com/sign-up" class="f1 blue1 dn di-l b no-underline underline-hover" target="_blank" rel="noreferrer">Get Started Free</a></span><span class="f1 gray4 dn di-l pr1">|</span><span class="dn di-l"><a target="_blank" href="https://www.cloudflare.com/plans/enterprise/contact/" class="f1 gray4 no-underline underline-hover pr1" rel="noreferrer">Contact Sales</a></span><span class="f1 gray4 dn di-l pr1">|</span><div class="relative flex cf-dropdown"><div class="flex items-center" dir="ltr"><button type="button" class="f1 gray4 no-underline language-picker js-language-picker" style="background:transparent;border:none;padding:0"><span class="language-picker__globe-icon"></span><span class="language-picker__caret-icon ph1">▼</span></button></div></div></div></div></div><div class="w-100 w-50-l flex items-end nb5 nb1-l"><a href="/" class="header-logo mr4 dn db-l"><img class="header-logo" src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/69RwBidpiEHCDZ9rFVVk7T/092507edbed698420b89658e5a6d5105/CF_logo_stacked_blktype.png" alt="The Cloudflare Blog" width="170" height="57"/></a><h2 class="mt0 mb1 dn di-l"><a href="/" class="fw5 f5 gray3 no-underline"><span class="dn di-l">The Cloudflare Blog</span></a></h2></div><div class="w-100 w-50-l dn db-l"><div class="w-100 tr mkto-sub-message"><p class="f2">Subscribe to receive notifications of new posts:</p></div><div class="w-100 tr"><div class="marketo-form-container"><form id="mktoForm_1653"><div class="top-subscribe-form-container"><div class="top-subscribe-form-field"><input placeholder="Email Address" class="top-subscribe-form-input" name="email" type="email" title="Must be valid email."/></div><button class="top-subscribe-form-button" type="button">Subscribe</button></div></form></div></div></div></header><nav dir="ltr" class="bb b--black-10 db dn-l w-100 ph3 "><div class=" flex justify-between items-center" style="height:44px"><a href="/search/"><img class="h-6 w-6" src="/images/magnifier.svg" alt="magnifier icon"/></a><button type="button" style="background:transparent;border:none"><img src="/images/hamburger.svg" alt="hamburger menu"/></button></div><div class="js-mobile-nav-container dn"><div class="flex flex-column flex-wrap bg-gray9 o-95 absolute ph3 z-1 left-0 right-0 mx-4"><div class="pv3 ph2 tl"><a href="/tag/ai/" class="no-underline gray1 f4 fw7">AI</a></div><div class="pv3 ph2 tl"><a href="/tag/developers/" class="no-underline gray1 f4 fw7">Developers</a></div><div class="pv3 ph2 tl"><a href="/tag/cloudflare-radar/" class="no-underline gray1 f4 fw7">Radar</a></div><div class="pv3 ph2 tl"><a href="/tag/product-news/" class="no-underline gray1 f4 fw7">Product News</a></div><div class="pv3 ph2 tl"><a href="/tag/security/" class="no-underline gray1 f4 fw7">Security</a></div><div class="pv3 ph2 tl"><a href="/tag/policy/" class="no-underline gray1 f4 fw7">Policy &amp; Legal</a></div><div class="pv3 ph2 tl"><a href="/tag/zero-trust/" class="no-underline gray1 f4 fw7">Zero Trust</a></div><div class="pv3 ph2 tl"><a href="/tag/speed-and-reliability/" class="no-underline gray1 f4 fw7">Speed &amp; Reliability</a></div><div class="pv3 ph2 tl"><a href="/tag/life-at-cloudflare/" class="no-underline gray1 f4 fw7">Life at Cloudflare</a></div><div class="pv3 ph2 tl"><a href="/tag/partners/" class="no-underline gray1 f4 fw7">Partners</a></div></div></div></nav><nav id="nav" class="w-100 bb-0 bb-l b--black-10 z-1"><div id="desktop-nav-items-container" class="flex flex-wrap justify-between items-center mw8 center mv3 mv0-l"><div data-tag="ai" class="nav-item nav-item-desktop ml3 mr2 dn db-l pv3"><a href="/tag/ai/" class="no-underline gray1 f2 fw5 pv3">AI</a></div><div data-tag="developers" class="nav-item nav-item-desktop ml3 mr2 dn db-l pv3"><a href="/tag/developers/" class="no-underline gray1 f2 fw5 pv3">Developers</a></div><div data-tag="cloudflare-radar" class="nav-item nav-item-desktop ml3 mr2 dn db-l pv3"><a href="/tag/cloudflare-radar/" class="no-underline gray1 f2 fw5 pv3">Radar</a></div><div data-tag="product-news" class="nav-item nav-item-desktop ml3 mr2 dn db-l pv3"><a href="/tag/product-news/" class="no-underline gray1 f2 fw5 pv3">Product News</a></div><div data-tag="security" class="nav-item nav-item-desktop ml3 mr2 dn db-l pv3"><a href="/tag/security/" class="no-underline gray1 f2 fw5 pv3">Security</a></div><div data-tag="policy" class="nav-item nav-item-desktop ml3 mr2 dn db-l pv3"><a href="/tag/policy/" class="no-underline gray1 f2 fw5 pv3">Policy &amp; Legal</a></div><div data-tag="zero-trust" class="nav-item nav-item-desktop ml3 mr2 dn db-l pv3"><a href="/tag/zero-trust/" class="no-underline gray1 f2 fw5 pv3">Zero Trust</a></div><div data-tag="speed-and-reliability" class="nav-item nav-item-desktop ml3 mr2 dn db-l pv3"><a href="/tag/speed-and-reliability/" class="no-underline gray1 f2 fw5 pv3">Speed &amp; Reliability</a></div><div data-tag="life-at-cloudflare" class="nav-item nav-item-desktop ml3 mr2 dn db-l pv3"><a href="/tag/life-at-cloudflare/" class="no-underline gray1 f2 fw5 pv3">Life at Cloudflare</a></div><div data-tag="partners" class="nav-item nav-item-desktop ml3 mr2 dn db-l pv3"><a href="/tag/partners/" class="no-underline gray1 f2 fw5 pv3">Partners</a></div><div class="nav-item ml2 mr3 dn db-l pv3" data-tag="search icon"><a href="/search/"><img id="search-icon" class="h-6 w-6" src="/images/magnifier.svg" alt="magnifier icon"/></a></div></div></nav><!--astro:end--></astro-island> <script>(()=>{var e=async t=>{await(await t())()};(self.Astro||(self.Astro={})).load=e;window.dispatchEvent(new Event("astro:load"));})();</script> <div class="flex flex-row flex-wrap mw8 center bb b--gray8 ph3"> <h1 class="site-title f7 fw4 mt4 mb3 mv4-l">Outage</h1> </div> <main id="site-main" class="flex flex-row flex-wrap mw8 center pt0 pt3-l mt4-l"> <astro-island uid="dpuzB" prefix="r0" component-url="/_astro/PostCard.DalyEN7z.js" component-export="PostCard" renderer-url="/_astro/client.DLO1yDVm.js" props="{&quot;currentPage&quot;:[0,1],&quot;isFeaturedImageFirstPost&quot;:[0,true],&quot;post&quot;:[0,{&quot;id&quot;:[0,&quot;2dN6tdkhtvWTTgAgbfzaSX&quot;],&quot;title&quot;:[0,&quot;Cloudflare service outage June 12, 2025&quot;],&quot;slug&quot;:[0,&quot;cloudflare-service-outage-june-12-2025&quot;],&quot;excerpt&quot;:[0,&quot;Multiple Cloudflare services, including Workers KV, Access, WARP and the Cloudflare dashboard, experienced an outage for up to 2 hours and 28 minutes on June 12, 2025.&quot;],&quot;featured&quot;:[0,false],&quot;html&quot;:[0,&quot;&lt;p&gt;On June 12, 2025, Cloudflare suffered a significant service outage that affected a large set of our critical services, including Workers KV, WARP, Access, Gateway, Images, Stream, Workers AI, Turnstile and Challenges, AutoRAG, Zaraz, and parts of the Cloudflare Dashboard.&lt;/p&gt;&lt;p&gt;This outage lasted 2 hours and 28 minutes, and globally impacted all Cloudflare customers using the affected services. The cause of this outage was due to a failure in the underlying storage infrastructure used by our Workers KV service, which is a critical dependency for many Cloudflare products and relied upon for configuration, authentication and asset delivery across the affected services. Part of this infrastructure is backed by a third-party cloud provider, which experienced an outage today and directly impacted availability of our KV service.&lt;/p&gt;&lt;p&gt;We’re deeply sorry for this outage: this was a failure on our part, and while the proximate cause (or trigger) for this outage was a third-party vendor failure, we are ultimately responsible for our chosen dependencies and how we choose to architect around them.&lt;/p&gt;&lt;p&gt;This was not the result of an attack or other security event. No data was lost as a result of this incident. Cloudflare Magic Transit and Magic WAN, DNS, Cache, proxy, WAF and related services were not directly impacted by this incident.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;what-was-impacted\&quot;&gt;What was impacted?&lt;/h2&gt;\n            &lt;a href=\&quot;#what-was-impacted\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;As a rule, Cloudflare designs and builds our services on our own platform building blocks, and as such many of Cloudflare’s products are built to rely on the Workers KV service. &lt;/p&gt;&lt;p&gt;The following table details the impacted services, including the user-facing impact, operation failures, and increases in error rates observed:&lt;/p&gt;&lt;table&gt;&lt;tr&gt;&lt;th&gt;&lt;p&gt;&lt;b&gt;Product/Service&lt;/b&gt;&lt;/p&gt;&lt;/th&gt;&lt;th&gt;&lt;p&gt;&lt;b&gt;Impact&lt;/b&gt;&lt;/p&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Workers KV&lt;/b&gt;&lt;/p&gt;&lt;p&gt;\n\n&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Workers KV saw 90.22% of requests failing: any key-value pair not cached and that required to retrieve the value from Workers KV&amp;#39;s origin storage backends resulted in failed requests with response code 503 or 500. &lt;/p&gt;&lt;p&gt;The remaining requests were successfully served from Workers KV&amp;#39;s cache (status code 200 and 404) or returned errors within our expected limits and/or error budget.&lt;/p&gt;&lt;p&gt;This did not impact data stored in Workers KV.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Access&lt;/b&gt;&lt;/p&gt;&lt;p&gt;\n\n&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Access uses Workers KV to store application and policy configuration along with user identity information.&lt;/p&gt;&lt;p&gt;During the incident Access failed 100% of identity based logins for all application types including Self-Hosted, SaaS and Infrastructure. User Identity information was unavailable to other services like WARP and Gateway during this incident. Access is designed to fail closed when it cannot successfully fetch policy configuration or a user’s identity. &lt;/p&gt;&lt;p&gt;Active Infrastructure Application SSH sessions with command logging enabled failed to save logs due to a Workers KV dependency. &lt;/p&gt;&lt;p&gt;Access’ System for Cross Domain Identity (SCIM) service was also impacted due to its reliance on Workers KV and Durable Objects (which depended on KV) to store user information. During this incident, user identities were not updated due to Workers KV updates failures. These failures would result in a 500 returned to identity providers. Some providers may require a manual re-synchronization but most customers would have seen immediate service restoration once Access’ SCIM service was restored due to retry logic by the identity provider.&lt;/p&gt;&lt;p&gt;Service authentication based logins (e.g. service token, Mutual TLS, and IP-based policies) and Bypass policies were unaffected. No Access policy edits or changes were lost during this time.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Gateway&lt;/b&gt;&lt;/p&gt;&lt;p&gt;\n\n&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;This incident did not affect most Gateway DNS queries, including those over IPv4, IPv6, DNS over TLS (DoT), and DNS over HTTPS (DoH).&lt;/p&gt;&lt;p&gt;However, there were two exceptions:&lt;/p&gt;&lt;p&gt;DoH queries with identity-based rules failed. This happened because Gateway couldn&amp;#39;t retrieve the required user’s identity information.&lt;/p&gt;&lt;p&gt;Authenticated DoH was disrupted for some users. Users with active sessions with valid authentication tokens were unaffected, but those needing to start new sessions or refresh authentication tokens could not.&lt;/p&gt;&lt;p&gt;Users of Gateway proxy, egress, and TLS decryption were unable to connect, register, proxy, or log traffic.&lt;/p&gt;&lt;p&gt;This was due to our reliance on Workers KV to retrieve up-to-date identity and device posture information. Each of these actions requires a call to Workers KV, and when unavailable, Gateway is designed to fail closed to prevent traffic from bypassing customer-configured rules.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;WARP&lt;/b&gt;&lt;/p&gt;&lt;p&gt;\n\n\n&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;The WARP client was impacted due to core dependencies on Access and Workers KV, which is required for device registration and authentication. As a result, no new clients were able to connect or sign up during the incident.&lt;/p&gt;&lt;p&gt;Existing WARP client users sessions that were routed through the Gateway proxy experienced disruptions, as Gateway was unable to perform its required policy evaluations.&lt;/p&gt;&lt;p&gt;Additionally, the WARP emergency disconnect override was rendered unavailable because of a failure in its underlying dependency, Workers KV.&lt;/p&gt;&lt;p&gt;Consumer WARP saw a similar sporadic impact as the Zero Trust version.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Dashboard&lt;/b&gt;&lt;/p&gt;&lt;p&gt;\n\n&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Dashboard user logins and most of the existing dashboard sessions were unavailable. This was due to an outage affecting Turnstile, DO, KV, and Access. The specific causes for login failures were:&lt;/p&gt;&lt;p&gt;Standard Logins (User/Password): Failed due to Turnstile unavailability.&lt;/p&gt;&lt;p&gt;Sign-in with Google (OIDC) Logins: Failed due to a KV dependency issue.&lt;/p&gt;&lt;p&gt;SSO Logins: Failed due to a full dependency on Access.&lt;/p&gt;&lt;p&gt;The Cloudflare v4 API was not impacted during this incident.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Challenges and Turnstile&lt;/b&gt;&lt;/p&gt;&lt;p&gt;\n\n&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;The Challenge platform that powers Cloudflare Challenges and Turnstile saw a high rate of failure and timeout for siteverify API requests during the incident window due to its dependencies on Workers KV and Durable Objects.&lt;/p&gt;&lt;p&gt;We have kill switches in place to disable these calls in case of incidents and outages such as this. We activated these kill switches as a mitigation so that eyeballs are not blocked from proceeding. Notably, while these kill switches were active, Turnstile’s siteverify API (the API that validates issued tokens) could redeem valid tokens multiple times, potentially allowing for attacks where a bad actor might try to use a previously valid token to bypass. &lt;/p&gt;&lt;p&gt;There was no impact to Turnstile’s ability to detect bots. A bot attempting to solve a challenge would still have failed the challenge and thus, not receive a token. &lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Browser Isolation&lt;/b&gt;&lt;/p&gt;&lt;p&gt;\n\n&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Existing Browser Isolation sessions via Link-based isolation were impacted due to a reliance on Gateway for policy evaluation.&lt;/p&gt;&lt;p&gt;New link-based Browser Isolation sessions could not be initiated due to a dependency on Cloudflare Access. All Gateway-initiated isolation sessions failed due its Gateway dependency.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Images&lt;/b&gt;&lt;/p&gt;&lt;p&gt;\n\n&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Batch uploads to Cloudflare Images were impacted during the incident window, with a 100% failure rate at the peak of the incident. Other uploads were not impacted.&lt;/p&gt;&lt;p&gt;Overall image delivery dipped to around 97% success rate. Image Transformations were not significantly impacted, and Polish was not impacted.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Stream&lt;/b&gt;&lt;/p&gt;&lt;p&gt;\n\n&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Stream’s error rate exceeded 90% during the incident window as video playlists were unable to be served. Stream Live observed a 100% error rate.&lt;/p&gt;&lt;p&gt;Video uploads were not impacted.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Realtime&lt;/b&gt;&lt;/p&gt;&lt;p&gt;\n\n&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;The Realtime TURN (Traversal Using Relays around NAT) service uses KV and was heavily impacted. Error rates were near 100% for the duration of the incident window.&lt;/p&gt;&lt;p&gt;The Realtime SFU service (Selective Forwarding Unit) was unable to create new sessions, although existing connections were maintained. This caused a reduction to 20% of normal traffic during the impact window. &lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Workers AI&lt;/b&gt;&lt;/p&gt;&lt;p&gt;\n\n&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;All inference requests to Workers AI failed for the duration of the incident. Workers AI depends on Workers KV for distributing configuration and routing information for AI requests globally.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Pages &amp;amp; Workers Assets&lt;/b&gt;&lt;/p&gt;&lt;p&gt;\n\n&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Static assets served by Cloudflare Pages and Workers Assets (such as HTML, JavaScript, CSS, images, etc) are stored in Workers KV, cached, and retrieved at request time. Workers Assets saw an average error rate increase of around 0.06% of total requests during this time. &lt;/p&gt;&lt;p&gt;During the incident window, Pages error rate peaked to ~100% and all Pages builds could not complete. &lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;AutoRAG&lt;/b&gt;&lt;/p&gt;&lt;p&gt;\n\n&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;AutoRAG relies on Workers AI models for both document conversion and generating vector embeddings during indexing, as well as LLM models for querying and search. AutoRAG was unavailable during the incident window because of the Workers AI dependency.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Durable Objects&lt;/b&gt;&lt;/p&gt;&lt;p&gt;\n\n&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;SQLite-backed Durable Objects share the same underlying storage infrastructure as Workers KV. The average error rate during the incident window peaked at 22%, and dropped to 2% as services started to recover.&lt;/p&gt;&lt;p&gt;Durable Object namespaces using the legacy key-value storage were not impacted.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;D1&lt;/b&gt;&lt;/p&gt;&lt;p&gt;\n&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;D1 databases share the same underlying storage infrastructure as Workers KV and Durable Objects.&lt;/p&gt;&lt;p&gt;Similar to Durable Objects, the average error rate during the incident window peaked at 22%, and dropped to 2% as services started to recover.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Queues &amp;amp; Event Notifications&lt;/b&gt;&lt;/p&gt;&lt;p&gt;\n&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Queues message operations including–pushing and consuming–were unavailable during the incident window.&lt;/p&gt;&lt;p&gt;Queues uses KV to map each Queue to underlying Durable Objects that contain queued messages.&lt;/p&gt;&lt;p&gt;Event Notifications use Queues as their underlying delivery mechanism.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;AI Gateway&lt;/b&gt;&lt;/p&gt;&lt;p&gt;\n\n&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;AI Gateway is built on top of Workers and relies on Workers KV for client and internal configurations. During the incident window, AI Gateway saw error rates peak at 97% of requests until dependencies recovered.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;CDN&lt;/b&gt;&lt;/p&gt;&lt;p&gt;\n\n&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Automated traffic management infrastructure was operational but acted with reduced efficacy during the impact period. In particular, registration requests from Zero Trust clients increased substantially as a result of the outage.&lt;/p&gt;&lt;p&gt;The increase in requests imposed additional load in several Cloudflare locations, triggering response from automated traffic management. In response to these conditions, systems rerouted incoming CDN traffic to nearby locations, reducing impact to customers. There was a portion of traffic that was not rerouted as expected and is under investigation. CDN requests impacted by this issue would experience elevated latency, HTTP 499 errors, and / or HTTP 503 errors. Impacted Cloudflare service areas included São Paulo, Philadelphia, Atlanta, and Raleigh.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Workers / Workers for Platforms&lt;/b&gt;&lt;/p&gt;&lt;p&gt;\n\n&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Workers and Workers for Platforms rely on a third party service for uploads. During the incident window, Workers saw an overall error rate peak to ~2% of total requests. Workers for Platforms saw an overall error rate peak to ~10% of total requests during the same time period. &lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Workers Builds (CI/CD)\n &lt;/b&gt;&lt;/p&gt;&lt;p&gt;\n&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Starting at 18:03 UTC Workers builds could not receive new source code management push events due to Access being down.&lt;/p&gt;&lt;p&gt;100% of new Workers Builds failed during the incident window.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Browser Rendering&lt;/b&gt;&lt;/p&gt;&lt;p&gt;\n\n&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Browser Rendering depends on Browser Isolation for browser instance infrastructure.&lt;/p&gt;&lt;p&gt;Requests to both the REST API and via the Workers Browser Binding were 100% impacted during the incident window.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Zaraz&lt;/b&gt;&lt;/p&gt;&lt;p&gt;\n&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;100% of requests were impacted during the incident window. Zaraz relies on Workers KV configs for websites when handling eyeball traffic. Due to the same dependency, attempts to save updates to Zaraz configs were unsuccessful during this period, but our monitoring shows that only a single user was affected.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;background\&quot;&gt;Background&lt;/h2&gt;\n            &lt;a href=\&quot;#background\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;Workers KV is built as what we call a “coreless” service which means there should be no single point of failure as the service runs independently in each of our locations worldwide. However, Workers KV today relies on a central data store to provide a source of truth for data. A failure of that store caused a complete outage for cold reads and writes to the KV namespaces used by services across Cloudflare.&lt;/p&gt;&lt;p&gt;Workers KV is in the process of being transitioned to significantly more resilient infrastructure for its central store: regrettably, we had a gap in coverage which was exposed during this incident. Workers KV removed a storage provider as we worked to re-architect KV’s backend, including migrating it to Cloudflare R2, to prevent data consistency issues (caused by the original data syncing architecture), and to improve support for data residency requirements.&lt;/p&gt;&lt;p&gt;One of our principles is to build Cloudflare services on our own platform as much as possible, and Workers KV is no exception. Many of our internal and external services rely heavily on Workers KV, which under normal circumstances helps us deliver the most robust services possible, instead of service teams attempting to build their own storage services. In this case, the cascading impact from the failure from Workers KV exacerbated the issue and significantly broadened the blast radius. &lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;incident-timeline-and-impact\&quot;&gt;Incident timeline and impact&lt;/h2&gt;\n            &lt;a href=\&quot;#incident-timeline-and-impact\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;The incident timeline, including the initial impact, investigation, root cause, and remediation, are detailed below. &lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7CBPPVgr3GroJP2EcD3yvB/6073457ce6263e7e05f6eb3d796ddd48/BLOG-2847_2.png\&quot; alt=\&quot;BLOG-2847 2\&quot; class=\&quot;kg-image\&quot; width=\&quot;1686\&quot; height=\&quot;794\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;i&gt;&lt;sub&gt;Workers KV error rates to storage infrastructure. 91% of requests to KV failed during the incident window.&lt;/sub&gt;&lt;/i&gt;&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5sGFmSsNHD9yXwJ9Ea5jov/78349be4318cb738cdd72643e69f7bdb/BLOG-2847_1.png\&quot; alt=\&quot;BLOG-2847 1\&quot; class=\&quot;kg-image\&quot; width=\&quot;978\&quot; height=\&quot;501\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;i&gt;&lt;sub&gt;Cloudflare Access percentage of successful requests. Cloudflare Access relies directly on Workers KV and serves as a good proxy to measure Workers KV availability over time.&lt;/sub&gt;&lt;/i&gt;&lt;/p&gt;&lt;p&gt;All timestamps referenced are in Coordinated Universal Time (UTC).&lt;/p&gt;&lt;table&gt;&lt;tr&gt;&lt;th&gt;&lt;p&gt;&lt;b&gt;Time&lt;/b&gt;&lt;/p&gt;&lt;/th&gt;&lt;th&gt;&lt;p&gt;&lt;b&gt;Event&lt;/b&gt;&lt;/p&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;2025-06-12 17:52&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;INCIDENT START\n&lt;/b&gt;Cloudflare WARP team begins to see registrations of new devices fail and begin to investigate these failures and declares an incident.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;2025-06-12 18:05&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Cloudflare Access team received an alert due to a rapid increase in error rates.&lt;/p&gt;&lt;p&gt;Service Level Objectives for multiple services drop below targets and trigger alerts across those teams.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;2025-06-12 18:06&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Multiple service-specific incidents are combined into a single incident as we identify a shared cause (Workers KV unavailability). Incident priority upgraded to P1.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;2025-06-12 18:21&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Incident priority upgraded to P0 from P1 as severity of impact becomes clear.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;2025-06-12 18:43&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Cloudflare Access begins exploring options to remove Workers KV dependency by migrating to a different backing datastore with the Workers KV engineering team. This was proactive in the event the storage infrastructure continued to be down.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;2025-06-12 19:09&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Zero Trust Gateway began working to remove dependencies on Workers KV by gracefully degrading rules that referenced Identity or Device Posture state.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;2025-06-12 19:32&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Access and Device Posture force drop identity and device posture requests to shed load on Workers KV until third-party service comes back online.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;2025-06-12 19:45&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Cloudflare teams continue to work on a path to deploying a Workers KV release against an alternative backing datastore and having critical services write configuration data to that store.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;2025-06-12 20:23&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Services begin to recover as storage infrastructure begins to recover. We continue to see a non-negligible error rate and infrastructure rate limits due to the influx of services repopulating caches.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;2025-06-12 20:25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Access and Device Posture restore calling Workers KV as third-party service is restored.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;2025-06-12 20:28&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;IMPACT END \n&lt;/b&gt;Service Level Objectives return to pre-incident level. Cloudflare teams continue to monitor systems to ensure services do not degrade as dependent systems recover.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;\n&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;INCIDENT END\n&lt;/b&gt;Cloudflare team see all affected services return to normal function. Service level objective alerts are recovered.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;remediation-and-follow-up-steps\&quot;&gt;Remediation and follow-up steps&lt;/h2&gt;\n            &lt;a href=\&quot;#remediation-and-follow-up-steps\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;We’re taking immediate steps to improve the resiliency of services that depend on Workers KV and our storage infrastructure. This includes existing planned work that we are accelerating as a result of this incident.&lt;/p&gt;&lt;p&gt;This encompasses several workstreams, including efforts to avoid singular dependencies on storage infrastructure we do not own, improving the ability for us to recover critical services (including Access, Gateway and WARP) &lt;/p&gt;&lt;p&gt;Specifically:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;(Actively in-flight): Bringing forward our work to improve the redundancy within Workers KV’s storage infrastructure, removing the dependency on any single provider. During the incident window we began work to cut over and backfill critical KV namespaces to our own infrastructure, in the event the incident continued. &lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;(Actively in-flight): Short-term blast radius remediations for individual products that were impacted by this incident so that each product becomes resilient to any loss of service caused by any single point of failure, including third party dependencies.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;(Actively in-flight): Implementing tooling that allows us to progressively re-enable namespaces during storage infrastructure incidents. This will allow us to ensure that key dependencies, including Access and WARP, are able to come up without risking a denial-of-service against our own infrastructure as caches are repopulated.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This list is not exhaustive: our teams continue to revisit design decisions and assess the infrastructure changes we need to make in both the near (immediate) term and long term to mitigate the incidents like this going forward.&lt;/p&gt;&lt;p&gt;This was a serious outage, and we understand that organizations and institutions that are large and small depend on us to protect and/or run their websites, applications, zero trust and network infrastructure.  Again we are deeply sorry for the impact and are working diligently to improve our service resiliency. &lt;/p&gt;&quot;],&quot;published_at&quot;:[0,&quot;2025-06-12T14:00-08:00&quot;],&quot;updated_at&quot;:[0,&quot;2025-06-19T13:58:52.829Z&quot;],&quot;feature_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/CvsaXPEHDPXb5sf0jWB1a/4e152d7ff5e4ccaa8d9d4ee09636e539/image1.png&quot;],&quot;tags&quot;:[1,[[0,{&quot;id&quot;:[0,&quot;4yliZlpBPZpOwBDZzo1tTh&quot;],&quot;name&quot;:[0,&quot;Outage&quot;],&quot;slug&quot;:[0,&quot;outage&quot;]}],[0,{&quot;id&quot;:[0,&quot;3cCNoJJ5uusKFBLYKFX1jB&quot;],&quot;name&quot;:[0,&quot;Post Mortem&quot;],&quot;slug&quot;:[0,&quot;post-mortem&quot;]}]]],&quot;relatedTags&quot;:[0],&quot;authors&quot;:[1,[[0,{&quot;name&quot;:[0,&quot;Jeremy Hartman&quot;],&quot;slug&quot;:[0,&quot;jeremy-hartman&quot;],&quot;bio&quot;:[0,null],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1yTvNpd60qmjgY8fbItcDp/f964f6cd281c1693cee7b4a43a6e3845/jeremy-hartman.jpeg&quot;],&quot;location&quot;:[0,null],&quot;website&quot;:[0,null],&quot;twitter&quot;:[0,null],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}],[0,{&quot;name&quot;:[0,&quot;CJ Desai&quot;],&quot;slug&quot;:[0,&quot;cj-desai&quot;],&quot;bio&quot;:[0],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/38fnsyN8gdlupsCRxEBMar/1bfb2964eb7c9221efe9fa4af3c694cd/CJ_Desai__President_of_Product_and_Engineering__Cloudflare.JPG&quot;],&quot;location&quot;:[0],&quot;website&quot;:[0],&quot;twitter&quot;:[0],&quot;facebook&quot;:[0],&quot;publiclyIndex&quot;:[0,true]}]]],&quot;meta_description&quot;:[0,&quot;Multiple Cloudflare services, including Workers KV, Access, WARP and the Cloudflare dashboard, experienced an outage for up to 2 hours and 28 minutes on June 12, 2025.&quot;],&quot;primary_author&quot;:[0,{}],&quot;localeList&quot;:[0,{&quot;name&quot;:[0,&quot;LOC: Cloudflare service outage June 12, 2025&quot;],&quot;enUS&quot;:[0,&quot;English for Locale&quot;],&quot;zhCN&quot;:[0,&quot;Translated for Locale&quot;],&quot;zhHansCN&quot;:[0,&quot;No Page for Locale&quot;],&quot;zhTW&quot;:[0,&quot;Translated for Locale&quot;],&quot;frFR&quot;:[0,&quot;Translated for Locale&quot;],&quot;deDE&quot;:[0,&quot;Translated for Locale&quot;],&quot;itIT&quot;:[0,&quot;No Page for Locale&quot;],&quot;jaJP&quot;:[0,&quot;Translated for Locale&quot;],&quot;koKR&quot;:[0,&quot;Translated for Locale&quot;],&quot;ptBR&quot;:[0,&quot;No Page for Locale&quot;],&quot;esLA&quot;:[0,&quot;No Page for Locale&quot;],&quot;esES&quot;:[0,&quot;Translated for Locale&quot;],&quot;enAU&quot;:[0,&quot;No Page for Locale&quot;],&quot;enCA&quot;:[0,&quot;No Page for Locale&quot;],&quot;enIN&quot;:[0,&quot;No Page for Locale&quot;],&quot;enGB&quot;:[0,&quot;No Page for Locale&quot;],&quot;idID&quot;:[0,&quot;No Page for Locale&quot;],&quot;ruRU&quot;:[0,&quot;No Page for Locale&quot;],&quot;svSE&quot;:[0,&quot;No Page for Locale&quot;],&quot;viVN&quot;:[0,&quot;No Page for Locale&quot;],&quot;plPL&quot;:[0,&quot;No Page for Locale&quot;],&quot;arAR&quot;:[0,&quot;No Page for Locale&quot;],&quot;nlNL&quot;:[0,&quot;Translated for Locale&quot;],&quot;thTH&quot;:[0,&quot;English for Locale&quot;],&quot;trTR&quot;:[0,&quot;English for Locale&quot;],&quot;heIL&quot;:[0,&quot;English for Locale&quot;],&quot;lvLV&quot;:[0,&quot;English for Locale&quot;],&quot;etEE&quot;:[0,&quot;English for Locale&quot;],&quot;ltLT&quot;:[0,&quot;English for Locale&quot;]}],&quot;url&quot;:[0,&quot;https://blog.cloudflare.com/cloudflare-service-outage-june-12-2025&quot;],&quot;metadata&quot;:[0,{&quot;title&quot;:[0,&quot;Cloudflare service outage June 12, 2025&quot;],&quot;description&quot;:[0,&quot;Today, June 12, 2025, Cloudflare suffered a significant service outage that affected a large set of our critical services, including Workers KV, WARP, Access, Gateway, Images, Stream, Workers AI, Turnstile and Challenges, AutoRAG, and parts of the Cloudflare Dashboard.&quot;],&quot;imgPreview&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1PPINmVPRc1emQMpc5JIXe/1bf284f6d9c8ccb36bb40b7cffb1cab3/Cloudflare_service_outage_June_12__2025-OG.png&quot;]}],&quot;publicly_index&quot;:[0,true]}],&quot;translations&quot;:[0,{&quot;posts.by&quot;:[0,&quot;By&quot;],&quot;footer.gdpr&quot;:[0,&quot;GDPR&quot;],&quot;lang_blurb1&quot;:[0,&quot;This post is also available in {lang1}.&quot;],&quot;lang_blurb2&quot;:[0,&quot;This post is also available in {lang1} and {lang2}.&quot;],&quot;lang_blurb3&quot;:[0,&quot;This post is also available in {lang1}, {lang2} and {lang3}.&quot;],&quot;footer.press&quot;:[0,&quot;Press&quot;],&quot;header.title&quot;:[0,&quot;The Cloudflare Blog&quot;],&quot;search.clear&quot;:[0,&quot;Clear&quot;],&quot;search.filter&quot;:[0,&quot;Filter&quot;],&quot;search.source&quot;:[0,&quot;Source&quot;],&quot;footer.careers&quot;:[0,&quot;Careers&quot;],&quot;footer.company&quot;:[0,&quot;Company&quot;],&quot;footer.support&quot;:[0,&quot;Support&quot;],&quot;footer.the_net&quot;:[0,&quot;theNet&quot;],&quot;search.filters&quot;:[0,&quot;Filters&quot;],&quot;footer.our_team&quot;:[0,&quot;Our team&quot;],&quot;footer.webinars&quot;:[0,&quot;Webinars&quot;],&quot;page.more_posts&quot;:[0,&quot;More posts&quot;],&quot;posts.time_read&quot;:[0,&quot;{time} min read&quot;],&quot;search.language&quot;:[0,&quot;Language&quot;],&quot;footer.community&quot;:[0,&quot;Community&quot;],&quot;footer.resources&quot;:[0,&quot;Resources&quot;],&quot;footer.solutions&quot;:[0,&quot;Solutions&quot;],&quot;footer.trademark&quot;:[0,&quot;Trademark&quot;],&quot;header.subscribe&quot;:[0,&quot;Subscribe&quot;],&quot;footer.compliance&quot;:[0,&quot;Compliance&quot;],&quot;footer.free_plans&quot;:[0,&quot;Free plans&quot;],&quot;footer.impact_ESG&quot;:[0,&quot;Impact/ESG&quot;],&quot;posts.follow_on_X&quot;:[0,&quot;Follow on X&quot;],&quot;footer.help_center&quot;:[0,&quot;Help center&quot;],&quot;footer.network_map&quot;:[0,&quot;Network Map&quot;],&quot;header.please_wait&quot;:[0,&quot;Please Wait&quot;],&quot;page.related_posts&quot;:[0,&quot;Related posts&quot;],&quot;search.result_stat&quot;:[0,&quot;Results &lt;strong&gt;{search_range}&lt;/strong&gt; of &lt;strong&gt;{search_total}&lt;/strong&gt; for &lt;strong&gt;{search_keyword}&lt;/strong&gt;&quot;],&quot;footer.case_studies&quot;:[0,&quot;Case Studies&quot;],&quot;footer.connect_2024&quot;:[0,&quot;Connect 2024&quot;],&quot;footer.terms_of_use&quot;:[0,&quot;Terms of Use&quot;],&quot;footer.white_papers&quot;:[0,&quot;White Papers&quot;],&quot;footer.cloudflare_tv&quot;:[0,&quot;Cloudflare TV&quot;],&quot;footer.community_hub&quot;:[0,&quot;Community Hub&quot;],&quot;footer.compare_plans&quot;:[0,&quot;Compare plans&quot;],&quot;footer.contact_sales&quot;:[0,&quot;Contact Sales&quot;],&quot;header.contact_sales&quot;:[0,&quot;Contact Sales&quot;],&quot;header.email_address&quot;:[0,&quot;Email Address&quot;],&quot;page.error.not_found&quot;:[0,&quot;Page not found&quot;],&quot;footer.developer_docs&quot;:[0,&quot;Developer docs&quot;],&quot;footer.privacy_policy&quot;:[0,&quot;Privacy Policy&quot;],&quot;footer.request_a_demo&quot;:[0,&quot;Request a demo&quot;],&quot;page.continue_reading&quot;:[0,&quot;Continue reading&quot;],&quot;footer.analysts_report&quot;:[0,&quot;Analyst reports&quot;],&quot;footer.for_enterprises&quot;:[0,&quot;For enterprises&quot;],&quot;footer.getting_started&quot;:[0,&quot;Getting Started&quot;],&quot;footer.learning_center&quot;:[0,&quot;Learning Center&quot;],&quot;footer.project_galileo&quot;:[0,&quot;Project Galileo&quot;],&quot;pagination.newer_posts&quot;:[0,&quot;Newer Posts&quot;],&quot;pagination.older_posts&quot;:[0,&quot;Older Posts&quot;],&quot;posts.social_buttons.x&quot;:[0,&quot;Discuss on X&quot;],&quot;search.icon_aria_label&quot;:[0,&quot;Search&quot;],&quot;search.source_location&quot;:[0,&quot;Source/Location&quot;],&quot;footer.about_cloudflare&quot;:[0,&quot;About Cloudflare&quot;],&quot;footer.athenian_project&quot;:[0,&quot;Athenian Project&quot;],&quot;footer.become_a_partner&quot;:[0,&quot;Become a partner&quot;],&quot;footer.cloudflare_radar&quot;:[0,&quot;Cloudflare Radar&quot;],&quot;footer.network_services&quot;:[0,&quot;Network services&quot;],&quot;footer.trust_and_safety&quot;:[0,&quot;Trust &amp; Safety&quot;],&quot;header.get_started_free&quot;:[0,&quot;Get Started Free&quot;],&quot;page.search.placeholder&quot;:[0,&quot;Search Cloudflare&quot;],&quot;footer.cloudflare_status&quot;:[0,&quot;Cloudflare Status&quot;],&quot;footer.cookie_preference&quot;:[0,&quot;Cookie Preferences&quot;],&quot;header.valid_email_error&quot;:[0,&quot;Must be valid email.&quot;],&quot;search.result_stat_empty&quot;:[0,&quot;Results &lt;strong&gt;{search_range}&lt;/strong&gt; of &lt;strong&gt;{search_total}&lt;/strong&gt;&quot;],&quot;footer.connectivity_cloud&quot;:[0,&quot;Connectivity cloud&quot;],&quot;footer.developer_services&quot;:[0,&quot;Developer services&quot;],&quot;footer.investor_relations&quot;:[0,&quot;Investor relations&quot;],&quot;page.not_found.error_code&quot;:[0,&quot;Error Code: 404&quot;],&quot;search.autocomplete_title&quot;:[0,&quot;Insert a query. Press enter to send&quot;],&quot;footer.logos_and_press_kit&quot;:[0,&quot;Logos &amp; press kit&quot;],&quot;footer.application_services&quot;:[0,&quot;Application services&quot;],&quot;footer.get_a_recommendation&quot;:[0,&quot;Get a recommendation&quot;],&quot;posts.social_buttons.reddit&quot;:[0,&quot;Discuss on Reddit&quot;],&quot;footer.sse_and_sase_services&quot;:[0,&quot;SSE and SASE services&quot;],&quot;page.not_found.outdated_link&quot;:[0,&quot;You may have used an outdated link, or you may have typed the address incorrectly.&quot;],&quot;footer.report_security_issues&quot;:[0,&quot;Report Security Issues&quot;],&quot;page.error.error_message_page&quot;:[0,&quot;Sorry, we can&#39;t find the page you are looking for.&quot;],&quot;header.subscribe_notifications&quot;:[0,&quot;Subscribe to receive notifications of new posts:&quot;],&quot;footer.cloudflare_for_campaigns&quot;:[0,&quot;Cloudflare for Campaigns&quot;],&quot;header.subscription_confimation&quot;:[0,&quot;Subscription confirmed. Thank you for subscribing!&quot;],&quot;posts.social_buttons.hackernews&quot;:[0,&quot;Discuss on Hacker News&quot;],&quot;footer.diversity_equity_inclusion&quot;:[0,&quot;Diversity, equity &amp; inclusion&quot;],&quot;footer.critical_infrastructure_defense_project&quot;:[0,&quot;Critical Infrastructure Defense Project&quot;]}]}" ssr client="load" opts="{&quot;name&quot;:&quot;PostCard&quot;,&quot;value&quot;:true}" await-children><article class="w-100 featured-post  flex flex-row flex-wrap mb4 items-center bb b--gray8 bn-l  mt4 mt2-l mb4 ph3 bb b--gray8 bn-l"><div class="w-50-l"><a href="/cloudflare-service-outage-june-12-2025/" class="fw5 no-underline gray1" data-testid="post-title"><h2 class="fw5 mt2">Cloudflare service outage June 12, 2025</h2></a><p class="f3 fw5 gray5 my" data-testid="post-date">2025-06-12</p><p class="f4 fw3 lh-copy " data-testid="post-content">Multiple Cloudflare services, including Workers KV, Access, WARP and the Cloudflare dashboard, experienced an outage for up to 2 hours and 28 minutes on June 12, 2025.<!-- -->...</p><a href="/cloudflare-service-outage-june-12-2025/" class="no-underline gray1 f4 lh-copy fw3 underline-hover" data-testid="post-continue-reading">Continue reading »</a><ul class="author-lists flex pl0"><li class="list flex items-center pr2 mb3"><a href="/author/jeremy-hartman/" class="static-avatar pr1"><img class="author-profile-image br-100 mr2" src="https://blog.cloudflare.com/cdn-cgi/image/format=auto,dpr=3,width=64,height=64,gravity=face,fit=crop,zoom=0.5/https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1yTvNpd60qmjgY8fbItcDp/f964f6cd281c1693cee7b4a43a6e3845/jeremy-hartman.jpeg" alt="Jeremy Hartman" width="62" height="62"/></a><div class="author-name-tooltip"><a href="/author/jeremy-hartman/" class="fw5 f4 no-underline black">Jeremy Hartman</a></div></li><li class="list flex items-center pr2 mb3"><a href="/author/cj-desai/" class="static-avatar pr1"><img class="author-profile-image br-100 mr2" src="https://blog.cloudflare.com/cdn-cgi/image/format=auto,dpr=3,width=64,height=64,gravity=face,fit=crop,zoom=0.5/https://cf-assets.www.cloudflare.com/zkvhlag99gkb/38fnsyN8gdlupsCRxEBMar/1bfb2964eb7c9221efe9fa4af3c694cd/CJ_Desai__President_of_Product_and_Engineering__Cloudflare.JPG" alt="CJ Desai" width="62" height="62"/></a><div class="author-name-tooltip"><a href="/author/cj-desai/" class="fw5 f4 no-underline black">CJ Desai</a></div></li></ul></div><div class="w-50-l"><img class="dn di-l " src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/CvsaXPEHDPXb5sf0jWB1a/4e152d7ff5e4ccaa8d9d4ee09636e539/image1.png" alt="Cloudflare service outage June 12, 2025"/></div></article><!--astro:end--></astro-island><astro-island uid="19ygB" prefix="r1" component-url="/_astro/PostCard.DalyEN7z.js" component-export="PostCard" renderer-url="/_astro/client.DLO1yDVm.js" props="{&quot;currentPage&quot;:[0,1],&quot;isFeaturedImageFirstPost&quot;:[0,false],&quot;post&quot;:[0,{&quot;id&quot;:[0,&quot;3Zqv5LUUJauYsk7Dn0BIye&quot;],&quot;title&quot;:[0,&quot;How the April 28, 2025, power outage in Portugal and Spain impacted Internet traffic and connectivity&quot;],&quot;slug&quot;:[0,&quot;how-power-outage-in-portugal-spain-impacted-internet&quot;],&quot;excerpt&quot;:[0,&quot;A massive power outage struck significant portions of Portugal and Spain at 10:34 UTC on April 28, disrupting everyday activities and services.&quot;],&quot;featured&quot;:[0,false],&quot;html&quot;:[0,&quot;&lt;p&gt;A massive &lt;a href=\&quot;https://www.reuters.com/world/europe/large-parts-spain-portugal-hit-by-power-outage-2025-04-28/\&quot;&gt;&lt;u&gt;power outage struck significant portions of Portugal and Spain&lt;/u&gt;&lt;/a&gt; at 10:34 UTC on April 28, grinding transportation to a halt, shutting retail businesses, and otherwise disrupting everyday activities and services. Parts of France were also reportedly impacted by the power outage. Portugal’s electrical grid operator &lt;a href=\&quot;https://www.bbc.com/news/live/c9wpq8xrvd9t?post=asset%3Aa1493644-407b-44c0-aef9-c6f64d7fad0e#post\&quot;&gt;&lt;u&gt;blamed&lt;/u&gt;&lt;/a&gt; the outage on a &amp;quot;&lt;i&gt;fault in the Spanish electricity grid&lt;/i&gt;”, and &lt;a href=\&quot;https://www.bbc.com/news/live/c9wpq8xrvd9t?post=asset%3Addda9592-0346-4fe8-a17a-2261efc1ba5b#post\&quot;&gt;&lt;u&gt;later stated&lt;/u&gt;&lt;/a&gt; that &amp;quot;&lt;i&gt;due to extreme temperature variations in the interior of Spain, there were anomalous oscillations in the very high voltage lines (400 kilovolts), a phenomenon known as &amp;#39;induced atmospheric vibration&amp;#39;&lt;/i&gt;&amp;quot; and that &amp;quot;&lt;i&gt;These oscillations caused synchronisation failures between the electrical systems, leading to successive disturbances across the interconnected European network&lt;/i&gt;.&amp;quot; However, the operator later &lt;a href=\&quot;https://sicnoticias.pt/pais/2025-04-28-e-falso-que-fenomeno-atmosferico-raro-tenha-estado-na-origem-do-apagao-1a078544\&quot;&gt;&lt;u&gt;denied&lt;/u&gt;&lt;/a&gt; these claims. &lt;/p&gt;&lt;p&gt;The breadth of Cloudflare’s network and our customer base provides us with a unique perspective on Internet resilience, enabling us to observe the Internet impact of this power outage at both a local and national level, as well as at a network level, across traffic, network quality, and routing metrics.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;impacts-in-portugal\&quot;&gt;Impacts in Portugal&lt;/h2&gt;\n            &lt;a href=\&quot;#impacts-in-portugal\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          \n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;country-level\&quot;&gt;Country level&lt;/h3&gt;\n            &lt;a href=\&quot;#country-level\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;In Portugal, Internet traffic dropped as the power grid failed, with traffic immediately dropping by half as compared to the previous week, falling to approximately 90% below the previous week within the next five hours.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/21ezFb3KrFDR36Gn66twwd/99ed60e71501eccf948e7e1d2c0eb3a3/BLOG-2817_2.png\&quot; alt=\&quot;BLOG-2817 2\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;Request traffic from users in Portugal to Cloudflare’s &lt;a href=\&quot;https://1.1.1.1/dns\&quot;&gt;&lt;u&gt;1.1.1.1 DNS resolver&lt;/u&gt;&lt;/a&gt; also fell when the power went out, initially dropping by 40% as compared to the previous week, and falling further over the next several hours. &lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/GgzpC2ll27P1cfv0dQlFw/69dfabcfddd2dcb4db5f00885b12c67f/BLOG-2817_3.png\&quot; alt=\&quot;BLOG-2817 3\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;network-level\&quot;&gt;Network level&lt;/h3&gt;\n            &lt;a href=\&quot;#network-level\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;At a network level, the loss of Internet traffic from local providers including NOS, Vodafone, MEO, and NOWO was swift and significant. The Cloudflare Radar graphs below show that traffic from those networks effectively evaporated over the hours after the power outage began. The &lt;a href=\&quot;https://www.cloudflare.com/learning/network-layer/what-is-an-autonomous-system/\&quot;&gt;&lt;u&gt;autonomous systems (ASNs)&lt;/u&gt;&lt;/a&gt; shown below for these providers may carry a mix of fixed and mobile broadband traffic. However, MEO breaks out at least some of their mobile traffic onto a separate ASN, and the graph below for MEO-MOVEL (AS42863) shows that request traffic from that network more than doubled after the power went out, as subscribers turned to their mobile devices for information about what was happening. However, despite the initial spike, this mobile traffic also fell over the next several hours, dropping to approximately half of the volume seen the prior week.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4fys8MdtL3ImmHS6b25x0i/b1ccbd24818e4ec93170ae9f699c9727/BLOG-2817_4.png\&quot; alt=\&quot;BLOG-2817 4\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5LCdCDX9XoOHMgdVRzyjD0/1e276a9bb6eae716ee22059d88517615/BLOG-2817_5.png\&quot; alt=\&quot;BLOG-2817 5\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4fxFCuhYkBHXSDDizyj6AX/87d9e5f6e9e610cff365d3f5be8c75cb/BLOG-2817_6.png\&quot; alt=\&quot;BLOG-2817 6\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5RfJ5HwTx3AqMKJ6c5FaaI/f595795b57dfb1b54fb6013ccca532fc/BLOG-2817_7.png\&quot; alt=\&quot;BLOG-2817 7\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7kYztdmWgq6n8lZgokElhh/a34f81d3dce5c259ee43b567ebbb8e9a/BLOG-2817_8.png\&quot; alt=\&quot;BLOG-2817 8\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;regional-level\&quot;&gt;Regional level&lt;/h3&gt;\n            &lt;a href=\&quot;#regional-level\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;In addition to looking at traffic at a national and network level, we can also look at traffic at a regional level. As noted above, the power outage did not impact every region of the country. The traffic graphs below show the changes in Internet traffic from the parts of Portugal where an impact was observed.&lt;/p&gt;&lt;p&gt;In Lisbon and Porto, a sharp, but limited drop in traffic was observed as the power outage began, with traffic recovering slightly almost as quickly. However, traffic gradually declined in the subsequent hours, in contrast to the other regions reviewed below.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/78BxDMSIsfvNyoPUczJ1Cv/aa4cf6cd71684726fc891c63dcb5108f/BLOG-2817_9.png\&quot; alt=\&quot;BLOG-2817 9\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/23KJh2ptN7NynAACvmFH9L/d71dc49bcd20ede70847592fb0d55b72/BLOG-2817_10.png\&quot; alt=\&quot;BLOG-2817 10\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;The most significant immediate traffic drops were observed in Aveiro, Beja, Bragança, Castelo Branco, Évora, Faro, Guarda, Portalegre, Santarém, Viana do Castelo, Vila Real, and Viseu. In these areas, traffic fell and then quickly stabilized at very low volumes. In Braga and Setúbal, traffic declined more gradually after the initial drop.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4tF73OLez4RM8I7x2I9ST0/06751ebb8bfdc22bc243939881eb2d16/BLOG-2817_11.png\&quot; alt=\&quot;BLOG-2817 11\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7fYFHRgvyG8jlSZtIQ55St/1b3656d6212c1dd0a1e8ee6be5863f26/BLOG-2817_12.png\&quot; alt=\&quot;BLOG-2817 12\&quot; class=\&quot;kg-image\&quot; width=\&quot;1651\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/JKrwsr5k82cDreQluW336/61cc1d1b278a42995e71f98a02924d8c/BLOG-2817_13.png\&quot; alt=\&quot;BLOG-2817 13\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5q736FpU8TFEFZzNMl3ahB/b4f0105be84f00a9dc28d63ffb820124/BLOG-2817_14.png\&quot; alt=\&quot;BLOG-2817 14\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/717jnbhzFFBGxC8oKQzbWc/44ca9f1d5ca08104434f651750825bc9/BLOG-2817_15.png\&quot; alt=\&quot;BLOG-2817 15\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7sghSM0J7Hx793fpzBNhBa/8e105feb10216547aa6fc4c829c5c95f/BLOG-2817_16.png\&quot; alt=\&quot;BLOG-2817 16\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5TRbyRB0hrjClK3S74Z6U1/71dc72b9b2bff67fd58fa43d5566aefb/BLOG-2817_17.png\&quot; alt=\&quot;BLOG-2817 17\&quot; class=\&quot;kg-image\&quot; width=\&quot;1651\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2IEvNIigmrvmQ0qELWpLgO/63388e385162c421bb5ddf225993d300/BLOG-2817_18.png\&quot; alt=\&quot;BLOG-2817 18\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2KWHQhpaMdU8EZUAjvJyZn/8de4ec173e79971e06cdbbc931e3f149/BLOG-2817_19.png\&quot; alt=\&quot;BLOG-2817 19\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5NCILxkS2oymGlRpKcoiG6/89977e5bc093ce81311585f397fff97e/BLOG-2817_20.png\&quot; alt=\&quot;BLOG-2817 20\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5s16pM0WdaX2bwDZuMuxda/af239a2a28abfeb5ce7da93c1094dd8c/BLOG-2817_21.png\&quot; alt=\&quot;BLOG-2817 21\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1jkQrdlsCsGr4qyXX8EN42/7d90bbc1afcf138094a0f87d88b342e7/BLOG-2817_22.png\&quot; alt=\&quot;BLOG-2817 22\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/xnoq8NQjx0nMruchenCRW/4a0a29367a0a4903a7623a9c3db72031/BLOG-2817_23.png\&quot; alt=\&quot;BLOG-2817 23\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1sN1UZ4YYy7ZuOOy98KyIw/7c837a3034144937b8b9f3d43e0d7ffa/BLOG-2817_24.png\&quot; alt=\&quot;BLOG-2817 24\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;network-quality\&quot;&gt;Network quality&lt;/h3&gt;\n            &lt;a href=\&quot;#network-quality\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;The power outage also impacted the quality of connectivity at a national level in Portugal. Prior to the loss of power, median download speeds across the country were around 40 Mbps, but within several hours after the state of the outage, fell as low as 15 Mbps. As expected, latency at a country level saw an opposite impact. Prior to the loss of power, median latency was around 20 ms. However, it gradually grew to as much as 50 ms. The lower download speeds and higher latency are likely due to the congestion of the network links that remained available.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5IZu3b640cB11ZjnqQGcFh/886c356c4d8124be7f8b2ce01c9582cc/BLOG-2817_25.png\&quot; alt=\&quot;BLOG-2817 25\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2nq7wmaWEZOgusVYw9v1it/8685d5ad7a343f22b94e09c72a34a0d5/BLOG-2817_26.png\&quot; alt=\&quot;BLOG-2817 26\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;routing\&quot;&gt;Routing&lt;/h3&gt;\n            &lt;a href=\&quot;#routing\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Network infrastructure in Portugal was also impacted by the power outage, with the impact seen as a drop in announced IP address space. (This means that portions of Portuguese providers’ networks are no longer visible to the rest of the Internet.) The number of announced IPv4 /24s (blocks of 256 IPv4 addresses) dropped by ~300 (around 1.2%), and the number of announced IPv6 /48s (blocks of over 1.2 octillion IPv6 addresses) dropped from 17,928,551 to 16,355,607 (around 9%). Address space began to drop further after 16:00 UTC, possibly as a result of backup power being exhausted and associated network infrastructure falling offline.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/ZaC5NQzz6dzDzo5ywePst/417192abd6fc942ff85d06e247f7de66/BLOG-2817_27.png\&quot; alt=\&quot;BLOG-2817 27\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/asO2sxhD9Adue3q0FiBJv/40b8159855bd3c2156df49360adf898b/BLOG-2817_28.png\&quot; alt=\&quot;BLOG-2817 28\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;impacts-in-spain\&quot;&gt;Impacts in Spain&lt;/h2&gt;\n            &lt;a href=\&quot;#impacts-in-spain\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          \n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;country-level\&quot;&gt;Country level&lt;/h3&gt;\n            &lt;a href=\&quot;#country-level\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;In Spain, Internet traffic dropped as the power grid failed, with traffic immediately dropping by around 60% as compared to the previous week, falling to approximately 80% below the previous week within the next five hours.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4NWiuqfI5Z3MI5Q8fTXJM/df6438db91848c3faff11aaae43a7328/BLOG-2817_29.png\&quot; alt=\&quot;BLOG-2817 29\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;Request traffic from users in Spain to Cloudflare’s &lt;a href=\&quot;https://1.1.1.1/dns\&quot;&gt;&lt;u&gt;1.1.1.1 DNS resolver&lt;/u&gt;&lt;/a&gt; also fell when the power went out, initially dropping by 54% as compared to the previous week, but quickly stabilizing. &lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1F1N4JwFD2543isQ7laC6k/cf7ad7cce146ed18fd84ad9a32872e6e/BLOG-2817_30.png\&quot; alt=\&quot;BLOG-2817 30\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;network-level\&quot;&gt;Network level&lt;/h3&gt;\n            &lt;a href=\&quot;#network-level\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;At a network level, traffic volumes from the &lt;a href=\&quot;https://radar.cloudflare.com/traffic/es?dateRange=1d#autonomous-systems\&quot;&gt;&lt;u&gt;top five ASNs in Spain&lt;/u&gt;&lt;/a&gt; fell rapidly once power was lost, with most declining gradually over the next several hours. In contrast, traffic from Digi Spain Telecom (AS57269) fell quickly, but then stabilized at the lower level. In comparison to the previous week, traffic from these providers fell between 75% and 93% in the hours after the power outage began.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4oFLKubgeo2NsffE9tGx2f/89af580571c94e14703b218feadb058b/BLOG-2817_31.png\&quot; alt=\&quot;BLOG-2817 31\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/YTkS67VGnW9ACB3t58kBF/672f7e3e7d990bc7f33aa9a5155e133f/BLOG-2817_32.png\&quot; alt=\&quot;BLOG-2817 32\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/56sGr0XxMAifw2ZqYnvSWU/07f168a415a2f0801bb2aebb1a7b45f9/BLOG-2817_33.png\&quot; alt=\&quot;BLOG-2817 33\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5CpRU7YzB4LnTJppDnN2DZ/e479899ec5d6a0034c38361abf311d2f/BLOG-2817_34.png\&quot; alt=\&quot;BLOG-2817 34\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/qYPxLDJQM2bfv0LTrY547/694f327f221bbc094580dbea731527d1/BLOG-2817_35.png\&quot; alt=\&quot;BLOG-2817 35\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;regional-level\&quot;&gt;Regional level&lt;/h3&gt;\n            &lt;a href=\&quot;#regional-level\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;In most of the impacted regions in Spain, traffic dropped off quickly and stabilized, or continued to fall further. However, some recovery in traffic is also evident, and can be seen in Navarre, La Rioja, Cantabria, and Basque Country. This traffic recovery is likely associated with an initial restoration of power in those regions, as an &lt;a href=\&quot;https://www.ree.es/es/sala-de-prensa/actualidad/nota-de-prensa/2025/04/proceso-de-recuperacion-de-la-tension-en-el-sistema-electrico-peninsular\&quot;&gt;&lt;u&gt;update&lt;/u&gt;&lt;/a&gt; from &lt;a href=\&quot;https://www.redeia.com/en/about-us/our-brand\&quot;&gt;&lt;u&gt;Red Eléctrica&lt;/u&gt;&lt;/a&gt; (operator of Spain’s national electricity grid) noted that “&lt;i&gt;Electricity is now available in parts of Catalonia, Aragon, the Basque Country, Galicia, Asturias, Navarre, Castile and León, Extremadura, Andalusia, and La Rioja.&lt;/i&gt;”&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6ziGXO8PBjWNAwhiYNa8hT/9af98f7fad1b22f482445d90314a524e/BLOG-2817_36.png\&quot; alt=\&quot;BLOG-2817 36\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/17WcnWkXfG1BlxBCUwp5fW/1688269ff5dd6dbad06c09278e9ccd8d/BLOG-2817_37.png\&quot; alt=\&quot;BLOG-2817 37\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5ho5Cc18AYxd8G54mtmfcH/739731e105a9236a00a6531a1a61c10f/BLOG-2817_38.png\&quot; alt=\&quot;BLOG-2817 38\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1K4A82RT9L0tCXUBEVjZOw/a0798877806ac2c071cf82e71101a558/BLOG-2817_39.png\&quot; alt=\&quot;BLOG-2817 39\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6zFHmbct6zR2155GbfyM0F/af7f5aad5076bafc373127f7e5da82be/BLOG-2817_40.png\&quot; alt=\&quot;BLOG-2817 40\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2FBbLHYIziEcd0qJJM02s1/404bcca11c826a758d174ce4ff94a638/BLOG-2817_41.png\&quot; alt=\&quot;BLOG-2817 41\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/349JW0IsbTDKRALrlQd91P/97b397344d72d3e6322a572e9c562ee2/BLOG-2817_42.png\&quot; alt=\&quot;BLOG-2817 42\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5BNKpHFhRfNOlv1smU5BXr/9cda4655d68648c216f741cb200f0c51/BLOG-2817_43.png\&quot; alt=\&quot;BLOG-2817 43\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2g9WMm6XRkUvJxpW8pE0QJ/214f04aa2f8caa307e5f422db7a85dd3/BLOG-2817_44.png\&quot; alt=\&quot;BLOG-2817 44\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/TeXN8cdr56fUFyNnbBtXo/f5ec765241d0b4af2f15eab70b65aa5c/BLOG-2817_45.png\&quot; alt=\&quot;BLOG-2817 45\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2h2R1k3eabXg7qB0XvfP0t/637dd2050cbc0e25b6ae441fe79bb14c/BLOG-2817_46.png\&quot; alt=\&quot;BLOG-2817 46\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/37gqrGzlp0dIFinCinmAYk/6ed9f0b5c5d73490bbc539e577125df2/BLOG-2817_47.png\&quot; alt=\&quot;BLOG-2817 47\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4Cr2Otys8KDJA0amR3PpUj/f51a2f1ffdbb50ce4f3ca7501352fc5d/BLOG-2817_48.png\&quot; alt=\&quot;BLOG-2817 48\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1K415209i5YGlJmcMuoRMr/1b5285b4872b1dc904ddb0f3a0417704/BLOG-2817_49.png\&quot; alt=\&quot;BLOG-2817 49\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/AGjopp98UyZh52X5Jf1F9/df72d3f181012e07bb566aec3ab01ca6/BLOG-2817_50.png\&quot; alt=\&quot;BLOG-2817 50\&quot; class=\&quot;kg-image\&quot; width=\&quot;1650\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;network-quality\&quot;&gt;Network quality&lt;/h3&gt;\n            &lt;a href=\&quot;#network-quality\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;The power outage also impacted the quality of connectivity at a national level in Spain. Prior to the loss of power, median download speeds across the country were around 35 Mbps, but within several hours after the state of the outage, fell as low as 19 Mbps. Interestingly, the median bandwidth didn’t see the clean gradual decline as it did in Portugal, instead falling and recovering twice before gradually declining.&lt;/p&gt;&lt;p&gt;As expected, latency at a country level saw a significant increase. Prior to the loss of power, median latency was around 22 ms, but grew to as much as 40 ms. As in Portugal, the lower download speeds and higher latency are likely due to the congestion of the network links that remained available.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6SvaDFDPdleRDctpTezUIf/65834285ceb6d7dedc76c97095871859/BLOG-2817_51.png\&quot; alt=\&quot;BLOG-2817 51\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6BxQUuqVQdIHxro6XDAzUC/83e6001ffaa1492079cf54f25c36785c/BLOG-2817_52.png\&quot; alt=\&quot;BLOG-2817 52\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;routing\&quot;&gt;Routing&lt;/h3&gt;\n            &lt;a href=\&quot;#routing\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Similar to Portugal, network infrastructure in Spain was also impacted by the power outage, with the impact seen as a drop in announced IP address space. By 14:30 UTC, the number of announced IPv4 /24 address blocks had fallen by around 2.4%, and continued to drop further over the following hours. The number of announced IPv6 /48 address blocks fell by over 8% during that same time span, and also continued to drop in the following hours.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6o4hGGWXhf8aoqkqUUCNnO/5ad97dafb731679c368f837f69fc7044/BLOG-2817_53.png\&quot; alt=\&quot;BLOG-2817 53\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3ZfoHrCrwHAMACg0oCTceD/8f816416c4cde1c562aa519099eed058/BLOG-2817_54.png\&quot; alt=\&quot;BLOG-2817 54\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;impacts-in-other-european-countries\&quot;&gt;Impacts in other European countries&lt;/h2&gt;\n            &lt;a href=\&quot;#impacts-in-other-european-countries\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;Parts of Andorra and France were also &lt;a href=\&quot;https://www.euronews.com/my-europe/2025/04/28/spain-portugal-and-parts-of-france-hit-by-massive-power-outage\&quot;&gt;&lt;u&gt;reportedly impacted&lt;/u&gt;&lt;/a&gt; by the power outage, with additional outages reported as far away as Belgium. At a national level, no traffic disruptions were evident in any of the countries.&lt;/p&gt;&lt;p&gt;\n&lt;/p&gt;&lt;p&gt;Analysis of traffic at a regional level in France shows a slight decline concurrent with the power outage in several regions, but the drops were nominal in comparison to Spain and Portugal, and traffic volumes recovered to expected levels within 90 minutes. No impact was evident at a regional level in Andorra.&lt;/p&gt;&lt;p&gt;It appears that Morocco may have been impacted in some fashion by the power outage, or at least Orange Maroc was. In a &lt;a href=\&quot;https://x.com/OrangeMaroc/status/1916866583047147690\&quot;&gt;&lt;u&gt;post on X&lt;/u&gt;&lt;/a&gt;, the provider stated (translated) “&lt;i&gt;Internet traffic has been disrupted following a massive power outage in Spain and Portugal, which is affecting international connections.&lt;/i&gt;” Cloudflare Radar shows that traffic from the network fell sharply around 12:00 UTC, 90 minutes after the power outage began, with a full outage beginning around 15:00 UTC.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/62cA1IF7zleHp8RpCZu2Dq/2733086494e7d05b3feac5fd700e1c0f/BLOG-2817_55.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;conclusion\&quot;&gt;Conclusion&lt;/h2&gt;\n            &lt;a href=\&quot;#conclusion\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;Power restoration in Spain had already started as this post was being written, and full recovery will likely take hours to days. As power is restored, Internet traffic and other metrics will recover as well. The current state of Internet connectivity in &lt;a href=\&quot;https://radar.cloudflare.com/es\&quot;&gt;&lt;u&gt;Spain&lt;/u&gt;&lt;/a&gt; and &lt;a href=\&quot;https://radar.cloudflare.com/pt\&quot;&gt;&lt;u&gt;Portugal&lt;/u&gt;&lt;/a&gt; can be tracked on Cloudflare Radar.&lt;/p&gt;&lt;p&gt;The Cloudflare Radar team is constantly monitoring for Internet disruptions, sharing our observations on the &lt;a href=\&quot;https://radar.cloudflare.com/outage-center\&quot;&gt;&lt;u&gt;Cloudflare Radar Outage Center&lt;/u&gt;&lt;/a&gt;, via social media, and in posts on &lt;a href=\&quot;https://blog.cloudflare.com/tag/cloudflare-radar/\&quot;&gt;&lt;u&gt;blog.cloudflare.com&lt;/u&gt;&lt;/a&gt;. Follow us on social media at &lt;a href=\&quot;https://twitter.com/CloudflareRadar\&quot;&gt;&lt;u&gt;@CloudflareRadar&lt;/u&gt;&lt;/a&gt; (X), &lt;a href=\&quot;https://noc.social/@cloudflareradar\&quot;&gt;&lt;u&gt;noc.social/@cloudflareradar&lt;/u&gt;&lt;/a&gt; (Mastodon), and &lt;a href=\&quot;https://bsky.app/profile/radar.cloudflare.com\&quot;&gt;&lt;u&gt;radar.cloudflare.com&lt;/u&gt;&lt;/a&gt; (Bluesky), or contact us via &lt;a href=\&quot;mailto:radar@cloudflare.com\&quot;&gt;email&lt;/a&gt;.&lt;/p&gt;&quot;],&quot;published_at&quot;:[0,&quot;2025-04-28T12:30-09:00&quot;],&quot;updated_at&quot;:[0,&quot;2025-04-30T14:26:19.083Z&quot;],&quot;feature_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3viDYyiXZTF1EjDq7zQEbj/6389eb42add0f785cb87d29680df2fa6/image10.png&quot;],&quot;tags&quot;:[1,[[0,{&quot;id&quot;:[0,&quot;5kZtWqjqa7aOUoZr8NFGwI&quot;],&quot;name&quot;:[0,&quot;Radar&quot;],&quot;slug&quot;:[0,&quot;cloudflare-radar&quot;]}],[0,{&quot;id&quot;:[0,&quot;0kgHdg1ytbdWl5BNo6bEa&quot;],&quot;name&quot;:[0,&quot;Internet Traffic&quot;],&quot;slug&quot;:[0,&quot;internet-traffic&quot;]}],[0,{&quot;id&quot;:[0,&quot;4yliZlpBPZpOwBDZzo1tTh&quot;],&quot;name&quot;:[0,&quot;Outage&quot;],&quot;slug&quot;:[0,&quot;outage&quot;]}],[0,{&quot;id&quot;:[0,&quot;5DD7GZ0oxjP3NGOaJMwyWq&quot;],&quot;name&quot;:[0,&quot;Internet Quality&quot;],&quot;slug&quot;:[0,&quot;internet-quality&quot;]}],[0,{&quot;id&quot;:[0,&quot;2ScX2j6LG2ruyaS8eLYhsd&quot;],&quot;name&quot;:[0,&quot;Traffic&quot;],&quot;slug&quot;:[0,&quot;traffic&quot;]}]]],&quot;relatedTags&quot;:[0],&quot;authors&quot;:[1,[[0,{&quot;name&quot;:[0,&quot;David Belson&quot;],&quot;slug&quot;:[0,&quot;david-belson&quot;],&quot;bio&quot;:[0,null],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/en7vkXf6rLBm4F8IcNHXT/645022bf841fabff7732aa3be3949808/david-belson.jpeg&quot;],&quot;location&quot;:[0,null],&quot;website&quot;:[0,null],&quot;twitter&quot;:[0,&quot;@dbelson&quot;],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}]]],&quot;meta_description&quot;:[0,&quot;A massive power outage struck significant portions of Portugal and Spain at 10:34 UTC on April 28, disrupting everyday activities and services. The power outage also caused Internet outages across both countries, impacting Internet traffic and connectivity.&quot;],&quot;primary_author&quot;:[0,{}],&quot;localeList&quot;:[0,{&quot;name&quot;:[0,&quot;LOC: How the April 28, 2025, power outage in Portugal…&quot;],&quot;enUS&quot;:[0,&quot;English for Locale&quot;],&quot;zhCN&quot;:[0,&quot;English for Locale&quot;],&quot;zhHansCN&quot;:[0,&quot;English for Locale&quot;],&quot;zhTW&quot;:[0,&quot;English for Locale&quot;],&quot;frFR&quot;:[0,&quot;English for Locale&quot;],&quot;deDE&quot;:[0,&quot;English for Locale&quot;],&quot;itIT&quot;:[0,&quot;English for Locale&quot;],&quot;jaJP&quot;:[0,&quot;English for Locale&quot;],&quot;koKR&quot;:[0,&quot;English for Locale&quot;],&quot;ptBR&quot;:[0,&quot;Translated for Locale&quot;],&quot;esLA&quot;:[0,&quot;English for Locale&quot;],&quot;esES&quot;:[0,&quot;Translated for Locale&quot;],&quot;enAU&quot;:[0,&quot;English for Locale&quot;],&quot;enCA&quot;:[0,&quot;English for Locale&quot;],&quot;enIN&quot;:[0,&quot;English for Locale&quot;],&quot;enGB&quot;:[0,&quot;English for Locale&quot;],&quot;idID&quot;:[0,&quot;English for Locale&quot;],&quot;ruRU&quot;:[0,&quot;English for Locale&quot;],&quot;svSE&quot;:[0,&quot;English for Locale&quot;],&quot;viVN&quot;:[0,&quot;English for Locale&quot;],&quot;plPL&quot;:[0,&quot;English for Locale&quot;],&quot;arAR&quot;:[0,&quot;English for Locale&quot;],&quot;nlNL&quot;:[0,&quot;English for Locale&quot;],&quot;thTH&quot;:[0,&quot;English for Locale&quot;],&quot;trTR&quot;:[0,&quot;English for Locale&quot;],&quot;heIL&quot;:[0,&quot;English for Locale&quot;],&quot;lvLV&quot;:[0,&quot;English for Locale&quot;],&quot;etEE&quot;:[0,&quot;English for Locale&quot;],&quot;ltLT&quot;:[0,&quot;English for Locale&quot;]}],&quot;url&quot;:[0,&quot;https://blog.cloudflare.com/how-power-outage-in-portugal-spain-impacted-internet&quot;],&quot;metadata&quot;:[0,{&quot;title&quot;:[0,&quot;How the April 28, 2025, power outage in Portugal and Spain impacted Internet traffic and connectivity&quot;],&quot;description&quot;:[0,&quot;A massive power outage struck significant portions of Portugal and Spain at 10:34 UTC on April 28, disrupting everyday activities and services. The power outage also caused Internet outages across both countries, impacting Internet traffic and connectivity.&quot;],&quot;imgPreview&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/64tFS55n5YPGSdx4pMLQDp/9f91a9be556c0b4d5bb6768c754fbaae/How_the_power_outage_in_Portugal_and_Spain_impacted_Internet_traffic_and_connectivity-OG.png&quot;]}],&quot;publicly_index&quot;:[0,true]}],&quot;translations&quot;:[0,{&quot;posts.by&quot;:[0,&quot;By&quot;],&quot;footer.gdpr&quot;:[0,&quot;GDPR&quot;],&quot;lang_blurb1&quot;:[0,&quot;This post is also available in {lang1}.&quot;],&quot;lang_blurb2&quot;:[0,&quot;This post is also available in {lang1} and {lang2}.&quot;],&quot;lang_blurb3&quot;:[0,&quot;This post is also available in {lang1}, {lang2} and {lang3}.&quot;],&quot;footer.press&quot;:[0,&quot;Press&quot;],&quot;header.title&quot;:[0,&quot;The Cloudflare Blog&quot;],&quot;search.clear&quot;:[0,&quot;Clear&quot;],&quot;search.filter&quot;:[0,&quot;Filter&quot;],&quot;search.source&quot;:[0,&quot;Source&quot;],&quot;footer.careers&quot;:[0,&quot;Careers&quot;],&quot;footer.company&quot;:[0,&quot;Company&quot;],&quot;footer.support&quot;:[0,&quot;Support&quot;],&quot;footer.the_net&quot;:[0,&quot;theNet&quot;],&quot;search.filters&quot;:[0,&quot;Filters&quot;],&quot;footer.our_team&quot;:[0,&quot;Our team&quot;],&quot;footer.webinars&quot;:[0,&quot;Webinars&quot;],&quot;page.more_posts&quot;:[0,&quot;More posts&quot;],&quot;posts.time_read&quot;:[0,&quot;{time} min read&quot;],&quot;search.language&quot;:[0,&quot;Language&quot;],&quot;footer.community&quot;:[0,&quot;Community&quot;],&quot;footer.resources&quot;:[0,&quot;Resources&quot;],&quot;footer.solutions&quot;:[0,&quot;Solutions&quot;],&quot;footer.trademark&quot;:[0,&quot;Trademark&quot;],&quot;header.subscribe&quot;:[0,&quot;Subscribe&quot;],&quot;footer.compliance&quot;:[0,&quot;Compliance&quot;],&quot;footer.free_plans&quot;:[0,&quot;Free plans&quot;],&quot;footer.impact_ESG&quot;:[0,&quot;Impact/ESG&quot;],&quot;posts.follow_on_X&quot;:[0,&quot;Follow on X&quot;],&quot;footer.help_center&quot;:[0,&quot;Help center&quot;],&quot;footer.network_map&quot;:[0,&quot;Network Map&quot;],&quot;header.please_wait&quot;:[0,&quot;Please Wait&quot;],&quot;page.related_posts&quot;:[0,&quot;Related posts&quot;],&quot;search.result_stat&quot;:[0,&quot;Results &lt;strong&gt;{search_range}&lt;/strong&gt; of &lt;strong&gt;{search_total}&lt;/strong&gt; for &lt;strong&gt;{search_keyword}&lt;/strong&gt;&quot;],&quot;footer.case_studies&quot;:[0,&quot;Case Studies&quot;],&quot;footer.connect_2024&quot;:[0,&quot;Connect 2024&quot;],&quot;footer.terms_of_use&quot;:[0,&quot;Terms of Use&quot;],&quot;footer.white_papers&quot;:[0,&quot;White Papers&quot;],&quot;footer.cloudflare_tv&quot;:[0,&quot;Cloudflare TV&quot;],&quot;footer.community_hub&quot;:[0,&quot;Community Hub&quot;],&quot;footer.compare_plans&quot;:[0,&quot;Compare plans&quot;],&quot;footer.contact_sales&quot;:[0,&quot;Contact Sales&quot;],&quot;header.contact_sales&quot;:[0,&quot;Contact Sales&quot;],&quot;header.email_address&quot;:[0,&quot;Email Address&quot;],&quot;page.error.not_found&quot;:[0,&quot;Page not found&quot;],&quot;footer.developer_docs&quot;:[0,&quot;Developer docs&quot;],&quot;footer.privacy_policy&quot;:[0,&quot;Privacy Policy&quot;],&quot;footer.request_a_demo&quot;:[0,&quot;Request a demo&quot;],&quot;page.continue_reading&quot;:[0,&quot;Continue reading&quot;],&quot;footer.analysts_report&quot;:[0,&quot;Analyst reports&quot;],&quot;footer.for_enterprises&quot;:[0,&quot;For enterprises&quot;],&quot;footer.getting_started&quot;:[0,&quot;Getting Started&quot;],&quot;footer.learning_center&quot;:[0,&quot;Learning Center&quot;],&quot;footer.project_galileo&quot;:[0,&quot;Project Galileo&quot;],&quot;pagination.newer_posts&quot;:[0,&quot;Newer Posts&quot;],&quot;pagination.older_posts&quot;:[0,&quot;Older Posts&quot;],&quot;posts.social_buttons.x&quot;:[0,&quot;Discuss on X&quot;],&quot;search.icon_aria_label&quot;:[0,&quot;Search&quot;],&quot;search.source_location&quot;:[0,&quot;Source/Location&quot;],&quot;footer.about_cloudflare&quot;:[0,&quot;About Cloudflare&quot;],&quot;footer.athenian_project&quot;:[0,&quot;Athenian Project&quot;],&quot;footer.become_a_partner&quot;:[0,&quot;Become a partner&quot;],&quot;footer.cloudflare_radar&quot;:[0,&quot;Cloudflare Radar&quot;],&quot;footer.network_services&quot;:[0,&quot;Network services&quot;],&quot;footer.trust_and_safety&quot;:[0,&quot;Trust &amp; Safety&quot;],&quot;header.get_started_free&quot;:[0,&quot;Get Started Free&quot;],&quot;page.search.placeholder&quot;:[0,&quot;Search Cloudflare&quot;],&quot;footer.cloudflare_status&quot;:[0,&quot;Cloudflare Status&quot;],&quot;footer.cookie_preference&quot;:[0,&quot;Cookie Preferences&quot;],&quot;header.valid_email_error&quot;:[0,&quot;Must be valid email.&quot;],&quot;search.result_stat_empty&quot;:[0,&quot;Results &lt;strong&gt;{search_range}&lt;/strong&gt; of &lt;strong&gt;{search_total}&lt;/strong&gt;&quot;],&quot;footer.connectivity_cloud&quot;:[0,&quot;Connectivity cloud&quot;],&quot;footer.developer_services&quot;:[0,&quot;Developer services&quot;],&quot;footer.investor_relations&quot;:[0,&quot;Investor relations&quot;],&quot;page.not_found.error_code&quot;:[0,&quot;Error Code: 404&quot;],&quot;search.autocomplete_title&quot;:[0,&quot;Insert a query. Press enter to send&quot;],&quot;footer.logos_and_press_kit&quot;:[0,&quot;Logos &amp; press kit&quot;],&quot;footer.application_services&quot;:[0,&quot;Application services&quot;],&quot;footer.get_a_recommendation&quot;:[0,&quot;Get a recommendation&quot;],&quot;posts.social_buttons.reddit&quot;:[0,&quot;Discuss on Reddit&quot;],&quot;footer.sse_and_sase_services&quot;:[0,&quot;SSE and SASE services&quot;],&quot;page.not_found.outdated_link&quot;:[0,&quot;You may have used an outdated link, or you may have typed the address incorrectly.&quot;],&quot;footer.report_security_issues&quot;:[0,&quot;Report Security Issues&quot;],&quot;page.error.error_message_page&quot;:[0,&quot;Sorry, we can&#39;t find the page you are looking for.&quot;],&quot;header.subscribe_notifications&quot;:[0,&quot;Subscribe to receive notifications of new posts:&quot;],&quot;footer.cloudflare_for_campaigns&quot;:[0,&quot;Cloudflare for Campaigns&quot;],&quot;header.subscription_confimation&quot;:[0,&quot;Subscription confirmed. Thank you for subscribing!&quot;],&quot;posts.social_buttons.hackernews&quot;:[0,&quot;Discuss on Hacker News&quot;],&quot;footer.diversity_equity_inclusion&quot;:[0,&quot;Diversity, equity &amp; inclusion&quot;],&quot;footer.critical_infrastructure_defense_project&quot;:[0,&quot;Critical Infrastructure Defense Project&quot;]}]}" ssr client="load" opts="{&quot;name&quot;:&quot;PostCard&quot;,&quot;value&quot;:true}" await-children><article class="w-50-l  mt4 mt2-l mb4 ph3 bb b--gray8 bn-l"><div class="w-100"><a href="/how-power-outage-in-portugal-spain-impacted-internet/" class="fw5 no-underline gray1" data-testid="post-title"><h2 class="fw5 mt2">How the April 28, 2025, power outage in Portugal and Spain impacted Internet traffic and connectivity</h2></a><p class="f3 fw5 gray5 my" data-testid="post-date">2025-04-28</p><div class=""><a href="/tag/cloudflare-radar/" class="dib pl2 pr2 pt1 pb1 mb2 bg-gray8 no-underline blue3 f2 mr1" data-testid="post-tag">Radar</a><a href="/tag/internet-traffic/" class="dib pl2 pr2 pt1 pb1 mb2 bg-gray8 no-underline blue3 f2 mr1" data-testid="post-tag">Internet Traffic</a><a href="/tag/outage/" class="dib pl2 pr2 pt1 pb1 mb2 bg-gray8 no-underline blue3 f2 mr1" data-testid="post-tag">Outage</a><a href="/tag/internet-quality/" class="dib pl2 pr2 pt1 pb1 mb2 bg-gray8 no-underline blue3 f2 mr1" data-testid="post-tag">Internet Quality</a><a href="/tag/traffic/" class="dib pl2 pr2 pt1 pb1 mb2 bg-gray8 no-underline blue3 f2 mr1" data-testid="post-tag">Traffic</a></div><p class="f3 fw4 gray1 lh-copy " data-testid="post-content">A massive power outage struck significant portions of Portugal and Spain at 10:34 UTC on April 28, disrupting everyday activities and services.<!-- -->...</p><ul class="author-lists flex pl0"><li class="list flex items-center pr2 mb3"><a href="/author/david-belson/" class="static-avatar pr1"><img class="author-profile-image br-100 mr2" src="https://blog.cloudflare.com/cdn-cgi/image/format=auto,dpr=3,width=64,height=64,gravity=face,fit=crop,zoom=0.5/https://cf-assets.www.cloudflare.com/zkvhlag99gkb/en7vkXf6rLBm4F8IcNHXT/645022bf841fabff7732aa3be3949808/david-belson.jpeg" alt="David Belson" width="62" height="62"/></a><div class="author-name-tooltip"><a href="/author/david-belson/" class="fw4 f3 no-underline black">David Belson</a></div></li></ul></div></article><!--astro:end--></astro-island><astro-island uid="Z1vYdoM" prefix="r2" component-url="/_astro/PostCard.DalyEN7z.js" component-export="PostCard" renderer-url="/_astro/client.DLO1yDVm.js" props="{&quot;currentPage&quot;:[0,1],&quot;isFeaturedImageFirstPost&quot;:[0,false],&quot;post&quot;:[0,{&quot;id&quot;:[0,&quot;4I4XNCQlRirlf9SaA9ySTS&quot;],&quot;title&quot;:[0,&quot;Cloudflare incident on March 21, 2025&quot;],&quot;slug&quot;:[0,&quot;cloudflare-incident-march-21-2025&quot;],&quot;excerpt&quot;:[0,&quot;On March 21, 2025, multiple Cloudflare services, including R2 object storage experienced an elevated rate of error responses. Here’s what caused the incident, the impact, and how we are making sure it&quot;],&quot;featured&quot;:[0,false],&quot;html&quot;:[0,&quot;&lt;p&gt;Multiple Cloudflare services, including &lt;a href=\&quot;https://developers.cloudflare.com/r2/\&quot;&gt;&lt;u&gt;R2 object storage&lt;/u&gt;&lt;/a&gt;, experienced an elevated rate of errors for 1 hour and 7 minutes on March 21, 2025 (starting at 21:38 UTC and ending 22:45 UTC). During the incident window, 100% of write operations failed and approximately 35% of read operations to R2 failed globally. Although this incident started with R2, it impacted other Cloudflare services including &lt;a href=\&quot;https://www.cloudflare.com/developer-platform/products/cache-reserve/\&quot;&gt;&lt;u&gt;Cache Reserve&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://www.cloudflare.com/developer-platform/products/cloudflare-images/\&quot;&gt;&lt;u&gt;Images&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://developers.cloudflare.com/logs/edge-log-delivery/\&quot;&gt;&lt;u&gt;Log Delivery&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://www.cloudflare.com/developer-platform/products/cloudflare-stream/\&quot;&gt;&lt;u&gt;Stream&lt;/u&gt;&lt;/a&gt;, and &lt;a href=\&quot;https://developers.cloudflare.com/vectorize/\&quot;&gt;&lt;u&gt;Vectorize&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;While rotating credentials used by the R2 Gateway service (R2&amp;#39;s API frontend) to authenticate with our storage infrastructure, the R2 engineering team inadvertently deployed the new credentials (ID and key pair) to a development instance of the service instead of production. When the old credentials were deleted from our storage infrastructure (as part of the key rotation process), the production R2 Gateway service did not have access to the new credentials. This ultimately resulted in R2’s Gateway service not being able to authenticate with our storage backend. There was no data loss or corruption that occurred as part of this incident: any in-flight uploads or mutations that returned successful HTTP status codes were persisted.&lt;/p&gt;&lt;p&gt;Once the root cause was identified and we realized we hadn’t deployed the new credentials to the production R2 Gateway service, we deployed the updated credentials and service availability was restored. &lt;/p&gt;&lt;p&gt;This incident happened because of human error and lasted longer than it should have because we didn’t have proper visibility into which credentials were being used by the Gateway Worker to authenticate with our storage infrastructure. &lt;/p&gt;&lt;p&gt;We’re deeply sorry for this incident and the disruption it may have caused to you or your users. We hold ourselves to a high standard and this is not acceptable. This blog post exactly explains the impact, what happened and when, and the steps we are taking to make sure this failure (and others like it) doesn’t happen again.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;what-was-impacted\&quot;&gt;What was impacted?&lt;/h2&gt;\n            &lt;a href=\&quot;#what-was-impacted\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;&lt;b&gt;The primary incident window occurred between 21:38 UTC and 22:45 UTC.&lt;/b&gt;&lt;/p&gt;&lt;p&gt;The following table details the specific impact to R2 and Cloudflare services that depend on, or interact with, R2:&lt;/p&gt;&lt;style type=\&quot;text/css\&quot;&gt;\n.tg  {border-collapse:collapse;border-spacing:0;margin:0px auto;}\n.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n  overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg .tg-fymr{border-color:inherit;font-weight:bold;text-align:left;vertical-align:top}\n.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}\n@media screen and (max-width: 767px) {.tg {width: auto !important;}.tg col {width: auto !important;}.tg-wrap {overflow-x: auto;-webkit-overflow-scrolling: touch;margin: auto 0px;}}&lt;/style&gt;\n&lt;div class=\&quot;tg-wrap\&quot;&gt;&lt;table class=\&quot;tg\&quot;&gt;&lt;thead&gt;\n  &lt;tr&gt;\n    &lt;th class=\&quot;tg-fymr\&quot;&gt;&lt;span style=\&quot;font-weight:bold;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Product/Service&lt;/span&gt;&lt;/th&gt;\n    &lt;th class=\&quot;tg-0pky\&quot;&gt;&lt;span style=\&quot;font-weight:700;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Impact&lt;/span&gt;&lt;/th&gt;\n  &lt;/tr&gt;&lt;/thead&gt;\n&lt;tbody&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-fymr\&quot;&gt;&lt;span style=\&quot;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;R2&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0pky\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;All customers using Cloudflare R2 would have experienced an elevated error rate during the primary incident window. Specifically:&lt;/span&gt;&lt;br&gt;&lt;br&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;* Object write operations had a 100% error rate.&lt;/span&gt;&lt;br&gt;&lt;br&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;* Object reads had an approximate error rate of 35% globally. Individual customer error rate varied during this window depending on access patterns. Customers accessing public assets through custom domains would have seen a reduced error rate as cached object reads were not impacted.&lt;/span&gt;&lt;br&gt;&lt;br&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;* Operations involving metadata only (e.g., head and list operations) were not impacted.&lt;/span&gt;&lt;br&gt;&lt;br&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;There was no data loss or risk to data integrity within R2&#39;s storage subsystem. This incident was limited to a temporary authentication issue between R2&#39;s API frontend and our storage infrastructure.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-fymr\&quot;&gt;&lt;span style=\&quot;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Billing&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0pky\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Billing uses R2 to store customer invoices. During the primary incident window, customers may have experienced errors when attempting to download/access past Cloudflare invoices.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-fymr\&quot;&gt;&lt;span style=\&quot;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Cache Reserve&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0pky\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Cache Reserve customers observed an increase in requests to their origin during the incident window as an increased percentage of reads to R2 failed. This resulted in an increase in requests to origins to fetch assets unavailable in Cache Reserve during this period.&lt;/span&gt;&lt;br&gt;&lt;br&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;User-facing requests for assets to sites with Cache Reserve did not observe failures as cache misses failed over to the origin.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-fymr\&quot;&gt;&lt;span style=\&quot;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Email Security&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0pky\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Email Security depends on R2 for customer-facing metrics. During the primary incident window, customer-facing metrics would not have updated.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-fymr\&quot;&gt;&lt;span style=\&quot;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Images&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0pky\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;All (100% of) uploads failed during the primary incident window. Successful delivery of stored images dropped to approximately 25%.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-fymr\&quot;&gt;&lt;span style=\&quot;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Key Transparency Auditor&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0pky\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;All (100% of) operations failed during the primary incident window due to dependence on R2 writes and/or reads. Once the incident was resolved, service returned to normal operation immediately.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-fymr\&quot;&gt;&lt;span style=\&quot;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Log Delivery&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0pky\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Log delivery (for Logpush and Logpull) was delayed during the primary incident window, resulting in significant delays (up to 70 minutes) in log processing. All logs were delivered after incident resolution.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-fymr\&quot;&gt;&lt;span style=\&quot;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Stream&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0pky\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;All (100% of) uploads failed during the primary incident window. Successful Stream video segment delivery dropped to 94%. Viewers may have seen video stalls every minute or so, although actual impact would have varied.&lt;/span&gt;&lt;br&gt;&lt;br&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Stream Live was down during the primary incident window as it depends on object writes.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-fymr\&quot;&gt;&lt;span style=\&quot;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Vectorize&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0pky\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Queries and operations against Vectorize indexes were impacted during the incident window. During the incident window, Vectorize customers would have seen an increased error rate for read queries to indexes and all (100% of) insert and upsert operation failed as Vectorize depends on R2 for persistent storage.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;incident-timeline\&quot;&gt;Incident timeline&lt;/h2&gt;\n            &lt;a href=\&quot;#incident-timeline\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;&lt;b&gt;All timestamps referenced are in Coordinated Universal Time (UTC).&lt;/b&gt;&lt;/p&gt;&lt;style type=\&quot;text/css\&quot;&gt;\n.tg  {border-collapse:collapse;border-spacing:0;margin:0px auto;}\n.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n  overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n.tg .tg-0lax{text-align:left;vertical-align:top}\n@media screen and (max-width: 767px) {.tg {width: auto !important;}.tg col {width: auto !important;}.tg-wrap {overflow-x: auto;-webkit-overflow-scrolling: touch;margin: auto 0px;}}&lt;/style&gt;\n&lt;div class=\&quot;tg-wrap\&quot;&gt;&lt;table class=\&quot;tg\&quot; style=\&quot;undefined;table-layout: fixed; width: 762px\&quot;&gt;&lt;colgroup&gt;\n&lt;col style=\&quot;width: 185.88889px\&quot;&gt;\n&lt;col style=\&quot;width: 575.88889px\&quot;&gt;\n&lt;/colgroup&gt;\n&lt;thead&gt;\n  &lt;tr&gt;\n    &lt;th class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:bold;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Time&lt;/span&gt;&lt;/th&gt;\n    &lt;th class=\&quot;tg-1wig\&quot;&gt;&lt;span style=\&quot;font-weight:700;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Event&lt;/span&gt;&lt;/th&gt;\n  &lt;/tr&gt;&lt;/thead&gt;\n&lt;tbody&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-1wig\&quot;&gt;&lt;span style=\&quot;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Mar 21, 2025 - 19:49 UTC&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;The R2 engineering team started the credential rotation process. A new set of credentials (ID and key pair) for storage infrastructure was created. Old credentials were maintained to avoid downtime during credential change over.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-1wig\&quot;&gt;&lt;span style=\&quot;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Mar 21, 2025 - 20:19 UTC&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Set updated production secret (&lt;/span&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#188038;background-color:transparent\&quot;&gt;wrangler secret put&lt;/span&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;) and executed &lt;/span&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#188038;background-color:transparent\&quot;&gt;wrangler deploy&lt;/span&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt; command to deploy R2 Gateway service with updated credentials. &lt;/span&gt;&lt;br&gt;&lt;br&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Note: We later discovered the &lt;/span&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#188038;background-color:transparent\&quot;&gt;--env&lt;/span&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt; parameter was inadvertently omitted for both Wrangler commands. This resulted in credentials being deployed to the Worker assigned to the &lt;/span&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#188038;background-color:transparent\&quot;&gt;default&lt;/span&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt; environment instead of the Worker assigned to the &lt;/span&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#188038;background-color:transparent\&quot;&gt;production&lt;/span&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt; environment.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-1wig\&quot;&gt;&lt;span style=\&quot;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Mar 21, 2025 - 20:20 UTC&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;The R2 Gateway service Worker assigned to the &lt;/span&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#188038;background-color:transparent\&quot;&gt;default&lt;/span&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt; environment is now using the updated storage infrastructure credentials.&lt;/span&gt;&lt;br&gt;&lt;br&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Note: This was the wrong Worker, the &lt;/span&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#188038;background-color:transparent\&quot;&gt;production&lt;/span&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt; environment should have been explicitly set. But, at this point, we incorrectly believed the credentials were updated on the correct production Worker.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-1wig\&quot;&gt;&lt;span style=\&quot;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Mar 21, 2025 - 20:37 UTC&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Old credentials were removed from our storage infrastructure to complete the credential rotation process.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-1wig\&quot;&gt;&lt;span style=\&quot;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Mar 21, 2025 - 21:38 UTC&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-1wig\&quot;&gt;&lt;span style=\&quot;font-weight:700;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;– IMPACT BEGINS –&lt;/span&gt;&lt;br&gt;&lt;br&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;R2 availability metrics begin to show signs of service degradation. The impact to R2 availability metrics was gradual and not immediately obvious because there was a delay in the propagation of the previous credential deletion to storage infrastructure.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-1wig\&quot;&gt;&lt;span style=\&quot;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Mar 21, 2025 - 21:45 UTC&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;R2 global availability alerts are triggered (indicating 2% of error budget burn rate).&lt;/span&gt;&lt;br&gt;&lt;br&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;The R2 engineering team began looking at operational dashboards and logs to understand impact.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-1wig\&quot;&gt;&lt;span style=\&quot;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Mar 21, 2025 - 21:50 UTC&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Internal incident declared.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-1wig\&quot;&gt;&lt;span style=\&quot;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Mar 21, 2025 - 21:51 UTC&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;R2 engineering team observes gradual but consistent decline in R2 availability metrics for both read and write operations. Operations involving metadata only (e.g., head and list operations) were not impacted.&lt;/span&gt;&lt;br&gt;&lt;br&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Given gradual decline in availability metrics, R2 engineering team suspected a potential regression in propagation of new credentials in storage infrastructure.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-1wig\&quot;&gt;&lt;span style=\&quot;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Mar 21, 2025 - 22:05 UTC&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Public incident status page published.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-1wig\&quot;&gt;&lt;span style=\&quot;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Mar 21, 2025 - 22:15 UTC&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;R2 engineering team created a new set of credentials (ID and key pair) for storage infrastructure in an attempt to force re-propagation.&lt;/span&gt;&lt;br&gt;&lt;br&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Continued monitoring operational dashboards and logs.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-1wig\&quot;&gt;&lt;span style=\&quot;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Mar 21, 2025 - 22:20 UTC&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;R2 engineering team saw no improvement in availability metrics. Continued investigating other potential root causes.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-1wig\&quot;&gt;&lt;span style=\&quot;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Mar 21, 2025 - 22:30 UTC&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;R2 engineering team deployed a new set of credentials (ID and key pair) to R2 Gateway service Worker. This was to validate whether there was an issue with the credentials we had pushed to gateway service.&lt;/span&gt;&lt;br&gt;&lt;br&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Environment parameter was still omitted in the &lt;/span&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#188038;background-color:transparent\&quot;&gt;deploy&lt;/span&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt; and &lt;/span&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#188038;background-color:transparent\&quot;&gt;secret put&lt;/span&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt; commands, so this deployment was still to the wrong non-production Worker.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-1wig\&quot;&gt;&lt;span style=\&quot;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Mar 21, 2025 - 22:36 UTC&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-1wig\&quot;&gt;&lt;span style=\&quot;font-weight:700;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;– ROOT CAUSE IDENTIFIED –&lt;/span&gt;&lt;br&gt;&lt;br&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;The R2 engineering team discovered that credentials had been deployed to a non-production Worker by reviewing production Worker release history.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-1wig\&quot;&gt;&lt;span style=\&quot;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Mar 21, 2025 - 22:45 UTC&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-1wig\&quot;&gt;&lt;span style=\&quot;font-weight:700;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;– IMPACT ENDS –&lt;/span&gt;&lt;br&gt;&lt;br&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Deployed credentials to correct production Worker. R2 availability recovered.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-1wig\&quot;&gt;&lt;span style=\&quot;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Mar 21, 2025 - 22:54 UTC&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;The incident is considered resolved.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;analysis\&quot;&gt;Analysis&lt;/h2&gt;\n            &lt;a href=\&quot;#analysis\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;R2’s architecture is primarily composed of three parts: R2 production gateway Worker (serves requests from S3 API, REST API, Workers API), metadata service, and storage infrastructure (stores encrypted object data).&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1G9gfdEE4RIuMIUeNz42RN/25d1b4cca187a4a24c600a43ba51fb71/BLOG-2793_2.png\&quot; alt=\&quot;BLOG-2793 2\&quot; class=\&quot;kg-image\&quot; width=\&quot;1840\&quot; height=\&quot;1000\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;The R2 Gateway Worker uses credentials (ID and key pair) to securely authenticate with our distributed storage infrastructure. We rotate these credentials regularly as a best practice security precaution.&lt;/p&gt;&lt;p&gt;Our key rotation process involves the following high-level steps:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;Create a new set of credentials (ID and key pair) for our storage infrastructure. At this point, the old credentials are maintained to avoid downtime during credential change over.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Set the new credential secret for the R2 production gateway Worker using the &lt;code&gt;wrangler secret put&lt;/code&gt; command.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Set the new updated credential ID as an environment variable in the R2 production gateway Worker using the &lt;code&gt;wrangler deploy&lt;/code&gt; command. At this point, new storage credentials start being used by the gateway Worker.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Remove previous credentials from our storage infrastructure to complete the credential rotation process.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Monitor operational dashboards and logs to validate change over.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;The R2 engineering team uses &lt;a href=\&quot;https://developers.cloudflare.com/workers/wrangler/environments/\&quot;&gt;&lt;u&gt;Workers environments&lt;/u&gt;&lt;/a&gt; to separate production and development environments for the R2 Gateway Worker. Each environment defines a separate isolated Cloudflare Worker with separate environment variables and secrets. &lt;/p&gt;&lt;p&gt;Critically, both &lt;code&gt;wrangler secret put&lt;/code&gt; and &lt;code&gt;wrangler deploy&lt;/code&gt; commands default to the default environment if the --env command line parameter is not included. In this case, due to human error, we inadvertently omitted the --env parameter and deployed the new storage credentials to the wrong Worker (&lt;code&gt;default&lt;/code&gt; environment instead of &lt;code&gt;production&lt;/code&gt;). To correctly deploy storage credentials to the production R2 Gateway Worker, we need to specify &lt;code&gt;--env production&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;The action we took on step 4 above to remove the old credentials from our storage infrastructure caused authentication errors, as the R2 Gateway production Worker still had the old credentials. This is ultimately what resulted in degraded availability.&lt;/p&gt;&lt;p&gt;The decline in R2 availability metrics was gradual and not immediately obvious because there was a delay in the propagation of the previous credential deletion to storage infrastructure. This accounted for a delay in our initial discovery of the problem. Instead of relying on availability metrics after updating the old set of credentials, we should have explicitly validated which token was being used by the R2 Gateway service to authenticate with R2&amp;#39;s storage infrastructure.&lt;/p&gt;&lt;p&gt;Overall, the impact on read availability was significantly mitigated by our intermediate cache that sits in front of storage and continued to serve requests.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;resolution\&quot;&gt;Resolution&lt;/h2&gt;\n            &lt;a href=\&quot;#resolution\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;Once we identified the root cause, we were able to resolve the incident quickly by deploying the new credentials to the production R2 Gateway Worker. This resulted in an immediate recovery of R2 availability.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;next-steps\&quot;&gt;Next steps&lt;/h2&gt;\n            &lt;a href=\&quot;#next-steps\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;This incident happened because of human error and lasted longer than it should have because we didn’t have proper visibility into which credentials were being used by the R2 Gateway Worker to authenticate with our storage infrastructure.&lt;/p&gt;&lt;p&gt;We have taken immediate steps to prevent this failure (and others like it) from happening again:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Added logging tags that include the suffix of the credential ID the R2 Gateway Worker uses to authenticate with our storage infrastructure. With this change, we can explicitly confirm which credential is being used.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Related to the above step, our internal processes now require explicit confirmation that the suffix of the new token ID matches logs from our storage infrastructure before deleting the previous token.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Require that key rotation takes place through our hotfix release tooling instead of relying on manual wrangler command entry which introduces human error. Our hotfix release deploy tooling explicitly enforces the environment configuration and contains other safety checks.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;While it’s been an implicit standard that this process involves at least two humans to validate the changes ahead as we progress, we’ve updated our relevant SOPs (standard operating procedures) to include this explicitly.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;In Progress&lt;/b&gt;: Extend our existing closed loop health check system that monitors our endpoints to test new keys, automate reporting of their status through our alerting platform, and ensure global propagation prior to releasing the gateway Worker.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;In Progress&lt;/b&gt;: To expedite triage on any future issues with our distributed storage endpoints, we are updating our observability platform to include views of upstream success rates that bypass caching to give clearer indication of issues serving requests for any reason.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The list above is not exhaustive: as we work through the above items, we will likely uncover other improvements to our systems, controls, and processes that we’ll be applying to improve R2’s resiliency, on top of our business-as-usual efforts. We are confident that this set of changes will prevent this failure, and related credential rotation failure modes, from occurring again. Again, we sincerely apologize for this incident and deeply regret any disruption it has caused you or your users.&lt;/p&gt;&quot;],&quot;published_at&quot;:[0,&quot;2025-03-25T01:40:38.542Z&quot;],&quot;updated_at&quot;:[0,&quot;2025-04-07T23:11:40.989Z&quot;],&quot;feature_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1zVzYYX4Zs6rRox4hJO4wJ/c64947208676753e532135f9393df5c5/BLOG-2793_1.png&quot;],&quot;tags&quot;:[1,[[0,{&quot;id&quot;:[0,&quot;7JpaihvGGjNhG2v4nTxeFV&quot;],&quot;name&quot;:[0,&quot;R2 Storage&quot;],&quot;slug&quot;:[0,&quot;cloudflare-r2&quot;]}],[0,{&quot;id&quot;:[0,&quot;4yliZlpBPZpOwBDZzo1tTh&quot;],&quot;name&quot;:[0,&quot;Outage&quot;],&quot;slug&quot;:[0,&quot;outage&quot;]}],[0,{&quot;id&quot;:[0,&quot;3cCNoJJ5uusKFBLYKFX1jB&quot;],&quot;name&quot;:[0,&quot;Post Mortem&quot;],&quot;slug&quot;:[0,&quot;post-mortem&quot;]}]]],&quot;relatedTags&quot;:[0],&quot;authors&quot;:[1,[[0,{&quot;name&quot;:[0,&quot;Phillip Jones&quot;],&quot;slug&quot;:[0,&quot;phillip&quot;],&quot;bio&quot;:[0,null],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5KTNNpw9VHuwoZlwWsA7MN/c50f3f98d822a0fdce3196d7620d714e/phillip.jpg&quot;],&quot;location&quot;:[0,null],&quot;website&quot;:[0,null],&quot;twitter&quot;:[0,&quot;@akaphill&quot;],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}]]],&quot;meta_description&quot;:[0,&quot;On March 21, 2025, multiple Cloudflare services, including R2 object storage experienced an elevated rate of error responses. Here’s what caused the incident, the impact, and how we are making sure it doesn’t happen again.&quot;],&quot;primary_author&quot;:[0,{}],&quot;localeList&quot;:[0,{&quot;name&quot;:[0,&quot;LOC: Cloudflare incident on March 21, 2025&quot;],&quot;enUS&quot;:[0,&quot;English for Locale&quot;],&quot;zhCN&quot;:[0,&quot;Translated for Locale&quot;],&quot;zhHansCN&quot;:[0,&quot;No Page for Locale&quot;],&quot;zhTW&quot;:[0,&quot;No Page for Locale&quot;],&quot;frFR&quot;:[0,&quot;No Page for Locale&quot;],&quot;deDE&quot;:[0,&quot;No Page for Locale&quot;],&quot;itIT&quot;:[0,&quot;No Page for Locale&quot;],&quot;jaJP&quot;:[0,&quot;Translated for Locale&quot;],&quot;koKR&quot;:[0,&quot;No Page for Locale&quot;],&quot;ptBR&quot;:[0,&quot;No Page for Locale&quot;],&quot;esLA&quot;:[0,&quot;No Page for Locale&quot;],&quot;esES&quot;:[0,&quot;No Page for Locale&quot;],&quot;enAU&quot;:[0,&quot;No Page for Locale&quot;],&quot;enCA&quot;:[0,&quot;No Page for Locale&quot;],&quot;enIN&quot;:[0,&quot;No Page for Locale&quot;],&quot;enGB&quot;:[0,&quot;No Page for Locale&quot;],&quot;idID&quot;:[0,&quot;No Page for Locale&quot;],&quot;ruRU&quot;:[0,&quot;No Page for Locale&quot;],&quot;svSE&quot;:[0,&quot;No Page for Locale&quot;],&quot;viVN&quot;:[0,&quot;No Page for Locale&quot;],&quot;plPL&quot;:[0,&quot;No Page for Locale&quot;],&quot;arAR&quot;:[0,&quot;No Page for Locale&quot;],&quot;nlNL&quot;:[0,&quot;No Page for Locale&quot;],&quot;thTH&quot;:[0,&quot;No Page for Locale&quot;],&quot;trTR&quot;:[0,&quot;No Page for Locale&quot;],&quot;heIL&quot;:[0,&quot;No Page for Locale&quot;],&quot;lvLV&quot;:[0,&quot;No Page for Locale&quot;],&quot;etEE&quot;:[0,&quot;No Page for Locale&quot;],&quot;ltLT&quot;:[0,&quot;No Page for Locale&quot;]}],&quot;url&quot;:[0,&quot;https://blog.cloudflare.com/cloudflare-incident-march-21-2025&quot;],&quot;metadata&quot;:[0,{&quot;title&quot;:[0],&quot;description&quot;:[0,&quot;On March 21, 2025, multiple Cloudflare services, including R2 object storage experienced an elevated rate of error responses. Here’s what caused the incident, the impact, and how we are making sure it doesn’t happen again.&quot;],&quot;imgPreview&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4Snz5aLHm9r8iuQrJu1PFo/b08d68ab5199b08dfc096237501e8bf9/BLOG-2793_OG_Share.png&quot;]}],&quot;publicly_index&quot;:[0,true]}],&quot;translations&quot;:[0,{&quot;posts.by&quot;:[0,&quot;By&quot;],&quot;footer.gdpr&quot;:[0,&quot;GDPR&quot;],&quot;lang_blurb1&quot;:[0,&quot;This post is also available in {lang1}.&quot;],&quot;lang_blurb2&quot;:[0,&quot;This post is also available in {lang1} and {lang2}.&quot;],&quot;lang_blurb3&quot;:[0,&quot;This post is also available in {lang1}, {lang2} and {lang3}.&quot;],&quot;footer.press&quot;:[0,&quot;Press&quot;],&quot;header.title&quot;:[0,&quot;The Cloudflare Blog&quot;],&quot;search.clear&quot;:[0,&quot;Clear&quot;],&quot;search.filter&quot;:[0,&quot;Filter&quot;],&quot;search.source&quot;:[0,&quot;Source&quot;],&quot;footer.careers&quot;:[0,&quot;Careers&quot;],&quot;footer.company&quot;:[0,&quot;Company&quot;],&quot;footer.support&quot;:[0,&quot;Support&quot;],&quot;footer.the_net&quot;:[0,&quot;theNet&quot;],&quot;search.filters&quot;:[0,&quot;Filters&quot;],&quot;footer.our_team&quot;:[0,&quot;Our team&quot;],&quot;footer.webinars&quot;:[0,&quot;Webinars&quot;],&quot;page.more_posts&quot;:[0,&quot;More posts&quot;],&quot;posts.time_read&quot;:[0,&quot;{time} min read&quot;],&quot;search.language&quot;:[0,&quot;Language&quot;],&quot;footer.community&quot;:[0,&quot;Community&quot;],&quot;footer.resources&quot;:[0,&quot;Resources&quot;],&quot;footer.solutions&quot;:[0,&quot;Solutions&quot;],&quot;footer.trademark&quot;:[0,&quot;Trademark&quot;],&quot;header.subscribe&quot;:[0,&quot;Subscribe&quot;],&quot;footer.compliance&quot;:[0,&quot;Compliance&quot;],&quot;footer.free_plans&quot;:[0,&quot;Free plans&quot;],&quot;footer.impact_ESG&quot;:[0,&quot;Impact/ESG&quot;],&quot;posts.follow_on_X&quot;:[0,&quot;Follow on X&quot;],&quot;footer.help_center&quot;:[0,&quot;Help center&quot;],&quot;footer.network_map&quot;:[0,&quot;Network Map&quot;],&quot;header.please_wait&quot;:[0,&quot;Please Wait&quot;],&quot;page.related_posts&quot;:[0,&quot;Related posts&quot;],&quot;search.result_stat&quot;:[0,&quot;Results &lt;strong&gt;{search_range}&lt;/strong&gt; of &lt;strong&gt;{search_total}&lt;/strong&gt; for &lt;strong&gt;{search_keyword}&lt;/strong&gt;&quot;],&quot;footer.case_studies&quot;:[0,&quot;Case Studies&quot;],&quot;footer.connect_2024&quot;:[0,&quot;Connect 2024&quot;],&quot;footer.terms_of_use&quot;:[0,&quot;Terms of Use&quot;],&quot;footer.white_papers&quot;:[0,&quot;White Papers&quot;],&quot;footer.cloudflare_tv&quot;:[0,&quot;Cloudflare TV&quot;],&quot;footer.community_hub&quot;:[0,&quot;Community Hub&quot;],&quot;footer.compare_plans&quot;:[0,&quot;Compare plans&quot;],&quot;footer.contact_sales&quot;:[0,&quot;Contact Sales&quot;],&quot;header.contact_sales&quot;:[0,&quot;Contact Sales&quot;],&quot;header.email_address&quot;:[0,&quot;Email Address&quot;],&quot;page.error.not_found&quot;:[0,&quot;Page not found&quot;],&quot;footer.developer_docs&quot;:[0,&quot;Developer docs&quot;],&quot;footer.privacy_policy&quot;:[0,&quot;Privacy Policy&quot;],&quot;footer.request_a_demo&quot;:[0,&quot;Request a demo&quot;],&quot;page.continue_reading&quot;:[0,&quot;Continue reading&quot;],&quot;footer.analysts_report&quot;:[0,&quot;Analyst reports&quot;],&quot;footer.for_enterprises&quot;:[0,&quot;For enterprises&quot;],&quot;footer.getting_started&quot;:[0,&quot;Getting Started&quot;],&quot;footer.learning_center&quot;:[0,&quot;Learning Center&quot;],&quot;footer.project_galileo&quot;:[0,&quot;Project Galileo&quot;],&quot;pagination.newer_posts&quot;:[0,&quot;Newer Posts&quot;],&quot;pagination.older_posts&quot;:[0,&quot;Older Posts&quot;],&quot;posts.social_buttons.x&quot;:[0,&quot;Discuss on X&quot;],&quot;search.icon_aria_label&quot;:[0,&quot;Search&quot;],&quot;search.source_location&quot;:[0,&quot;Source/Location&quot;],&quot;footer.about_cloudflare&quot;:[0,&quot;About Cloudflare&quot;],&quot;footer.athenian_project&quot;:[0,&quot;Athenian Project&quot;],&quot;footer.become_a_partner&quot;:[0,&quot;Become a partner&quot;],&quot;footer.cloudflare_radar&quot;:[0,&quot;Cloudflare Radar&quot;],&quot;footer.network_services&quot;:[0,&quot;Network services&quot;],&quot;footer.trust_and_safety&quot;:[0,&quot;Trust &amp; Safety&quot;],&quot;header.get_started_free&quot;:[0,&quot;Get Started Free&quot;],&quot;page.search.placeholder&quot;:[0,&quot;Search Cloudflare&quot;],&quot;footer.cloudflare_status&quot;:[0,&quot;Cloudflare Status&quot;],&quot;footer.cookie_preference&quot;:[0,&quot;Cookie Preferences&quot;],&quot;header.valid_email_error&quot;:[0,&quot;Must be valid email.&quot;],&quot;search.result_stat_empty&quot;:[0,&quot;Results &lt;strong&gt;{search_range}&lt;/strong&gt; of &lt;strong&gt;{search_total}&lt;/strong&gt;&quot;],&quot;footer.connectivity_cloud&quot;:[0,&quot;Connectivity cloud&quot;],&quot;footer.developer_services&quot;:[0,&quot;Developer services&quot;],&quot;footer.investor_relations&quot;:[0,&quot;Investor relations&quot;],&quot;page.not_found.error_code&quot;:[0,&quot;Error Code: 404&quot;],&quot;search.autocomplete_title&quot;:[0,&quot;Insert a query. Press enter to send&quot;],&quot;footer.logos_and_press_kit&quot;:[0,&quot;Logos &amp; press kit&quot;],&quot;footer.application_services&quot;:[0,&quot;Application services&quot;],&quot;footer.get_a_recommendation&quot;:[0,&quot;Get a recommendation&quot;],&quot;posts.social_buttons.reddit&quot;:[0,&quot;Discuss on Reddit&quot;],&quot;footer.sse_and_sase_services&quot;:[0,&quot;SSE and SASE services&quot;],&quot;page.not_found.outdated_link&quot;:[0,&quot;You may have used an outdated link, or you may have typed the address incorrectly.&quot;],&quot;footer.report_security_issues&quot;:[0,&quot;Report Security Issues&quot;],&quot;page.error.error_message_page&quot;:[0,&quot;Sorry, we can&#39;t find the page you are looking for.&quot;],&quot;header.subscribe_notifications&quot;:[0,&quot;Subscribe to receive notifications of new posts:&quot;],&quot;footer.cloudflare_for_campaigns&quot;:[0,&quot;Cloudflare for Campaigns&quot;],&quot;header.subscription_confimation&quot;:[0,&quot;Subscription confirmed. Thank you for subscribing!&quot;],&quot;posts.social_buttons.hackernews&quot;:[0,&quot;Discuss on Hacker News&quot;],&quot;footer.diversity_equity_inclusion&quot;:[0,&quot;Diversity, equity &amp; inclusion&quot;],&quot;footer.critical_infrastructure_defense_project&quot;:[0,&quot;Critical Infrastructure Defense Project&quot;]}]}" ssr client="load" opts="{&quot;name&quot;:&quot;PostCard&quot;,&quot;value&quot;:true}" await-children><article class="w-50-l  mt4 mt2-l mb4 ph3 bb b--gray8 bn-l"><div class="w-100"><a href="/cloudflare-incident-march-21-2025/" class="fw5 no-underline gray1" data-testid="post-title"><h2 class="fw5 mt2">Cloudflare incident on March 21, 2025</h2></a><p class="f3 fw5 gray5 my" data-testid="post-date">2025-03-25</p><div class=""><a href="/tag/cloudflare-r2/" class="dib pl2 pr2 pt1 pb1 mb2 bg-gray8 no-underline blue3 f2 mr1" data-testid="post-tag">R2 Storage</a><a href="/tag/outage/" class="dib pl2 pr2 pt1 pb1 mb2 bg-gray8 no-underline blue3 f2 mr1" data-testid="post-tag">Outage</a><a href="/tag/post-mortem/" class="dib pl2 pr2 pt1 pb1 mb2 bg-gray8 no-underline blue3 f2 mr1" data-testid="post-tag">Post Mortem</a></div><p class="f3 fw4 gray1 lh-copy " data-testid="post-content">On March 21, 2025, multiple Cloudflare services, including R2 object storage experienced an elevated rate of error responses. Here’s what caused the incident, the impact, and how we are making sure it<!-- -->...</p><ul class="author-lists flex pl0"><li class="list flex items-center pr2 mb3"><a href="/author/phillip/" class="static-avatar pr1"><img class="author-profile-image br-100 mr2" src="https://blog.cloudflare.com/cdn-cgi/image/format=auto,dpr=3,width=64,height=64,gravity=face,fit=crop,zoom=0.5/https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5KTNNpw9VHuwoZlwWsA7MN/c50f3f98d822a0fdce3196d7620d714e/phillip.jpg" alt="Phillip Jones" width="62" height="62"/></a><div class="author-name-tooltip"><a href="/author/phillip/" class="fw4 f3 no-underline black">Phillip Jones</a></div></li></ul></div></article><!--astro:end--></astro-island><astro-island uid="c5ouN" prefix="r3" component-url="/_astro/PostCard.DalyEN7z.js" component-export="PostCard" renderer-url="/_astro/client.DLO1yDVm.js" props="{&quot;currentPage&quot;:[0,1],&quot;isFeaturedImageFirstPost&quot;:[0,false],&quot;post&quot;:[0,{&quot;id&quot;:[0,&quot;mDiwAePfMfpVHMlYrfrFu&quot;],&quot;title&quot;:[0,&quot;Cloudflare incident on February 6, 2025&quot;],&quot;slug&quot;:[0,&quot;cloudflare-incident-on-february-6-2025&quot;],&quot;excerpt&quot;:[0,&quot;On Thursday, February 6, 2025, we experienced an outage with our object storage service (R2) and products that rely on it. Here&#39;s what happened and what we&#39;re doing to fix this going forward.&quot;],&quot;featured&quot;:[0],&quot;html&quot;:[0,&quot;&lt;p&gt;Multiple Cloudflare services, including our &lt;a href=\&quot;https://www.cloudflare.com/developer-platform/products/r2/\&quot;&gt;&lt;u&gt;R2 object storage&lt;/u&gt;&lt;/a&gt;, were unavailable for 59 minutes on Thursday, February 6, 2025. This caused all operations against R2 to fail for the duration of the incident, and caused a number of other Cloudflare services that depend on R2 — including &lt;a href=\&quot;https://www.cloudflare.com/developer-platform/products/cloudflare-stream/\&quot;&gt;&lt;u&gt;Stream&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://www.cloudflare.com/developer-platform/products/cloudflare-images/\&quot;&gt;&lt;u&gt;Images&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://www.cloudflare.com/developer-platform/products/cache-reserve/\&quot;&gt;&lt;u&gt;Cache Reserve&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://www.cloudflare.com/developer-platform/products/vectorize/\&quot;&gt;&lt;u&gt;Vectorize&lt;/u&gt;&lt;/a&gt; and &lt;a href=\&quot;https://developers.cloudflare.com/logs/edge-log-delivery/\&quot;&gt;&lt;u&gt;Log Delivery&lt;/u&gt;&lt;/a&gt; — to suffer significant failures.&lt;/p&gt;&lt;p&gt;The incident occurred due to human error and insufficient validation safeguards during a routine abuse remediation for a report about a phishing site hosted on R2. The action taken on the complaint resulted in an advanced product disablement action on the site that led to disabling the production R2 Gateway service responsible for the R2 API.  &lt;/p&gt;&lt;p&gt;Critically, this incident did &lt;b&gt;not&lt;/b&gt; result in the loss or corruption of any data stored on R2. &lt;/p&gt;&lt;p&gt;We’re deeply sorry for this incident: this was a failure of a number of controls, and we are prioritizing work to implement additional system-level controls related not only to our abuse processing systems, but so that we continue to reduce the blast radius of &lt;i&gt;any&lt;/i&gt; system- or human- action that could result in disabling any production service at Cloudflare.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;what-was-impacted\&quot;&gt;What was impacted?&lt;/h2&gt;\n            &lt;a href=\&quot;#what-was-impacted\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;All customers using Cloudflare R2 would have observed a 100% failure rate against their R2 buckets and objects during the primary incident window. Services that depend on R2 (detailed in the table below) observed heightened error rates and failure modes depending on their usage of R2.&lt;/p&gt;&lt;p&gt;The primary incident window occurred between 08:14 UTC to 09:13 UTC, when operations against R2 had a 100% error rate. Dependent services (detailed below) observed increased failure rates for operations that relied on R2.&lt;/p&gt;&lt;p&gt;From 09:13 UTC to 09:36 UTC, as R2 recovered and clients reconnected, the backlog and resulting spike in client operations caused load issues with R2&amp;#39;s metadata layer (built on Durable Objects). This impact was significantly more isolated: we observed a 0.09% increase in error rates in calls to Durable Objects running in North America during this window. &lt;/p&gt;&lt;p&gt;The following table details the impacted services, including the user-facing impact, operation failures, and increases in error rates observed:&lt;/p&gt;&lt;table&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Product/Service&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Impact&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;R2&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;100% of operations against R2 buckets and objects, including uploads, downloads, and associated metadata operations were impacted during the primary incident window. During the secondary incident window, we observed a &amp;lt;1% increase in errors as clients reconnected and increased pressure on R2&amp;#39;s metadata layer.&lt;/p&gt;&lt;p&gt;There was no data loss within the R2 storage subsystem: this incident impacted the HTTP frontend of R2. Separation of concerns and blast radius management meant that the underlying R2 infrastructure was unaffected by this.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Stream&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;100% of operations (upload &amp;amp; streaming delivery) against assets managed by Stream were impacted during the primary incident window.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Images&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;100% of operations (uploads &amp;amp; downloads) against assets managed by Images were impacted during the primary incident window.&lt;/p&gt;&lt;p&gt;Impact to Image Delivery was minor: success rate dropped to 97% as these assets are fetched from existing customer backends and do not rely on intermediate storage.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Cache Reserve&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Cache Reserve customers observed an increase in requests to their origin during the incident window as 100% of operations failed. This resulted in an increase in requests to origins to fetch assets unavailable in Cache Reserve during this period. This impacted less than 0.049% of all cacheable requests served during the incident window.&lt;/p&gt;&lt;p&gt;User-facing requests for assets to sites with Cache Reserve did not observe failures as cache misses failed over to the origin.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Log Delivery&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Log delivery was delayed during the primary incident window, resulting in significant delays (up to an hour) in log processing, as well as some dropped logs. &lt;/p&gt;&lt;p&gt;Specifically:&lt;/p&gt;&lt;p&gt;Non-R2 delivery jobs would have experienced up to 4.5% data loss during the incident. This level of data loss could have been different between jobs depending on log volume and buffer capacity in a given location.&lt;/p&gt;&lt;p&gt;R2 delivery jobs would have experienced up to 13.6% data loss during the incident. &lt;/p&gt;&lt;p&gt;R2 is a major destination for Cloudflare Logs. During the primary incident window, all available resources became saturated attempting to buffer and deliver data to R2. This prevented other jobs from acquiring resources to process their queues. Data loss (dropped logs) occurred when the job queues expired their data (to allow for new, incoming data). The system recovered when we enabled a kill switch to stop processing jobs sending data to R2.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Durable Objects&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Durable Objects, and services that rely on it for coordination &amp;amp; storage, were impacted as the stampeding horde of clients re-connecting to R2 drove an increase in load.&lt;/p&gt;&lt;p&gt;We observed a 0.09% actual increase in error rates in calls to Durable Objects running in North America, starting at 09:13 UTC and recovering by 09:36 UTC.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Cache Purge&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Requests to the Cache Purge API saw a 1.8% error rate (HTTP 5xx) increase and a 10x increase in p90 latency for purge operations during the primary incident window. Error rates returned to normal immediately after this.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Vectorize&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;Queries and operations against Vectorize indexes were impacted during the primary incident window. 75% of queries to indexes failed (the remainder were served out of cache) and 100% of insert, upsert, and delete operations failed during the incident window as Vectorize depends on R2 for persistent storage. Once R2 recovered, Vectorize systems recovered in full.&lt;/p&gt;&lt;p&gt;We observed no continued impact during the secondary incident window, and we have not observed any index corruption as the Vectorize system has protections in place for this.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Key Transparency Auditor&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;100% of signature publish &amp;amp; read operations to the KT auditor service failed during the primary incident window. No third party reads occurred during this window and thus were not impacted by the incident.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Workers &amp;amp; Pages&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;A small volume (0.002%) of deployments to Workers and Pages projects failed during the primary incident window. These failures were limited to services with bindings to R2, as our control plane was unable to communicate with the R2 service during this period.&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;incident-timeline-and-impact\&quot;&gt;Incident timeline and impact&lt;/h2&gt;\n            &lt;a href=\&quot;#incident-timeline-and-impact\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;The incident timeline, including the initial impact, investigation, root cause, and remediation, are detailed below.&lt;/p&gt;&lt;p&gt;&lt;b&gt;All timestamps referenced are in Coordinated Universal Time (UTC).&lt;/b&gt;&lt;/p&gt;&lt;style type=\&quot;text/css\&quot;&gt;\n.tg  {border-collapse:collapse;border-spacing:0;margin:0px auto;}\n.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n  overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n.tg .tg-mwxp{background-color:#FFF;color:#172B4D;font-style:italic;text-align:left;vertical-align:top}\n.tg .tg-amwm{font-weight:bold;text-align:center;vertical-align:top}\n.tg .tg-6t3r{font-style:italic;font-weight:bold;text-align:left;vertical-align:top}\n.tg .tg-0lax{text-align:left;vertical-align:top}\n@media screen and (max-width: 767px) {.tg {width: auto !important;}.tg col {width: auto !important;}.tg-wrap {overflow-x: auto;-webkit-overflow-scrolling: touch;margin: auto 0px;}}&lt;/style&gt;\n&lt;div class=\&quot;tg-wrap\&quot;&gt;&lt;table class=\&quot;tg\&quot; style=\&quot;undefined;table-layout: fixed; width: 689px\&quot;&gt;&lt;colgroup&gt;\n&lt;col style=\&quot;width: 137.444444px\&quot;&gt;\n&lt;col style=\&quot;width: 551.444444px\&quot;&gt;\n&lt;/colgroup&gt;\n&lt;thead&gt;\n  &lt;tr&gt;\n    &lt;th class=\&quot;tg-amwm\&quot;&gt;&lt;span style=\&quot;font-weight:700;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Time&lt;/span&gt;&lt;/th&gt;\n    &lt;th class=\&quot;tg-amwm\&quot;&gt;&lt;span style=\&quot;font-weight:700;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Event&lt;/span&gt;&lt;/th&gt;\n  &lt;/tr&gt;&lt;/thead&gt;\n&lt;tbody&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-6t3r\&quot;&gt;&lt;span style=\&quot;font-weight:700;font-style:italic;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;2025-02-06 08:12&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-mwxp\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:italic;text-decoration:none;color:#172B4D;background-color:#FFF\&quot;&gt;The R2 Gateway service is inadvertently disabled while responding to an abuse report.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-6t3r\&quot;&gt;&lt;span style=\&quot;font-weight:700;font-style:italic;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;2025-02-06 08:14&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-1wig\&quot;&gt;&lt;span style=\&quot;font-weight:700;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;-- IMPACT BEGINS --&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-6t3r\&quot;&gt;&lt;span style=\&quot;font-weight:700;font-style:italic;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;2025-02-06 08:15&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;R2 service metrics begin to show signs of service degradation.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-6t3r\&quot;&gt;&lt;span style=\&quot;font-weight:700;font-style:italic;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;2025-02-06 08:17&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Critical R2 alerts begin to fire due to our service no longer responding to our health checks.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-6t3r\&quot;&gt;&lt;span style=\&quot;font-weight:700;font-style:italic;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;2025-02-06 08:18&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;R2 on-call engaged and began looking at our operational dashboards and service logs to understand impact to availability.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-6t3r\&quot;&gt;&lt;span style=\&quot;font-weight:700;font-style:italic;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;2025-02-06 08:23&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Sales engineering escalated to the R2 engineering team that customers are experiencing a rapid increase in HTTP 500’s from all R2 APIs.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-6t3r\&quot;&gt;&lt;span style=\&quot;font-weight:700;font-style:italic;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;2025-02-06 08:25 &lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Internal incident declared.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-6t3r\&quot;&gt;&lt;span style=\&quot;font-weight:700;font-style:italic;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;2025-02-06 08:33&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;R2 on-call was unable to identify the root cause and escalated to the lead on-call for assistance.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-6t3r\&quot;&gt;&lt;span style=\&quot;font-weight:700;font-style:italic;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;2025-02-06 08:42&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;Root cause identified as R2 team reviews service deployment history and configuration, which surfaces the action and the validation gap that allowed this to impact a production service.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-6t3r\&quot;&gt;&lt;span style=\&quot;font-weight:700;font-style:italic;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;2025-02-06 08:46&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;On-call attempts to re-enable the R2 Gateway service using our internal admin tooling, however this tooling was unavailable because it relies on R2.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-6t3r\&quot;&gt;&lt;span style=\&quot;font-weight:700;font-style:italic;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;2025-02-06 08:49&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;On-call escalates to an operations team who has lower level system access and can re-enable the R2 Gateway service. &lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-6t3r\&quot;&gt;&lt;span style=\&quot;font-weight:700;font-style:italic;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;2025-02-06 08:57&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;The operations team engaged and began to re-enable the R2 Gateway service.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-6t3r\&quot;&gt;&lt;span style=\&quot;font-weight:700;font-style:italic;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;2025-02-06 09:09&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;R2 team triggers a redeployment of the R2 Gateway service.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-6t3r\&quot;&gt;&lt;span style=\&quot;font-weight:700;font-style:italic;text-decoration:none;color:#000;background-color:transparent\&quot;&gt; 2025-02-06 09:10&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;R2 began to recover as the forced re-deployment rolled out as clients were able to reconnect to R2.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-6t3r\&quot;&gt;&lt;span style=\&quot;font-weight:700;font-style:italic;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;2025-02-06 09:13&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-1wig\&quot;&gt;&lt;span style=\&quot;font-weight:700;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;-- IMPACT ENDS --&lt;/span&gt;&lt;br&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;R2 availability recovers to within its service-level objective (SLO). Durable Objects begins to observe a slight increase in error rate (0.09%) for Durable Objects running in North America due to the spike in R2 clients reconnecting.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-6t3r\&quot;&gt;&lt;span style=\&quot;font-weight:700;font-style:italic;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;2025-02-06 09:36&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;The Durable Objects error rate recovers.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td class=\&quot;tg-6t3r\&quot;&gt;&lt;span style=\&quot;font-weight:700;font-style:italic;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;2025-02-06 10:29&lt;/span&gt;&lt;/td&gt;\n    &lt;td class=\&quot;tg-0lax\&quot;&gt;&lt;span style=\&quot;font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent\&quot;&gt;The incident is closed after monitoring error rates.&lt;/span&gt;&lt;/td&gt;\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;p&gt;At the R2 service level, our internal Prometheus metrics showed R2’s SLO near-immediately drop to 0% as R2’s Gateway service stopped serving all requests and terminated in-flight requests.&lt;/p&gt;&lt;p&gt;The slight delay in failure was due to the product disablement action taking 1–2 minutes to take effect as well as our configured metrics aggregation intervals:&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4pbONRcG99RWttIUyGqnI6/bad397f73762a706285ea143ed2418b3/BLOG-2685_2.png\&quot; alt=\&quot;BLOG-2685 2\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;844\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;For context, R2’s architecture separates the Gateway service, which is responsible for authenticating and serving requests to R2’s S3 &amp;amp; REST APIs and is the “front door” for R2 — its metadata store (built on Durable Objects), our intermediate caches, and the underlying, distributed storage subsystem responsible for durably storing objects. &lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/E2cgDKA2zGwaQDBs31tPk/4272c94625fd788148d16a90cc7cceaa/Image_20250206_172217_707.png\&quot; alt=\&quot;BLOG-2685 3\&quot; class=\&quot;kg-image\&quot; width=\&quot;2324\&quot; height=\&quot;1000\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;During the incident, all other components of R2 remained up: this is what allowed the service to recover so quickly once the R2 Gateway service was restored and re-deployed. The R2 Gateway acts as the coordinator for all work when operations are made against R2. During the request lifecycle, we validate authentication and authorization, write any new data to a new immutable key in our object store, then update our metadata layer to point to the new object. When the service was disabled, all running processes stopped.&lt;/p&gt;&lt;p&gt;While this means that all in-flight and subsequent requests fail, anything that had received a HTTP 200 response had already succeeded with no risk of reverting to a prior version when the service recovered. This is critical to R2’s consistency guarantees and mitigates the chance of a client receiving a successful API response without the underlying metadata &lt;i&gt;and &lt;/i&gt;storage infrastructure having persisted the change.  &lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;deep-dive\&quot;&gt;Deep dive &lt;/h2&gt;\n            &lt;a href=\&quot;#deep-dive\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;&lt;b&gt;Due to human error and insufficient validation safeguards in our admin tooling, the R2 Gateway service was taken down as part of a routine remediation for a phishing URL.&lt;/b&gt;&lt;/p&gt;&lt;p&gt;During a routine abuse remediation, action was taken on a complaint that inadvertently disabled the R2 Gateway service instead of the specific endpoint/bucket associated with the report. This was a failure of multiple system level controls (first and foremost) and operator training. &lt;/p&gt;&lt;p&gt;A key system-level control that led to this incident was in how we identify (or &amp;quot;tag&amp;quot;) internal accounts used by our teams. Teams typically have multiple accounts (dev, staging, prod) to reduce the blast radius of any configuration changes or deployments, but our abuse processing systems were not explicitly configured to identify these accounts and block disablement actions against them. Instead of disabling the specific endpoint associated with the abuse report, the system allowed the operator to (incorrectly) disable the R2 Gateway service. &lt;/p&gt;&lt;p&gt;Once we identified this as the cause of the outage, remediation and recovery was inhibited by the lack of direct controls to revert the product disablement action and the need to engage an operations team with lower level access than is routine. The R2 Gateway service then required a re-deployment in order to rebuild its routing pipeline across our edge network.&lt;/p&gt;&lt;p&gt;Once re-deployed, clients were able to re-connect to R2, and error rates for dependent services (including Stream, Images, Cache Reserve and Vectorize) returned to normal levels.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;remediation-and-follow-up-steps\&quot;&gt;Remediation and follow-up steps&lt;/h2&gt;\n            &lt;a href=\&quot;#remediation-and-follow-up-steps\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;We have taken immediate steps to resolve the validation gaps in our tooling to prevent this specific failure from occurring in the future.&lt;/p&gt;&lt;p&gt;We are prioritizing several work-streams to implement stronger, system-wide controls (defense-in-depth) to prevent this, including how we provision internal accounts so that we are not relying on our teams to correctly and reliably tag accounts. A key theme to our remediation efforts here is around removing the need to rely on training or process, and instead ensuring that our systems have the right guardrails and controls built-in to prevent operator errors.&lt;/p&gt;&lt;p&gt;These work-streams include (but are not limited to) the following:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Actioned: &lt;/b&gt;deployed additional guardrails implemented in the Admin API to prevent product disablement of services running in internal accounts.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Actioned&lt;/b&gt;: Product disablement actions in the abuse review UI have been disabled while we add more robust safeguards. This will prevent us from inadvertently repeating similar high-risk manual actions.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;In-flight&lt;/b&gt;: Changing how we create all internal accounts (staging, dev, production) to ensure that all accounts are correctly provisioned into the correct organization. This must include protections against creating standalone accounts to avoid re-occurrence of this incident (or similar) in the future.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;In-flight: &lt;/b&gt;Further restricting access to product disablement actions beyond the remediations recommended by the system to a smaller group of senior operators.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;In-flight&lt;/b&gt;: Two-party approval required for ad-hoc product disablement actions. Going forward, if an investigator requires additional remediations, they must be submitted to a manager or a person on our approved remediation acceptance list to approve their additional actions on an abuse report. &lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;In-flight&lt;/b&gt;: Expand existing abuse checks that prevent accidental blocking of internal hostnames to also prevent any product disablement action of products associated with an internal Cloudflare account.  &lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;In-flight&lt;/b&gt;: Internal accounts are being moved to our new Organizations model ahead of public release of this feature. The R2 production account was a member of this organization, but our abuse remediation engine did not have the necessary protections to prevent acting against accounts within this organization.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;We’re continuing to discuss &amp;amp; review additional steps and effort that can continue to reduce the blast radius of any system- or human- action that could result in disabling any production service at Cloudflare.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;conclusion\&quot;&gt;Conclusion&lt;/h2&gt;\n            &lt;a href=\&quot;#conclusion\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;We understand this was a serious incident, and we are painfully aware of — and extremely sorry for — the impact it caused to customers and teams building and running their businesses on Cloudflare.&lt;/p&gt;&lt;p&gt;This is the first (and ideally, the last) incident of this kind and duration for R2, and we’re committed to improving controls across our systems and workflows to prevent this in the future.&lt;/p&gt;&quot;],&quot;published_at&quot;:[0,&quot;2025-02-06T16:00-08:00&quot;],&quot;updated_at&quot;:[0,&quot;2025-02-07T20:37:36.839Z&quot;],&quot;feature_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1JR64uLhxWHgQPhhOlkyTt/dc50a43a0475ab8a0069bb8fce372e47/Screenshot_2025-02-06_at_4.54.16_PM.png&quot;],&quot;tags&quot;:[1,[[0,{&quot;id&quot;:[0,&quot;3cCNoJJ5uusKFBLYKFX1jB&quot;],&quot;name&quot;:[0,&quot;Post Mortem&quot;],&quot;slug&quot;:[0,&quot;post-mortem&quot;]}],[0,{&quot;id&quot;:[0,&quot;4yliZlpBPZpOwBDZzo1tTh&quot;],&quot;name&quot;:[0,&quot;Outage&quot;],&quot;slug&quot;:[0,&quot;outage&quot;]}],[0,{&quot;id&quot;:[0,&quot;7JpaihvGGjNhG2v4nTxeFV&quot;],&quot;name&quot;:[0,&quot;R2 Storage&quot;],&quot;slug&quot;:[0,&quot;cloudflare-r2&quot;]}]]],&quot;relatedTags&quot;:[0],&quot;authors&quot;:[1,[[0,{&quot;name&quot;:[0,&quot;Matt Silverlock&quot;],&quot;slug&quot;:[0,&quot;silverlock&quot;],&quot;bio&quot;:[0,&quot;Director of Product at Cloudflare.&quot;],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7xP5qePZD9eyVtwIesXYxh/e714aaa573161ec9eb48d59bd1aa6225/silverlock.jpeg&quot;],&quot;location&quot;:[0,null],&quot;website&quot;:[0,null],&quot;twitter&quot;:[0,&quot;@elithrar&quot;],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}],[0,{&quot;name&quot;:[0,&quot;Javier Castro&quot;],&quot;slug&quot;:[0,&quot;javier&quot;],&quot;bio&quot;:[0,null],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3hJsvxP0uRGmk4DjS9IdSW/0197c661fe20e1ebc9922768d727df02/javier.png&quot;],&quot;location&quot;:[0,null],&quot;website&quot;:[0,null],&quot;twitter&quot;:[0,null],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}]]],&quot;meta_description&quot;:[0,&quot;On Thursday February 6th, we experienced an outage with our object storage service (R2) and products that rely on it. Here&#39;s what happened and what we&#39;re doing to fix this going forward.&quot;],&quot;primary_author&quot;:[0,{}],&quot;localeList&quot;:[0,{&quot;name&quot;:[0,&quot;blog-english-only&quot;],&quot;enUS&quot;:[0,&quot;English for Locale&quot;],&quot;zhCN&quot;:[0,&quot;No Page for Locale&quot;],&quot;zhHansCN&quot;:[0,&quot;No Page for Locale&quot;],&quot;zhTW&quot;:[0,&quot;No Page for Locale&quot;],&quot;frFR&quot;:[0,&quot;No Page for Locale&quot;],&quot;deDE&quot;:[0,&quot;No Page for Locale&quot;],&quot;itIT&quot;:[0,&quot;No Page for Locale&quot;],&quot;jaJP&quot;:[0,&quot;No Page for Locale&quot;],&quot;koKR&quot;:[0,&quot;No Page for Locale&quot;],&quot;ptBR&quot;:[0,&quot;No Page for Locale&quot;],&quot;esLA&quot;:[0,&quot;No Page for Locale&quot;],&quot;esES&quot;:[0,&quot;No Page for Locale&quot;],&quot;enAU&quot;:[0,&quot;No Page for Locale&quot;],&quot;enCA&quot;:[0,&quot;No Page for Locale&quot;],&quot;enIN&quot;:[0,&quot;No Page for Locale&quot;],&quot;enGB&quot;:[0,&quot;No Page for Locale&quot;],&quot;idID&quot;:[0,&quot;No Page for Locale&quot;],&quot;ruRU&quot;:[0,&quot;No Page for Locale&quot;],&quot;svSE&quot;:[0,&quot;No Page for Locale&quot;],&quot;viVN&quot;:[0,&quot;No Page for Locale&quot;],&quot;plPL&quot;:[0,&quot;No Page for Locale&quot;],&quot;arAR&quot;:[0,&quot;No Page for Locale&quot;],&quot;nlNL&quot;:[0,&quot;No Page for Locale&quot;],&quot;thTH&quot;:[0,&quot;No Page for Locale&quot;],&quot;trTR&quot;:[0,&quot;No Page for Locale&quot;],&quot;heIL&quot;:[0,&quot;No Page for Locale&quot;],&quot;lvLV&quot;:[0,&quot;No Page for Locale&quot;],&quot;etEE&quot;:[0,&quot;No Page for Locale&quot;],&quot;ltLT&quot;:[0,&quot;No Page for Locale&quot;]}],&quot;url&quot;:[0,&quot;https://blog.cloudflare.com/cloudflare-incident-on-february-6-2025&quot;],&quot;metadata&quot;:[0,{&quot;title&quot;:[0,&quot;Cloudflare incident on February 6, 2025&quot;],&quot;description&quot;:[0,&quot;On Thursday, February 6, 2025, we experienced an outage with our object storage service (R2) and products that rely on it. Here&#39;s what happened and what we&#39;re doing to fix this going forward.&quot;],&quot;imgPreview&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/JjRBjBprqgy01LVreSbzM/9744518638a7c5c7072d3e29bdf8e267/BLOG-2685_OG.png&quot;]}],&quot;publicly_index&quot;:[0,true]}],&quot;translations&quot;:[0,{&quot;posts.by&quot;:[0,&quot;By&quot;],&quot;footer.gdpr&quot;:[0,&quot;GDPR&quot;],&quot;lang_blurb1&quot;:[0,&quot;This post is also available in {lang1}.&quot;],&quot;lang_blurb2&quot;:[0,&quot;This post is also available in {lang1} and {lang2}.&quot;],&quot;lang_blurb3&quot;:[0,&quot;This post is also available in {lang1}, {lang2} and {lang3}.&quot;],&quot;footer.press&quot;:[0,&quot;Press&quot;],&quot;header.title&quot;:[0,&quot;The Cloudflare Blog&quot;],&quot;search.clear&quot;:[0,&quot;Clear&quot;],&quot;search.filter&quot;:[0,&quot;Filter&quot;],&quot;search.source&quot;:[0,&quot;Source&quot;],&quot;footer.careers&quot;:[0,&quot;Careers&quot;],&quot;footer.company&quot;:[0,&quot;Company&quot;],&quot;footer.support&quot;:[0,&quot;Support&quot;],&quot;footer.the_net&quot;:[0,&quot;theNet&quot;],&quot;search.filters&quot;:[0,&quot;Filters&quot;],&quot;footer.our_team&quot;:[0,&quot;Our team&quot;],&quot;footer.webinars&quot;:[0,&quot;Webinars&quot;],&quot;page.more_posts&quot;:[0,&quot;More posts&quot;],&quot;posts.time_read&quot;:[0,&quot;{time} min read&quot;],&quot;search.language&quot;:[0,&quot;Language&quot;],&quot;footer.community&quot;:[0,&quot;Community&quot;],&quot;footer.resources&quot;:[0,&quot;Resources&quot;],&quot;footer.solutions&quot;:[0,&quot;Solutions&quot;],&quot;footer.trademark&quot;:[0,&quot;Trademark&quot;],&quot;header.subscribe&quot;:[0,&quot;Subscribe&quot;],&quot;footer.compliance&quot;:[0,&quot;Compliance&quot;],&quot;footer.free_plans&quot;:[0,&quot;Free plans&quot;],&quot;footer.impact_ESG&quot;:[0,&quot;Impact/ESG&quot;],&quot;posts.follow_on_X&quot;:[0,&quot;Follow on X&quot;],&quot;footer.help_center&quot;:[0,&quot;Help center&quot;],&quot;footer.network_map&quot;:[0,&quot;Network Map&quot;],&quot;header.please_wait&quot;:[0,&quot;Please Wait&quot;],&quot;page.related_posts&quot;:[0,&quot;Related posts&quot;],&quot;search.result_stat&quot;:[0,&quot;Results &lt;strong&gt;{search_range}&lt;/strong&gt; of &lt;strong&gt;{search_total}&lt;/strong&gt; for &lt;strong&gt;{search_keyword}&lt;/strong&gt;&quot;],&quot;footer.case_studies&quot;:[0,&quot;Case Studies&quot;],&quot;footer.connect_2024&quot;:[0,&quot;Connect 2024&quot;],&quot;footer.terms_of_use&quot;:[0,&quot;Terms of Use&quot;],&quot;footer.white_papers&quot;:[0,&quot;White Papers&quot;],&quot;footer.cloudflare_tv&quot;:[0,&quot;Cloudflare TV&quot;],&quot;footer.community_hub&quot;:[0,&quot;Community Hub&quot;],&quot;footer.compare_plans&quot;:[0,&quot;Compare plans&quot;],&quot;footer.contact_sales&quot;:[0,&quot;Contact Sales&quot;],&quot;header.contact_sales&quot;:[0,&quot;Contact Sales&quot;],&quot;header.email_address&quot;:[0,&quot;Email Address&quot;],&quot;page.error.not_found&quot;:[0,&quot;Page not found&quot;],&quot;footer.developer_docs&quot;:[0,&quot;Developer docs&quot;],&quot;footer.privacy_policy&quot;:[0,&quot;Privacy Policy&quot;],&quot;footer.request_a_demo&quot;:[0,&quot;Request a demo&quot;],&quot;page.continue_reading&quot;:[0,&quot;Continue reading&quot;],&quot;footer.analysts_report&quot;:[0,&quot;Analyst reports&quot;],&quot;footer.for_enterprises&quot;:[0,&quot;For enterprises&quot;],&quot;footer.getting_started&quot;:[0,&quot;Getting Started&quot;],&quot;footer.learning_center&quot;:[0,&quot;Learning Center&quot;],&quot;footer.project_galileo&quot;:[0,&quot;Project Galileo&quot;],&quot;pagination.newer_posts&quot;:[0,&quot;Newer Posts&quot;],&quot;pagination.older_posts&quot;:[0,&quot;Older Posts&quot;],&quot;posts.social_buttons.x&quot;:[0,&quot;Discuss on X&quot;],&quot;search.icon_aria_label&quot;:[0,&quot;Search&quot;],&quot;search.source_location&quot;:[0,&quot;Source/Location&quot;],&quot;footer.about_cloudflare&quot;:[0,&quot;About Cloudflare&quot;],&quot;footer.athenian_project&quot;:[0,&quot;Athenian Project&quot;],&quot;footer.become_a_partner&quot;:[0,&quot;Become a partner&quot;],&quot;footer.cloudflare_radar&quot;:[0,&quot;Cloudflare Radar&quot;],&quot;footer.network_services&quot;:[0,&quot;Network services&quot;],&quot;footer.trust_and_safety&quot;:[0,&quot;Trust &amp; Safety&quot;],&quot;header.get_started_free&quot;:[0,&quot;Get Started Free&quot;],&quot;page.search.placeholder&quot;:[0,&quot;Search Cloudflare&quot;],&quot;footer.cloudflare_status&quot;:[0,&quot;Cloudflare Status&quot;],&quot;footer.cookie_preference&quot;:[0,&quot;Cookie Preferences&quot;],&quot;header.valid_email_error&quot;:[0,&quot;Must be valid email.&quot;],&quot;search.result_stat_empty&quot;:[0,&quot;Results &lt;strong&gt;{search_range}&lt;/strong&gt; of &lt;strong&gt;{search_total}&lt;/strong&gt;&quot;],&quot;footer.connectivity_cloud&quot;:[0,&quot;Connectivity cloud&quot;],&quot;footer.developer_services&quot;:[0,&quot;Developer services&quot;],&quot;footer.investor_relations&quot;:[0,&quot;Investor relations&quot;],&quot;page.not_found.error_code&quot;:[0,&quot;Error Code: 404&quot;],&quot;search.autocomplete_title&quot;:[0,&quot;Insert a query. Press enter to send&quot;],&quot;footer.logos_and_press_kit&quot;:[0,&quot;Logos &amp; press kit&quot;],&quot;footer.application_services&quot;:[0,&quot;Application services&quot;],&quot;footer.get_a_recommendation&quot;:[0,&quot;Get a recommendation&quot;],&quot;posts.social_buttons.reddit&quot;:[0,&quot;Discuss on Reddit&quot;],&quot;footer.sse_and_sase_services&quot;:[0,&quot;SSE and SASE services&quot;],&quot;page.not_found.outdated_link&quot;:[0,&quot;You may have used an outdated link, or you may have typed the address incorrectly.&quot;],&quot;footer.report_security_issues&quot;:[0,&quot;Report Security Issues&quot;],&quot;page.error.error_message_page&quot;:[0,&quot;Sorry, we can&#39;t find the page you are looking for.&quot;],&quot;header.subscribe_notifications&quot;:[0,&quot;Subscribe to receive notifications of new posts:&quot;],&quot;footer.cloudflare_for_campaigns&quot;:[0,&quot;Cloudflare for Campaigns&quot;],&quot;header.subscription_confimation&quot;:[0,&quot;Subscription confirmed. Thank you for subscribing!&quot;],&quot;posts.social_buttons.hackernews&quot;:[0,&quot;Discuss on Hacker News&quot;],&quot;footer.diversity_equity_inclusion&quot;:[0,&quot;Diversity, equity &amp; inclusion&quot;],&quot;footer.critical_infrastructure_defense_project&quot;:[0,&quot;Critical Infrastructure Defense Project&quot;]}]}" ssr client="load" opts="{&quot;name&quot;:&quot;PostCard&quot;,&quot;value&quot;:true}" await-children><article class="w-50-l  mt4 mt2-l mb4 ph3 bb b--gray8 bn-l"><div class="w-100"><a href="/cloudflare-incident-on-february-6-2025/" class="fw5 no-underline gray1" data-testid="post-title"><h2 class="fw5 mt2">Cloudflare incident on February 6, 2025</h2></a><p class="f3 fw5 gray5 my" data-testid="post-date">2025-02-07</p><div class=""><a href="/tag/post-mortem/" class="dib pl2 pr2 pt1 pb1 mb2 bg-gray8 no-underline blue3 f2 mr1" data-testid="post-tag">Post Mortem</a><a href="/tag/outage/" class="dib pl2 pr2 pt1 pb1 mb2 bg-gray8 no-underline blue3 f2 mr1" data-testid="post-tag">Outage</a><a href="/tag/cloudflare-r2/" class="dib pl2 pr2 pt1 pb1 mb2 bg-gray8 no-underline blue3 f2 mr1" data-testid="post-tag">R2 Storage</a></div><p class="f3 fw4 gray1 lh-copy " data-testid="post-content">On Thursday, February 6, 2025, we experienced an outage with our object storage service (R2) and products that rely on it. Here&#x27;s what happened and what we&#x27;re doing to fix this going forward.<!-- -->...</p><ul class="author-lists flex pl0"><li class="list flex items-center pr2 mb3"><a href="/author/silverlock/" class="static-avatar pr1"><img class="author-profile-image br-100 mr2" src="https://blog.cloudflare.com/cdn-cgi/image/format=auto,dpr=3,width=64,height=64,gravity=face,fit=crop,zoom=0.5/https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7xP5qePZD9eyVtwIesXYxh/e714aaa573161ec9eb48d59bd1aa6225/silverlock.jpeg" alt="Matt Silverlock" width="62" height="62"/></a><div class="author-name-tooltip"><a href="/author/silverlock/" class="fw4 f3 no-underline black">Matt Silverlock</a></div></li><li class="list flex items-center pr2 mb3"><a href="/author/javier/" class="static-avatar pr1"><img class="author-profile-image br-100 mr2" src="https://blog.cloudflare.com/cdn-cgi/image/format=auto,dpr=3,width=64,height=64,gravity=face,fit=crop,zoom=0.5/https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3hJsvxP0uRGmk4DjS9IdSW/0197c661fe20e1ebc9922768d727df02/javier.png" alt="Javier Castro" width="62" height="62"/></a><div class="author-name-tooltip"><a href="/author/javier/" class="fw4 f3 no-underline black">Javier Castro</a></div></li></ul></div></article><!--astro:end--></astro-island><astro-island uid="zfc5U" prefix="r4" component-url="/_astro/PostCard.DalyEN7z.js" component-export="PostCard" renderer-url="/_astro/client.DLO1yDVm.js" props="{&quot;currentPage&quot;:[0,1],&quot;isFeaturedImageFirstPost&quot;:[0,false],&quot;post&quot;:[0,{&quot;id&quot;:[0,&quot;4oLkLHLIZ1vibq8dtPJP6F&quot;],&quot;title&quot;:[0,&quot;Cloudflare 2024 Year in Review&quot;],&quot;slug&quot;:[0,&quot;radar-2024-year-in-review&quot;],&quot;excerpt&quot;:[0,&quot;The 2024 Cloudflare Radar Year in Review is our fifth annual review of Internet trends and patterns at both a global and country/region level.&quot;],&quot;featured&quot;:[0,false],&quot;html&quot;:[0,&quot;&lt;p&gt;The &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024\&quot;&gt;2024 Cloudflare Radar Year in Review&lt;/a&gt; is our fifth annual review of Internet trends and patterns observed throughout the year at both a global and country/region level across a variety of metrics. In this year’s review, we have added several new traffic, adoption, connectivity, and email security metrics, as well as the ability to do year-over-year and geographic comparisons for selected metrics. &lt;/p&gt;&lt;p&gt;Below, we present a summary of key findings, and then explore them in more detail in subsequent sections.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;key-findings\&quot;&gt;Key Findings&lt;/h2&gt;\n            &lt;a href=\&quot;#key-findings\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          \n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;traffic\&quot;&gt;Traffic&lt;/h3&gt;\n            &lt;a href=\&quot;#traffic\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;ul&gt;&lt;li&gt;&lt;p&gt;Global Internet traffic grew 17.2% in 2024. &lt;a href=\&quot;#global-internet-traffic-grew-17-2-in-2024\&quot;&gt;&lt;u&gt;🔗&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Google maintained its position as the most popular Internet service overall. OpenAI remained at the top of the Generative AI category. Binance remained at the top of the Cryptocurrency category. WhatsApp remained the top Messaging platform, and Facebook remained the top Social Media site. &lt;a href=\&quot;#google-maintained-its-position-as-the-most-popular-internet-service-openai-binance-whatsapp-and-facebook-led-their-respective-categories\&quot;&gt;&lt;u&gt;🔗&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Global traffic from Starlink grew 3.3x in 2024, in line with last year’s growth rate. After initiating service in Malawi in July 2023, Starlink traffic from that country grew 38x in 2024. As Starlink added new markets, we saw traffic grow rapidly in those locations. &lt;a href=\&quot;#global-traffic-from-starlink-grew-3-3x-in-2024-in-line-with-last-years-growth-rate-after-initiating-service-in-malawi-in-july-2023-starlink-traffic-from-that-country-grew-38x-in-2024\&quot;&gt;&lt;u&gt;🔗&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Googlebot, Google’s web crawler, was responsible for the highest volume of request traffic to Cloudflare in 2024, as it retrieved content from millions of Cloudflare customer sites for search indexing. &lt;a href=\&quot;#google-maintained-its-position-as-the-most-popular-internet-service-openai-binance-whatsapp-and-facebook-led-their-respective-categories\&quot;&gt;&lt;u&gt;🔗&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Traffic from ByteDance’s AI crawler (Bytespider) gradually declined over the course of 2024. Anthropic’s AI crawler (ClaudeBot) first started showing signs of ongoing crawling activity in April, then declined after an initial peak in May &amp;amp; June. &lt;a href=\&quot;#among-ai-bots-and-crawlers-bytespider-bytedance-traffic-gradually-declined-over-the-course-of-2024-while-claudebot-anthropic-was-more-active-during-the-back-half-of-the-year\&quot;&gt;&lt;u&gt;🔗&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;13.0% of TLS 1.3 traffic is using post-quantum encryption. &lt;a href=\&quot;#13-0-of-tls-1-3-traffic-is-using-post-quantum-encryption\&quot;&gt;&lt;u&gt;🔗&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;adoption-usage\&quot;&gt;Adoption &amp;amp; Usage&lt;/h3&gt;\n            &lt;a href=\&quot;#adoption-usage\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;ul&gt;&lt;li&gt;&lt;p&gt;Globally, nearly one-third of mobile device traffic was from Apple iOS devices. Android had a &amp;gt;90% share of mobile device traffic in 29 countries/regions; peak iOS mobile device traffic share was over 60% in eight countries/regions. &lt;a href=\&quot;#globally-nearly-one-third-of-mobile-device-traffic-was-from-apple-ios-devices-android-had-a-90-share-of-mobile-device-traffic-in-29-countries-regions-peak-ios-mobile-device-traffic-share-was-over-60-in-eight-countries-regions\&quot;&gt;&lt;u&gt;🔗&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Globally, nearly half of web requests used HTTP/2, with 20.5% using HTTP/3. Usage of both versions was up slightly from 2023. &lt;a href=\&quot;#globally-nearly-half-of-web-requests-used-http-2-with-20-5-using-http-3\&quot;&gt;&lt;u&gt;🔗&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;React, PHP, and jQuery were among the most popular technologies used to build websites, while HubSpot, Google, and WordPress were among the most popular vendors of supporting services and platforms. &lt;a href=\&quot;#react-php-and-jquery-were-among-the-most-popular-technologies-used-to-build-websites-while-hubspot-google-and-wordpress-were-among-the-most-popular-vendors-of-supporting-services-and-platforms\&quot;&gt;&lt;u&gt;🔗&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Go surpassed NodeJS as the most popular language used for making automated API requests. &lt;a href=\&quot;#go-surpassed-nodejs-as-the-most-popular-language-used-for-making-automated-api-requests\&quot;&gt;&lt;u&gt;🔗&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Google is far and away the most popular search engine globally, across all platforms. On mobile devices and operating systems, Baidu is a distant second. Bing is a distant second across desktop and Windows devices, with DuckDuckGo second most popular on macOS. Shares vary by platform and country/region. &lt;a href=\&quot;#google-is-the-most-popular-search-engine-globally-across-all-platforms-on-mobile-devices-os-baidu-is-a-distant-second-bing-is-a-distant-second-across-desktop-and-windows-devices-with-duckduckgo-second-most-popular-on-macos\&quot;&gt;&lt;u&gt;🔗&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Google Chrome is far and away the most popular browser overall. While this is also true on macOS devices, Safari usage is well ahead of Chrome on iOS devices. On Windows, Edge is the second most popular browser as it comes preinstalled and is the initial default. &lt;a href=\&quot;#google-chrome-is-the-most-popular-browser-overall-while-also-true-on-macos-devices-safari-usage-is-well-ahead-of-chrome-on-ios-devices-on-windows-edge-is-the-second-most-popular-browser\&quot;&gt;&lt;u&gt;🔗&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;connectivity\&quot;&gt;Connectivity&lt;/h3&gt;\n            &lt;a href=\&quot;#connectivity\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;ul&gt;&lt;li&gt;&lt;p&gt;225 major Internet disruptions were observed globally in 2024, with many due to government-directed regional and national shutdowns of Internet connectivity. Cable cuts and power outages were also leading causes. &lt;a href=\&quot;#225-major-internet-outages-were-observed-around-the-world-in-2024-with-many-due-to-government-directed-regional-and-national-shutdowns-of-internet-connectivity\&quot;&gt;&lt;u&gt;🔗&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Aggregated across 2024, 28.5% of IPv6-capable requests were made over IPv6. India and Malaysia were the strongest countries, at 68.9% and 59.6% IPv6 adoption respectively. &lt;a href=\&quot;#globally-nearly-half-of-web-requests-used-http-2-with-20-5-using-http-3\&quot;&gt;&lt;u&gt;🔗&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The top 10 countries ranked by Internet speed all had average download speeds above 200 Mbps. Spain was consistently among the top locations across the measured Internet quality metrics. &lt;a href=\&quot;#the-top-10-countries-ranked-by-internet-speed-all-had-average-download-speeds-above-200-mbps-spain-was-consistently-among-the-top-locations-across-measured-internet-quality-metrics\&quot;&gt;&lt;u&gt;🔗&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;41.3% of global traffic comes from mobile devices. In nearly 100 countries/regions, the majority of traffic comes from mobile devices. &lt;a href=\&quot;#41-3-of-global-traffic-comes-from-mobile-devices-in-nearly-100-countries-regions-the-majority-of-traffic-comes-from-mobile-devices\&quot;&gt;&lt;u&gt;🔗&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;20.7% of TCP connections are unexpectedly terminated before any useful data can be exchanged. &lt;a href=\&quot;#20-7-of-tcp-connections-are-unexpectedly-terminated-before-any-useful-data-can-be-exchanged\&quot;&gt;&lt;u&gt;🔗&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;security\&quot;&gt;Security&lt;/h3&gt;\n            &lt;a href=\&quot;#security\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;ul&gt;&lt;li&gt;&lt;p&gt;6.5% of global traffic was mitigated by Cloudflare&amp;#39;s systems as being potentially malicious or for customer-defined reasons. In the United States, the share of mitigated traffic grew to 5.1%, while in South Korea, it dropped slightly to 8.1%. In 44 countries/regions, over 10% of traffic was mitigated. &lt;a href=\&quot;#6-5-of-global-traffic-was-mitigated-by-cloudflares-systems-as-being-potentially-malicious-or-for-customer-defined-reasons\&quot;&gt;&lt;u&gt;🔗&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The United States was responsible for over a third of global bot traffic. Amazon Web Services was responsible for 12.7% of global bot traffic, and 7.8% came from Google. &lt;a href=\&quot;#the-united-states-was-responsible-for-over-a-third-of-global-bot-traffic-amazon-web-services-was-responsible-for-12-7-of-global-bot-traffic-and-7-8-came-from-google\&quot;&gt;&lt;u&gt;🔗&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Globally, Gambling/Games was the most attacked industry, slightly ahead of 2023’s most targeted industry, Finance. &lt;a href=\&quot;#globally-gambling-games-was-the-most-attacked-industry-slightly-ahead-of-2023s-most-targeted-industry-finance\&quot;&gt;&lt;u&gt;🔗&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Log4j, a vulnerability discovered in 2021, remains a persistent threat and was actively targeted throughout 2024. &lt;a href=\&quot;#log4j-remains-a-persistent-threat-and-was-actively-targeted-throughout-2024\&quot;&gt;&lt;u&gt;🔗&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Routing security, measured as the share of RPKI valid routes and the share of covered IP address space, continued to improve globally throughout 2024. We saw a 4.7% increase in RPKI valid IPv4 address space in 2024, and a 6.4% increase in RPKI valid routes in 2024. &lt;a href=\&quot;#routing-security-measured-as-the-share-of-rpki-valid-routes-and-the-share-of-covered-ip-address-space-continued-to-improve-globally-throughout-2024\&quot;&gt;&lt;u&gt;🔗&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;email-security\&quot;&gt;Email Security&lt;/h3&gt;\n            &lt;a href=\&quot;#email-security\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;ul&gt;&lt;li&gt;&lt;p&gt;An average of 4.3% of emails were determined to be malicious in 2024, although this figure was likely influenced by spikes observed in March, April, and May. Deceptive links and identity deception were the two most common types of threats found in malicious email messages. &lt;a href=\&quot;#an-average-of-4-3-of-emails-were-determined-to-be-malicious-in-2024\&quot;&gt;&lt;u&gt;🔗&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Over 99% of the email messages processed by Cloudflare Email Security from the .bar, .rest, and .uno top level domains (TLDs) were found to be either spam or malicious in nature. &lt;a href=\&quot;#over-99-of-the-email-messages-processed-by-cloudflare-email-security-from-the-bar-rest-and-uno-top-level-domains-tlds-were-found-to-be-either-spam-or-malicious-in-nature\&quot;&gt;&lt;u&gt;🔗&lt;/u&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;introduction\&quot;&gt;Introduction&lt;/h2&gt;\n            &lt;a href=\&quot;#introduction\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;Over the last four years (&lt;a href=\&quot;https://blog.cloudflare.com/cloudflare-radar-2020-year-in-review/\&quot;&gt;&lt;u&gt;2020&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://blog.cloudflare.com/cloudflare-radar-2021-year-in-review/\&quot;&gt;&lt;u&gt;2021&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://blog.cloudflare.com/radar-2022-year-in-review/\&quot;&gt;&lt;u&gt;2022&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://blog.cloudflare.com/radar-2023-year-in-review/\&quot;&gt;&lt;u&gt;2023&lt;/u&gt;&lt;/a&gt;), we have aggregated perspectives from &lt;a href=\&quot;https://radar.cloudflare.com/\&quot;&gt;&lt;u&gt;Cloudflare Radar&lt;/u&gt;&lt;/a&gt; into an annual Year In Review, illustrating the Internet’s patterns across multiple areas over the course of that year. The &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024\&quot;&gt;&lt;u&gt;Cloudflare Radar 2024 Year In Review&lt;/u&gt;&lt;/a&gt; microsite continues that tradition, featuring interactive charts, graphs, and maps you can use to explore and compare notable Internet trends observed throughout this past year.&lt;/p&gt;&lt;p&gt;Cloudflare’s &lt;a href=\&quot;https://www.cloudflare.com/network\&quot;&gt;&lt;u&gt;network&lt;/u&gt;&lt;/a&gt; currently spans more than 330 cities in over 120 countries/regions, serving an average of over 63 million HTTP(S) requests per second for millions of Internet properties, in addition to handling over 42 million DNS requests per second on average. The resulting data generated by this usage, combined with data from other complementary Cloudflare tools, enables Radar to provide unique near-real time perspectives on the patterns and trends around security, traffic, performance, and usage that we observe across the Internet. &lt;/p&gt;&lt;p&gt;The 2024 Year In Review is organized into five sections: &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#traffic\&quot;&gt;&lt;u&gt;Traffic&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#adoption-and-usage\&quot;&gt;&lt;u&gt;Adoption &amp;amp; Usage&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#connectivity\&quot;&gt;&lt;u&gt;Connectivity&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#security\&quot;&gt;&lt;u&gt;Security&lt;/u&gt;&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#email-security\&quot;&gt;&lt;u&gt;Email Security&lt;/u&gt;&lt;/a&gt; and covers the period from January 1 to December 1, 2024. We have incorporated several new metrics this year, including AI bot &amp;amp; crawler traffic, search engine and browser market share, connection tampering, and “most dangerous” top level domains (TLDs). To ensure consistency, we have kept underlying methodologies consistent with previous years’ calculations. Trends for 200 countries/regions are available on the microsite; smaller or less populated locations are excluded due to insufficient data. Some metrics are only shown worldwide, and are not displayed if a country/region is selected. &lt;/p&gt;&lt;p&gt;Below, we provide an overview of the content contained within the major Year In Review sections (Traffic, Adoption &amp;amp; Usage, Connectivity, Security, and Email Security), along with notable observations and key findings. In addition, we have also published a companion blog post that specifically explores trends seen across &lt;a href=\&quot;https://blog.cloudflare.com/radar-2024-year-in-review-internet-services/\&quot;&gt;&lt;u&gt;Top Internet Services&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The key findings and associated discussion within this post only provide a high-level perspective on the unique insights that can be found in the &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024\&quot;&gt;&lt;u&gt;Year in Review microsite&lt;/u&gt;&lt;/a&gt;. Visit the microsite to explore the various datasets and metrics in more detail, including trends seen in your country/region, how these trends have changed as compared to 2023, and how they compare to other countries/regions of interest. Surveying the Internet from this vantage point provides insights that can inform decisions on everything from an organization’s security posture and IT priorities to product development and strategy. &lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;traffic-trends\&quot;&gt;Traffic trends&lt;/h2&gt;\n            &lt;a href=\&quot;#traffic-trends\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          \n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4XlL4SnJROa2fArrtUheuo/822ede9708eb6e9aeeebce4331d62140/2627_Graph.png\&quot; alt=\&quot;2627 Graph\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;417\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;global-internet-traffic-grew-17-2-in-2024\&quot;&gt;Global Internet traffic grew 17.2% in 2024.&lt;/h3&gt;\n            &lt;a href=\&quot;#global-internet-traffic-grew-17-2-in-2024\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;An inflection point for Internet traffic arguably occurred thirty years ago. The World Wide Web went mainstream in 1994, thanks to the late 1993 &lt;a href=\&quot;https://cybercultural.com/p/1993-mosaic-launches-and-the-web-is-set-free/\&quot;&gt;&lt;u&gt;release&lt;/u&gt;&lt;/a&gt; of the &lt;a href=\&quot;https://www.ncsa.illinois.edu/research/project-highlights/ncsa-mosaic/\&quot;&gt;&lt;u&gt;NCSA Mosaic&lt;/u&gt;&lt;/a&gt; browser for multiple popular operating systems, which included support for embedded images. In turn, “heavier” (in contrast to text-based) Internet content became the norm, and coupled with the growth in consumption through popular online services and the emerging consumer ISP industry, &lt;a href=\&quot;https://blogs.cisco.com/sp/the-history-and-future-of-internet-traffic\&quot;&gt;&lt;u&gt;Internet traffic began to rapidly increase&lt;/u&gt;&lt;/a&gt;, and that trend has continued to the present.&lt;/p&gt;&lt;p&gt;To determine the traffic trends over time for the Year in Review, we use the average daily traffic volume (excluding bot traffic) over the second full calendar week (January 8-15) of 2024 as our baseline. (The second calendar week is used to allow time for people to get back into their “normal” school and work routines after the winter holidays and New Year’s Day. The percent change shown in the traffic trends chart is calculated relative to the baseline value — it does not represent absolute traffic volume for a country/region. The trend line represents a seven-day trailing average, which is used to smooth the sharp changes seen with data at a daily granularity. To compare 2024’s traffic trends with 2023 data and/or other locations, click the “Compare” icon at the upper right of the graph.&lt;/p&gt;&lt;p&gt;Throughout the first half of 2024, &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024?#internet-traffic-growth\&quot;&gt;&lt;u&gt;worldwide Internet traffic growth&lt;/u&gt;&lt;/a&gt; appeared to be fairly limited, within a percent or two on either side of the baseline value through mid-August. However, at that time growth clearly began to accelerate, climbing consistently through the end of November, growing 17.2% for the year. This trend is similar to those also seen in 2023 and 2022, as we discussed in the &lt;a href=\&quot;https://blog.cloudflare.com/radar-2023-year-in-review/\&quot;&gt;&lt;u&gt;2023 Year in Review blog post&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5NjOCs902pW74OQ0bx2usy/58896c0bc06b4a9c819736bde28ed3f4/traffic_-_worldwide.png\&quot; alt=\&quot;Internet traffic trends in 2024, worldwide\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;840\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Internet traffic trends in 2024, worldwide&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;The West African country of &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/gn?previousYear=true\&quot;&gt;&lt;u&gt;Guinea&lt;/u&gt;&lt;/a&gt; experienced the most significant Internet traffic growth seen in 2024, reaching as much as 350% above baseline. Traffic growth didn’t begin in earnest until late February, and reached an initial peak in early April. It remained between 100% and 200% above baseline until September, when it experienced several multi-week periods of growth. While the September-November periods of traffic growth also occurred in 2023, they peaked at under 90% above baseline.&lt;/p&gt;&lt;p&gt;The impact of significant Internet outages is also clearly visible when looking at data across the year. Two significant Internet outages in &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/cu#internet-traffic-growth\&quot;&gt;&lt;u&gt;Cuba&lt;/u&gt;&lt;/a&gt; are clearly visible as large drops in traffic in October and November. A reported “complete disconnection” of the national electricity system on the island &lt;a href=\&quot;https://x.com/CloudflareRadar/status/1847325224208891950\&quot;&gt;&lt;u&gt;occurred on October 18&lt;/u&gt;&lt;/a&gt;, lasting &lt;a href=\&quot;https://x.com/CloudflareRadar/status/1848680148813406474\&quot;&gt;&lt;u&gt;just over three days&lt;/u&gt;&lt;/a&gt;. Just a couple of weeks later, on November 6, &lt;a href=\&quot;https://x.com/CloudflareRadar/status/1854291286322544752\&quot;&gt;&lt;u&gt;damage from Hurricane Rafael caused widespread power outages in Cuba&lt;/u&gt;&lt;/a&gt;, resulting in another large drop in Internet traffic. Traffic has remained lower as Cuba’s electrical infrastructure &lt;a href=\&quot;https://x.com/CloudflareRadar/status/1864263679442567604\&quot;&gt;&lt;u&gt;continues to struggle&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2rvK8AFYdcJAgQhJQUTiQw/8c4790fd06af8323636878977a9d712c/traffic_-_Cuba.png\&quot; alt=\&quot;traffic - Cuba\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;840\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Internet traffic trends in 2024, Cuba&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;As we frequently discuss in Cloudflare Radar blog and social media posts, government-directed Internet shutdowns occur all too frequently, and the impact of these actions are also clearly visible when looking at long-term traffic data. In &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/bd#internet-traffic-growth\&quot;&gt;&lt;u&gt;Bangladesh&lt;/u&gt;&lt;/a&gt;, the government ordered the &lt;a href=\&quot;https://blog.cloudflare.com/q3-2024-internet-disruption-summary/#bangladesh\&quot;&gt;&lt;u&gt;shutdown of mobile Internet connectivity&lt;/u&gt;&lt;/a&gt; on July 18, in response to student protests. Shortly after mobile networks were shut down, fixed broadband networks were taken offline as well, resulting in a near complete loss of Internet traffic from the country. Connectivity gradually returned over the course of several days, between July 23-28.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5FvubyG6qMeZ9hv1wgFayl/91d356b23788a8f9cdd970cc7e65f8fc/traffic_-_Bangladesh.png\&quot; alt=\&quot;traffic - Bangladesh\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;840\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Internet traffic trends in 2024, Bangladesh&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;As we also noted last year, the celebration of major holidays can also have a visible impact on Internet traffic at a country level. For example, in Muslim countries including &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/ae?compareWith=ID#internet-traffic-growth\&quot;&gt;&lt;u&gt;Indonesia and the United Arab Emirates&lt;/u&gt;&lt;/a&gt;, the celebration of Eid al-Fitr, the festival marking the end of the fast of Ramadan, is visible as a noticeable drop in traffic around April 9-10. &lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/aFTFP2banlfW65XkjUIZM/84bfd5db1036da1b4740843575217113/traffic_-_UAE_Indonesia.png\&quot; alt=\&quot;traffic - UAE Indonesia\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;840\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Internet traffic trends in 2024, Indonesia and United Arab Emirates&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;google-maintained-its-position-as-the-most-popular-internet-service-openai-binance-whatsapp-and-facebook-led-their-respective-categories\&quot;&gt;Google maintained its position as the most popular Internet service. OpenAI, Binance, WhatsApp, and Facebook led their respective categories. &lt;/h3&gt;\n            &lt;a href=\&quot;#google-maintained-its-position-as-the-most-popular-internet-service-openai-binance-whatsapp-and-facebook-led-their-respective-categories\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Over the last several years, the Year In Review has ranked the &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#internet-services\&quot;&gt;&lt;u&gt;most popular Internet services&lt;/u&gt;&lt;/a&gt;. These rankings cover an “overall” perspective, as well as a dozen more specific categories, based on analysis of anonymized query data of traffic to our &lt;a href=\&quot;https://1.1.1.1/dns\&quot;&gt;&lt;u&gt;1.1.1.1 public DNS resolver&lt;/u&gt;&lt;/a&gt; from millions of users around the world. For the purposes of these rankings, domains that belong to a single Internet service are grouped together.&lt;/p&gt;&lt;p&gt;Google once again held the top spot overall, supported by its broad portfolio of services, as well as the popularity of the Android mobile operating system (more on that &lt;a href=\&quot;#globally-nearly-one-third-of-mobile-device-traffic-was-from-apple-ios-devices-android-had-a-90-share-of-mobile-device-traffic-in-29-countries-regions-peak-ios-mobile-device-traffic-share-was-over-60-in-eight-countries-regions\&quot;&gt;&lt;u&gt;below&lt;/u&gt;&lt;/a&gt;). Meta properties Facebook, Instagram, and WhatsApp also held spots in the top 10.&lt;/p&gt;&lt;p&gt;&lt;a href=\&quot;https://www.cloudflare.com/learning/ai/what-is-generative-ai/\&quot;&gt;&lt;u&gt;Generative AI&lt;/u&gt;&lt;/a&gt; continued to grow in popularity throughout 2024, and in this category, OpenAI again held the top spot, building on the continued success and popularity of ChatGPT. Within Social Media, the top five remained consistent with 2023’s and 2022’s ranking, including Facebook, TikTok, Instagram, X, and Snapchat.&lt;/p&gt;&lt;p&gt;These categorical rankings, as well as trends seen by specific services, are explored in more detail in a separate blog post, &lt;a href=\&quot;https://blog.cloudflare.com/radar-2024-year-in-review-internet-services/\&quot;&gt;&lt;i&gt;&lt;u&gt;From ChatGPT to Temu: ranking top Internet services in 2024&lt;/u&gt;&lt;/i&gt;&lt;/a&gt;.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;global-traffic-from-starlink-grew-3-3x-in-2024-in-line-with-last-years-growth-rate-after-initiating-service-in-malawi-in-july-2023-starlink-traffic-from-that-country-grew-38x-in-2024\&quot;&gt;Global traffic from Starlink grew 3.3x in 2024, in line with last year’s growth rate. After initiating service in Malawi in July 2023, Starlink traffic from that country grew 38x in 2024.&lt;/h3&gt;\n            &lt;a href=\&quot;#global-traffic-from-starlink-grew-3-3x-in-2024-in-line-with-last-years-growth-rate-after-initiating-service-in-malawi-in-july-2023-starlink-traffic-from-that-country-grew-38x-in-2024\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;SpaceX’s Starlink continues to be the leading satellite Internet service provider, bringing connectivity to unserved or underserved areas. In addition to opening up new markets in 2024, Starlink also announced relationships to provide in-flight connectivity to &lt;a href=\&quot;https://www.cnbc.com/2024/09/17/spacexs-starlink-has-2500-aircraft-under-contract.html\&quot;&gt;&lt;u&gt;multiple airlines&lt;/u&gt;&lt;/a&gt;, and on &lt;a href=\&quot;https://x.com/Starlink/status/1790426484022342081\&quot;&gt;&lt;u&gt;cruise ships&lt;/u&gt;&lt;/a&gt; and &lt;a href=\&quot;https://x.com/Starlink/status/1857166233969607123\&quot;&gt;&lt;u&gt;trains&lt;/u&gt;&lt;/a&gt;, as well as enabling subscribers to roam with their subscription using the &lt;a href=\&quot;https://www.theverge.com/2024/7/11/24196294/starlink-mini-available-us-price-specs\&quot;&gt;&lt;u&gt;Starlink Mini&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;We analyzed aggregate Cloudflare traffic volumes associated with Starlink&amp;#39;s primary &lt;a href=\&quot;https://www.cloudflare.com/learning/network-layer/what-is-an-autonomous-system/\&quot;&gt;&lt;u&gt;autonomous system&lt;/u&gt;&lt;/a&gt; (&lt;a href=\&quot;https://radar.cloudflare.com/as14593\&quot;&gt;&lt;u&gt;AS14593&lt;/u&gt;&lt;/a&gt;) to track the growth in usage of the service throughout 2024. Similar to the traffic trends discussed above, the request volume shown on the trend line in the chart represents a seven-day trailing average. Comparisons with 2023 data can be shown by clicking the “Compare” icon at the upper right of the graph. Within comparative views, the lines are scaled to the maximum value shown.&lt;/p&gt;&lt;p&gt;On a &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#starlink-traffic.trends\&quot;&gt;&lt;u&gt;worldwide&lt;/u&gt;&lt;/a&gt; basis, steady, consistent growth was seen across the year, though it accelerates throughout November. This acceleration may have been driven by traffic associated with customer-specific large software updates. &lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6Dy2qt4O5b3MCswkckhELA/aa29c7235497bed8c985aa9dd9b63477/traffic_-_Starlink_worldwide.png\&quot; alt=\&quot;traffic - Starlink worldwide\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;840\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Starlink traffic growth worldwide in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;In many locations, there is pent-up demand for “alternative” connectivity providers such as Starlink, and in these countries/regions, we see rapid traffic growth when service becomes available, such as in &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/zw#starlink-traffic.trends\&quot;&gt;&lt;u&gt;Zimbabwe&lt;/u&gt;&lt;/a&gt;. Service availability was &lt;a href=\&quot;https://x.com/Starlink/status/1832392080481563037\&quot;&gt;&lt;u&gt;announced on September 7&lt;/u&gt;&lt;/a&gt;, and traffic from the country began to grow rapidly almost immediately thereafter.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1aLywcrB5w88flsDyK1R1q/1039d989e19dc566cf5f62e60f3f1886/traffic_-_Starlink_Zimbabwe.png\&quot; alt=\&quot;traffic - Starlink Zimbabwe\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;840\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Starlink traffic growth in Zimbabwe in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;In new markets, traffic growth continues after that initial increase. For example Starlink service became available in Malawi &lt;a href=\&quot;https://x.com/Starlink/status/1683897037639790592\&quot;&gt;&lt;u&gt;in July 2023&lt;/u&gt;&lt;/a&gt;, and throughout 2024, Starlink traffic from the country grew 38x. While &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/mw#starlink-traffic.trends\&quot;&gt;&lt;u&gt;Malawi’s 38x increase&lt;/u&gt;&lt;/a&gt; is impressive, other countries also experienced significant growth. In the Eastern European country of &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/ge#starlink-traffic.trends\&quot;&gt;&lt;u&gt;Georgia&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://x.com/Starlink/status/1719581885200998485\&quot;&gt;&lt;u&gt;service became available on November 1, 2023&lt;/u&gt;&lt;/a&gt;. After a slow ramp, traffic began to take off growing over 100x through 2024. In &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/py#starlink-traffic.trends\&quot;&gt;&lt;u&gt;Paraguay&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://x.com/Starlink/status/1737914318522581489\&quot;&gt;&lt;u&gt;service availability was announced on December 21&lt;/u&gt;&lt;/a&gt;, and began to grow at the beginning of January, registering an increase of over 900x across the year.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6AXOON7CO7XgnWSNnezoiF/bd56192d682c574a2d242845bb0eda16/traffic_-_Starlink_Malawi.png\&quot; alt=\&quot;traffic - Starlink Malawi\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;840\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Starlink traffic growth in Malawi in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;googlebot-was-responsible-for-the-highest-volume-of-request-traffic-to-cloudflare-in-2024-as-it-retrieved-content-from-millions-of-cloudflare-customer-sites-for-search-indexing\&quot;&gt;Googlebot was responsible for the highest volume of request traffic to Cloudflare in 2024 as it retrieved content from millions of Cloudflare customer sites for search indexing. &lt;/h3&gt;\n            &lt;a href=\&quot;#googlebot-was-responsible-for-the-highest-volume-of-request-traffic-to-cloudflare-in-2024-as-it-retrieved-content-from-millions-of-cloudflare-customer-sites-for-search-indexing\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Cloudflare Radar shows users Internet traffic trends over a selected period of time, but at a country/region or network level. However, &lt;a href=\&quot;https://blog.cloudflare.com/radar-2023-year-in-review/#googlebot-was-responsible-for-the-highest-volume-of-request-traffic-to-cloudflare-in-2023\&quot;&gt;&lt;u&gt;as we did in 2023&lt;/u&gt;&lt;/a&gt;, we again wanted to look at the traffic Cloudflare saw over the course of the full year from the entire IPv4 Internet. To do so, we can use &lt;a href=\&quot;https://en.wikipedia.org/wiki/Hilbert_curve\&quot;&gt;&lt;u&gt;Hilbert curves&lt;/u&gt;&lt;/a&gt;, which allow us to visualize a sequence of IPv4 addresses in a two-dimensional pattern that keeps nearby IP addresses close to each other, making them &lt;a href=\&quot;https://xkcd.com/195/\&quot;&gt;&lt;u&gt;useful&lt;/u&gt;&lt;/a&gt; for surveying the Internet&amp;#39;s IPv4 address space.&lt;/p&gt;&lt;p&gt;Using a Hilbert curve, we can &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#ipv4-traffic-distribution\&quot;&gt;&lt;u&gt;visualize aggregated IPv4 request traffic to Cloudflare&lt;/u&gt;&lt;/a&gt; from January 1 through December 1, 2024. Within the visualization, we aggregate IPv4 addresses at a &lt;a href=\&quot;https://www.ripe.net/about-us/press-centre/IPv4CIDRChart_2015.pdf\&quot;&gt;&lt;u&gt;/20&lt;/u&gt;&lt;/a&gt; level, meaning that at the highest zoom level, each square represents traffic from 4,096 IPv4 addresses. This aggregation is done to keep the amount of data used for the visualization manageable. (While we would like to create a similar visualization for IPv6 traffic, the enormity of the full IPv6 address space would make associated traffic very &lt;a href=\&quot;https://observablehq.com/@vasturiano/hilbert-map-of-ipv6-address-space\&quot;&gt;&lt;u&gt;hard to see&lt;/u&gt;&lt;/a&gt; in such a visualization, especially as such a small amount has been &lt;a href=\&quot;https://www.iana.org/numbers/allocations/\&quot;&gt;&lt;u&gt;allocated for assignment by the Regional Internet Registries&lt;/u&gt;&lt;/a&gt;.)&lt;/p&gt;&lt;p&gt;Within the visualization, IP addresses are grouped by ownership, and for much of the IP address space shown there, a mouseover at the default zoom level will show the &lt;a href=\&quot;https://www.nro.net/about/rirs/\&quot;&gt;&lt;u&gt;Regional Internet Registry (RIR)&lt;/u&gt;&lt;/a&gt; that the address block belongs to. However, there are also a number of blocks that were assigned prior to the existence of the RIR system, and for these, they are labeled with the name of the organization that owns them. Progressive zooming ultimately shows the autonomous system and country/region that the IP address block is associated with, as well as its share of traffic relative to the maximum. (If a country/region is selected, only the IP address blocks associated with that location are visible.) Overall traffic shares are indicated by shading based on a color scale, and although a number of large unshaded blocks are visible, this does not necessarily mean that the associated address space is unused, but rather that it may be used in a way that does not generate traffic to Cloudflare.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6gtrL1H2gUjSKH7AMSabgM/361d38f34860258449a914e26519a4b4/traffic_-_Hilbert_curve.png\&quot; alt=\&quot;traffic - Hilbert curve\&quot; class=\&quot;kg-image\&quot; width=\&quot;1578\&quot; height=\&quot;981\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Hilbert curve showing aggregated 2024 traffic to Cloudflare across the IPv4 Internet&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;Warmer orange/red shading within the visualization represents areas of higher request volume, and buried within one of those areas is the IP address block that had the maximum request volume to Cloudflare during 2024. As it was in 2023, this address block was &lt;a href=\&quot;https://radar.cloudflare.com/routing/prefix/66.249.64.0/20\&quot;&gt;&lt;u&gt;66.249.64.0/20&lt;/u&gt;&lt;/a&gt;, which belongs to Google, and is &lt;a href=\&quot;https://developers.google.com/static/search/apis/ipranges/googlebot.json\&quot;&gt;&lt;u&gt;one of several&lt;/u&gt;&lt;/a&gt; used by the &lt;a href=\&quot;https://developers.google.com/search/docs/crawling-indexing/googlebot\&quot;&gt;&lt;u&gt;Googlebot&lt;/u&gt;&lt;/a&gt; web crawler to retrieve content for search indexing. This use of that address space is a likely explanation for the high request volume, given the number of web properties on Cloudflare’s network.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/g5rQhT7r4DsgpzYdMT3QT/0d6809d96791ee7165ada170d24156e3/traffic_-_Hilbert_curve_Googlebot.png\&quot; alt=\&quot;traffic - Hilbert curve Googlebot\&quot; class=\&quot;kg-image\&quot; width=\&quot;1578\&quot; height=\&quot;981\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Zoomed Hilbert curve view showing the IPv4 address block that generated the highest volume of requests&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;In addition to Google, owners of other prefixes in the top 20 include Alibaba, Microsoft, Amazon, and Apple. To explore the IPv4 Internet in more detail, we encourage you to go to &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/#ipv4-traffic-distribution\&quot;&gt;&lt;u&gt;the Year in Review microsite&lt;/u&gt;&lt;/a&gt; and explore it by dragging and zooming to move around IPv4 address space.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;among-ai-bots-and-crawlers-bytespider-bytedance-traffic-gradually-declined-over-the-course-of-2024-while-claudebot-anthropic-was-more-active-during-the-back-half-of-the-year\&quot;&gt;Among AI bots and crawlers, Bytespider (ByteDance) traffic gradually declined over the course of 2024, while ClaudeBot (Anthropic) was more active during the back half of the year.&lt;/h3&gt;\n            &lt;a href=\&quot;#among-ai-bots-and-crawlers-bytespider-bytedance-traffic-gradually-declined-over-the-course-of-2024-while-claudebot-anthropic-was-more-active-during-the-back-half-of-the-year\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;AI bots and crawlers have been in the news throughout 2024 as they voraciously consume content to train ever-evolving models. Controversy has followed them, as not all bots and crawlers respect content owner directives to restrict crawling activity. In July, Cloudflare enabled customers to &lt;a href=\&quot;https://blog.cloudflare.com/declaring-your-aindependence-block-ai-bots-scrapers-and-crawlers-with-a-single-click/\&quot;&gt;&lt;u&gt;block these bots and crawlers with a single click&lt;/u&gt;&lt;/a&gt;, and during Birthday Week &lt;a href=\&quot;https://blog.cloudflare.com/cloudflare-ai-audit-control-ai-content-crawlers/\&quot;&gt;&lt;u&gt;we introduced AI Audit&lt;/u&gt;&lt;/a&gt; to give website owners even more visibility into and control over how AI platforms access their content. &lt;/p&gt;&lt;p&gt;Tracking traffic trends for AI bots can help us better understand their activity over time — observing which are the most aggressive and have the highest volume of requests, which perform crawls on a regular basis, etc. The new &lt;a href=\&quot;https://radar.cloudflare.com/traffic#ai-bot-crawler-traffic\&quot;&gt;&lt;u&gt;AI bot &amp;amp; crawler traffic graph on Radar’s Traffic page&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://blog.cloudflare.com/bringing-ai-to-cloudflare/#ai-bot-traffic-insights-on-cloudflare-radar\&quot;&gt;&lt;u&gt;launched in September&lt;/u&gt;&lt;/a&gt;, provides insight into these traffic trends gathered over the selected time period for the top known AI bots. &lt;/p&gt;&lt;p&gt;&lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#ai-bot-and-crawler-traffic\&quot;&gt;&lt;u&gt;Looking at traffic trends&lt;/u&gt;&lt;/a&gt; from two of those bots, we can see some interesting patterns. &lt;a href=\&quot;https://darkvisitors.com/agents/bytespider\&quot;&gt;&lt;u&gt;Bytespider&lt;/u&gt;&lt;/a&gt; is a crawler operated by ByteDance, the Chinese owner of TikTok, and is reportedly used to download training data for ByteDance’s Large Language Models (LLMs). Bytespider’s crawling activity trended generally downwards over the course of 2024, with end-of-November activity approximately 80-85% lower than that seen at the start of the year. &lt;a href=\&quot;https://darkvisitors.com/agents/claudebot\&quot;&gt;&lt;u&gt;ClaudeBot&lt;/u&gt;&lt;/a&gt; is Anthropic’s crawler, which downloads training data for its LLMs that power AI products like Claude. Traffic from ClaudeBot appeared to be mostly non-existent through mid-April, except for some small spikes that possibly represent test runs. Traffic became more consistently non-zero starting in late April, but after an early spike, trailed off through the remainder of the year.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7cm0SG0GC36Z3dFu3A6p3J/10a6e32a469984b2083ee0c2ed743d53/traffic_-_AI_bots_--_NEW.png\&quot; alt=\&quot;traffic - AI bots\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;840\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Traffic trends for AI crawlers Bytespider and ClaudeBot in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;Traffic trends for the full list of AI bots &amp;amp; crawlers can be found in the &lt;a href=\&quot;https://radar.cloudflare.com/explorer?dataSet=ai.bots&amp;dt=2024-01-01_2024-12-31\&quot;&gt;&lt;u&gt;Cloudflare Radar Data Explorer&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;13-0-of-tls-1-3-traffic-is-using-post-quantum-encryption\&quot;&gt;13.0% of TLS 1.3 traffic is using post-quantum encryption.&lt;/h3&gt;\n            &lt;a href=\&quot;#13-0-of-tls-1-3-traffic-is-using-post-quantum-encryption\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;The term “&lt;a href=\&quot;https://en.wikipedia.org/wiki/Post-quantum_cryptography\&quot;&gt;&lt;u&gt;post-quantum&lt;/u&gt;&lt;/a&gt;” refers to a new set of cryptographic techniques designed to protect data from adversaries that have the ability to capture and store current data for decryption by sufficiently powerful quantum computers in the future. The Cloudflare Research team has been &lt;a href=\&quot;https://blog.cloudflare.com/sidh-go/\&quot;&gt;&lt;u&gt;exploring post-quantum cryptography since 2017&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;In October 2022, we enabled &lt;a href=\&quot;https://blog.cloudflare.com/post-quantum-for-all/\&quot;&gt;&lt;u&gt;post-quantum key agreement&lt;/u&gt;&lt;/a&gt; on our network by default, but use of it requires that browsers and clients support it as well. In 2024, Google&amp;#39;s &lt;a href=\&quot;https://developer.chrome.com/release-notes/124\&quot;&gt;&lt;u&gt;Chrome 124&lt;/u&gt;&lt;/a&gt; enabled it by default on April 17, and &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#post-quantum-encryption\&quot;&gt;&lt;u&gt;adoption grew rapidly following that release&lt;/u&gt;&lt;/a&gt;, increasing from just over 2% of requests to around 12% within a month, and ended November at 13%. We expect that adoption will continue to grow into and during 2025 due to support in other Chromium-based browsers, growing default support in Mozilla Firefox, and initial testing in Apple Safari.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4ipRtCowVftgad37ht9uMF/68958f72a47bbc179959c2d7ac6cdd72/traffic_-_post-quantum_worldwide.png\&quot; alt=\&quot;traffic - post-quantum worldwide\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;840\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Growth trends in post-quantum encrypted TLS 1.3 traffic during 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;adoption-usage-insights\&quot;&gt;Adoption &amp;amp; Usage insights&lt;/h2&gt;\n            &lt;a href=\&quot;#adoption-usage-insights\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          \n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/177RCO2sEvFJJeJeCBzZim/68acfcc309c57ef2027e9291a5f76d2f/2627_Shield.png\&quot; alt=\&quot;2627 Shield\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;417\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;globally-nearly-one-third-of-mobile-device-traffic-was-from-apple-ios-devices-android-had-a-90-share-of-mobile-device-traffic-in-29-countries-regions-peak-ios-mobile-device-traffic-share-was-over-60-in-eight-countries-regions\&quot;&gt;Globally, nearly one-third of mobile device traffic was from Apple iOS devices. Android had a &amp;gt;90% share of mobile device traffic in 29 countries/regions; peak iOS mobile device traffic share was over 60% in eight countries/regions.&lt;/h3&gt;\n            &lt;a href=\&quot;#globally-nearly-one-third-of-mobile-device-traffic-was-from-apple-ios-devices-android-had-a-90-share-of-mobile-device-traffic-in-29-countries-regions-peak-ios-mobile-device-traffic-share-was-over-60-in-eight-countries-regions\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;The two leading mobile device operating systems globally are &lt;a href=\&quot;https://en.wikipedia.org/wiki/IOS\&quot;&gt;&lt;u&gt;Apple’s iOS&lt;/u&gt;&lt;/a&gt; and &lt;a href=\&quot;https://en.wikipedia.org/wiki/Android_(operating_system)\&quot;&gt;&lt;u&gt;Google’s Android&lt;/u&gt;&lt;/a&gt;, and by analyzing information in the &lt;a href=\&quot;https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/User-Agent\&quot;&gt;&lt;u&gt;user agent&lt;/u&gt;&lt;/a&gt; reported with each request, we can get insight into the distribution of traffic by client operating system throughout the year. Again, we found that Android is responsible for the majority of mobile device traffic when aggregated globally, due to the wide distribution of price points, form factors, and capabilities.&lt;/p&gt;&lt;p&gt;Similar to &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2023#ios-vs-android\&quot;&gt;&lt;u&gt;2023’s findings&lt;/u&gt;&lt;/a&gt;, Android was once again &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#ios-vs-android\&quot;&gt;&lt;u&gt;responsible for just over two-thirds of mobile device traffic&lt;/u&gt;&lt;/a&gt;. Looking at the top countries for Android traffic, we find a greater than 95% share in &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/sd#ios-vs-android\&quot;&gt;&lt;u&gt;Sudan&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/bd#ios-vs-android\&quot;&gt;&lt;u&gt;Bangladesh&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/tm#ios-vs-android\&quot;&gt;&lt;u&gt;Turkmenistan&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/mw#ios-vs-android\&quot;&gt;&lt;u&gt;Malawi&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/pg#ios-vs-android\&quot;&gt;&lt;u&gt;Papua New Guinea&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/sy#ios-vs-android\&quot;&gt;&lt;u&gt;Syria&lt;/u&gt;&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/ye#ios-vs-android\&quot;&gt;&lt;u&gt;Yemen&lt;/u&gt;&lt;/a&gt;, up from just two countries in 2023. Similar to last year, we again found that countries/regions with higher levels of Android usage are largely in Africa, Oceania/Asia, and South America, and that many have lower levels of &lt;a href=\&quot;https://ourworldindata.org/grapher/gross-national-income-per-capita?tab=table\&quot;&gt;&lt;u&gt;gross national income per capita&lt;/u&gt;&lt;/a&gt;. In these countries/regions, the availability of lower priced “budget” Android devices supports increased adoption.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/9bsuRwzYBybYpOiKqwLja/cbdafb60eab1913a91ec916899d1e807/connectivity_-_mobile_desktop.png\&quot; alt=\&quot;connectivity - mobile desktop\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;268\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Global distribution of mobile device traffic by operating system in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;In contrast, iOS adoption tops out in the 65% range in &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/je#ios-vs-android\&quot;&gt;&lt;u&gt;Jersey&lt;/u&gt;&lt;/a&gt;, the &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/fo#ios-vs-android\&quot;&gt;&lt;u&gt;Faroe Islands&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/gg#ios-vs-android\&quot;&gt;&lt;u&gt;Guernsey&lt;/u&gt;&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/dk#ios-vs-android\&quot;&gt;&lt;u&gt;Denmark&lt;/u&gt;&lt;/a&gt;. Adoption rates of 50% or more were seen in a total of 26 countries/regions, including &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/no#ios-vs-android\&quot;&gt;&lt;u&gt;Norway&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/se#ios-vs-android\&quot;&gt;&lt;u&gt;Sweden&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/au#ios-vs-android\&quot;&gt;&lt;u&gt;Australia&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/jp#ios-vs-android\&quot;&gt;&lt;u&gt;Japan&lt;/u&gt;&lt;/a&gt;, the &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/us#ios-vs-android\&quot;&gt;&lt;u&gt;United States&lt;/u&gt;&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/ca#ios-vs-android\&quot;&gt;&lt;u&gt;Canada&lt;/u&gt;&lt;/a&gt;. These locations likely have a greater ability to afford higher priced devices, owing to their comparatively higher gross national income per capita.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/QCfjlx0TgEotwU2wPm0hE/af1359f249aec86894b681249fe7ee70/adoption_-_Android_iOS_top_5.png\&quot; alt=\&quot;adoption - Android iOS top 5\&quot; class=\&quot;kg-image\&quot; width=\&quot;967\&quot; height=\&quot;556\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Countries/regions with the largest share of iOS traffic in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;globally-nearly-half-of-web-requests-used-http-2-with-20-5-using-http-3\&quot;&gt;Globally, nearly half of web requests used HTTP/2, with 20.5% using HTTP/3.&lt;/h3&gt;\n            &lt;a href=\&quot;#globally-nearly-half-of-web-requests-used-http-2-with-20-5-using-http-3\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;HTTP (HyperText Transfer Protocol) is the core protocol that the web relies upon. &lt;a href=\&quot;https://datatracker.ietf.org/doc/html/rfc1945\&quot;&gt;&lt;u&gt;HTTP/1.0&lt;/u&gt;&lt;/a&gt; was first standardized in 1996, &lt;a href=\&quot;https://www.rfc-editor.org/rfc/rfc2616.html\&quot;&gt;&lt;u&gt;HTTP/1.1&lt;/u&gt;&lt;/a&gt; in 1999, and &lt;a href=\&quot;https://www.rfc-editor.org/rfc/rfc7540.html\&quot;&gt;&lt;u&gt;HTTP/2&lt;/u&gt;&lt;/a&gt; in 2015. The most recent version, &lt;a href=\&quot;https://www.rfc-editor.org/rfc/rfc9114.html\&quot;&gt;&lt;u&gt;HTTP/3&lt;/u&gt;&lt;/a&gt;, was completed in 2022, and runs on top of a new transport protocol known as &lt;a href=\&quot;https://blog.cloudflare.com/the-road-to-quic/\&quot;&gt;&lt;u&gt;QUIC&lt;/u&gt;&lt;/a&gt;. By running on top of QUIC, &lt;a href=\&quot;https://www.cloudflare.com/learning/performance/what-is-http3/\&quot;&gt;&lt;u&gt;HTTP/3&lt;/u&gt;&lt;/a&gt; can deliver improved performance by mitigating the effects of packet loss and network changes, as well as establishing connections more quickly. HTTP/3 also provides encryption by default, which mitigates the risk of attacks. &lt;/p&gt;&lt;p&gt;Current versions of desktop and mobile Google Chrome (and Chromium-based variants), Mozilla Firefox, and Apple Safari &lt;a href=\&quot;https://caniuse.com/?search=http%2F3\&quot;&gt;&lt;u&gt;all support HTTP/3 by default&lt;/u&gt;&lt;/a&gt;. Cloudflare makes HTTP/3 &lt;a href=\&quot;https://developers.cloudflare.com/speed/optimization/protocol/http3/\&quot;&gt;&lt;u&gt;available for free&lt;/u&gt;&lt;/a&gt; to all of our customers, although not every customer chooses to enable it.&lt;/p&gt;&lt;p&gt;Analysis of the HTTP version negotiated for each request provides insight into the distribution of traffic by the various versions of the protocol aggregated across the year. (“HTTP/1.x” aggregates requests made over HTTP/1.0 and HTTP/1.1.) At a &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#http-versions\&quot;&gt;&lt;u&gt;global&lt;/u&gt;&lt;/a&gt; level, 20.5% of requests in 2024 were made using HTTP/3. Another 29.9% of requests were made over the older HTTP/1.x versions, while HTTP/2 remained dominant, accounting for the remaining 49.6%.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/r7KQkjdsXXEtxHoEkFQbO/efb19d1bbd58bef3d657b96555d70103/adoption_-_HTTP_versions_global.png\&quot; alt=\&quot;adoption - HTTP versions global\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;375\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Global distribution of traffic by HTTP version in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;Looking at version distribution geographically, we found eight countries/regions sending more than a third of their requests over HTTP/3, with &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/re#http-versions\&quot;&gt;&lt;u&gt;Reunion&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/lk#http-versions\&quot;&gt;&lt;u&gt;Sri Lanka&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/mn#http-versions\&quot;&gt;&lt;u&gt;Mongolia&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/gr#http-versions\&quot;&gt;&lt;u&gt;Greece&lt;/u&gt;&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/mk#http-versions\&quot;&gt;&lt;u&gt;North Macedonia&lt;/u&gt;&lt;/a&gt; comprising the top five as shown below. Eight other countries/regions, including &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/ir#http-versions\&quot;&gt;&lt;u&gt;Iran&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/ie#http-versions\&quot;&gt;&lt;u&gt;Ireland&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/hk#http-versions\&quot;&gt;&lt;u&gt;Hong Kong&lt;/u&gt;&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/cn#http-versions\&quot;&gt;&lt;u&gt;China&lt;/u&gt;&lt;/a&gt;, sent more than half of their requests over HTTP/1.x throughout 2024. More than half of requests were made over HTTP/2 in a total of 147 countries/regions.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2Zq4mMgbvw6jT6pb6LLdF7/401b98731302233b6f9674e74196e819/adoption_-_HTTP_versions_top_5.png\&quot; alt=\&quot;adoption - HTTP versions top 5\&quot; class=\&quot;kg-image\&quot; width=\&quot;967\&quot; height=\&quot;556\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Countries/regions with the largest shares of HTTP/3 traffic in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;react-php-and-jquery-were-among-the-most-popular-technologies-used-to-build-websites-while-hubspot-google-and-wordpress-were-among-the-most-popular-vendors-of-supporting-services-and-platforms\&quot;&gt;React, PHP, and jQuery were among the most popular technologies used to build websites, while Hubspot, Google, and WordPress were among the most popular vendors of supporting services and platforms.&lt;/h3&gt;\n            &lt;a href=\&quot;#react-php-and-jquery-were-among-the-most-popular-technologies-used-to-build-websites-while-hubspot-google-and-wordpress-were-among-the-most-popular-vendors-of-supporting-services-and-platforms\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Modern websites and applications are extremely complex, built on and integrating on a mix of frameworks, platforms, services, and tools. In order to deliver a seamless user experience, developers must ensure that all of these components happily coexist with each other. Using &lt;a href=\&quot;https://radar.cloudflare.com/scan\&quot;&gt;&lt;u&gt;Cloudflare Radar’s URL Scanner&lt;/u&gt;&lt;/a&gt;, we again scanned websites associated with the &lt;a href=\&quot;https://radar.cloudflare.com/domains\&quot;&gt;&lt;u&gt;top 5000 domains&lt;/u&gt;&lt;/a&gt; to identify the &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#website-technologies\&quot;&gt;&lt;u&gt;most popular technologies and services&lt;/u&gt;&lt;/a&gt; used across a dozen different categories. &lt;/p&gt;&lt;p&gt;In looking at core technologies used to build websites, &lt;a href=\&quot;https://react.dev/\&quot;&gt;&lt;u&gt;React&lt;/u&gt;&lt;/a&gt; had a commanding lead over &lt;a href=\&quot;https://vuejs.org/\&quot;&gt;&lt;u&gt;Vue.js&lt;/u&gt;&lt;/a&gt; and other JavaScript frameworks, &lt;a href=\&quot;https://www.php.net/\&quot;&gt;&lt;u&gt;PHP&lt;/u&gt;&lt;/a&gt; was the most popular programming technology, and &lt;a href=\&quot;https://jquery.com/\&quot;&gt;&lt;u&gt;jQuery&lt;/u&gt;&lt;/a&gt;’s share was 10x other popular JavaScript libraries.&lt;/p&gt;&lt;p&gt;Third-party services and platforms are also used by websites and applications to support things like analytics, content management, and marketing automation. Google Analytics remained the most widely used analytics provider, WordPress had a greater than 50% share among content management systems, and for marketing automation providers, category leader HubSpot had nearly twice the usage share of Marketo and MailChimp.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2fJS1OpqRlVCsZ9VOXdU89/c01320ff9d20da4ad2471de780a86033/adoption_-_top_website_technologies.png\&quot; alt=\&quot;adoption - top website technologies\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;902\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Top website technologies, JavaScript frameworks category in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;go-surpassed-nodejs-as-the-most-popular-language-used-for-making-automated-api-requests\&quot;&gt;Go surpassed NodeJS as the most popular language used for making automated API requests.&lt;/h3&gt;\n            &lt;a href=\&quot;#go-surpassed-nodejs-as-the-most-popular-language-used-for-making-automated-api-requests\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Many dynamic websites and applications are built on &lt;a href=\&quot;https://blog.cloudflare.com/2024-api-security-report/\&quot;&gt;&lt;u&gt;automated API calls&lt;/u&gt;&lt;/a&gt;, and we can use our unique visibility into Web traffic to identify the top languages these API clients are written in. Applying heuristics to API-related requests determined to not be coming from a person using a browser or native mobile application helps us to identify the language used to build the API client.&lt;/p&gt;&lt;p&gt;&lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#api-client-language-popularity\&quot;&gt;&lt;u&gt;Our analysis&lt;/u&gt;&lt;/a&gt; found that almost 12% of automated API requests are made by &lt;a href=\&quot;https://go.dev/\&quot;&gt;&lt;u&gt;Go&lt;/u&gt;&lt;/a&gt;-based clients, with &lt;a href=\&quot;https://nodejs.org/en/\&quot;&gt;&lt;u&gt;NodeJS&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://www.python.org/\&quot;&gt;&lt;u&gt;Python&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://www.java.com/\&quot;&gt;&lt;u&gt;Java&lt;/u&gt;&lt;/a&gt;, and &lt;a href=\&quot;https://dotnet.microsoft.com/\&quot;&gt;&lt;u&gt;.NET&lt;/u&gt;&lt;/a&gt; holding smaller shares. Compared to &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2023#api-client-language-popularity\&quot;&gt;&lt;u&gt;2023&lt;/u&gt;&lt;/a&gt;, Go’s share increased by approximately 40%, allowing it to capture the top spot, while NodeJS’s share fell by just over 30%. Python and Java also saw their shares increase, while .NET’s fell.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7oq8vCSsDq57HNYCbEV59n/9373b727f7f7da45be317ba34d23dcab/adoption_-_api_client_languages.png\&quot; alt=\&quot;adoption - api client languages\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;521\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Most popular API client languages in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;google-is-the-most-popular-search-engine-globally-across-all-platforms-on-mobile-devices-os-baidu-is-a-distant-second-bing-is-a-distant-second-across-desktop-and-windows-devices-with-duckduckgo-second-most-popular-on-macos\&quot;&gt;Google is the most popular search engine globally, across all platforms. On mobile devices/OS, Baidu is a distant second. Bing is a distant second across desktop and Windows devices, with DuckDuckGo second most popular on macOS. &lt;/h3&gt;\n            &lt;a href=\&quot;#google-is-the-most-popular-search-engine-globally-across-all-platforms-on-mobile-devices-os-baidu-is-a-distant-second-bing-is-a-distant-second-across-desktop-and-windows-devices-with-duckduckgo-second-most-popular-on-macos\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Protecting and accelerating websites and applications for millions of customers, Cloudflare is in a unique position to measure search engine market share data. Our methodology uses HTTP’s &lt;a href=\&quot;https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Referer\&quot;&gt;&lt;u&gt;referer header&lt;/u&gt;&lt;/a&gt; to identify the search engine sending traffic to customer sites and applications. The market share data is presented as an overall aggregate, as well as broken out by device type and operating system. (Device type and operating system data is derived from the &lt;a href=\&quot;https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/User-Agent\&quot;&gt;&lt;u&gt;User-Agent&lt;/u&gt;&lt;/a&gt; and &lt;a href=\&quot;https://developer.mozilla.org/en-US/docs/Web/HTTP/Client_hints\&quot;&gt;&lt;u&gt;Client Hints&lt;/u&gt;&lt;/a&gt; headers accompanying a content request.)&lt;/p&gt;&lt;p&gt;Aggregated at a &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#search-engine-market-share\&quot;&gt;&lt;u&gt;global&lt;/u&gt;&lt;/a&gt; level, Google referred the most traffic to Cloudflare customers, with a greater than 88% share across 2024. Yandex, Baidu, Bing, and DuckDuckGo round out the top five, all with single digit percentage shares. &lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7bwTSu9NktZ9chotEmTQhs/fd231b3f13fe4709ca7480546276d2e0/adoption_-_search_engine_overall_worldwide.png\&quot; alt=\&quot;adoption - search engine overall worldwide\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;840\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Overall worldwide search engine market share in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;However, when drilling down by location or platform, differences are apparent in the top search engines and their shares. For example, in &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/kr#search-engine-market-share\&quot;&gt;&lt;u&gt;South Korea&lt;/u&gt;&lt;/a&gt;, Google is responsible for only two-thirds of referrals, while local platform &lt;a href=\&quot;https://www.naver.com/\&quot;&gt;&lt;u&gt;Naver&lt;/u&gt;&lt;/a&gt; drives 29.2%, with local portal &lt;a href=\&quot;https://www.daum.net/\&quot;&gt;&lt;u&gt;Daum&lt;/u&gt;&lt;/a&gt; also in the top five at 1.3%.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/rxOIPPwpJSt73X1GXH8t4/5597fd261ec7fda2cf357c70479be13f/adoption_-_search_engine_overall_South_Korea.png\&quot; alt=\&quot;adoption - search engine overall South Korea\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;840\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Overall search engine market share in South Korea in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;Google’s dominance is also blunted a bit on Windows devices, where it drives only 80% of referrals globally. Unsurprisingly, Bing holds the second spot for Windows users, with a 10.4% share. Yandex, Yahoo, and DuckDuckGo round out the top 5, all with shares below 5%.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4sKOs50fTPbchv55J7gQrM/1ce8b0c1287bbd5b35d9e987e2061207/adoption_-_search_engine_overall_worldwide_Windows.png\&quot; alt=\&quot;adoption - search engine overall worldwide Windows\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;840\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Overall worldwide search engine market share for Windows devices in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;For additional details, including search engines aggregated under “Other”, please refer to the quarterly &lt;a href=\&quot;https://radar.cloudflare.com/reports/search-engines\&quot;&gt;&lt;u&gt;Search Engine Referral Reports&lt;/u&gt;&lt;/a&gt; on Cloudflare Radar.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;google-chrome-is-the-most-popular-browser-overall-while-also-true-on-macos-devices-safari-usage-is-well-ahead-of-chrome-on-ios-devices-on-windows-edge-is-the-second-most-popular-browser\&quot;&gt;Google Chrome is the most popular browser overall. While also true on MacOS devices, Safari usage is well ahead of Chrome on iOS devices. On Windows, Edge is the second most popular browser. &lt;/h3&gt;\n            &lt;a href=\&quot;#google-chrome-is-the-most-popular-browser-overall-while-also-true-on-macos-devices-safari-usage-is-well-ahead-of-chrome-on-ios-devices-on-windows-edge-is-the-second-most-popular-browser\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Similar to our ability to measure search engine market share, Cloudflare is also in a unique position to measure browser market share. Our methodology uses information from the &lt;a href=\&quot;https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/User-Agent\&quot;&gt;&lt;u&gt;User-Agent&lt;/u&gt;&lt;/a&gt; and &lt;a href=\&quot;https://developer.mozilla.org/en-US/docs/Web/HTTP/Client_hints\&quot;&gt;&lt;u&gt;Client Hints&lt;/u&gt;&lt;/a&gt; headers to identify the browser making content requests, along with the associated operating system. Browser market share data is presented as an overall aggregate, as well as broken out by device type and operating system. Note that the shares of browsers available on both desktop and mobile devices, such as Chrome or Safari, are presented in aggregate.&lt;/p&gt;&lt;p&gt;&lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#browser-market-share\&quot;&gt;&lt;u&gt;Globally&lt;/u&gt;&lt;/a&gt;, we found that 65.8% of requests came from Google’s Chrome browser across 2024, and that just 15.5% came from Apple’s Safari browser. Microsoft Edge, Mozilla Firefox, and the &lt;a href=\&quot;https://www.samsung.com/us/support/owners/app/samsung-internet\&quot;&gt;&lt;u&gt;Samsung Internet browser&lt;/u&gt;&lt;/a&gt; rounded out the top five, all with shares below 10%.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1bEuEbqSrAqe57gnBTeL6c/4426dc0dbc8869d05344433535e0698a/adoption_-_browser_overall_worldwide.png\&quot; alt=\&quot;adoption - browser overall worldwide\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;840\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Overall worldwide web browser market share in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;Similar to the search engine statistics discussed above, differences are clearly visible when drilling down by location or platform. In some countries where iOS holds a larger market share than Android, Chrome remains the leading browser, but by a much lower margin. For example, in &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/se#browser-market-share\&quot;&gt;&lt;u&gt;Sweden&lt;/u&gt;&lt;/a&gt;, Chrome’s share fell to 56.2%, while Safari’s increased to 22.5%. In &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/no#browser-market-share\&quot;&gt;&lt;u&gt;Norway&lt;/u&gt;&lt;/a&gt;, Chrome fell to just 50%, while Safari grew to 25.6%.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2Dkt8A1HuUpg61G8GYkEXs/5c2649e96d2959a2606afa9d932d5b82/adoption_-_browser_overall_Norway.png\&quot; alt=\&quot;adoption - browser overall Norway\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;840\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Overall web browser market share in Norway in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;As the default browser on devices running iOS, Apple Safari was the most popular browser for iOS devices, commanding an 81.7% market share across the year, with Chrome at just 16.1%. And despite being the preinstalled default browser on Windows devices, Edge held just a 17.3% share, in comparison to Chrome’s 68.5%&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5Hvnf7VPBuVTjba0P1bGRU/6d6e31c609a54c8248afe120576210aa/adoption_-_browser_overall_worldwide_iOS.png\&quot; alt=\&quot;adoption - browser overall worldwide iOS\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;840\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Overall worldwide web browser market share for iOS devices in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;For additional details, including browsers aggregated under “Other”, please refer to the quarterly &lt;u&gt;Browser Market Share Reports&lt;/u&gt; on Cloudflare Radar.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;connectivity\&quot;&gt;Connectivity&lt;/h2&gt;\n            &lt;a href=\&quot;#connectivity\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          \n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7xC8lBdDHpahlvkJrf1nI9/7b050dc62c1628e3a5ab3a9418e572d3/2627_Rocket.png\&quot; alt=\&quot;2627 Rocket\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;417\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;225-major-internet-outages-were-observed-around-the-world-in-2024-with-many-due-to-government-directed-regional-and-national-shutdowns-of-internet-connectivity\&quot;&gt;225 major Internet outages were observed around the world in 2024, with many due to government-directed regional and national shutdowns of Internet connectivity.&lt;/h3&gt;\n            &lt;a href=\&quot;#225-major-internet-outages-were-observed-around-the-world-in-2024-with-many-due-to-government-directed-regional-and-national-shutdowns-of-internet-connectivity\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Throughout 2024, as we have over the last several years, we have written frequently about observed Internet outages, whether due to &lt;a href=\&quot;https://blog.cloudflare.com/east-african-internet-connectivity-again-impacted-by-submarine-cable-cuts\&quot;&gt;&lt;u&gt;cable cuts&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://blog.cloudflare.com/impact-of-verizons-september-30-outage-on-internet-traffic/\&quot;&gt;&lt;u&gt;unspecified technical issues&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://blog.cloudflare.com/syria-iraq-algeria-exam-internet-shutdown\&quot;&gt;&lt;u&gt;government-directed shutdowns&lt;/u&gt;&lt;/a&gt;, or a number of other reasons covered in our quarterly summary posts (&lt;a href=\&quot;https://blog.cloudflare.com/q1-2024-internet-disruption-summary\&quot;&gt;&lt;u&gt;Q1&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://blog.cloudflare.com/q2-2024-internet-disruption-summary\&quot;&gt;&lt;u&gt;Q2&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://blog.cloudflare.com/q3-2024-internet-disruption-summary\&quot;&gt;&lt;u&gt;Q3&lt;/u&gt;&lt;/a&gt;). The impacts of these outages can be significant, including significant economic losses and severely limited communications. The &lt;a href=\&quot;https://radar.cloudflare.com/outage-center\&quot;&gt;&lt;u&gt;Cloudflare Radar Outage Center&lt;/u&gt;&lt;/a&gt; tracks these Internet outages, and uses Cloudflare traffic data for insights into their scope and duration.&lt;/p&gt;&lt;p&gt;Some of the outages seen through the year were short-lived, lasting just a few hours, while others stretched on for days or weeks. In the latter category, an Internet outage in &lt;a href=\&quot;https://blog.cloudflare.com/q3-2024-internet-disruption-summary/#haiti\&quot;&gt;&lt;u&gt;Haiti&lt;/u&gt;&lt;/a&gt; dragged on for eight days in September because repair crews were barred from accessing a damaged submarine cable due to a business dispute, while shutdowns of mobile and fixed Internet providers in &lt;a href=\&quot;https://blog.cloudflare.com/q3-2024-internet-disruption-summary/#bangladesh\&quot;&gt;&lt;u&gt;Bangladesh&lt;/u&gt;&lt;/a&gt; lasted for approximately 10 days in July. In the former category, &lt;a href=\&quot;https://blog.cloudflare.com/q3-2024-internet-disruption-summary/#iraqi-kurdistan\&quot;&gt;&lt;u&gt;Iraq&lt;/u&gt;&lt;/a&gt; frequently experienced multi-hour nationwide Internet shutdowns intended to prevent cheating on academic exams — these contribute to the clustering visible in the timeline during June, July, August, and September.&lt;/p&gt;&lt;p&gt;Within the &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#internet-outages\&quot;&gt;&lt;u&gt;timeline&lt;/u&gt;&lt;/a&gt; on the Year in Review microsite, hovering over a dot will display metadata about that outage, and clicking on it will open a page with additional information. Below the map and timeline, we have added a bar graph illustrating the recorded reasons associated with the observed outages. In 2024, over half were due to government-directed shutdowns. If a country/region is selected, only outages and reasons for that country/region will be displayed.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/VDxaH2IkD28RXrcStCn8j/39ce7ad40f6a3d59e155ff09664f80e0/connectivity_-_Internet_outage_map.png\&quot; alt=\&quot;connectivity - Internet outage map\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;1151\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Over 200 Internet outages were observed around the world during 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;aggregated-across-2024-28-5-of-ipv6-capable-requests-were-made-over-ipv6-india-and-malaysia-were-the-strongest-countries-at-68-9-and-59-6-ipv6-adoption-respectively\&quot;&gt;Aggregated across 2024, 28.5% of IPv6-capable requests were made over IPv6. India and Malaysia were the strongest countries, at 68.9% and 59.6% IPv6 adoption respectively.&lt;/h3&gt;\n            &lt;a href=\&quot;#aggregated-across-2024-28-5-of-ipv6-capable-requests-were-made-over-ipv6-india-and-malaysia-were-the-strongest-countries-at-68-9-and-59-6-ipv6-adoption-respectively\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;The IPv4 protocol still used by many Internet-connected devices was developed in the 1970s, and was never meant to handle the vast and growing scale of the modern Internet. An &lt;a href=\&quot;https://www.rfc-editor.org/rfc/rfc1883\&quot;&gt;&lt;u&gt;initial specification for its successor&lt;/u&gt;&lt;/a&gt;, IPv6, was published in December 1995, evolving to a &lt;a href=\&quot;https://www.rfc-editor.org/rfc/rfc2460\&quot;&gt;&lt;u&gt;draft standard&lt;/u&gt;&lt;/a&gt; three years later, offering an expanded address space intended to better support the expected growth in the number of Internet-connected devices. At this point, available IPv4 space has long since been &lt;a href=\&quot;https://ipv4.potaroo.net/\&quot;&gt;&lt;u&gt;exhausted&lt;/u&gt;&lt;/a&gt;, and connectivity providers use solutions like &lt;a href=\&quot;https://en.wikipedia.org/wiki/Network_address_translation\&quot;&gt;&lt;u&gt;Network Address Translation&lt;/u&gt;&lt;/a&gt; to stretch limited IPv4 resources. Hungry for IPv4 address space as their businesses and infrastructure grow, cloud and hosting providers are acquiring blocks of IPv4 address space for &lt;a href=\&quot;https://auctions.ipv4.global/\&quot;&gt;&lt;u&gt;as much as \\$30 - \\$50 per address&lt;/u&gt;&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;Cloudflare has been a vocal and active advocate for IPv6 since 2011, when we announced our &lt;a href=\&quot;https://blog.cloudflare.com/introducing-cloudflares-automatic-ipv6-gatewa/\&quot;&gt;&lt;u&gt;Automatic IPv6 Gateway&lt;/u&gt;&lt;/a&gt;, which enabled free IPv6 support for all of our customers. In 2014, we enabled &lt;a href=\&quot;https://blog.cloudflare.com/i-joined-cloudflare-on-monday-along-with-5-000-others\&quot;&gt;&lt;u&gt;IPv6 support by default for all of our customers&lt;/u&gt;&lt;/a&gt;, but not all customers choose to keep it enabled for a variety of reasons. Note that server-side support is only half of the equation for driving IPv6 adoption, as end user connections need to support it as well. (In reality, it is a bit more complex than that, but server and client side support across applications, operating systems, and network environments are the two primary requirements. From a network perspective, implementing IPv6 also brings a number of other &lt;a href=\&quot;https://www.catchpoint.com/benefits-of-ipv6\&quot;&gt;&lt;u&gt;benefits&lt;/u&gt;&lt;/a&gt;.) By analyzing the IP version used for each request made to Cloudflare, aggregated throughout the year, we can get insight into the distribution of traffic by the various versions of the protocol.&lt;/p&gt;&lt;p&gt;At a &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#ipv6-adoption\&quot;&gt;&lt;u&gt;global&lt;/u&gt;&lt;/a&gt; level, 28.5% of IPv6-capable (“&lt;a href=\&quot;https://www.techopedia.com/definition/19025/dual-stack-network\&quot;&gt;&lt;u&gt;dual-stack&lt;/u&gt;&lt;/a&gt;”) requests were made over IPv6, up from 26.4% in &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024?previousYear=true\&quot;&gt;&lt;u&gt;2023&lt;/u&gt;&lt;/a&gt;. &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/in#ipv6-adoption\&quot;&gt;&lt;u&gt;India&lt;/u&gt;&lt;/a&gt; was again the country with the highest level of IPv6 adoption, at 68.9%, carried in large part by &lt;a href=\&quot;https://radar.cloudflare.com/adoption-and-usage/as55836?dateStart=2024-01-01&amp;dateEnd=2024-12-01\&quot;&gt;&lt;u&gt;94% IPv6 adoption at Reliance Jio&lt;/u&gt;&lt;/a&gt;, one of the country’s largest Internet service providers. India was followed closely by &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/my#ipv6-adoption\&quot;&gt;&lt;u&gt;Malaysia&lt;/u&gt;&lt;/a&gt;, where 59.6% of dual-stacked requests were made over IPv6 during 2024, thanks to &lt;a href=\&quot;https://radar.cloudflare.com/explorer?dataSet=http&amp;groupBy=ases&amp;loc=MY&amp;dt=14d&amp;metric=ip_version%2FIPv6\&quot;&gt;&lt;u&gt;strong IPv6 adoption rates across leading Internet providers&lt;/u&gt;&lt;/a&gt; within the country. IPv6 adoption in India was up from 66% in &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/in?previousYear=true#ipv6-adoption\&quot;&gt;&lt;u&gt;2023&lt;/u&gt;&lt;/a&gt;, and in Malaysia, it was up from 57.3% &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/my?previousYear=true#ipv6-adoption\&quot;&gt;&lt;u&gt;last year&lt;/u&gt;&lt;/a&gt;. &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/sa#ipv6-adoption\&quot;&gt;&lt;u&gt;Saudi Arabia&lt;/u&gt;&lt;/a&gt; was the only other country with an IPv6 adoption rate above 50% this year, at 51.8%, whereas that list also included &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2023/vn#ipv6-adoption\&quot;&gt;&lt;u&gt;Vietnam&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2023/gr#ipv6-adoption\&quot;&gt;&lt;u&gt;Greece&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2023/fr#ipv6-adoption\&quot;&gt;&lt;u&gt;France&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2023/uy#ipv6-adoption\&quot;&gt;&lt;u&gt;Uruguay&lt;/u&gt;&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2023/th#ipv6-adoption\&quot;&gt;&lt;u&gt;Thailand&lt;/u&gt;&lt;/a&gt; in 2023. Thirty four countries/regions, including many in Africa, still have IPv6 adoption rates below 1%, while a total of 96 countries/regions have adoption rates below 10%.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/48L0qRLujnWQRuJ8ZMa8Ed/ac5209577812dd556d275279d4740041/connectivity_-_IPv6_adoption.png\&quot; alt=\&quot;connectivity - IPv6 adoption\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;268\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Global distribution of traffic by IP version in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/NjeXm7lfs7ZGM3Gn5ToZM/3b401894664cb22347db1a8d8a2bfdc8/connectivity_-_IPv6_adoption_top_5.png\&quot; alt=\&quot;connectivity - IPv6 adoption top 5\&quot; class=\&quot;kg-image\&quot; width=\&quot;967\&quot; height=\&quot;556\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Countries/regions with the largest shares of IPv6 traffic in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;the-top-10-countries-ranked-by-internet-speed-all-had-average-download-speeds-above-200-mbps-spain-was-consistently-among-the-top-locations-across-measured-internet-quality-metrics\&quot;&gt;The top 10 countries ranked by Internet speed all had average download speeds above 200 Mbps. Spain was consistently among the top locations across measured Internet quality metrics.&lt;/h3&gt;\n            &lt;a href=\&quot;#the-top-10-countries-ranked-by-internet-speed-all-had-average-download-speeds-above-200-mbps-spain-was-consistently-among-the-top-locations-across-measured-internet-quality-metrics\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;As more and more of our everyday lives move online, including entertainment, work, education, finance, shopping, and even basic social and personal interaction, the quality of our Internet connections is arguably more important than ever, necessitating higher connection speeds and lower latency. Although Internet providers continue to evolve their service portfolios to offer increased connection speeds and reduced latency in order to support growth in use cases like videoconferencing, live streaming, and online gaming, consumer adoption is often mixed due to cost, availability, or other issues. By aggregating the results of &lt;a href=\&quot;https://speed.cloudflare.com/\&quot;&gt;&lt;u&gt;speed.cloudflare.com&lt;/u&gt;&lt;/a&gt; tests taken during 2024, we can get a geographic perspective on &lt;a href=\&quot;https://developers.cloudflare.com/radar/glossary/#connection-quality\&quot;&gt;&lt;u&gt;connection quality&lt;/u&gt;&lt;/a&gt; metrics including average download and upload speeds, and average idle and loaded latencies, as well as the distribution of the measurements.&lt;/p&gt;&lt;p&gt;In &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#internet-quality\&quot;&gt;&lt;u&gt;2024&lt;/u&gt;&lt;/a&gt;, Spain was a leader in download speed (292.6 Mbps) and upload speed (192.6 Mbps) metrics, and placed second globally for loaded latency (78.6 ms). (Loaded latency is the round-trip time when data-heavy applications are being used on the network.) Spain’s leadership in these connection quality metrics is supported by the strong progress that the country has made &lt;a href=\&quot;https://ec.europa.eu/newsroom/dae/redirection/document/106695\&quot;&gt;&lt;u&gt;towards achieving the EU’s “Digital Decade” objectives&lt;/u&gt;&lt;/a&gt;, including fixed very high capacity network (VHCN) deployment, fiber-to-the-premises (FTTP) coverage, and 5G coverage with the latter two &lt;a href=\&quot;https://www.trade.gov/country-commercial-guides/spain-digital-economy\&quot;&gt;&lt;u&gt;reaching&lt;/u&gt;&lt;/a&gt; 95.2% and 92.3% respectively. High speed fiber broadband connections are also relatively affordable, with research showing major providers offering 100 Mbps, 300 Mbps, 600 Mbps, and 1 Gbps packages, with the latter priced between €30 and €46 per month. The figures below for &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/es#internet-quality\&quot;&gt;&lt;u&gt;Spain&lt;/u&gt;&lt;/a&gt; show the largest clusters of speed measurements around the 100 Mbps mark, with slight bumps also visible around 300 Mbps, suggesting that the former package has the highest subscription rate, followed by the latter. Further, they show these connections are also relatively low latency, with 87% of idle latency measurements below 50 ms and 65% of loaded latency measurements below 100 ms, providing users with good &lt;a href=\&quot;https://www.screenbeam.com/wifihelp/wifibooster/how-to-reduce-latency-or-lag-in-gaming-2/#:~:text=Latency%20is%20measured%20in%20milliseconds,%2C%2020%2D40ms%20is%20optimal.\&quot;&gt;&lt;u&gt;gaming&lt;/u&gt;&lt;/a&gt; and &lt;a href=\&quot;https://www.haivision.com/glossary/video-latency/#:~:text=Low%20latency%20is%20typically%20defined,and%20streaming%20previously%20recorded%20events.\&quot;&gt;&lt;u&gt;videoconferencing/streaming&lt;/u&gt;&lt;/a&gt; experiences.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/51PcbNyPpAQX79gYg0SxIU/a784aaadd65822d3384f1463570a6129/connectivity_-_Spain_bandwidth.png\&quot; alt=\&quot;connectivity - Spain bandwidth\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;485\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Measured download/upload speed distribution in Spain in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3Refsg6ctWdHNzscsoIDDF/75da3336fa1e31fd71a2188787944a57/connectivity_-_Spain_latency.png\&quot; alt=\&quot;connectivity - Spain latency\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;485\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Measured idle/loaded latency distribution in Spain in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;41-3-of-global-traffic-comes-from-mobile-devices-in-nearly-100-countries-regions-the-majority-of-traffic-comes-from-mobile-devices\&quot;&gt;41.3% of global traffic comes from mobile devices. In nearly 100 countries/regions, the majority of traffic comes from mobile devices.&lt;/h3&gt;\n            &lt;a href=\&quot;#41-3-of-global-traffic-comes-from-mobile-devices-in-nearly-100-countries-regions-the-majority-of-traffic-comes-from-mobile-devices\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;With approximately &lt;a href=\&quot;https://www.statista.com/topics/840/smartphones/#topicOverview\&quot;&gt;&lt;u&gt;70% of the world’s population using smartphones&lt;/u&gt;&lt;/a&gt;, and &lt;a href=\&quot;https://www.pewresearch.org/internet/fact-sheet/mobile/\&quot;&gt;&lt;u&gt;91% of Americans owning a smartphone&lt;/u&gt;&lt;/a&gt;, these mobile devices have become an integral part of both our personal and professional lives, providing us with Internet access from nearly any place at any time. In some countries/regions, mobile devices primarily connect to the Internet via Wi-Fi, while other countries/regions are “mobile first”, where 4G/5G services are the primary means of Internet access.&lt;/p&gt;&lt;p&gt;Analysis of information contained with the user agent reported with each request to Cloudflare enables us to categorize it as coming from a mobile, desktop, or other type of device. Aggregating this categorization throughout the year at a &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#mobile-vs-desktop\&quot;&gt;&lt;u&gt;global&lt;/u&gt;&lt;/a&gt; level, we found that 41.3% of traffic came from mobile devices, with 58.7% coming from desktop devices such as laptops and “classic” PCs. These traffic shares were in line with those measured in both &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2023#mobile-vs-desktop\&quot;&gt;&lt;u&gt;2023&lt;/u&gt;&lt;/a&gt; and 2022, suggesting that mobile device usage has achieved a “steady state”. Over 77% of traffic came from mobile devices in &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/sd#mobile-vs-desktop\&quot;&gt;&lt;u&gt;Sudan&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/cu#mobile-vs-desktop\&quot;&gt;&lt;u&gt;Cuba&lt;/u&gt;&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/sy#mobile-vs-desktop\&quot;&gt;&lt;u&gt;Syria&lt;/u&gt;&lt;/a&gt;, making them the countries/regions with the largest mobile device traffic share in 2024. Other countries/regions that had more than 50% of traffic come from mobile devices were concentrated in the Middle East/Africa, the Asia Pacific region, and South/Central America. &lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/9bsuRwzYBybYpOiKqwLja/cbdafb60eab1913a91ec916899d1e807/connectivity_-_mobile_desktop.png\&quot; alt=\&quot;connectivity - mobile desktop\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;268\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Global distribution of traffic by device type in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/KRujuREGMTBvLHVAHonuU/ad575fdd822ee3ee0bcabd41a96ef736/connectivity_-_mobile_desktop_top_5.png\&quot; alt=\&quot;connectivity - mobile desktop top 5\&quot; class=\&quot;kg-image\&quot; width=\&quot;967\&quot; height=\&quot;556\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Countries/regions with the largest shares of mobile device usage in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;20-7-of-tcp-connections-are-unexpectedly-terminated-before-any-useful-data-can-be-exchanged\&quot;&gt;20.7% of TCP connections are unexpectedly terminated before any useful data can be exchanged.&lt;/h3&gt;\n            &lt;a href=\&quot;#20-7-of-tcp-connections-are-unexpectedly-terminated-before-any-useful-data-can-be-exchanged\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Cloudflare is in a unique position to help measure the health and behaviors of Internet networks around the world. One way we do this is passively measuring rates of connections to Cloudflare that appear &lt;i&gt;anomalous&lt;/i&gt;, meaning that they are unexpectedly terminated before any useful data exchange occurs. The underlying causes of connection anomalies are varied and range from DoS attacks to quirky client behavior to third-party connection tampering (e.g., when a network monitors and selectively disrupts connections to filter content).&lt;/p&gt;&lt;p&gt;Connection anomalies are symptoms — visible signs that “something abnormal” is happening in a network, but the underlying root cause is not always clear from the outset. However, we can gain a better understanding by incorporating previously-reported network behaviors, active measurements and on-the-ground reports, and macro trends across networks. Additional details on such analysis can be found in the blog posts &lt;a href=\&quot;https://blog.cloudflare.com/connection-tampering/\&quot;&gt;&lt;i&gt;&lt;u&gt;A global assessment of third-party connection tampering&lt;/u&gt;&lt;/i&gt;&lt;/a&gt; and&lt;a href=\&quot;https://blog.cloudflare.com/tcp-resets-timeouts/\&quot;&gt; &lt;i&gt;&lt;u&gt;Bringing insights into TCP resets and timeouts to Cloudflare Radar&lt;/u&gt;&lt;/i&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Insights into TCP connection anomalies were &lt;a href=\&quot;https://blog.cloudflare.com/tcp-resets-timeouts/\&quot;&gt;&lt;u&gt;launched on Cloudflare Radar&lt;/u&gt;&lt;/a&gt; in September, with the plot lines in the associated graph corresponding to the stage of the TCP connection in which the connection anomalously closed (using shorthand, the first three messages we typically receive from the client in a TCP connection are “SYN” and “ACK” packets to establish a connection, and then a “PSH” packet indicating the requested resource). In aggregate &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#tcp-connection-anomalies\&quot;&gt;&lt;u&gt;globally&lt;/u&gt;&lt;/a&gt;, over 20% of connections to Cloudflare were terminated unexpectedly, with the largest share (nearly half) being closed “Post SYN” — that is, after our server has received a client’s SYN packet, but before we have received a subsequent acknowledgement (ACK) from the client or any useful data that would follow the acknowledgement. These terminations can often be attributed to DoS attacks or Internet scanning. Post-ACK (3.1% globally) and Post-PSH (1.4% globally) anomalies are more often associated with connection tampering, especially when they occur at high rates in specific networks.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/11XcEAXkMgOhytTbCsf21J/159fa2459ebc6b9c268bd5d8455213ba/connectivity_-_TCP_connection_anomalies.png\&quot; alt=\&quot;connectivity - TCP connection anomalies\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;840\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Trends in TCP connection anomalies by stage in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;security\&quot;&gt;Security&lt;/h2&gt;\n            &lt;a href=\&quot;#security\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          \n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4CkCPZHGlR8gQQQrXt0b5H/cfd3faabbe406fd348b8751825bc43e5/2627_Shield_Globe.png\&quot; alt=\&quot;2627 Shield Globe\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;417\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;6-5-of-global-traffic-was-mitigated-by-cloudflares-systems-as-being-potentially-malicious-or-for-customer-defined-reasons\&quot;&gt;6.5% of global traffic was mitigated by Cloudflare&amp;#39;s systems as being potentially malicious or for customer-defined reasons.&lt;/h3&gt;\n            &lt;a href=\&quot;#6-5-of-global-traffic-was-mitigated-by-cloudflares-systems-as-being-potentially-malicious-or-for-customer-defined-reasons\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;To &lt;a href=\&quot;https://www.cloudflare.com/products/zero-trust/threat-defense/\&quot;&gt;&lt;u&gt;protect customers from threats&lt;/u&gt;&lt;/a&gt; posed by malicious bots used to attack websites and applications, Cloudflare mitigates this attack traffic using &lt;a href=\&quot;https://www.cloudflare.com/learning/ddos/what-is-a-ddos-attack/\&quot;&gt;&lt;u&gt;DDoS&lt;/u&gt;&lt;/a&gt; mitigation techniques or &lt;a href=\&quot;https://developers.cloudflare.com/waf/managed-rules/\&quot;&gt;&lt;u&gt;Web Application Firewall (WAF) Managed Rules&lt;/u&gt;&lt;/a&gt;. For a variety of other reasons, customers may also want Cloudflare to mitigate traffic using techniques like &lt;a href=\&quot;https://developers.cloudflare.com/waf/rate-limiting-rules/\&quot;&gt;&lt;u&gt;rate-limiting&lt;/u&gt;&lt;/a&gt; requests, or &lt;a href=\&quot;https://developers.cloudflare.com/waf/tools/ip-access-rules/\&quot;&gt;&lt;u&gt;blocking all traffic from a given location&lt;/u&gt;&lt;/a&gt;, even if it isn’t malicious. Analyzing traffic to Cloudflare’s network throughout 2024, we looked at the overall share that was mitigated for any reason, as well as the share that was blocked as a DDoS attack or by WAF Managed Rules. &lt;/p&gt;&lt;p&gt;In 2024, &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#mitigated-traffic\&quot;&gt;&lt;u&gt;6.5% of global traffic was mitigated&lt;/u&gt;&lt;/a&gt;, up almost one percentage point from &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2023#mitigated-traffic\&quot;&gt;&lt;u&gt;2023&lt;/u&gt;&lt;/a&gt;. Just 3.2% was mitigated as a DDoS attack, or by WAF Managed Rules, a rate slightly higher than in 2023. More than 10% of the traffic originating from 44 countries/regions had mitigations generally applied, while DDoS/WAF mitigations were applied to more than 10% of the traffic originating from just seven countries/regions.&lt;/p&gt;&lt;p&gt;At a country/region level, &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/al?#mitigated-traffic\&quot;&gt;&lt;u&gt;Albania&lt;/u&gt;&lt;/a&gt; had one of the highest mitigated traffic shares throughout the year, at 42.9%, while &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/ly#mitigated-traffic\&quot;&gt;&lt;u&gt;Libya&lt;/u&gt;&lt;/a&gt; had one of the highest shares of traffic that was mitigated as a DDoS attack or by WAF Managed Rules, at 19.2%. In &lt;a href=\&quot;https://blog.cloudflare.com/radar-2023-year-in-review/#just-under-6-of-global-traffic-was-mitigated-by-cloudflares-systems-as-being-potentially-malicious-or-for-customer-defined-reasons-in-the-united-states-3-65-of-traffic-was-mitigated-while-in-south-korea-it-was-8-36\&quot;&gt;&lt;u&gt;2023’s Year in Review blog post&lt;/u&gt;&lt;/a&gt;, we highlighted the United States and Korea. This year, the share of mitigated traffic grew to 5.0% in the &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/us?#mitigated-traffic\&quot;&gt;&lt;u&gt;United States&lt;/u&gt;&lt;/a&gt; (up from 3.65% in 2023), while in &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/kr?#mitigated-traffic\&quot;&gt;&lt;u&gt;South Korea&lt;/u&gt;&lt;/a&gt;, it dropped slightly to 8.1%, down from 8.36%.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3GJ5r18m6Tpor4n2scVRQ5/cc85d08dc2aa496d677d8bfc9439417d/security_-_mitigated_traffic_worldwide.png\&quot; alt=\&quot;security - mitigated traffic worldwide\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;840\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Trends in mitigated traffic worldwide in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;the-united-states-was-responsible-for-over-a-third-of-global-bot-traffic-amazon-web-services-was-responsible-for-12-7-of-global-bot-traffic-and-7-8-came-from-google\&quot;&gt;The United States was responsible for over a third of global bot traffic. Amazon Web Services was responsible for 12.7% of global bot traffic, and 7.8% came from Google.&lt;/h3&gt;\n            &lt;a href=\&quot;#the-united-states-was-responsible-for-over-a-third-of-global-bot-traffic-amazon-web-services-was-responsible-for-12-7-of-global-bot-traffic-and-7-8-came-from-google\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;&lt;a href=\&quot;https://www.cloudflare.com/learning/bots/what-is-a-bot/\&quot;&gt;&lt;u&gt;Bot&lt;/u&gt;&lt;/a&gt; traffic describes any non-human Internet traffic, and by monitoring traffic suspected to be from bots site and application owners can spot and, if necessary, block potentially malicious activity. However, not all bots are malicious — bots can also be helpful, and Cloudflare maintains a list of &lt;a href=\&quot;https://radar.cloudflare.com/traffic/verified-bots\&quot;&gt;&lt;u&gt;verified bots&lt;/u&gt;&lt;/a&gt; that includes those used for things like search engine indexing, performance testing, and &lt;a href=\&quot;https://www.cloudflare.com/application-services/solutions/app-performance-monitoring/\&quot;&gt;&lt;u&gt;availability monitoring&lt;/u&gt;&lt;/a&gt;. Regardless of intent, we analyzed where bot traffic was originating from in 2024, using the IP address of a request to identify the network (&lt;a href=\&quot;https://www.cloudflare.com/learning/network-layer/what-is-an-autonomous-system/\&quot;&gt;&lt;u&gt;autonomous system&lt;/u&gt;&lt;/a&gt;) and country/region associated with the bot making the request. Cloud platforms remained among the leading sources of bot traffic due to a number of factors. These include the ease of using automated tools to quickly provision compute resources, the relatively low cost of using these compute resources in an ephemeral manner, the broadly distributed geographic footprint of cloud platforms, and the platforms’ high-bandwidth Internet connectivity.&lt;/p&gt;&lt;p&gt;&lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#bot-traffic-sources\&quot;&gt;&lt;u&gt;Globally&lt;/u&gt;&lt;/a&gt;, we found that 68.5% of observed bot traffic came from the top 10 countries in 2024, with the United States responsible for half of that total, over 5x the share of second place Germany. (In comparison to 2023, the US share was up slightly, while Germany’s was down slightly.) Among cloud platforms that originate bot traffic, Amazon Web Services was responsible for 12.7% of global bot traffic, and 7.8% came from Google. Microsoft, Hetzner, Digital Ocean, and OVH all also contributed more than a percent each.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3qlyS355w5LDtoBDtb1qXE/8354c2b07c0af46121a0c667e6d687e4/security_-_bot_distribution_by_source_country.png\&quot; alt=\&quot;security - bot distribution by source country\&quot; class=\&quot;kg-image\&quot; width=\&quot;1578\&quot; height=\&quot;860\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Global bot traffic distribution by source country in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6euMUlCDcfOInLiCpssg2t/54eb345624346f24ab984bbe6b1c9f67/security_-_bot_distribution_by_source_network.png\&quot; alt=\&quot;security - bot distribution by source network\&quot; class=\&quot;kg-image\&quot; width=\&quot;1578\&quot; height=\&quot;821\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Global bot traffic distribution by source network in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;globally-gambling-games-was-the-most-attacked-industry-slightly-ahead-of-2023s-most-targeted-industry-finance\&quot;&gt;Globally, Gambling/Games was the most attacked industry, slightly ahead of 2023’s most targeted industry, Finance.&lt;/h3&gt;\n            &lt;a href=\&quot;#globally-gambling-games-was-the-most-attacked-industry-slightly-ahead-of-2023s-most-targeted-industry-finance\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;The industries targeted by attacks often shift over time, depending on the intent of the attackers. They may be trying to cause financial harm by attacking ecommerce sites during a busy shopping period, gain an advantage against opponents by attacking an online game, or make a political statement by attacking government-related sites. To identify industry-targeted attack activity during 2024, we analyzed mitigated traffic for customers that had an associated industry and vertical within their customer record. Mitigated traffic was aggregated weekly by source country/region across 19 target industries.&lt;/p&gt;&lt;p&gt;Companies in the Gambling/Games industry were, in aggregate, the &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#most-attacked-industries\&quot;&gt;&lt;u&gt;most attacked during 2024&lt;/u&gt;&lt;/a&gt;, with 6.6% of global mitigated traffic targeting the industry. The industry was slightly ahead of Finance, which led 2023’s aggregate list. (Both industries are shown at 6.6% in the Summary view due to rounding.)  Gambling/Games sites saw the largest shares of mitigated traffic in January and the first week of February, possibly related to National Football League playoffs in the United States, heading into the &lt;a href=\&quot;https://blog.cloudflare.com/super-bowl-lviii/\&quot;&gt;&lt;u&gt;Super Bowl&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Attacks targeting Finance organizations were most active in May, reaching a peak of 15.3% of mitigated traffic the week of May 13. This is in line with the figure in our &lt;a href=\&quot;https://radar.cloudflare.com/reports/ddos-2024-q2#id-9-top-attacked-industries\&quot;&gt;&lt;i&gt;&lt;u&gt;DDoS threat report for Q2 2024&lt;/u&gt;&lt;/i&gt;&lt;/a&gt; that shows that Financial Services was the most attacked industry by request volume during the quarter in South America and the Middle East region.&lt;/p&gt;&lt;p&gt;As we have seen in the past, peak attack activity varied by industry on a weekly basis. The highest peaks for the year were seen in attacks targeting People &amp;amp; Society organizations (19.6% of mitigated traffic, week of January 1), the Autos &amp;amp; Vehicles industry (29.7% of mitigated traffic, week of January 15), and the Real Estate industry (27.5% of mitigated traffic, week of August 26).&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4qjMffdMn6uV7OEFhE5l0F/397672a455b62f712946e30130969657/security_-_targeted_industries.png\&quot; alt=\&quot;security - targeted industries\&quot; class=\&quot;kg-image\&quot; width=\&quot;1124\&quot; height=\&quot;659\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Global mitigated traffic share by industry in 2024, summary view&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;log4j-remains-a-persistent-threat-and-was-actively-targeted-throughout-2024\&quot;&gt;Log4j remains a persistent threat and was actively targeted throughout 2024.&lt;/h3&gt;\n            &lt;a href=\&quot;#log4j-remains-a-persistent-threat-and-was-actively-targeted-throughout-2024\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;In December 2021, we published a &lt;a href=\&quot;https://blog.cloudflare.com/tag/log4j/\&quot;&gt;&lt;u&gt;series of blog posts about the Log4j vulnerability&lt;/u&gt;&lt;/a&gt;, highlighting the threat that it posed, our observations of attempted exploitation, and the steps we took to protect customers. Two years on, in our &lt;a href=\&quot;https://blog.cloudflare.com/radar-2023-year-in-review/\&quot;&gt;&lt;u&gt;2023 Year in Review&lt;/u&gt;&lt;/a&gt;, we &lt;a href=\&quot;https://blog.cloudflare.com/radar-2023-year-in-review/#even-as-an-older-vulnerability-log4j-remained-a-top-target-for-attacks-during-2023-however-http-2-rapid-reset-emerged-as-a-significant-new-vulnerability-beginning-with-a-flurry-of-record-breaking-attacks\&quot;&gt;&lt;u&gt;noted&lt;/u&gt;&lt;/a&gt; that even as an older vulnerability, Log4j remained a top target for attacks during 2023, with related attack activity significantly higher than other commonly exploited vulnerabilities.&lt;/p&gt;&lt;p&gt;In 2024, three years after the initial Log4j disclosure, we found that Log4j remains an active threat. This year, we compared normalized daily attack activity for Log4j with attack activity for Atlassian Confluence Code Injection, a vulnerability we &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2023#commonly-exploited-vulnerabilities\&quot;&gt;&lt;u&gt;examined in the 2023 Year in Review&lt;/u&gt;&lt;/a&gt;, as well as aggregated daily attack activity for multiple &lt;a href=\&quot;https://en.wikipedia.org/wiki/Common_Vulnerabilities_and_Exposures\&quot;&gt;&lt;u&gt;CVEs&lt;/u&gt;&lt;/a&gt; related to &lt;a href=\&quot;https://capec.mitre.org/data/definitions/115.html\&quot;&gt;&lt;u&gt;Authentication Bypass&lt;/u&gt;&lt;/a&gt; and &lt;a href=\&quot;https://www.cloudflare.com/en-gb/learning/security/what-is-remote-code-execution/\&quot;&gt;&lt;u&gt;Remote Code Execution&lt;/u&gt;&lt;/a&gt; vulnerabilities published in 2024.&lt;/p&gt;&lt;p&gt;&lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#commonly-exploited-vulnerabilities\&quot;&gt;&lt;u&gt;Log4j attack activity&lt;/u&gt;&lt;/a&gt; appeared to trend generally upwards across the year, with several significant spikes visible during the first half of the year, and then again in October and November. In terms of the difference in activity, Log4j ranges from approximately 4x to over 20x the activity seen for Atlassian Confluence Code Injection, and as much as 100x the aggregated activity seen for Authentication Bypass or Remote Code Injection vulnerabilities.  &lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2YdyQ3qMUh10zLAHLefcdU/8a723a1970652c293a1f6c59efe51a99/security_-_vulnerabilities_Log4J.png\&quot; alt=\&quot;security - vulnerabilities Log4J\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;840\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Global attack activity trends for commonly exploited vulnerabilities in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;routing-security-measured-as-the-share-of-rpki-valid-routes-and-the-share-of-covered-ip-address-space-continued-to-improve-globally-throughout-2024\&quot;&gt;Routing security, measured as the share of RPKI valid routes and the share of covered IP address space, continued to improve globally throughout 2024. &lt;/h3&gt;\n            &lt;a href=\&quot;#routing-security-measured-as-the-share-of-rpki-valid-routes-and-the-share-of-covered-ip-address-space-continued-to-improve-globally-throughout-2024\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;As the routing protocol that underpins the Internet, &lt;a href=\&quot;https://www.cloudflare.com/learning/security/glossary/what-is-bgp/\&quot;&gt;&lt;u&gt;Border Gateway Protocol (BGP)&lt;/u&gt;&lt;/a&gt; communicates routes between networks, enabling traffic to flow between source and destination. BGP, however, relies on trust between networks, and incorrect information shared between peers, whether or not it was shared intentionally, can send traffic to the wrong place, potentially with &lt;a href=\&quot;https://blog.cloudflare.com/bgp-leaks-and-crypto-currencies/\&quot;&gt;&lt;u&gt;malicious results&lt;/u&gt;&lt;/a&gt;. &lt;a href=\&quot;https://blog.cloudflare.com/rpki/\&quot;&gt;&lt;u&gt;Resource Public Key Infrastructure (RPKI)&lt;/u&gt;&lt;/a&gt; is a cryptographic method of signing records that associate a BGP route announcement with the correct originating autonomous system (AS) number, providing a way of ensuring that the information being shared originally came from a network that is allowed to do so. (It is important to note that this is only half of the challenge of implementing routing security, because network providers also need to validate these signatures and filter out invalid announcements to prevent sharing them further.)&lt;/p&gt;&lt;p&gt;Cloudflare has long been an advocate for routing security, including being a founding participant in the &lt;a href=\&quot;https://www.manrs.org/2020/03/new-category-of-cdns-and-cloud-providers-join-manrs-to-improve-routing-security/\&quot;&gt;&lt;u&gt;MANRS CDN and Cloud Programme&lt;/u&gt;&lt;/a&gt; and providing a &lt;a href=\&quot;https://isbgpsafeyet.com/\&quot;&gt;&lt;u&gt;public tool&lt;/u&gt;&lt;/a&gt; that enables users to test whether their Internet provider has implemented BGP safely. Building on insights available in the &lt;a href=\&quot;https://radar.cloudflare.com/routing\&quot;&gt;&lt;u&gt;Routing page&lt;/u&gt;&lt;/a&gt; on Cloudflare Radar, we analyzed data from &lt;a href=\&quot;https://ftp.ripe.net/rpki/\&quot;&gt;&lt;u&gt;RIPE NCC&amp;#39;s RPKI daily archive&lt;/u&gt;&lt;/a&gt; to determine the share of RPKI valid routes (as opposed to those route announcements that are &lt;a href=\&quot;https://rpki.readthedocs.io/en/latest/about/help.html\&quot;&gt;&lt;u&gt;invalid or whose status is unknown&lt;/u&gt;&lt;/a&gt;) and how that share has changed over the course of 2024, as well as determining the share of IP address space covered by valid routes. The latter metric is of interest because a route announcement covering a significant amount of IP address space (millions of IPv4 addresses, for example) has a greater potential impact than an announcement covering a small block of IP address space (hundreds of IPv4 addresses, for example).&lt;/p&gt;&lt;p&gt;At a &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#routing-security\&quot;&gt;&lt;u&gt;global&lt;/u&gt;&lt;/a&gt; level during 2024, we saw a 6.4 percentage point increase (from 43.4% to 49.8%) in valid IPv4 routes, and a 3.2 percentage point increase (from 53.7% to 56.9%) in valid IPv6 routes. Given the trajectory, it is likely that over half of IPv4 routes will be RPKI valid by the end of calendar year 2024. Looking at the global share of IP address space covered by valid routes, we saw a 4.7 percentage point increase (from 38.9% to 43.6%) for IPv4, and a 3.3 percentage point increase (from 57.6% to 60.9%) for IPv6.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2ojjIa2U45vvsbha8v6ITk/2c61631ded62b80481d47e1da8a5d2cc/security_-_routing_global_valid_routes.png\&quot; alt=\&quot;security - routing global valid routes\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;840\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Shares of global RPKI valid routing entries by IP version in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2rCCmsaqULazLsBgoXZLLC/9aa265e9658d71bd7ee113423c6945ca/security_-_routing_global_valid_ip_address_space.png\&quot; alt=\&quot;security - routing global valid ip address space\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;840\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Shares of globally announced IP address space covered by RPKI valid routes in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/es#routing-security\&quot;&gt;&lt;u&gt;Spain&lt;/u&gt;&lt;/a&gt; started 2024 with less than half of its routes (both IPv4 and IPv6) RPKI valid. However, the share of valid routes grew significantly on February 15, when &lt;a href=\&quot;https://radar.cloudflare.com/as12479\&quot;&gt;&lt;u&gt;AS12479 (Orange Espagne)&lt;/u&gt;&lt;/a&gt; signed records associated with 98% of their IP address prefixes that were previously in an &lt;a href=\&quot;https://www.ripe.net/manage-ips-and-asns/resource-management/rpki/bgp-origin-validation/\&quot;&gt;&lt;u&gt;“unknown” (or NotFound) state of RPKI validity&lt;/u&gt;&lt;/a&gt;, thus converting these prefixes from unknown to valid. That drove an immediate increase for IPv4 to 76%, reaching 81% validity by December 1, and an immediate increase for IPv6 to 91%, reaching 92.9% validity by December 1. A notable change in covered IP address space was observed in &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024/cm#routing-security\&quot;&gt;&lt;u&gt;Cameroon&lt;/u&gt;&lt;/a&gt;, where covered IPv4 space more than doubled at the end of January, growing from 32% to 82%. This was due to &lt;a href=\&quot;https://radar.cloudflare.com/as36912\&quot;&gt;&lt;u&gt;AS36912 (Orange Cameroun)&lt;/u&gt;&lt;/a&gt; signing records associated with all of their IPv4 address prefixes, changing the associated IP address space to RPKI valid. &lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5e7SUVIju8fidAEBkIOSq4/2085f3237411eca0816a3d2862e9e3df/security_-_routing_Spain_valid_routes.png\&quot; alt=\&quot;security - routing Spain valid routes\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;840\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;IPv4 and IPv6 shares of RPKI valid routes for Spain in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/G9adlberrdCmDnB3MupQa/6c866261fc478334673115d6dd01fd76/security_-_routing_Cameroon_valid_ipv4_address_space.png\&quot; alt=\&quot;security - routing Cameroon valid ipv4 address space\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;840\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Share of IPv4 address space covered by RPKI valid routes for Cameroon in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;email-security\&quot;&gt;Email Security&lt;/h2&gt;\n            &lt;a href=\&quot;#email-security\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          \n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7vC1TSUDDHpepgs2Yv3Lpx/eb43b5c0a203d7ec0a74939c23684ae5/2627_Shield_Plane.png\&quot; alt=\&quot;2627 Shield Plane\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;417\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;an-average-of-4-3-of-emails-were-determined-to-be-malicious-in-2024\&quot;&gt;An average of 4.3% of emails were determined to be malicious in 2024. &lt;/h3&gt;\n            &lt;a href=\&quot;#an-average-of-4-3-of-emails-were-determined-to-be-malicious-in-2024\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Despite the growing enterprise use of collaboration/messaging apps, email remains an important business application and is a very attractive entry point into enterprise networks for attackers. Attackers will send targeted malicious emails that attempt to impersonate an otherwise legitimate sender (such as a corporate executive), that try to get the user to click on a deceptive link, or that contain a dangerous attachment, among other types of threats. &lt;a href=\&quot;https://www.cloudflare.com/zero-trust/products/email-security/\&quot;&gt;&lt;u&gt;Cloudflare Email Security&lt;/u&gt;&lt;/a&gt; protects customers from email-based attacks, including those carried out through targeted malicious email messages. During&lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#malicious-emails\&quot;&gt;&lt;u&gt; 2024&lt;/u&gt;&lt;/a&gt;, an average of 4.3% of emails analyzed by Cloudflare were found to be malicious. Aggregated at a weekly level, spikes above 14% were seen in late March, early April, and mid-May. We believe that these spikes were related to targeted “backscatter” attacks, where the attacker flooded a target with undeliverable messages, which then bounced the messages to the victim, whose email had been set as the reply-to: address.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/693EaEyePShBH8CZ7cZWv1/c08e0acd6f8a6a15b730b1cd90bf6283/email_-_malicious_worldwide.png\&quot; alt=\&quot;email - malicious worldwide\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;840\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Global malicious email share trends in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;deceptive-links-and-identity-deception-were-the-two-most-common-types-of-threats-found-in-malicious-email-messages\&quot;&gt;Deceptive links and identity deception were the two most common types of threats found in malicious email messages. &lt;/h3&gt;\n            &lt;a href=\&quot;#deceptive-links-and-identity-deception-were-the-two-most-common-types-of-threats-found-in-malicious-email-messages\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Attackers use a variety of techniques, which we refer to as threat categories, when they use malicious email messages as an attack vector. These categories are defined and explored in detail in our &lt;a href=\&quot;https://blog.cloudflare.com/2023-phishing-report/\&quot;&gt;&lt;u&gt;phishing threats report&lt;/u&gt;&lt;/a&gt;. In our analysis of malicious emails, we have found that such messages may contain multiple types of threats. In reviewing a weekly aggregation of threat activity trends for these categories, we found that, &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024#top-email-threats\&quot;&gt;&lt;u&gt;averaged across 2024&lt;/u&gt;&lt;/a&gt;, 42.9% of malicious email messages contained deceptive links, with the share reaching 70% at times throughout the year. Activity for this thread category was spiky, with low points seen in the March to May timeframe, and a general downward trend visible from July through November.&lt;/p&gt;&lt;p&gt;Identity deception was a similarly active threat category, with such threats also found in up to 70% of analyzed emails several weeks throughout the year. Averaged across 2024, 35.1% of emails contained attempted identity deception. The activity pattern for this threat category appears to be somewhat similar to deceptive links, with a number of the peaks and valleys occurring during the same weeks. At times, identity deception was a more prevalent threat in analyzed emails than deceptive links, as seen in the graph below.&lt;/p&gt;&lt;p&gt;Among other threat categories, extortion saw the most significant change throughout the year. After being found in 86% of malicious emails during the first week of January, its share gradually trended lower throughout the year, finishing November under 10%.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/47EGZSEcRbUY67bsnYTSip/81ce3c89beefe1ddbe66f68710366c87/email_-_threat_category.png\&quot; alt=\&quot;email - threat category\&quot; class=\&quot;kg-image\&quot; width=\&quot;1575\&quot; height=\&quot;840\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Global malicious email threat category trends for Deceptive Links and Identity Deception in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;over-99-of-the-email-messages-processed-by-cloudflare-email-security-from-the-bar-rest-and-uno-top-level-domains-tlds-were-found-to-be-either-spam-or-malicious-in-nature\&quot;&gt;Over 99% of the email messages processed by Cloudflare Email Security from the .bar, .rest, and .uno top level domains (TLDs) were found to be either spam or malicious in nature.&lt;/h3&gt;\n            &lt;a href=\&quot;#over-99-of-the-email-messages-processed-by-cloudflare-email-security-from-the-bar-rest-and-uno-top-level-domains-tlds-were-found-to-be-either-spam-or-malicious-in-nature\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;In March 2024, we &lt;a href=\&quot;https://blog.cloudflare.com/email-security-insights-on-cloudflare-radar/\&quot;&gt;&lt;u&gt;launched a set of email security insights on Cloudflare Radar&lt;/u&gt;&lt;/a&gt;, including visibility into so-called “dangerous domains” — those top level domains (TLDs) that were found to be the sources of the most spam or malicious email among messages analyzed by Cloudflare Email Security. The analysis is based on the sending domain’s TLD, found in the &lt;code&gt;From&lt;/code&gt;: header of an email message. For example, if a message came from &lt;code&gt;sender@example.com&lt;/code&gt;, then &lt;code&gt;example.com&lt;/code&gt; is the sending domain, and .com is the associated TLD.&lt;/p&gt;&lt;p&gt;&lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024?#most-observed-tlds\&quot;&gt;&lt;u&gt;In aggregate across 2024&lt;/u&gt;&lt;/a&gt;, we found that the &lt;a href=\&quot;https://icannwiki.org/.bar\&quot;&gt;&lt;code&gt;&lt;u&gt;.bar&lt;/u&gt;&lt;/code&gt;&lt;/a&gt;, &lt;a href=\&quot;https://icannwiki.org/.rest\&quot;&gt;&lt;code&gt;&lt;u&gt;.rest&lt;/u&gt;&lt;/code&gt;&lt;/a&gt;, and &lt;a href=\&quot;https://icannwiki.org/.uno\&quot;&gt;&lt;code&gt;&lt;u&gt;.uno&lt;/u&gt;&lt;/code&gt;&lt;/a&gt; TLDs were the “most dangerous”, each with over 99% of analyzed email messages characterized as either spam or malicious. (These TLDs are all at least a decade old, and each sees at least some usage, with &lt;a href=\&quot;https://research.domaintools.com/statistics/tld-counts/\&quot;&gt;&lt;u&gt;between 20,000 and 60,000 registered domain names&lt;/u&gt;&lt;/a&gt;.)  Sorting by malicious email share, the &lt;a href=\&quot;https://icannwiki.org/.ws\&quot;&gt;&lt;code&gt;&lt;u&gt;.ws&lt;/u&gt;&lt;/code&gt;&lt;/a&gt; ccTLD (country code top level domain) belonging to Western Samoa came out on top, with over 90% of analyzed emails categorized as malicious. Sorting by spam email share, &lt;a href=\&quot;https://icannwiki.org/.quest\&quot;&gt;&lt;code&gt;&lt;u&gt;.quest&lt;/u&gt;&lt;/code&gt;&lt;/a&gt; is the biggest offender, with over 88% of emails originating from associated domains characterized as spam.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/30rfi3V9NkY31itUpHQ9is/d1cbb9fce0ecf5a1c3a237f2694c5a13/email_-_dangerous_tlds.png\&quot; alt=\&quot;email - dangerous tlds\&quot; class=\&quot;kg-image\&quot; width=\&quot;1578\&quot; height=\&quot;860\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;TLDs originating the largest total shares of malicious and spam email in 2024&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;conclusion\&quot;&gt;Conclusion&lt;/h2&gt;\n            &lt;a href=\&quot;#conclusion\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;The Internet is an amazingly complex and dynamic organism, constantly changing, growing, and evolving.&lt;/p&gt;&lt;p&gt;With the &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024\&quot;&gt;&lt;u&gt;Cloudflare Radar 2024 Year In Review&lt;/u&gt;&lt;/a&gt;, we are providing insights into the change, growth, and evolution that we have measured and observed throughout the year. Trend graphs, maps, tables, and summary statistics provide our unique perspectives on Internet traffic, Internet quality, and Internet security, and how key metrics across these areas vary around the world and over time.&lt;/p&gt;&lt;p&gt;We strongly encourage you to visit the &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2024\&quot;&gt;&lt;u&gt;Cloudflare Radar 2024 Year In Review microsite&lt;/u&gt;&lt;/a&gt; and explore the trends for your country/region, and to consider how they impact your organization so that you are appropriately prepared for 2025. In addition, for insights into the top Internet services across multiple industry categories, we encourage you to read the companion Year in Review blog post, &lt;a href=\&quot;https://blog.cloudflare.com/radar-2024-year-in-review-internet-services/\&quot;&gt;&lt;i&gt;&lt;u&gt;From ChatGPT to Temu: ranking top Internet services in 2024&lt;/u&gt;&lt;/i&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;If you have any questions, you can contact the Cloudflare Radar team at radar@cloudflare.com or on social media at &lt;a href=\&quot;https://twitter.com/CloudflareRadar\&quot;&gt;&lt;u&gt;@CloudflareRadar&lt;/u&gt;&lt;/a&gt; (X), &lt;a href=\&quot;https://noc.social/@cloudflareradar\&quot;&gt;&lt;u&gt;https://noc.social/@cloudflareradar&lt;/u&gt;&lt;/a&gt; (Mastodon), and &lt;a href=\&quot;https://bsky.app/profile/radar.cloudflare.com\&quot;&gt;&lt;u&gt;radar.cloudflare.com&lt;/u&gt;&lt;/a&gt; (Bluesky).&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;acknowledgements\&quot;&gt;Acknowledgements&lt;/h2&gt;\n            &lt;a href=\&quot;#acknowledgements\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;As it is every year, it truly is a team effort to produce the data, microsite, and content for our annual Year in Review, and I’d like to acknowledge those team members that contributed to this year’s effort. Thank you to: Jorge Pacheco, Sabina Zejnilovic, Carlos Azevedo, Mingwei Zhang (Data Analysis); André Jesus, Nuno Pereira (Front End Development); João Tomé (Most popular Internet services); Jackie Dutton, Kari Linder, Guille Lasarte (Communications); Eunice Giles (Brand Design); Jason Kincaid (blog editing); and Paula Tavares (Engineering Management), as well as countless other colleagues for their answers, edits, support, and ideas.&lt;/p&gt;&quot;],&quot;published_at&quot;:[0,&quot;2024-12-09T14:05+00:00&quot;],&quot;updated_at&quot;:[0,&quot;2025-01-03T17:15:59.515Z&quot;],&quot;feature_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2nWfStnBrKwLWixhTVnzoT/7b206bb56a5335d9a36981890e0c626c/image8.png&quot;],&quot;tags&quot;:[1,[[0,{&quot;id&quot;:[0,&quot;231XTGyX1Pw7Huv9D0rhMS&quot;],&quot;name&quot;:[0,&quot;Year in Review&quot;],&quot;slug&quot;:[0,&quot;year-in-review&quot;]}],[0,{&quot;id&quot;:[0,&quot;5kZtWqjqa7aOUoZr8NFGwI&quot;],&quot;name&quot;:[0,&quot;Radar&quot;],&quot;slug&quot;:[0,&quot;cloudflare-radar&quot;]}],[0,{&quot;id&quot;:[0,&quot;3yArjf0gLKZy8ObEDxbNNi&quot;],&quot;name&quot;:[0,&quot;Trends&quot;],&quot;slug&quot;:[0,&quot;trends&quot;]}],[0,{&quot;id&quot;:[0,&quot;0kgHdg1ytbdWl5BNo6bEa&quot;],&quot;name&quot;:[0,&quot;Internet Traffic&quot;],&quot;slug&quot;:[0,&quot;internet-traffic&quot;]}],[0,{&quot;id&quot;:[0,&quot;4yliZlpBPZpOwBDZzo1tTh&quot;],&quot;name&quot;:[0,&quot;Outage&quot;],&quot;slug&quot;:[0,&quot;outage&quot;]}],[0,{&quot;id&quot;:[0,&quot;5DD7GZ0oxjP3NGOaJMwyWq&quot;],&quot;name&quot;:[0,&quot;Internet Quality&quot;],&quot;slug&quot;:[0,&quot;internet-quality&quot;]}],[0,{&quot;id&quot;:[0,&quot;6Mp7ouACN2rT3YjL1xaXJx&quot;],&quot;name&quot;:[0,&quot;Security&quot;],&quot;slug&quot;:[0,&quot;security&quot;]}]]],&quot;relatedTags&quot;:[0],&quot;authors&quot;:[1,[[0,{&quot;name&quot;:[0,&quot;David Belson&quot;],&quot;slug&quot;:[0,&quot;david-belson&quot;],&quot;bio&quot;:[0,null],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/en7vkXf6rLBm4F8IcNHXT/645022bf841fabff7732aa3be3949808/david-belson.jpeg&quot;],&quot;location&quot;:[0,null],&quot;website&quot;:[0,null],&quot;twitter&quot;:[0,&quot;@dbelson&quot;],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}]]],&quot;meta_description&quot;:[0,&quot;The 2024 Cloudflare Radar Year in Review is our fifth annual review of Internet trends and patterns at both a global and country/region level. For 2024, we added several new metrics, as well as the ability to do year-over-year and geographic comparisons for selected metrics. \n&quot;],&quot;primary_author&quot;:[0,{}],&quot;localeList&quot;:[0,{&quot;name&quot;:[0,&quot;Cloudflare 2024 Year in Review: Loc&quot;],&quot;enUS&quot;:[0,&quot;English for Locale&quot;],&quot;zhCN&quot;:[0,&quot;Translated for Locale&quot;],&quot;zhHansCN&quot;:[0,&quot;No Page for Locale&quot;],&quot;zhTW&quot;:[0,&quot;Translated for Locale&quot;],&quot;frFR&quot;:[0,&quot;English for Locale&quot;],&quot;deDE&quot;:[0,&quot;English for Locale&quot;],&quot;itIT&quot;:[0,&quot;English for Locale&quot;],&quot;jaJP&quot;:[0,&quot;English for Locale&quot;],&quot;koKR&quot;:[0,&quot;English for Locale&quot;],&quot;ptBR&quot;:[0,&quot;Translated for Locale&quot;],&quot;esLA&quot;:[0,&quot;Translated for Locale&quot;],&quot;esES&quot;:[0,&quot;Translated for Locale&quot;],&quot;enAU&quot;:[0,&quot;No Page for Locale&quot;],&quot;enCA&quot;:[0,&quot;No Page for Locale&quot;],&quot;enIN&quot;:[0,&quot;No Page for Locale&quot;],&quot;enGB&quot;:[0,&quot;No Page for Locale&quot;],&quot;idID&quot;:[0,&quot;Translated for Locale&quot;],&quot;ruRU&quot;:[0,&quot;No Page for Locale&quot;],&quot;svSE&quot;:[0,&quot;No Page for Locale&quot;],&quot;viVN&quot;:[0,&quot;Translated for Locale&quot;],&quot;plPL&quot;:[0,&quot;English for Locale&quot;],&quot;arAR&quot;:[0,&quot;English for Locale&quot;],&quot;nlNL&quot;:[0,&quot;English for Locale&quot;],&quot;thTH&quot;:[0,&quot;Translated for Locale&quot;],&quot;trTR&quot;:[0,&quot;English for Locale&quot;],&quot;heIL&quot;:[0,&quot;English for Locale&quot;],&quot;lvLV&quot;:[0,&quot;English for Locale&quot;],&quot;etEE&quot;:[0,&quot;English for Locale&quot;],&quot;ltLT&quot;:[0,&quot;English for Locale&quot;]}],&quot;url&quot;:[0,&quot;https://blog.cloudflare.com/radar-2024-year-in-review&quot;],&quot;metadata&quot;:[0,{&quot;title&quot;:[0,&quot;Cloudflare 2024 Year in Review&quot;],&quot;description&quot;:[0,&quot;The 2024 Cloudflare Radar Year in Review is our fifth annual review of Internet trends and patterns at both a global and country/region level. For 2024, we added several new metrics, as well as the ability to do year-over-year and geographic comparisons for selected metrics. \n&quot;],&quot;imgPreview&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/Xw63gQRdZSUjMoaW6oFyy/190bd0fc341de1277929e0ce620ffe7a/Cloudflare_2024_Year_in_Review-OG.png&quot;]}],&quot;publicly_index&quot;:[0,true]}],&quot;translations&quot;:[0,{&quot;posts.by&quot;:[0,&quot;By&quot;],&quot;footer.gdpr&quot;:[0,&quot;GDPR&quot;],&quot;lang_blurb1&quot;:[0,&quot;This post is also available in {lang1}.&quot;],&quot;lang_blurb2&quot;:[0,&quot;This post is also available in {lang1} and {lang2}.&quot;],&quot;lang_blurb3&quot;:[0,&quot;This post is also available in {lang1}, {lang2} and {lang3}.&quot;],&quot;footer.press&quot;:[0,&quot;Press&quot;],&quot;header.title&quot;:[0,&quot;The Cloudflare Blog&quot;],&quot;search.clear&quot;:[0,&quot;Clear&quot;],&quot;search.filter&quot;:[0,&quot;Filter&quot;],&quot;search.source&quot;:[0,&quot;Source&quot;],&quot;footer.careers&quot;:[0,&quot;Careers&quot;],&quot;footer.company&quot;:[0,&quot;Company&quot;],&quot;footer.support&quot;:[0,&quot;Support&quot;],&quot;footer.the_net&quot;:[0,&quot;theNet&quot;],&quot;search.filters&quot;:[0,&quot;Filters&quot;],&quot;footer.our_team&quot;:[0,&quot;Our team&quot;],&quot;footer.webinars&quot;:[0,&quot;Webinars&quot;],&quot;page.more_posts&quot;:[0,&quot;More posts&quot;],&quot;posts.time_read&quot;:[0,&quot;{time} min read&quot;],&quot;search.language&quot;:[0,&quot;Language&quot;],&quot;footer.community&quot;:[0,&quot;Community&quot;],&quot;footer.resources&quot;:[0,&quot;Resources&quot;],&quot;footer.solutions&quot;:[0,&quot;Solutions&quot;],&quot;footer.trademark&quot;:[0,&quot;Trademark&quot;],&quot;header.subscribe&quot;:[0,&quot;Subscribe&quot;],&quot;footer.compliance&quot;:[0,&quot;Compliance&quot;],&quot;footer.free_plans&quot;:[0,&quot;Free plans&quot;],&quot;footer.impact_ESG&quot;:[0,&quot;Impact/ESG&quot;],&quot;posts.follow_on_X&quot;:[0,&quot;Follow on X&quot;],&quot;footer.help_center&quot;:[0,&quot;Help center&quot;],&quot;footer.network_map&quot;:[0,&quot;Network Map&quot;],&quot;header.please_wait&quot;:[0,&quot;Please Wait&quot;],&quot;page.related_posts&quot;:[0,&quot;Related posts&quot;],&quot;search.result_stat&quot;:[0,&quot;Results &lt;strong&gt;{search_range}&lt;/strong&gt; of &lt;strong&gt;{search_total}&lt;/strong&gt; for &lt;strong&gt;{search_keyword}&lt;/strong&gt;&quot;],&quot;footer.case_studies&quot;:[0,&quot;Case Studies&quot;],&quot;footer.connect_2024&quot;:[0,&quot;Connect 2024&quot;],&quot;footer.terms_of_use&quot;:[0,&quot;Terms of Use&quot;],&quot;footer.white_papers&quot;:[0,&quot;White Papers&quot;],&quot;footer.cloudflare_tv&quot;:[0,&quot;Cloudflare TV&quot;],&quot;footer.community_hub&quot;:[0,&quot;Community Hub&quot;],&quot;footer.compare_plans&quot;:[0,&quot;Compare plans&quot;],&quot;footer.contact_sales&quot;:[0,&quot;Contact Sales&quot;],&quot;header.contact_sales&quot;:[0,&quot;Contact Sales&quot;],&quot;header.email_address&quot;:[0,&quot;Email Address&quot;],&quot;page.error.not_found&quot;:[0,&quot;Page not found&quot;],&quot;footer.developer_docs&quot;:[0,&quot;Developer docs&quot;],&quot;footer.privacy_policy&quot;:[0,&quot;Privacy Policy&quot;],&quot;footer.request_a_demo&quot;:[0,&quot;Request a demo&quot;],&quot;page.continue_reading&quot;:[0,&quot;Continue reading&quot;],&quot;footer.analysts_report&quot;:[0,&quot;Analyst reports&quot;],&quot;footer.for_enterprises&quot;:[0,&quot;For enterprises&quot;],&quot;footer.getting_started&quot;:[0,&quot;Getting Started&quot;],&quot;footer.learning_center&quot;:[0,&quot;Learning Center&quot;],&quot;footer.project_galileo&quot;:[0,&quot;Project Galileo&quot;],&quot;pagination.newer_posts&quot;:[0,&quot;Newer Posts&quot;],&quot;pagination.older_posts&quot;:[0,&quot;Older Posts&quot;],&quot;posts.social_buttons.x&quot;:[0,&quot;Discuss on X&quot;],&quot;search.icon_aria_label&quot;:[0,&quot;Search&quot;],&quot;search.source_location&quot;:[0,&quot;Source/Location&quot;],&quot;footer.about_cloudflare&quot;:[0,&quot;About Cloudflare&quot;],&quot;footer.athenian_project&quot;:[0,&quot;Athenian Project&quot;],&quot;footer.become_a_partner&quot;:[0,&quot;Become a partner&quot;],&quot;footer.cloudflare_radar&quot;:[0,&quot;Cloudflare Radar&quot;],&quot;footer.network_services&quot;:[0,&quot;Network services&quot;],&quot;footer.trust_and_safety&quot;:[0,&quot;Trust &amp; Safety&quot;],&quot;header.get_started_free&quot;:[0,&quot;Get Started Free&quot;],&quot;page.search.placeholder&quot;:[0,&quot;Search Cloudflare&quot;],&quot;footer.cloudflare_status&quot;:[0,&quot;Cloudflare Status&quot;],&quot;footer.cookie_preference&quot;:[0,&quot;Cookie Preferences&quot;],&quot;header.valid_email_error&quot;:[0,&quot;Must be valid email.&quot;],&quot;search.result_stat_empty&quot;:[0,&quot;Results &lt;strong&gt;{search_range}&lt;/strong&gt; of &lt;strong&gt;{search_total}&lt;/strong&gt;&quot;],&quot;footer.connectivity_cloud&quot;:[0,&quot;Connectivity cloud&quot;],&quot;footer.developer_services&quot;:[0,&quot;Developer services&quot;],&quot;footer.investor_relations&quot;:[0,&quot;Investor relations&quot;],&quot;page.not_found.error_code&quot;:[0,&quot;Error Code: 404&quot;],&quot;search.autocomplete_title&quot;:[0,&quot;Insert a query. Press enter to send&quot;],&quot;footer.logos_and_press_kit&quot;:[0,&quot;Logos &amp; press kit&quot;],&quot;footer.application_services&quot;:[0,&quot;Application services&quot;],&quot;footer.get_a_recommendation&quot;:[0,&quot;Get a recommendation&quot;],&quot;posts.social_buttons.reddit&quot;:[0,&quot;Discuss on Reddit&quot;],&quot;footer.sse_and_sase_services&quot;:[0,&quot;SSE and SASE services&quot;],&quot;page.not_found.outdated_link&quot;:[0,&quot;You may have used an outdated link, or you may have typed the address incorrectly.&quot;],&quot;footer.report_security_issues&quot;:[0,&quot;Report Security Issues&quot;],&quot;page.error.error_message_page&quot;:[0,&quot;Sorry, we can&#39;t find the page you are looking for.&quot;],&quot;header.subscribe_notifications&quot;:[0,&quot;Subscribe to receive notifications of new posts:&quot;],&quot;footer.cloudflare_for_campaigns&quot;:[0,&quot;Cloudflare for Campaigns&quot;],&quot;header.subscription_confimation&quot;:[0,&quot;Subscription confirmed. Thank you for subscribing!&quot;],&quot;posts.social_buttons.hackernews&quot;:[0,&quot;Discuss on Hacker News&quot;],&quot;footer.diversity_equity_inclusion&quot;:[0,&quot;Diversity, equity &amp; inclusion&quot;],&quot;footer.critical_infrastructure_defense_project&quot;:[0,&quot;Critical Infrastructure Defense Project&quot;]}]}" ssr client="load" opts="{&quot;name&quot;:&quot;PostCard&quot;,&quot;value&quot;:true}" await-children><article class="w-50-l  mt4 mt2-l mb4 ph3 bb b--gray8 bn-l"><div class="w-100"><a href="/radar-2024-year-in-review/" class="fw5 no-underline gray1" data-testid="post-title"><h2 class="fw5 mt2">Cloudflare 2024 Year in Review</h2></a><p class="f3 fw5 gray5 my" data-testid="post-date">2024-12-09</p><div class=""><a href="/tag/year-in-review/" class="dib pl2 pr2 pt1 pb1 mb2 bg-gray8 no-underline blue3 f2 mr1" data-testid="post-tag">Year in Review</a><a href="/tag/cloudflare-radar/" class="dib pl2 pr2 pt1 pb1 mb2 bg-gray8 no-underline blue3 f2 mr1" data-testid="post-tag">Radar</a><a href="/tag/trends/" class="dib pl2 pr2 pt1 pb1 mb2 bg-gray8 no-underline blue3 f2 mr1" data-testid="post-tag">Trends</a><a href="/tag/internet-traffic/" class="dib pl2 pr2 pt1 pb1 mb2 bg-gray8 no-underline blue3 f2 mr1" data-testid="post-tag">Internet Traffic</a><a href="/tag/outage/" class="dib pl2 pr2 pt1 pb1 mb2 bg-gray8 no-underline blue3 f2 mr1" data-testid="post-tag">Outage</a><a href="/tag/internet-quality/" class="dib pl2 pr2 pt1 pb1 mb2 bg-gray8 no-underline blue3 f2 mr1" data-testid="post-tag">Internet Quality</a><a href="/tag/security/" class="dib pl2 pr2 pt1 pb1 mb2 bg-gray8 no-underline blue3 f2 mr1" data-testid="post-tag">Security</a></div><p class="f3 fw4 gray1 lh-copy " data-testid="post-content">The 2024 Cloudflare Radar Year in Review is our fifth annual review of Internet trends and patterns at both a global and country/region level.<!-- -->...</p><ul class="author-lists flex pl0"><li class="list flex items-center pr2 mb3"><a href="/author/david-belson/" class="static-avatar pr1"><img class="author-profile-image br-100 mr2" src="https://blog.cloudflare.com/cdn-cgi/image/format=auto,dpr=3,width=64,height=64,gravity=face,fit=crop,zoom=0.5/https://cf-assets.www.cloudflare.com/zkvhlag99gkb/en7vkXf6rLBm4F8IcNHXT/645022bf841fabff7732aa3be3949808/david-belson.jpeg" alt="David Belson" width="62" height="62"/></a><div class="author-name-tooltip"><a href="/author/david-belson/" class="fw4 f3 no-underline black">David Belson</a></div></li></ul></div></article><!--astro:end--></astro-island> <astro-island uid="2p7i6M" prefix="r5" component-url="/_astro/MorePosts.DyRVOquy.js" component-export="default" renderer-url="/_astro/client.DLO1yDVm.js" props="{&quot;locale&quot;:[0,&quot;en-us&quot;],&quot;posts&quot;:[1,[[0,{&quot;id&quot;:[0,&quot;5DP2F9GATeUBYyfl6pQMej&quot;],&quot;title&quot;:[0,&quot;Resilient Internet connectivity in Europe mitigates impact from multiple cable cuts&quot;],&quot;slug&quot;:[0,&quot;resilient-internet-connectivity-baltic-cable-cuts&quot;],&quot;excerpt&quot;:[0,&quot;Two recent cable cuts that occurred in the Baltic Sea resulted in little-to-no observable impact to the affected countries, in large part because of the significant redundancy and resilience of Internet infrastructure in Europe.\n&quot;],&quot;featured&quot;:[0,false],&quot;html&quot;:[0,&quot;&lt;p&gt;&lt;/p&gt;&lt;p&gt;When cable cuts occur, whether submarine or terrestrial, they often result in observable disruptions to Internet connectivity, knocking a network, city, or country offline. This is especially true when there is insufficient resilience or alternative paths — that is, when a cable is effectively a single point of failure. Associated observations of traffic loss resulting from these disruptions are frequently covered by Cloudflare Radar in social media and blog posts. However, two recent cable cuts that occurred in the Baltic Sea resulted in little-to-no observable impact to the affected countries, as we discuss below, in large part because of the significant redundancy and resilience of Internet infrastructure in Europe.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;bcs-east-west-interlink\&quot;&gt;BCS East-West Interlink&lt;/h2&gt;\n            &lt;a href=\&quot;#bcs-east-west-interlink\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          \n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;traffic-volume-indicators\&quot;&gt;Traffic volume indicators&lt;/h3&gt;\n            &lt;a href=\&quot;#traffic-volume-indicators\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;On Sunday, November 17 2024, the &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/bcs-east-west-interlink\&quot;&gt;&lt;u&gt;BCS East-West Interlink submarine cable&lt;/u&gt;&lt;/a&gt; connecting Sventoji, Lithuania and Katthammarsvik, Sweden was &lt;a href=\&quot;https://www.datacenterdynamics.com/en/news/lithuania-sweden-subsea-cable-cut-was-10m-from-severed-finnish-german-cable/\&quot;&gt;&lt;u&gt;reportedly damaged&lt;/u&gt;&lt;/a&gt; around 10:00 local (Lithuania) time (08:00 UTC). A &lt;a href=\&quot;https://www.datacenterdynamics.com/en/news/lithuania-sweden-subsea-cable-cut-was-10m-from-severed-finnish-german-cable/\&quot;&gt;&lt;u&gt;Data Center Dynamics article about the cable cut&lt;/u&gt;&lt;/a&gt; quotes the CTO of Telia Lietuva, the telecommunications provider that operates the cable, and notes “&lt;i&gt;The Lithuanian cable carried about a third of the nation&amp;#39;s Internet capacity, but capacity was carried via other routes.&lt;/i&gt;”&lt;/p&gt;&lt;p&gt;As the Cloudflare Radar graphs below show, there was no apparent impact to traffic volumes in either country at the time that the cables were damaged. The NetFlows graphs represent the number of bytes that Cloudflare sends to users and clients in response to their requests.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7xDllSeyPtet5ovpXI3GMH/6bc5680bbd8219f417e891102c4ffb0e/BLOG-2626_2.png\&quot; alt=\&quot;BLOG-2626 2\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;1072\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2RE0V8M2CFPt1uxsOjhSBz/dc5c261808c021fc9ff0ab65963fce0b/BLOG-2626_3.png\&quot; alt=\&quot;BLOG-2626 3\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;1072\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6wjHy79iHDqcuzknxcK14o/a4526787c3fdde54a6627b16717aaec0/BLOG-2626_4.png\&quot; alt=\&quot;BLOG-2626 4\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;1072\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2zPi0GZ54gGDjCMyivhH0C/f6e50728ae7dc110fd15edc40f43b694/BLOG-2626_5.png\&quot; alt=\&quot;BLOG-2626 5\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;1072\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;internet-quality\&quot;&gt;Internet quality&lt;/h3&gt;\n            &lt;a href=\&quot;#internet-quality\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Internet quality metrics for both countries show changes in measured bandwidth and latency throughout the day on Sunday, but with no sudden anomalous shifts visible around the time of the cable cut. (The loss of connectivity associated with a cable cut potentially manifests itself as an increase in latency and concurrent decrease in bandwidth due to loss of capacity.) The latency graph for Sweden does show an increase in latency, but it began before the cable cut occurred, is similar to a pattern visible several hours earlier, and is matched by an increase in measured bandwidth, so it is unlikely to be related to the cable cut event.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3aXlBjU08WKKT0OSnWBsIP/eb32b937d1729160dec83204bba06e91/BLOG-2626_6.png\&quot; alt=\&quot;BLOG-2626 6\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5eeR8OlwA5CHROGkqKn1KJ/e372a25ad2a93aaa38339f360f3a7b0e/BLOG-2626_7.png\&quot; alt=\&quot;BLOG-2626 7\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6wGJFP5K0LkEjw8DXbQ45z/516cf3b04ac5c5f2f82398be508fe4b0/BLOG-2626_8.png\&quot; alt=\&quot;BLOG-2626 8\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2ZLyXG9lCsfazoMm1b6c4z/1af296913ff00da991c04d1422bd49fd/BLOG-2626_9.png\&quot; alt=\&quot;BLOG-2626 9\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;visibility-in-bgp-events-announced-ip-address-space-unaffected\&quot;&gt;Visibility in BGP events, announced IP address space unaffected&lt;/h3&gt;\n            &lt;a href=\&quot;#visibility-in-bgp-events-announced-ip-address-space-unaffected\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;&lt;a href=\&quot;https://developers.cloudflare.com/radar/glossary/#bgp-announcements\&quot;&gt;&lt;u&gt;BGP announcements&lt;/u&gt;&lt;/a&gt; are a way for network providers to communicate routing information to other networks, and announcement activity observed on Telia Lietuva’s &lt;a href=\&quot;https://www.cloudflare.com/learning/network-layer/what-is-an-autonomous-system/\&quot;&gt;&lt;u&gt;autonomous systems&lt;/u&gt;&lt;/a&gt; around the time of the cable cut may be related to the re-routing referenced in the article. No change in announced IP address space was visible for any of these autonomous systems, suggesting no loss of connectivity as the capacity was re-routed.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7dWHQYn0cJ3PdivPgI2sDI/696207021bf5e75d061040c33505923a/BLOG-2626_10.png\&quot; alt=\&quot;BLOG-2626 10\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5QPU28IyaW3QPCqaIzTZec/19b3ed7675d23441c9493c2313134a41/BLOG-2626_11.png\&quot; alt=\&quot;BLOG-2626 11\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4zSx3b14HwaBIFX5qc59bq/4f8e2b4951498a2edcae846068927350/BLOG-2626_12.png\&quot; alt=\&quot;BLOG-2626 12\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1P04AQZbfZOTisBPutbLZa/5e6520bfd1782976538c98914134fe94/BLOG-2626_13.png\&quot; alt=\&quot;BLOG-2626 13\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;Telegeography’s &lt;a href=\&quot;http://submarinecablemap.com\&quot;&gt;&lt;u&gt;submarinecablemap.com&lt;/u&gt;&lt;/a&gt; illustrates, at least in part, the resilience in connectivity enjoyed by these two countries. In addition to the damaged cable, it shows that &lt;a href=\&quot;https://www.submarinecablemap.com/country/lithuania\&quot;&gt;&lt;u&gt;Lithuania&lt;/u&gt;&lt;/a&gt; is &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/bcs-east\&quot;&gt;&lt;u&gt;connected to neighboring Latvia&lt;/u&gt;&lt;/a&gt; as well as &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/nordbalt\&quot;&gt;&lt;u&gt;to the Swedish mainland&lt;/u&gt;&lt;/a&gt;. Over 20 submarine cables land in &lt;a href=\&quot;https://www.submarinecablemap.com/country/sweden\&quot;&gt;&lt;u&gt;Sweden&lt;/u&gt;&lt;/a&gt;, connecting it to multiple countries across Europe. In addition to the submarine resilience, network providers in both countries can take advantage of terrestrial fiber connections to neighboring countries, such as those illustrated in a &lt;a href=\&quot;https://www.arelion.com/our-network\&quot;&gt;&lt;u&gt;European network map from Arelion&lt;/u&gt;&lt;/a&gt; (formerly Telia), which is only one of the large European backbone providers.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;c-lion1\&quot;&gt;C-Lion1&lt;/h2&gt;\n            &lt;a href=\&quot;#c-lion1\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          \n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;traffic-volume-indicators\&quot;&gt;Traffic volume indicators&lt;/h3&gt;\n            &lt;a href=\&quot;#traffic-volume-indicators\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Less than a day later, the &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/c-lion1\&quot;&gt;&lt;u&gt;C-Lion1 submarine cable&lt;/u&gt;&lt;/a&gt;, which connects Helsinki, Finland and Rostock Germany was &lt;a href=\&quot;https://www.datacenterdynamics.com/en/news/helsinki-rostock-subsea-cable-between-finland-and-germany-severed/\&quot;&gt;&lt;u&gt;reportedly damaged&lt;/u&gt;&lt;/a&gt; during the early morning hours of Monday, November 18. Cinia, the telecommunications company that owns the cable, &lt;a href=\&quot;https://www.theguardian.com/world/2024/nov/19/baltic-sea-cables-damage-sabotage-german-minister\&quot;&gt;&lt;u&gt;said&lt;/u&gt;&lt;/a&gt; that the cable stopped working at about 02:00 UTC. &lt;/p&gt;&lt;p&gt;In this situation as well, as the Cloudflare Radar graphs below show, there was no apparent impact to traffic volumes in either country at the time that the cables were damaged. The Finland graphs, week-on-week, show fewer bytes transferred and fewer HTTP requests, but that difference is present before the cable cut at 02:00 UTC. However, the trend of the current line does not change after the cable cut, so the two events would appear unrelated. &lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4OQtSFBgBzdmnzWz8AdM7Z/3a66cec98698bf6d506d93fc13fe4c74/BLOG-2626_14.png\&quot; alt=\&quot;BLOG-2626 14\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;1072\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4gqxHsD3ykjWGWhATVU8iw/f74916e1faf186efef94e6dc29bbca58/BLOG-2626_15.png\&quot; alt=\&quot;BLOG-2626 15\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;1072\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4gh5eLQZNabsz9XnOSgtU1/fb6d0770c62ce016d73c1a3c47ae99f1/BLOG-2626_16.png\&quot; alt=\&quot;BLOG-2626 16\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;1072\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6FIKh8U2nxHkxMdXho6HsI/9e349d0767df5d34d3b8274710c2cb0b/BLOG-2626_17.png\&quot; alt=\&quot;BLOG-2626 17\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;1072\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;internet-quality\&quot;&gt;Internet quality&lt;/h3&gt;\n            &lt;a href=\&quot;#internet-quality\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;By looking at volume-related metrics, alone, Internet connectivity would appear to be unaffected by the cable cut.&lt;/p&gt;&lt;p&gt;If, however, we change perspective and look at Internet quality, a brief yet interesting change is visible for Finland around the reported time of the cable damage, though it isn’t clear whether it is related in any way. Just after midnight, median measured bandwidth, previously consistent around 50 Mbps begins to grow, peaking just over 200 Mbps around 03:00 UTC. Around that same time, measured median latency also begins to drop, falling from around 30 ms to a low of 13 ms, also around 03:00 UTC. Median bandwidth returned to normal levels around 06:00 UTC, while latency took about two hours longer to return to normal levels.  These observed  improvements in bandwidth and latency could have been due to traffic being re-routed to along paths with better connectivity to measurement endpoints, but because the shifts began before the cable damage occurred, and recovered shortly thereafter, that is unlikely to be the root cause.&lt;/p&gt;&lt;p&gt;In Germany, a brief minor increase in median bandwidth peaked around 02:45 UTC, while no notable changes were observed in latency.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/94V0coi6oFBdUMX1SVyl7/44738b06af2e51b4e436c84dbe6a1a79/BLOG-2626_18.png\&quot; alt=\&quot;BLOG-2626 18\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/Bqy5uQ76FwmmOX92Co4cE/96190329454e264966119a0f9a4533ff/BLOG-2626_19.png\&quot; alt=\&quot;BLOG-2626 19\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1BJCVdjJMILFubi4SW8HR6/7b97343910ab70cc1a4cad3d3565a727/BLOG-2626_20.png\&quot; alt=\&quot;BLOG-2626 20\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3lf5GR9ElhjpW0wYzPieNI/c02a588af54ac36521f901307d9f62f7/BLOG-2626_21.png\&quot; alt=\&quot;BLOG-2626 21\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;bgp-business-as-usual\&quot;&gt;BGP business as usual&lt;/h3&gt;\n            &lt;a href=\&quot;#bgp-business-as-usual\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;From a routing perspective, there was no notable BGP announcement activity observed for top autonomous systems in either Finland or Germany around 02:00 on November 18, and total announced IP address space aggregated at a country level also demonstrated no change.&lt;/p&gt;&lt;p&gt;Telegeography’s &lt;a href=\&quot;http://submarinecablemap.com\&quot;&gt;&lt;u&gt;submarinecablemap.com&lt;/u&gt;&lt;/a&gt; shows that both Finland and Germany also have significant redundancy and resilience from a submarine cable perspective, with over 10 cables landing in &lt;a href=\&quot;https://www.submarinecablemap.com/country/finland\&quot;&gt;&lt;u&gt;Finland&lt;/u&gt;&lt;/a&gt;, and nearly 10 landing in &lt;a href=\&quot;https://www.submarinecablemap.com/country/germany\&quot;&gt;&lt;u&gt;Germany&lt;/u&gt;&lt;/a&gt;, including &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/atlantic-crossing-1-ac-1\&quot;&gt;&lt;u&gt;Atlantic Crossing-1 (AC-1)&lt;/u&gt;&lt;/a&gt;, which connects to the United States over two distinct paths. Terrestrial fiber maps from &lt;a href=\&quot;https://www.arelion.com/our-network\&quot;&gt;&lt;u&gt;Arelion&lt;/u&gt;&lt;/a&gt; and &lt;a href=\&quot;https://map.eunetworks.com/?_ga=2.220121625.1822578510.1543942339-1757484894.1536310774\&quot;&gt;&lt;u&gt;eunetworks&lt;/u&gt;&lt;/a&gt; (as just two examples) show multiple redundant fiber routes within both countries, as well as cross-border routes to other neighboring countries, enabling more resilient Internet connectivity.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;conclusion\&quot;&gt;Conclusion&lt;/h2&gt;\n            &lt;a href=\&quot;#conclusion\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;As we have discussed in multiple prior blog posts (&lt;a href=\&quot;https://blog.cloudflare.com/not-one-not-two-but-three-undersea-cables-cut-in-jersey\&quot;&gt;&lt;u&gt;Jersey, 2016&lt;/u&gt;&lt;/a&gt;; &lt;a href=\&quot;https://blog.cloudflare.com/aae-1-smw5-cable-cuts\&quot;&gt;&lt;u&gt;AAE-1/SMW5, 2022&lt;/u&gt;&lt;/a&gt;; &lt;a href=\&quot;https://blog-cloudflare-com.webpkgcache.com/doc/-/s/blog.cloudflare.com/undersea-cable-failures-cause-internet-disruptions-across-africa-march-14-2024\&quot;&gt;&lt;u&gt;WACS/MainOne/SAT3/ACE, 2024&lt;/u&gt;&lt;/a&gt;; &lt;a href=\&quot;https://blog.cloudflare.com/east-african-internet-connectivity-again-impacted-by-submarine-cable-cuts/\&quot;&gt;&lt;u&gt;EASSy/Seacom, 2024&lt;/u&gt;&lt;/a&gt;), cable cuts often cause significant disruptions to Internet connectivity, in many cases because they represent a concentrated point of vulnerability, whether for an individual network provider, city/state, or country. These disruptions are often quite lengthy as well, due to the time needed to marshal repair resources, identify the location of the damage, etc. Although it is not always feasible due to financial or geographic constraints, building redundant and resilient network architecture, at multiple levels, is a best practice. This includes the sending traffic over multiple physical cables (both submarine and terrestrial), connecting to multiple peer and upstream network providers, and even avoiding single points of failure in core Internet resources like DNS servers.&lt;/p&gt;&lt;p&gt;The Cloudflare Radar team continually monitors the status of Internet connectivity in countries/regions around the world, and we share our observations on the &lt;a href=\&quot;https://radar.cloudflare.com/outage-center\&quot;&gt;&lt;u&gt;Cloudflare Radar Outage Center&lt;/u&gt;&lt;/a&gt;, via social media, and in posts on &lt;a href=\&quot;https://blog.cloudflare.com/tag/cloudflare-radar/\&quot;&gt;&lt;u&gt;blog.cloudflare.com&lt;/u&gt;&lt;/a&gt;. Follow us on social media at &lt;a href=\&quot;https://twitter.com/CloudflareRadar\&quot;&gt;&lt;u&gt;@CloudflareRadar&lt;/u&gt;&lt;/a&gt; (X), &lt;a href=\&quot;https://noc.social/@cloudflareradar\&quot;&gt;&lt;u&gt;https://noc.social/@cloudflareradar&lt;/u&gt;&lt;/a&gt; (Mastodon), and &lt;a href=\&quot;https://bsky.app/profile/radar.cloudflare.com\&quot;&gt;&lt;u&gt;radar.cloudflare.com&lt;/u&gt;&lt;/a&gt; (Bluesky), or contact us via email.&lt;/p&gt;&quot;],&quot;published_at&quot;:[0,&quot;2024-11-20T13:30-08:00&quot;],&quot;updated_at&quot;:[0,&quot;2024-11-20T21:47:48.905Z&quot;],&quot;feature_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3dWoOcmImje5kF6Q7mXg8N/131884a8cd009a8c225d5aa3d64f4b97/BLOG-2626_1.png&quot;],&quot;tags&quot;:[1,[[0,{&quot;id&quot;:[0,&quot;5kZtWqjqa7aOUoZr8NFGwI&quot;],&quot;name&quot;:[0,&quot;Radar&quot;],&quot;slug&quot;:[0,&quot;cloudflare-radar&quot;]}],[0,{&quot;id&quot;:[0,&quot;0kgHdg1ytbdWl5BNo6bEa&quot;],&quot;name&quot;:[0,&quot;Internet Traffic&quot;],&quot;slug&quot;:[0,&quot;internet-traffic&quot;]}],[0,{&quot;id&quot;:[0,&quot;2ScX2j6LG2ruyaS8eLYhsd&quot;],&quot;name&quot;:[0,&quot;Traffic&quot;],&quot;slug&quot;:[0,&quot;traffic&quot;]}],[0,{&quot;id&quot;:[0,&quot;4yliZlpBPZpOwBDZzo1tTh&quot;],&quot;name&quot;:[0,&quot;Outage&quot;],&quot;slug&quot;:[0,&quot;outage&quot;]}]]],&quot;relatedTags&quot;:[0],&quot;authors&quot;:[1,[[0,{&quot;name&quot;:[0,&quot;David Belson&quot;],&quot;slug&quot;:[0,&quot;david-belson&quot;],&quot;bio&quot;:[0,null],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/en7vkXf6rLBm4F8IcNHXT/645022bf841fabff7732aa3be3949808/david-belson.jpeg&quot;],&quot;location&quot;:[0,null],&quot;website&quot;:[0,null],&quot;twitter&quot;:[0,&quot;@dbelson&quot;],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}]]],&quot;meta_description&quot;:[0,&quot;Two recent cable cuts that occurred in the Baltic Sea resulted in little-to-no observable impact to the affected countries, in large part because of the significant redundancy and resilience of Internet infrastructure in Europe.\n&quot;],&quot;primary_author&quot;:[0,{}],&quot;localeList&quot;:[0,{&quot;name&quot;:[0,&quot;blog-english-only&quot;],&quot;enUS&quot;:[0,&quot;English for Locale&quot;],&quot;zhCN&quot;:[0,&quot;No Page for Locale&quot;],&quot;zhHansCN&quot;:[0,&quot;No Page for Locale&quot;],&quot;zhTW&quot;:[0,&quot;No Page for Locale&quot;],&quot;frFR&quot;:[0,&quot;No Page for Locale&quot;],&quot;deDE&quot;:[0,&quot;No Page for Locale&quot;],&quot;itIT&quot;:[0,&quot;No Page for Locale&quot;],&quot;jaJP&quot;:[0,&quot;No Page for Locale&quot;],&quot;koKR&quot;:[0,&quot;No Page for Locale&quot;],&quot;ptBR&quot;:[0,&quot;No Page for Locale&quot;],&quot;esLA&quot;:[0,&quot;No Page for Locale&quot;],&quot;esES&quot;:[0,&quot;No Page for Locale&quot;],&quot;enAU&quot;:[0,&quot;No Page for Locale&quot;],&quot;enCA&quot;:[0,&quot;No Page for Locale&quot;],&quot;enIN&quot;:[0,&quot;No Page for Locale&quot;],&quot;enGB&quot;:[0,&quot;No Page for Locale&quot;],&quot;idID&quot;:[0,&quot;No Page for Locale&quot;],&quot;ruRU&quot;:[0,&quot;No Page for Locale&quot;],&quot;svSE&quot;:[0,&quot;No Page for Locale&quot;],&quot;viVN&quot;:[0,&quot;No Page for Locale&quot;],&quot;plPL&quot;:[0,&quot;No Page for Locale&quot;],&quot;arAR&quot;:[0,&quot;No Page for Locale&quot;],&quot;nlNL&quot;:[0,&quot;No Page for Locale&quot;],&quot;thTH&quot;:[0,&quot;No Page for Locale&quot;],&quot;trTR&quot;:[0,&quot;No Page for Locale&quot;],&quot;heIL&quot;:[0,&quot;No Page for Locale&quot;],&quot;lvLV&quot;:[0,&quot;No Page for Locale&quot;],&quot;etEE&quot;:[0,&quot;No Page for Locale&quot;],&quot;ltLT&quot;:[0,&quot;No Page for Locale&quot;]}],&quot;url&quot;:[0,&quot;https://blog.cloudflare.com/resilient-internet-connectivity-baltic-cable-cuts&quot;],&quot;metadata&quot;:[0,{&quot;title&quot;:[0],&quot;description&quot;:[0,&quot;Two recent cable cuts that occurred in the Baltic Sea resulted in little-to-no observable impact to the affected countries, in large part because of the significant redundancy and resilience of Internet infrastructure in Europe.\n&quot;],&quot;imgPreview&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6T4ztbR519lnRjX8eJFjvT/9b9524506c64906111ed02543f720bfe/OG_Share_2024__3_.png&quot;]}],&quot;publicly_index&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;Vn5VV2dLkJbOn1YNqSSBv&quot;],&quot;title&quot;:[0,&quot;Cloudflare’s perspective of the October 30, 2024, OVHcloud outage&quot;],&quot;slug&quot;:[0,&quot;cloudflare-perspective-of-the-october-30-2024-ovhcloud-outage&quot;],&quot;excerpt&quot;:[0,&quot;On October 30, 2024, cloud hosting provider OVHcloud (AS16276) suffered a brief but significant outage. Within this post, we review Cloudflare’s perspective on this outage.&quot;],&quot;featured&quot;:[0,false],&quot;html&quot;:[0,&quot;&lt;p&gt;On October 30, 2024, cloud hosting provider &lt;a href=\&quot;https://radar.cloudflare.com/as16276\&quot;&gt;&lt;u&gt;OVHcloud (AS16276)&lt;/u&gt;&lt;/a&gt; suffered a brief but significant outage. According to their &lt;a href=\&quot;https://network.status-ovhcloud.com/incidents/qgb1ynp8x0c4\&quot;&gt;&lt;u&gt;incident report&lt;/u&gt;&lt;/a&gt;, the problem started at 13:23 UTC, and was described simply as “&lt;i&gt;An incident is in progress on our backbone infrastructure.&lt;/i&gt;” OVHcloud noted that the incident ended 17 minutes later, at 13:40 UTC. As a major global cloud hosting provider, some customers use OVHcloud as an origin for sites delivered by Cloudflare — if a given content asset is not in our cache for a customer’s site, we retrieve the asset from OVHcloud.&lt;/p&gt;&lt;p&gt;We observed traffic starting to drop at 13:21 UTC, just ahead of the reported start time. By 13:28 UTC, it was approximately 95% lower than pre-incident levels. Recovery appeared to start at 13:31 UTC, and by 13:40 UTC, the reported end time of the incident, it had reached approximately 50% of pre-incident levels. &lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/62w8PcLJ3Q05F1BtA12zUb/6d8ce87f85eb585a7fe0ac02f8cd93d5/image4.jpg\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1556\&quot; height=\&quot;504\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sup&gt;&lt;i&gt;Traffic from OVHcloud (AS16276) to Cloudflare&lt;/i&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Cloudflare generally exchanges most of our traffic with OVHcloud over peering links. However, as shown below, peered traffic volume during the incident fell significantly. It appears that some small amount of traffic briefly began to flow over transit links from Cloudflare to OVHcloud due to sudden changes in which Cloudflare data centers we were receiving OVHcloud requests. (Peering is a direct connection between two network providers for the purpose of exchanging traffic. Transit is when one network pays an intermediary network to carry traffic to the destination network.) &lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2L0IaXd7B5C6RX23iTG5Pf/3fd2489f159e2281d191f157f5695f94/image3.jpg\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1580\&quot; height=\&quot;884\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;Because we peer directly, we exchange most traffic over our private peering sessions with OVHcloud. Instead, we found OVHcloud routing to Cloudflare dropped entirely for a few minutes, then switched to just a single Internet Exchange port in Amsterdam, and finally normalized globally minutes later.&lt;/p&gt;&lt;p&gt;As the graphs below illustrate, we normally see the largest amount of traffic from OVHcloud in our Frankfurt and Paris data centers, as &lt;a href=\&quot;https://www.ovhcloud.com/en/about-us/global-infrastructure/regions/\&quot;&gt;&lt;u&gt;OVHcloud has large data center presences in these regions&lt;/u&gt;&lt;/a&gt;. However, in that shift to transit, and the shift to an Amsterdam Internet Exchange peering point, we saw a spike in traffic routed to our Amsterdam data center. We suspect the routing shifts are the earliest signs of either internal BGP reconvergence, or general network recovery within AS16276, starting with their presence nearest our Amsterdam peering point.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/yCDGCplEsmqXU7uRifjTU/12176147c10ab6e9a766ee5d788b133a/image2.jpg\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1580\&quot; height=\&quot;910\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;The &lt;a href=\&quot;https://network.status-ovhcloud.com/incidents/qgb1ynp8x0c4\&quot;&gt;&lt;u&gt;postmortem&lt;/u&gt;&lt;/a&gt; published by OVHcloud noted that the incident was caused by “&lt;i&gt;an issue in a network configuration mistakenly pushed by one of our peering partner[s]&lt;/i&gt;” and that “&lt;i&gt;We immediately reconfigured our network routes to restore traffic.&lt;/i&gt;” One possible explanation for the backbone incident may be a BGP route leak by the mentioned peering partner, where OVHcloud could have accepted a full Internet table from the peer and therefore overwhelmed their network or the peering partner’s network with traffic, or caused unexpected internal BGP route updates within AS16276.&lt;/p&gt;&lt;p&gt;Upon investigating what route leak may have caused this incident impacting OVHcloud, we found evidence of a maximum prefix-limit threshold being breached on our peering with &lt;a href=\&quot;https://radar.cloudflare.com/as49981\&quot;&gt;&lt;u&gt;Worldstream (AS49981)&lt;/u&gt;&lt;/a&gt; in Amsterdam. &lt;/p&gt;\n            &lt;pre class=\&quot;language-unset\&quot;&gt;&lt;code class=\&quot;language-unset\&quot;&gt;Oct 30 13:16:53  edge02.ams01 rpd[9669]: RPD_BGP_NEIGHBOR_STATE_CHANGED: BGP peer 141.101.65.53 (External AS 49981) changed state from Established to Idle (event PrefixLimitExceeded) (instance master)&lt;/pre&gt;&lt;/code&gt;\n            &lt;p&gt;&lt;/p&gt;&lt;p&gt;As the number of received prefixes exceeded the limits configured for our peering session with Worldstream, the BGP session automatically entered an idle state. This prevented the route leak from impacting Cloudflare’s network. In analyzing &lt;a href=\&quot;https://datatracker.ietf.org/doc/html/rfc7854\&quot;&gt;&lt;u&gt;BGP Monitoring Protocol (BMP)&lt;/u&gt;&lt;/a&gt; data from AS49981 prior to the automatic session shutdown, we were able to confirm Worldstream was sending advertisements with AS paths that contained their upstream Tier 1 transit provider.&lt;/p&gt;&lt;p&gt;During this time, we also detected over 500,000 BGP announcements from AS49981, as Worldstream was announcing routes to many of their peers, visible on &lt;a href=\&quot;https://radar.cloudflare.com/routing/as49981?dateStart=2024-10-30&amp;dateEnd=2024-10-30#bgp-announcements\&quot;&gt;&lt;u&gt;Cloudflare Radar&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2YmTSJfXomzeb3mh93JyRH/15c764790576468a47d3760bc7f48153/Screenshot_2024-10-30_at_12.49.25_PM.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;776\&quot; height=\&quot;307\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;Worldstream later &lt;a href=\&quot;https://noc.worldstream.nl\&quot;&gt;&lt;u&gt;posted a notice&lt;/u&gt;&lt;/a&gt; on their status page, indicating that their network experienced a route leak, causing routes to be unintentionally advertised to all peers:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;i&gt;“Due to a configuration error on one of the core routers, all routes were briefly announced to all our peers. As a result, we pulled in more traffic than expected, leading to congestion on some paths. To address this, we temporarily shut down these BGP sessions to locate the issue and stabilize the network. We are sorry for the inconvenience.”&lt;/i&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;We believe Worldstream also leaked routes on an OVHcloud peering session in Amsterdam, which caused today’s impact.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;conclusion\&quot;&gt;Conclusion&lt;/h2&gt;\n            &lt;a href=\&quot;#conclusion\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;Cloudflare has written about&lt;a href=\&quot;https://blog.cloudflare.com/cloudflare-1111-incident-on-june-27-2024\&quot;&gt; &lt;u&gt;impactful route leaks&lt;/u&gt;&lt;/a&gt; before, and there are multiple methods available to prevent BGP route leaks from impacting your network. One is setting &lt;a href=\&quot;https://www.rfc-editor.org/rfc/rfc7454.html#section-8\&quot;&gt;&lt;u&gt;max prefix-limits&lt;/u&gt;&lt;/a&gt; for a peer, so the BGP session is automatically torn down when a peer sends more prefixes than they are expected to. Other forward-looking measures are&lt;a href=\&quot;https://manrs.org/2023/02/unpacking-the-first-route-leak-prevented-by-aspa/\&quot;&gt; &lt;u&gt;Autonomous System Provider Authorization (ASPA) for BGP&lt;/u&gt;&lt;/a&gt;, where Resource Public Key Infrastructure (RPKI) helps protect a network from accepting BGP routes with an invalid AS path, or&lt;a href=\&quot;https://rfc.hashnode.dev/rfc9234-observed-in-the-wild\&quot;&gt; &lt;u&gt;RFC9234,&lt;/u&gt;&lt;/a&gt; which prevents leaks by tying strict customer, peer, and provider relationships to BGP updates. For improved Internet resilience, we recommend that network operators follow recommendations defined within&lt;a href=\&quot;https://manrs.org/netops/\&quot;&gt; &lt;u&gt;MANRS for Network Operators&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&quot;],&quot;published_at&quot;:[0,&quot;2024-10-30T00:00+00:00&quot;],&quot;updated_at&quot;:[0,&quot;2025-04-28T16:42:56.665Z&quot;],&quot;feature_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1QiwxIoAtIDpjVYA5ds5Si/9764c458d85c5ff1fcbf89d543d7967e/Screenshot_2024-10-30_at_12.42.48_PM.png&quot;],&quot;tags&quot;:[1,[[0,{&quot;id&quot;:[0,&quot;5kZtWqjqa7aOUoZr8NFGwI&quot;],&quot;name&quot;:[0,&quot;Radar&quot;],&quot;slug&quot;:[0,&quot;cloudflare-radar&quot;]}],[0,{&quot;id&quot;:[0,&quot;3yArjf0gLKZy8ObEDxbNNi&quot;],&quot;name&quot;:[0,&quot;Trends&quot;],&quot;slug&quot;:[0,&quot;trends&quot;]}],[0,{&quot;id&quot;:[0,&quot;4nA5kKyA1tOqFyjHMque21&quot;],&quot;name&quot;:[0,&quot;Consumer Services&quot;],&quot;slug&quot;:[0,&quot;consumer-services&quot;]}],[0,{&quot;id&quot;:[0,&quot;4yliZlpBPZpOwBDZzo1tTh&quot;],&quot;name&quot;:[0,&quot;Outage&quot;],&quot;slug&quot;:[0,&quot;outage&quot;]}]]],&quot;relatedTags&quot;:[0],&quot;authors&quot;:[1,[[0,{&quot;name&quot;:[0,&quot;Bryton Herdes&quot;],&quot;slug&quot;:[0,&quot;bryton&quot;],&quot;bio&quot;:[0,null],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2CtRZInMXDzWbBSlJZq6ob/cc0d484943cf18a7d24debb3d01a3ece/bryton.jpeg&quot;],&quot;location&quot;:[0,null],&quot;website&quot;:[0,&quot;https://next-hopself.net/&quot;],&quot;twitter&quot;:[0,&quot;@next_hopself&quot;],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}],[0,{&quot;name&quot;:[0,&quot;David Belson&quot;],&quot;slug&quot;:[0,&quot;david-belson&quot;],&quot;bio&quot;:[0,null],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/en7vkXf6rLBm4F8IcNHXT/645022bf841fabff7732aa3be3949808/david-belson.jpeg&quot;],&quot;location&quot;:[0,null],&quot;website&quot;:[0,null],&quot;twitter&quot;:[0,&quot;@dbelson&quot;],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}],[0,{&quot;name&quot;:[0,&quot;Tanner Ryan&quot;],&quot;slug&quot;:[0,&quot;tanner&quot;],&quot;bio&quot;:[0,&quot;I work on global infrastructure at Cloudflare, helping to build a better Internet.&quot;],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3iETWecBBWy6tZtJS3gUGI/4bb0b2d0ad262f17985031e9660c292e/tanner.jpg&quot;],&quot;location&quot;:[0,&quot;Austin, TX&quot;],&quot;website&quot;:[0,&quot;https://txryan.com&quot;],&quot;twitter&quot;:[0,&quot;@TheTannerRyan&quot;],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}]]],&quot;meta_description&quot;:[0,&quot;On October 30, 2024, cloud hosting provider OVHcloud (AS16276) suffered a brief but significant outage. Within this post, we review Cloudflare’s perspective on this outage.&quot;],&quot;primary_author&quot;:[0,{}],&quot;localeList&quot;:[0,{&quot;name&quot;:[0,&quot;blog-english-only&quot;],&quot;enUS&quot;:[0,&quot;English for Locale&quot;],&quot;zhCN&quot;:[0,&quot;No Page for Locale&quot;],&quot;zhHansCN&quot;:[0,&quot;No Page for Locale&quot;],&quot;zhTW&quot;:[0,&quot;No Page for Locale&quot;],&quot;frFR&quot;:[0,&quot;No Page for Locale&quot;],&quot;deDE&quot;:[0,&quot;No Page for Locale&quot;],&quot;itIT&quot;:[0,&quot;No Page for Locale&quot;],&quot;jaJP&quot;:[0,&quot;No Page for Locale&quot;],&quot;koKR&quot;:[0,&quot;No Page for Locale&quot;],&quot;ptBR&quot;:[0,&quot;No Page for Locale&quot;],&quot;esLA&quot;:[0,&quot;No Page for Locale&quot;],&quot;esES&quot;:[0,&quot;No Page for Locale&quot;],&quot;enAU&quot;:[0,&quot;No Page for Locale&quot;],&quot;enCA&quot;:[0,&quot;No Page for Locale&quot;],&quot;enIN&quot;:[0,&quot;No Page for Locale&quot;],&quot;enGB&quot;:[0,&quot;No Page for Locale&quot;],&quot;idID&quot;:[0,&quot;No Page for Locale&quot;],&quot;ruRU&quot;:[0,&quot;No Page for Locale&quot;],&quot;svSE&quot;:[0,&quot;No Page for Locale&quot;],&quot;viVN&quot;:[0,&quot;No Page for Locale&quot;],&quot;plPL&quot;:[0,&quot;No Page for Locale&quot;],&quot;arAR&quot;:[0,&quot;No Page for Locale&quot;],&quot;nlNL&quot;:[0,&quot;No Page for Locale&quot;],&quot;thTH&quot;:[0,&quot;No Page for Locale&quot;],&quot;trTR&quot;:[0,&quot;No Page for Locale&quot;],&quot;heIL&quot;:[0,&quot;No Page for Locale&quot;],&quot;lvLV&quot;:[0,&quot;No Page for Locale&quot;],&quot;etEE&quot;:[0,&quot;No Page for Locale&quot;],&quot;ltLT&quot;:[0,&quot;No Page for Locale&quot;]}],&quot;url&quot;:[0,&quot;https://blog.cloudflare.com/cloudflare-perspective-of-the-october-30-2024-ovhcloud-outage&quot;],&quot;metadata&quot;:[0,{&quot;title&quot;:[0,&quot;Cloudflare’s perspective of the October 30, 2024, OVHcloud outage&quot;],&quot;description&quot;:[0,&quot;On October 30, 2024, cloud hosting provider OVHcloud (AS16276) suffered a brief but significant outage. Within this post, we review Cloudflare’s perspective on this outage.&quot;],&quot;imgPreview&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7KLbhGDOJJP448hp8wmV80/3f7482a1e948fe2ffb0d35572b6b69bd/OG_Share_2024.png&quot;]}],&quot;publicly_index&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;3xoUhxvPcDFTiYCT9CjHhs&quot;],&quot;title&quot;:[0,&quot;Forced offline: the Q3 2024 Internet disruption summary&quot;],&quot;slug&quot;:[0,&quot;q3-2024-internet-disruption-summary&quot;],&quot;excerpt&quot;:[0,&quot;The third quarter of 2024 was particularly active, with quite a few significant Internet disruptions. Underlying causes included government-directed shutdowns, power outages, hurricane damage, terrestrial and submarine cable cuts, military action, and more.&quot;],&quot;featured&quot;:[0,false],&quot;html&quot;:[0,&quot;&lt;p&gt;Cloudflare’s network spans more than 330 cities in over 120 countries, where we interconnect with over 13,000 network providers in order to provide a broad range of services to millions of customers. The breadth of both our network and our customer base provides us with a unique perspective on Internet resilience, enabling us to observe the impact of Internet disruptions. Thanks to &lt;a href=\&quot;https://radar.cloudflare.com/\&quot;&gt;&lt;u&gt;Cloudflare Radar&lt;/u&gt;&lt;/a&gt; functionality released earlier this year, we can explore the impact from a &lt;a href=\&quot;https://developers.cloudflare.com/radar/glossary/#bgp-announcements\&quot;&gt;&lt;u&gt;routing&lt;/u&gt;&lt;/a&gt; perspective, as well as a traffic perspective, at both a &lt;a href=\&quot;https://x.com/CloudflareRadar/status/1768654743742579059\&quot;&gt;&lt;u&gt;network&lt;/u&gt;&lt;/a&gt; and &lt;a href=\&quot;https://x.com/CloudflareRadar/status/1773704264650543416\&quot;&gt;&lt;u&gt;location&lt;/u&gt;&lt;/a&gt; level.&lt;/p&gt;&lt;p&gt;As we have noted in the past, this post is intended as a summary overview of observed and confirmed disruptions, and is not an exhaustive or complete list of issues that have occurred during the quarter. &lt;/p&gt;&lt;p&gt;A larger list of detected traffic anomalies is available in the &lt;a href=\&quot;https://radar.cloudflare.com/outage-center#traffic-anomalies\&quot;&gt;&lt;u&gt;Cloudflare Radar Outage Center&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Having said that, the third quarter of 2024 was particularly active, with quite a few significant Internet disruptions. Unfortunately, &lt;a href=\&quot;#government-directed\&quot;&gt;&lt;u&gt;governments continued to impose nationwide Internet shutdowns&lt;/u&gt;&lt;/a&gt; intended to prevent cheating on exams. &lt;a href=\&quot;#cable-cuts\&quot;&gt;&lt;u&gt;Damage to both terrestrial and submarine cables&lt;/u&gt;&lt;/a&gt; impacted Internet connectivity across Africa and in other parts of the world. &lt;a href=\&quot;#severe-weather\&quot;&gt;&lt;u&gt;Damage caused by an active hurricane season&lt;/u&gt;&lt;/a&gt; caused Internet outages across the Caribbean and in multiple parts of the United States. Because Internet connectivity is dependent on reliable electrical power, both &lt;a href=\&quot;#power-outages\&quot;&gt;&lt;u&gt;planned and unplanned power outages&lt;/u&gt;&lt;/a&gt; in South America and Africa resulted in multi-hour Internet disruptions. &lt;a href=\&quot;#military-action\&quot;&gt;&lt;u&gt;Military action&lt;/u&gt;&lt;/a&gt; continued to cause Internet outages in affected countries, as did &lt;a href=\&quot;#maintenance\&quot;&gt;&lt;u&gt;infrastructure maintenance&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;#fire\&quot;&gt;&lt;u&gt;fire&lt;/u&gt;&lt;/a&gt;, and a purported &lt;a href=\&quot;#cyberattack\&quot;&gt;&lt;u&gt;cyberattack&lt;/u&gt;&lt;/a&gt;. The quarter also saw several noteworthy Internet disruptions that &lt;a href=\&quot;#unknown\&quot;&gt;&lt;u&gt;did not have verified causes&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;government-directed\&quot;&gt;Government Directed&lt;/h2&gt;\n            &lt;a href=\&quot;#government-directed\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;Over the past several years, we have seen multiple governments around the world implement Internet shutdowns in response to protests within their countries. Some shutdowns are more targeted, affecting only (a subset of) mobile Internet providers, while others are more aggressive, effectively cutting off Internet connectivity at a national level. In addition, we all too frequently see governments implement nationwide multi-hour Internet shutdowns in an effort to prevent students from cheating on national exams. Unfortunately, governments were active in both respects during the third quarter, as we observed multiple government directed Internet shutdowns. Several were covered in our August 1 blog post, &lt;a href=\&quot;https://blog.cloudflare.com/a-recent-spate-of-internet-disruptions-july-2024/\&quot;&gt;&lt;i&gt;&lt;u&gt;A recent spate of Internet disruptions&lt;/u&gt;&lt;/i&gt;&lt;/a&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;bangladesh\&quot;&gt;Bangladesh&lt;/h3&gt;\n            &lt;a href=\&quot;#bangladesh\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;&lt;a href=\&quot;https://timesofindia.indiatimes.com/world/south-asia/internet-shut-nationwide-bandh-announced-why-is-bangladesh-experiencing-deadly-protests/articleshow/111829956.cms\&quot;&gt;&lt;u&gt;Violent student protests&lt;/u&gt;&lt;/a&gt; in &lt;a href=\&quot;https://radar.cloudflare.com/bd\&quot;&gt;&lt;u&gt;Bangladesh&lt;/u&gt;&lt;/a&gt; against quotas in government jobs and rising unemployment rates led the government to order the nationwide shutdown of mobile Internet connectivity on July 18, &lt;a href=\&quot;https://therecord.media/bangladesh-mobile-internet-social-media-outages-student-protests\&quot;&gt;&lt;u&gt;reportedly&lt;/u&gt;&lt;/a&gt; to “&lt;i&gt;ensure the security of citizens.&lt;/i&gt;” This government-directed shutdown ultimately became a near-complete Internet outage for the country, as broadband networks were taken offline as well. At a country level, &lt;a href=\&quot;https://radar.cloudflare.com/traffic/bd?dateStart=2024-07-14&amp;dateEnd=2024-07-28\&quot;&gt;&lt;u&gt;Internet traffic in Bangladesh dropped to near zero&lt;/u&gt;&lt;/a&gt; just before 21:00 local time (15:00 UTC). &lt;a href=\&quot;https://radar.cloudflare.com/routing/bd?dateStart=2024-07-14&amp;dateEnd=2024-07-28\&quot;&gt;&lt;u&gt;Announced IP address space from the country dropped to near zero&lt;/u&gt;&lt;/a&gt; at that time as well, meaning that nearly every network in the country was disconnected from the Internet.&lt;/p&gt;&lt;p&gt;Traffic and announced IP address space at a national level began to recover around 18:00 local time (12:00 UTC) on July 23, and continued over the next several days, as &lt;a href=\&quot;https://developingtelecoms.com/telecom-business/telecom-regulation/17059-mobile-internet-in-bangladesh-to-stay-dark-until-at-least-sunday.html\&quot;&gt;&lt;u&gt;fixed broadband connectivity was restored&lt;/u&gt;&lt;/a&gt;, with &lt;a href=\&quot;https://developingtelecoms.com/telecom-business/telecom-regulation/17067-mobile-internet-returns-to-bangladesh-but-not-social-media-apps.html\&quot;&gt;&lt;u&gt;mobile connectivity returning on July 28&lt;/u&gt;&lt;/a&gt;. The initial restoration was characterized as a “trial run”, prioritizing banking, commercial sectors, technology firms, exporters, outsourcing providers and media outlets, &lt;a href=\&quot;https://www.dhakatribune.com/bangladesh/352554/broadband-internet-restored-in-limited-areas-after\&quot;&gt;&lt;u&gt;according to&lt;/u&gt;&lt;/a&gt; the state minister for post, telecommunication and information technology.&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-07-16&amp;dateEnd=2024-07-29&amp;location=bd&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/BgpRoutesTimeseriesXY?dateStart=2024-07-16&amp;dateEnd=2024-07-29&amp;location=bd&amp;chartState=%7B%22bgpSignalsMinMax%22%3Afalse%2C%22bgpSignalsIpVersionParam%22%3A%22ipv4%22%2C%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Announced IP Address Space\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;p&gt;Ahead of this nationwide shutdown, we observed outages across several Bangladeshi network providers, perhaps foreshadowing what was to come. At &lt;a href=\&quot;https://radar.cloudflare.com/as24389\&quot;&gt;&lt;u&gt;AS24389 (Grameenphone)&lt;/u&gt;&lt;/a&gt;, a complete Internet outage started at 01:30 local time on July 18 (19:30 UTC on July 17), with a total loss of both &lt;a href=\&quot;https://radar.cloudflare.com/traffic/as24389?dateStart=2024-07-14&amp;dateEnd=2024-07-29\&quot;&gt;&lt;u&gt;Internet traffic&lt;/u&gt;&lt;/a&gt; and &lt;a href=\&quot;https://radar.cloudflare.com/routing/as24389?dateStart=2024-07-14&amp;dateEnd=2024-07-29\&quot;&gt;&lt;u&gt;announced IP address space&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-07-16&amp;dateEnd=2024-07-29&amp;location=as24389&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;p&gt;The outage at &lt;a href=\&quot;https://radar.cloudflare.com/as45245\&quot;&gt;&lt;u&gt;AS25245 (Banglalink)&lt;/u&gt;&lt;/a&gt; started at 02:15 local time on July 18 (20:15 UTC on July 17) as both &lt;a href=\&quot;https://radar.cloudflare.com/traffic/as45245?dateStart=2024-07-14&amp;dateEnd=2024-07-29\&quot;&gt;&lt;u&gt;Internet traffic&lt;/u&gt;&lt;/a&gt; and &lt;a href=\&quot;https://radar.cloudflare.com/routing/as45245?dateStart=2024-07-14&amp;dateEnd=2024-07-29\&quot;&gt;&lt;u&gt;announced IP address space&lt;/u&gt;&lt;/a&gt; dropped to zero.&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-07-17&amp;dateEnd=2024-07-31&amp;location=as45245&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;p&gt;At &lt;a href=\&quot;https://radar.cloudflare.com/as24432\&quot;&gt;&lt;u&gt;AS24432 (Robi Axiata)&lt;/u&gt;&lt;/a&gt;, an Internet outage was observed starting around 06:30 local time on July 18 (00:30 UTC), with both &lt;a href=\&quot;https://radar.cloudflare.com/traffic/as24432?dateStart=2024-07-14&amp;dateEnd=2024-07-29\&quot;&gt;&lt;u&gt;Internet traffic&lt;/u&gt;&lt;/a&gt; and &lt;a href=\&quot;https://radar.cloudflare.com/routing/as24432?dateStart=2024-07-14&amp;dateEnd=2024-07-29\&quot;&gt;&lt;u&gt;announced IP address space&lt;/u&gt;&lt;/a&gt; disappearing at that time.&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-07-16&amp;dateEnd=2024-07-29&amp;location=as24432&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;p&gt;&lt;a href=\&quot;https://radar.cloudflare.com/traffic/as58715?dateStart=2024-07-14&amp;dateEnd=2024-07-29\&quot;&gt;&lt;u&gt;Internet traffic&lt;/u&gt;&lt;/a&gt; at &lt;a href=\&quot;https://radar.cloudflare.com/as58715\&quot;&gt;&lt;u&gt;AS58715 (Earth Telecommunication)&lt;/u&gt;&lt;/a&gt; began to fall at 18:00 local time on July 18 (12:00 UTC), reaching zero four hours later. &lt;a href=\&quot;https://radar.cloudflare.com/routing/as58715?dateStart=2024-07-14&amp;dateEnd=2024-07-29\&quot;&gt;&lt;u&gt;Announced IP address space&lt;/u&gt;&lt;/a&gt; began to fall at 21:00 local time (15:00 UTC), and was completely gone by 21:25 local time (15:25 UTC).&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-07-16&amp;dateEnd=2024-07-29&amp;location=as58715&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;p&gt;&lt;a href=\&quot;https://radar.cloudflare.com/as63526\&quot;&gt;&lt;u&gt;AS63526 (Carnival Internet)&lt;/u&gt;&lt;/a&gt; was one of the last to fall before the complete shutdown, &lt;a href=\&quot;https://radar.cloudflare.com/traffic/as63526?dateStart=2024-07-14&amp;dateEnd=2024-07-29\&quot;&gt;&lt;u&gt;losing traffic&lt;/u&gt;&lt;/a&gt; at 20:45 local time (14:45 UTC), and seeing all of its &lt;a href=\&quot;https://radar.cloudflare.com/routing/as63526?dateStart=2024-07-14&amp;dateEnd=2024-07-29\&quot;&gt;&lt;u&gt;announced IP address space&lt;/u&gt;&lt;/a&gt; withdrawn over the following hour.&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-07-16&amp;dateEnd=2024-07-29&amp;location=as63526&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;p&gt;These mobile connectivity outages lasted from July 18 through July 28. Just a few days after connectivity was restored, &lt;a href=\&quot;https://www.business-standard.com/world-news/bangladesh-protests-internet-shutdown-curfew-imposed-97-dead-in-clashes-124080500205_1.html\&quot;&gt;&lt;u&gt;additional clashes between police and protestors&lt;/u&gt;&lt;/a&gt; drove the government to &lt;a href=\&quot;https://developingtelecoms.com/telecom-business/telecom-regulation/17105-bangladesh-switches-off-mobile-internet-again-as-protests-escalate-2.html\&quot;&gt;&lt;u&gt;order mobile Internet connectivity to be shut down&lt;/u&gt;&lt;/a&gt; again. As shown in the graphs below, traffic on these mobile network providers dropped between 13:30 and 14:15 local time (07:30 to 08:15 UTC) on Sunday, August 4.&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-03&amp;dateEnd=2024-08-06&amp;location=as24389&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-03&amp;dateEnd=2024-08-06&amp;location=as45245&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-03&amp;dateEnd=2024-08-06&amp;location=as24432&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-03&amp;dateEnd=2024-08-06&amp;location=as45925&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-03&amp;dateEnd=2024-08-06&amp;location=as45925&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;p&gt;These protests ultimately led the government to order a full Internet shutdown in the country, with both traffic and announced IP address space dropping precipitously around 10:30 local time (04:30 UTC) on Monday, August 5. However, the shutdown appeared to be short-lived, as &lt;a href=\&quot;https://en.prothomalo.com/bangladesh/gm0o97gu3x\&quot;&gt;&lt;u&gt;broadband connectivity&lt;/u&gt;&lt;/a&gt; began to recover around 13:20 local time (07:20 UTC), with &lt;a href=\&quot;https://en.prothomalo.com/bangladesh/aoczyp8xg8\&quot;&gt;&lt;u&gt;mobile connectivity&lt;/u&gt;&lt;/a&gt; being restored around 14:00 local time (08:00 UTC).&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-05&amp;dateEnd=2024-08-05&amp;location=bd&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/BgpRoutesTimeseriesXY?dateStart=2024-08-05&amp;dateEnd=2024-08-05&amp;location=bd&amp;chartState=%7B%22bgpSignalsMinMax%22%3Afalse%2C%22bgpSignalsIpVersionParam%22%3A%22ipv4%22%2C%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Announced IP Address Space\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;iraqi-kurdistan\&quot;&gt;Iraqi Kurdistan&lt;/h3&gt;\n            &lt;a href=\&quot;#iraqi-kurdistan\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Both &lt;a href=\&quot;https://radar.cloudflare.com/iq\&quot;&gt;&lt;u&gt;Iraq&lt;/u&gt;&lt;/a&gt; and Iraqi Kurdistan (the autonomous Kurdistan region in the northern part of the country) regularly implement government directed Internet shutdowns to prevent cheating on secondary and baccalaureate exams. Within Iraqi Kurdistan, we observed two sets of exam-related Internet shutdowns during the third quarter. The impacts of the shutdowns are visible on traffic from networks that operate within the region, as well as on the country-level graphs for Iraq.&lt;/p&gt;&lt;p&gt;The first round of shutdowns occurred in July, impacting &lt;a href=\&quot;https://radar.cloudflare.com/as59625\&quot;&gt;&lt;u&gt;AS59625 (KorekTel)&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as21277\&quot;&gt;&lt;u&gt;AS21277 (Newroz Telecom)&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as48492\&quot;&gt;&lt;u&gt;AS48492 (IQ Online)&lt;/u&gt;&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/as206206\&quot;&gt;&lt;u&gt;AS206206 (KNET)&lt;/u&gt;&lt;/a&gt; between 06:00 - 08:00 local time (03:00 - 05:00 UTC) on July 3, 7, 10, and 14. This is consistent with shutdowns observed in the &lt;a href=\&quot;https://blog.cloudflare.com/q2-2024-internet-disruption-summary/\&quot;&gt;&lt;u&gt;second quarter&lt;/u&gt;&lt;/a&gt;, as well as in &lt;a href=\&quot;https://blog.cloudflare.com/exam-internet-shutdowns-iraq-algeria/\&quot;&gt;&lt;u&gt;June 2023&lt;/u&gt;&lt;/a&gt;. None of the impacted networks experienced a drop in announced IP address space during these shutdowns.&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-07-03&amp;dateEnd=2024-07-14&amp;location=iq&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-07-03&amp;dateEnd=2024-07-14&amp;location=as59625&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-07-03&amp;dateEnd=2024-07-14&amp;location=as21277&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-07-03&amp;dateEnd=2024-07-14&amp;location=as48492&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-07-03&amp;dateEnd=2024-07-14&amp;location=as206206&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;p&gt;The second set of shutdowns in Iraqi Kurdistan took place across multiple days during the back half of August. On August 17, 19, 21, 24, 26, 28, and 31, all four network providers were again impacted, as seen in the graphs below, with traffic dropping between 06:00 - 08:00 local time (03:00 - 05:00 UTC).&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-17&amp;dateEnd=2024-08-31&amp;location=iq&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-17&amp;dateEnd=2024-08-31&amp;location=as21277&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-17&amp;dateEnd=2024-08-31&amp;location=as48492&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-17&amp;dateEnd=2024-08-31&amp;location=as206206&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;iraq\&quot;&gt;Iraq&lt;/h3&gt;\n            &lt;a href=\&quot;#iraq\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;In &lt;a href=\&quot;https://radar.cloudflare.com/iq\&quot;&gt;&lt;u&gt;Iraq&lt;/u&gt;&lt;/a&gt;, a second round of exams for 12th graders resulted in over two weeks of regular Internet shutdowns across the country occurring between 06:00 - 08:00 local time (03:00 - 05:00 UTC) on multiple days between August 29 and September 16, intended to prevent cheating on &lt;a href=\&quot;https://www.facebook.com/Iraq.Ministry.of.Education/posts/pfbid08kbeG2VEaFPweRiH1ofDdRazpVFKnHA2tRXM6pjQgCsQUXmuCar3oDSVsaCnwUZil\&quot;&gt;&lt;u&gt;second ministerial exams for secondary education&lt;/u&gt;&lt;/a&gt;. Both HTTP traffic and announced IP address space from Iraq dropped during these shutdowns, as seen in the graphs below.&lt;/p&gt;&lt;p&gt;(Note that the red annotation bar visible on September 11 &amp;amp; 12 on both the country and network-level graphs below highlights an internal data pipeline issue, and is not associated with an Internet shutdown in Iraq.)&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-29&amp;dateEnd=2024-09-16&amp;location=iq&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/BgpRoutesTimeseriesXY?dateStart=2024-08-29&amp;dateEnd=2024-09-16&amp;location=iq&amp;chartState=%7B%22bgpSignalsMinMax%22%3Afalse%2C%22bgpSignalsIpVersionParam%22%3A%22ipv4%22%2C%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Announced IP Address Space\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;p&gt;This round of government-directed shutdowns impacted multiple local network providers, including &lt;a href=\&quot;https://radar.cloudflare.com/as58322\&quot;&gt;&lt;u&gt;AS58322 (Halasat)&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as51684\&quot;&gt;&lt;u&gt;AS51684 (AsiaCell)&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as203214\&quot;&gt;&lt;u&gt;AS203214 (HulumTele)&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as199739\&quot;&gt;&lt;u&gt;AS199739 (Earthlink)&lt;/u&gt;&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/as59588\&quot;&gt;&lt;u&gt;AS59588 (ZAINAS)&lt;/u&gt;&lt;/a&gt;. In reviewing the distribution of mobile device and desktop traffic at a network level, gaps were observed during the shutdowns on &lt;a href=\&quot;https://radar.cloudflare.com/traffic/as58322?dateStart=2024-08-28&amp;dateEnd=2024-09-17#mobile-vs-desktop\&quot;&gt;&lt;u&gt;AS58322&lt;/u&gt;&lt;/a&gt; and &lt;a href=\&quot;https://radar.cloudflare.com/traffic/as199739?dateStart=2024-08-28&amp;dateEnd=2024-09-17#mobile-vs-desktop\&quot;&gt;&lt;u&gt;AS199739&lt;/u&gt;&lt;/a&gt;, and to a lesser extent, &lt;a href=\&quot;https://radar.cloudflare.com/traffic/as203214?dateStart=2024-08-28&amp;dateEnd=2024-09-17#mobile-vs-desktop\&quot;&gt;&lt;u&gt;AS203214&lt;/u&gt;&lt;/a&gt;, suggesting that these networks were completely offline, while AS56184 and AS59588 remained at least partially online. (This is also corroborated by complete or partial loss of announced IP address space across these networks during the shutdowns.)&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-29&amp;dateEnd=2024-09-16&amp;location=as58322&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-29&amp;dateEnd=2024-09-16&amp;location=as51684&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-29&amp;dateEnd=2024-09-16&amp;location=as203214&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-29&amp;dateEnd=2024-09-16&amp;location=as199739&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-29&amp;dateEnd=2024-09-16&amp;location=as59588&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;syria\&quot;&gt;Syria&lt;/h3&gt;\n            &lt;a href=\&quot;#syria\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;A first round of exam-related Internet shutdowns took place in &lt;a href=\&quot;https://radar.cloudflare.com/sy\&quot;&gt;&lt;u&gt;Syria&lt;/u&gt;&lt;/a&gt; earlier this year, between May 26 and June 13, and were discussed in our &lt;a href=\&quot;https://blog.cloudflare.com/syria-iraq-algeria-exam-internet-shutdown\&quot;&gt;&lt;u&gt;Exam-ining recent Internet shutdowns in Syria, Iraq, and Algeria&lt;/u&gt;&lt;/a&gt; blog post. A second set of exams, and the associated Internet shutdowns requested by the Ministry of Education, began on July 25 and ran through August 8, as specified in the schedule &lt;a href=\&quot;https://www.facebook.com/photo/?fbid=862569062570288&amp;set=a.449047400589125\&quot;&gt;&lt;u&gt;published by Syrian Telecom on its Facebook page&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The length of the shutdowns varied by day — they all began at 07:00 local time (04:00 UTC), but the end times ranged between 09:45 -10:30 local time (06:45 - 07:30 UTC). The graphs below show the impact at a country level, as well as to &lt;a href=\&quot;https://radar.cloudflare.com/as29256\&quot;&gt;&lt;u&gt;AS29256 (Syrian Telecom)&lt;/u&gt;&lt;/a&gt;, the &lt;a href=\&quot;https://radar.cloudflare.com/routing/sy\&quot;&gt;&lt;u&gt;primary telecommunications provider within the country&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;These shutdowns were also covered in our August 1 blog post, &lt;a href=\&quot;https://blog.cloudflare.com/a-recent-spate-of-internet-disruptions-july-2024/\&quot;&gt;&lt;i&gt;&lt;u&gt;A recent spate of Internet disruptions&lt;/u&gt;&lt;/i&gt;&lt;/a&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-07-25&amp;dateEnd=2024-08-08&amp;location=sy&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/BgpRoutesTimeseriesXY?dateStart=2024-07-25&amp;dateEnd=2024-08-08&amp;location=sy&amp;chartState=%7B%22bgpSignalsMinMax%22%3Afalse%2C%22bgpSignalsIpVersionParam%22%3A%22ipv4%22%2C%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Announced IP Address Space\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-07-25&amp;dateEnd=2024-08-08&amp;location=as29256&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;mauritania\&quot;&gt;Mauritania&lt;/h3&gt;\n            &lt;a href=\&quot;#mauritania\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;On August 12, a round of &lt;a href=\&quot;https://ami.mr/fr/archives/251895\&quot;&gt;&lt;u&gt;baccalaureate exams began&lt;/u&gt;&lt;/a&gt; in &lt;a href=\&quot;https://radar.cloudflare.com/mr\&quot;&gt;&lt;u&gt;Mauritania&lt;/u&gt;&lt;/a&gt;, and in an effort to &lt;a href=\&quot;https://akhbarwatan.net/%D9%85%D9%88%D8%B1%D9%8A%D8%AA%D8%A7%D9%86%D9%8A%D8%A7-%D9%82%D8%B7%D8%B9-%D8%A7%D9%84%D8%A5%D9%86%D8%AA%D8%B1%D9%86%D8%AA-%D8%A8%D8%B3%D8%A8%D8%A8-%D8%A7%D9%84%D9%85%D8%B3%D8%A7%D8%A8%D9%82%D8%A7/\&quot;&gt;&lt;u&gt;prevent student cheating on the exams&lt;/u&gt;&lt;/a&gt;, the government instituted multiple Internet shutdowns that impacted several major mobile providers. Two shutdowns were observed on August 12, between 08:00 - 12:00 local time (08:00 - 12:00 UTC) and between 15:00 - 19:00 local time (15:00 - 19:00 UTC), and an additional one was observed on August 13, between 08:00 - 12:30 local time (08:00 - 12:30 UTC). Impacted network providers included &lt;a href=\&quot;https://radar.cloudflare.com/as37508\&quot;&gt;&lt;u&gt;AS37508 (Mattel)&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as37541\&quot;&gt;&lt;u&gt;AS37541 (Chinguitel)&lt;/u&gt;&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/as29544\&quot;&gt;&lt;u&gt;AS29544 (Mauritel)&lt;/u&gt;&lt;/a&gt;. Announced IP address space for these networks remained unchanged during the shutdown periods, suggesting that that mobile subscriber connectivity was disabled, as opposed to the networks effectively being disconnected from the Internet, as we have seen in other countries.&lt;/p&gt;&lt;p&gt;Exam-related Internet shutdowns are, unfortunately, not new to Mauritania, as authorities in the country also implemented them &lt;a href=\&quot;https://smex.org/mauritania-the-drawbacks-of-disrupting-mobile-internet-after-prisoners-escape/\&quot;&gt;&lt;u&gt;between 2017 and 2020&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-12&amp;dateEnd=2024-08-13&amp;location=as37508&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-12&amp;dateEnd=2024-08-13&amp;location=as37541&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-12&amp;dateEnd=2024-08-13&amp;location=as29544&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;cable-cuts\&quot;&gt;Cable cuts&lt;/h2&gt;\n            &lt;a href=\&quot;#cable-cuts\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          \n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;eswatini-swaziland\&quot;&gt;Eswatini (Swaziland)&lt;/h3&gt;\n            &lt;a href=\&quot;#eswatini-swaziland\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;On July 14, MTN Eswatini (AS327765) informed customers via &lt;a href=\&quot;https://x.com/MTNEswatini/status/1812558000009163027\&quot;&gt;&lt;u&gt;a post on X&lt;/u&gt;&lt;/a&gt; that “&lt;i&gt;connection to the internet and data services is currently intermittent, because of fiber cable breaks resulting from wildfires.&lt;/i&gt;” This apparent connection disruption was visible in Cloudflare Radar between 19:30 and 20:15 local time (17:30 and 18:15 UTC).&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-07-14&amp;dateEnd=2024-07-14&amp;location=as327765&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;cameroon\&quot;&gt;Cameroon&lt;/h3&gt;\n            &lt;a href=\&quot;#cameroon\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;In &lt;a href=\&quot;https://radar.cloudflare.com/cm\&quot;&gt;&lt;u&gt;Cameroon&lt;/u&gt;&lt;/a&gt;, a fiber cut that occurred on August 4 during sanitation work disrupted mobile connectivity for Cameroon Telecommunications (&lt;a href=\&quot;https://radar.cloudflare.com/as15964\&quot;&gt;&lt;u&gt;AS15964 (Camtel)&lt;/u&gt;&lt;/a&gt;) customers for over half a day. According to a (translated) &lt;a href=\&quot;https://x.com/Camtelonline/status/1820133286058062079\&quot;&gt;&lt;u&gt;post on X from Camtel&lt;/u&gt;&lt;/a&gt;, “&lt;i&gt;We inform you that due to the sanitation work carried out in the city of Yaoundé, at the place called Cradat, our Voice and Data services have been temporarily interrupted on the entire mobile network.&lt;/i&gt;” The observed disruption occurred between 03:00 - 16:30 local time (02:00 - 15:30 UTC). Although it initially started during a time when traffic was lower overnight anyway, both &lt;a href=\&quot;https://radar.cloudflare.com/explorer?dataSet=http&amp;loc=as15964&amp;dt=2024-08-04_2024-08-04&amp;timeCompare=2024-07-28\&quot;&gt;&lt;u&gt;request&lt;/u&gt;&lt;/a&gt; and &lt;a href=\&quot;https://radar.cloudflare.com/explorer?dataSet=netflows&amp;loc=as15964&amp;dt=2024-08-04_2024-08-04&amp;timeCompare=2024-07-28\&quot;&gt;&lt;u&gt;bytes&lt;/u&gt;&lt;/a&gt; traffic remained lower than the same time a week prior during the duration of the disruption.&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-04&amp;dateEnd=2024-08-04&amp;location=as15964&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;liberia\&quot;&gt;Liberia&lt;/h3&gt;\n            &lt;a href=\&quot;#liberia\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;The &lt;a href=\&quot;https://radar.cloudflare.com/lr\&quot;&gt;&lt;u&gt;Liberia&lt;/u&gt;&lt;/a&gt; Telecommunications Authority &lt;a href=\&quot;https://www.facebook.com/TelecommunicationsAuthorityLIBERA/posts/pfbid0Ryktd7oPg1c8UYc1kAiDWo8aQPK3uUADDkuUYgSdeZtC2tYn4JiCYr66oZQoRBc2l\&quot;&gt;&lt;u&gt;posted an announcement to their Facebook page&lt;/u&gt;&lt;/a&gt; on August 21 noting that “&lt;i&gt;We have been informed by the CCL that the ACE Cable is experiencing interruptions.&lt;/i&gt;” (The &lt;a href=\&quot;https://ace-submarinecable.com/en/submarine-cable/\&quot;&gt;&lt;u&gt;Africa Coast to Europe (ACE) submarine cable&lt;/u&gt;&lt;/a&gt; connects multiple countries along the West Coast of Africa to Portugal and Europe.) The announcement further noted that the first signs of interruption occurred at 01:00 local time (and UTC), and that &lt;a href=\&quot;https://radar.cloudflare.com/as37410\&quot;&gt;&lt;u&gt;Lonestar Cell MTN (AS37410)&lt;/u&gt;&lt;/a&gt; was among the providers that had been “gravely affected” by the cut.&lt;/p&gt;&lt;p&gt;We observed traffic on Lonestar Cell MTN dropping just after 01:00, in line with the announcement. The network experienced a complete outage lasting over a day and a half, before traffic started to recover at 14:00 local time (and UTC) on August 22. In a &lt;a href=\&quot;https://www.facebook.com/LonestarCellMTN/posts/pfbid02xE2qxVEt1XnCHgqftjkj34KQssez13PoGTjSGoBAH688g6m4G7XCLHM58SLBCW8Ll\&quot;&gt;&lt;u&gt;Facebook post&lt;/u&gt;&lt;/a&gt; on August 22, Lonestar Cell MTN confirmed that Internet service had been restored, and that customer accounts would be credited with 500 MB of data for free.&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-20&amp;dateEnd=2024-08-22&amp;location=as37410&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;niger\&quot;&gt;Niger&lt;/h3&gt;\n            &lt;a href=\&quot;#niger\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;A September 7 &lt;a href=\&quot;https://x.com/airtelniger/status/1832430266222096571\&quot;&gt;&lt;u&gt;post on X from Airtel Niger&lt;/u&gt;&lt;/a&gt; alerted customers to Internet service disruptions caused by cuts on international fiber optic cables. As a land-locked country, &lt;a href=\&quot;https://radar.cloudflare.com/ne\&quot;&gt;&lt;u&gt;Niger&lt;/u&gt;&lt;/a&gt; is dependent on terrestrial connections to networks in neighboring countries, but it isn’t clear which connection or country Airtel Niger’s post was referencing.&lt;/p&gt;&lt;p&gt;Two significant Internet disruptions were observed around the time of Airtel Niger’s post that we believe are related to the referenced fiber cuts. The first occurred between 18:00 - 21:00 local time (17:00 - 20:00 UTC) on September 6, visible at a country level and at a network level as well on &lt;a href=\&quot;https://radar.cloudflare.com/as37531\&quot;&gt;&lt;u&gt;AS37531 (Airtel Niger)&lt;/u&gt;&lt;/a&gt; and &lt;a href=\&quot;https://radar.cloudflare.com/as37233\&quot;&gt;&lt;u&gt;AS37233 (Orange Niger / Zamani Telecom)&lt;/u&gt;&lt;/a&gt;. The second disruption occurred between 10:45 - 12:00 local time (09:45 - 11:00 UTC) on September 7, visible at a country level as well as on those two networks. &lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-09-06&amp;dateEnd=2024-09-07&amp;location=ne&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-09-06&amp;dateEnd=2024-09-07&amp;location=as37531&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-09-06&amp;dateEnd=2024-09-07&amp;location=as37233&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;haiti\&quot;&gt;Haiti&lt;/h3&gt;\n            &lt;a href=\&quot;#haiti\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Internet disruptions related to submarine cable failures often take a significant amount of time to resolve because of the challenges repair crews face in getting to, and accessing, the damaged portion of the cable, as it is frequently located deep underwater in the middle of an ocean. A September 14 submarine cable failure that impacted &lt;a href=\&quot;https://radar.cloudflare.com/as27653\&quot;&gt;&lt;u&gt;Digicel Haiti (AS27653)&lt;/u&gt;&lt;/a&gt; lasted for over a week for a similar, but slightly different, reason.&lt;/p&gt;&lt;p&gt;A significant loss of traffic on Digicel Haiti was first observed at 08:00 local time (12:00 UTC) on September 14. On September 16, Digicel Haiti &lt;a href=\&quot;https://x.com/DigicelHT/status/1835774732743876713/photo/1\&quot;&gt;&lt;u&gt;posted a press release&lt;/u&gt;&lt;/a&gt; confirming that since September 14, a failure had been detected on an international submarine cable belonging to Cable and Wireless, and that the cable damage occurred at Kaliko Beach Club (the property is &lt;a href=\&quot;https://www.haitilibre.com/en/news-43221-haiti-digicel-failure-detected-on-an-international-submarine-cable-against-a-backdrop-of-litigation.html\&quot;&gt;&lt;u&gt;reportedly&lt;/u&gt;&lt;/a&gt; used as a cable entry point). Digicel noted that their technicians went to the scene of the damage immediately, but were denied access, apparently because of a business dispute dating back to 2021. The release also explained that technical teams had taken temporary steps to ensure the continuity of essential services, which prevented the incident from resulting in a complete loss of connectivity. On September 22, a subsequent &lt;a href=\&quot;https://x.com/DigicelHT/status/1837875515148898513/photo/1\&quot;&gt;&lt;u&gt;press release&lt;/u&gt;&lt;/a&gt; posted by Digicel Haiti announced the restoration of Internet services as of 02:00 local time (06:00 UTC), and referenced vandalism as the cause of the cable damage.&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-09-14&amp;dateEnd=2024-09-22&amp;location=as27653&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;kyrgyzstan\&quot;&gt;Kyrgyzstan&lt;/h3&gt;\n            &lt;a href=\&quot;#kyrgyzstan\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Reported damage to the “&lt;a href=\&quot;https://akipress.com/news:797695:Internet_disruptions_in_Kyrgyzstan_caused_by_damage_of_main_communication_channel/\&quot;&gt;&lt;u&gt;backbone wire&lt;/u&gt;&lt;/a&gt;” or “&lt;a href=\&quot;https://economist-kg.translate.goog/novosti/2024/09/25/akniet-obiasnil-prichinu-probliem-s-dostupom-k-intiernietu-v-bishkiekie-i-chuiskoi-oblasti/?_x_tr_sl=auto&amp;_x_tr_tl=en&amp;_x_tr_hl=en&amp;_x_tr_pto=wapp\&quot;&gt;&lt;u&gt;main cable&lt;/u&gt;&lt;/a&gt;” of an &lt;a href=\&quot;https://kaktus-media.translate.goog/doc/510016_propal_internet_y_nekotoryh_sotovyh_operatorov_i_provayderov._pochemy.html?_x_tr_sl=auto&amp;_x_tr_tl=en&amp;_x_tr_hl=en&amp;_x_tr_pto=wapp\&quot;&gt;&lt;u&gt;upstream provider&lt;/u&gt;&lt;/a&gt; resulted in a brief Internet outage for &lt;a href=\&quot;https://radar.cloudflare.com/kg\&quot;&gt;&lt;u&gt;Kyrgyzstan&lt;/u&gt;&lt;/a&gt; Internet provider &lt;a href=\&quot;https://radar.cloudflare.com/as50223\&quot;&gt;&lt;u&gt;Megacom (AS50223)&lt;/u&gt;&lt;/a&gt; of September 25. &lt;a href=\&quot;https://radar.cloudflare.com/as12389\&quot;&gt;&lt;u&gt;AS12389 (Rostelecom)&lt;/u&gt;&lt;/a&gt; is &lt;a href=\&quot;https://radar.cloudflare.com/routing/as50223\&quot;&gt;&lt;u&gt;listed&lt;/u&gt;&lt;/a&gt; as Megacom’s only upstream provider.&lt;/p&gt;&lt;p&gt;The outage lasted for only an hour, between 15:45 and 16:45 local time (09:45 - 10:45 UTC), dropping both traffic and announced IP address space to zero. At a country level, traffic dropped as much as 72% as compared to the previous week. Given the complete loss of both traffic and IP address space, the damage likely occurred on the connection between Megacom and Rostelecom.&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-09-25&amp;dateEnd=2024-09-25&amp;location=as50223&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/BgpRoutesTimeseriesXY?dateStart=2024-09-25&amp;dateEnd=2024-09-25&amp;location=as50223&amp;chartState=%7B%22bgpSignalsMinMax%22%3Afalse%2C%22bgpSignalsIpVersionParam%22%3A%22ipv4%22%2C%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Announced IP Address Space\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-09-25&amp;dateEnd=2024-09-25&amp;location=kg&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;severe-weather\&quot;&gt;Severe weather&lt;/h2&gt;\n            &lt;a href=\&quot;#severe-weather\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;An active hurricane season during July, August, and September resulted in infrastructure damage caused by multiple hurricanes disrupting Internet connectivity in multiple places across the Caribbean and Southeastern United States.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;grenada-saint-vincent-and-the-grenadines\&quot;&gt;Grenada &amp;amp; Saint Vincent and the Grenadines&lt;/h3&gt;\n            &lt;a href=\&quot;#grenada-saint-vincent-and-the-grenadines\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;At the start of the third quarter, &lt;a href=\&quot;https://radar.cloudflare.com/gd\&quot;&gt;&lt;u&gt;Grenada&lt;/u&gt;&lt;/a&gt; and &lt;a href=\&quot;https://radar.cloudflare.com/vc\&quot;&gt;&lt;u&gt;Saint Vincent and the Grenadines&lt;/u&gt;&lt;/a&gt; both suffered significant damage from Hurricane Beryl, &lt;a href=\&quot;https://www.usatoday.com/story/news/nation/2024/07/03/hurricane-beryl-destruction-islands/74296817007/\&quot;&gt;&lt;u&gt;reportedly&lt;/u&gt;&lt;/a&gt; causing destruction of infrastructure, buildings, agriculture, and the natural environment.&lt;/p&gt;&lt;p&gt;On July 1, traffic from Grenada dropped significantly at 10:00 local time (14:00 UTC), just ahead of &lt;a href=\&quot;https://www.cnn.com/2024/07/01/weather/hurricane-beryl-caribbean-landfall-monday/index.html\&quot;&gt;&lt;u&gt;landfall&lt;/u&gt;&lt;/a&gt; on Grenada’s Carriacou Island. The most significant impacts to traffic were seen for approximately the first 24 hours, though traffic did not return to expected pre-storm levels until around 10:00 local time (14:00 UTC) on July 5.&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-06-29&amp;dateEnd=2024-07-05&amp;location=gd&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;p&gt;Internet traffic in Saint Vincent and the Grenadines was also disrupted by Hurricane Beryl, also falling at 10:00 local time (14:00 UTC). Similar to Grenada, the most significant impact was seen in the first 24 hours, with consistent gradual recovery seen after that time. However, traffic did not return to expected pre-storm levels until July 11.&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-06-29&amp;dateEnd=2024-07-12&amp;location=vc&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;jamaica\&quot;&gt;Jamaica&lt;/h3&gt;\n            &lt;a href=\&quot;#jamaica\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;As Hurricane Beryl continued across the Caribbean, it &lt;a href=\&quot;https://x.com/weatherchannel/status/1808576720234008765\&quot;&gt;&lt;u&gt;passed Jamaica on July 3&lt;/u&gt;&lt;/a&gt;. The associated damage that it caused impacted Internet connectivity on the island, with traffic dropping significantly around 14:00 local time (19:00 UTC). As the graph below shows, the disruption was preceded by higher than normal traffic volumes, presumably due to residents looking for information about Beryl. The disruption lasted nearly a week, with traffic returning to expected levels on July 10.&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-07-01&amp;dateEnd=2024-07-13&amp;location=jm&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;u-s-virgin-islands\&quot;&gt;U.S. Virgin Islands&lt;/h3&gt;\n            &lt;a href=\&quot;#u-s-virgin-islands\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;The following month, damage from Tropical Storm Ernesto caused &lt;a href=\&quot;https://x.com/VIWAPA/status/1824110275710091527\&quot;&gt;&lt;u&gt;power outages across the U.S. Virgin Islands&lt;/u&gt;&lt;/a&gt;, resulting in disruptions to Internet connectivity. Traffic from the islands dropped precipitously at 22:00 local time on August 13 (02:00 UTC on August 14) and remained lower for over two days, before returning to expected pre-storm levels around 11:00 local time (15:00 UTC) on August 16.&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-11&amp;dateEnd=2024-08-17&amp;location=vi&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;bermuda\&quot;&gt;Bermuda&lt;/h3&gt;\n            &lt;a href=\&quot;#bermuda\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Over the course of the following few days, Ernesto strengthened from a tropical storm into a hurricane, but had weakened by the time it hit &lt;a href=\&quot;https://radar.cloudflare.com/bm\&quot;&gt;&lt;u&gt;Bermuda&lt;/u&gt;&lt;/a&gt; on August 16/17. In this case, damage was &lt;a href=\&quot;https://www.reuters.com/business/environment/hurricane-ernesto-weakens-still-dangerous-it-closes-bermuda-2024-08-17/\&quot;&gt;&lt;u&gt;reportedly&lt;/u&gt;&lt;/a&gt; limited to power outages, downed trees, and flooding, but even this limited damage disrupted Internet connectivity on the island. As the storm made landfall on the island, traffic levels dropped over 80% at 22:00 local time on August 16 (01:00 UTC on August 17). Traffic levels remained depressed for about two and a half days, recovering to expected levels around 09:00 local time (12:00 UTC) on August 19.&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-14&amp;dateEnd=2024-08-20&amp;location=bm&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;nepal\&quot;&gt;Nepal&lt;/h3&gt;\n            &lt;a href=\&quot;#nepal\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;&lt;a href=\&quot;https://www.dw.com/en/nepal-floods-landslides-leave-at-least-151-dead/a-70354640\&quot;&gt;&lt;u&gt;Heavy rains in Nepal&lt;/u&gt;&lt;/a&gt; at the end of September resulted in flooding and landslides across much of the country, which in turn resulted in power outages and Internet disruptions. One such disruption believed to be associated with the impacts of the storm was observed on September 28, when &lt;a href=\&quot;https://radar.cloudflare.com/as23752\&quot;&gt;&lt;u&gt;AS23752 (Nepal Telecom)&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as45650\&quot;&gt;&lt;u&gt;AS45650 (Vianet)&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as139922\&quot;&gt;&lt;u&gt;AS139922 (Dishhome)&lt;/u&gt;&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/as17501\&quot;&gt;&lt;u&gt;AS17501 (Worldlink)&lt;/u&gt;&lt;/a&gt; all saw traffic drop 50 - 70% between 14:15 - 16:00 local time (08:30 - 10:15 UTC).&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-09-28&amp;dateEnd=2024-09-28&amp;location=as23752&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-09-28&amp;dateEnd=2024-09-28&amp;location=as45650&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-09-28&amp;dateEnd=2024-09-28&amp;location=as139922&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-09-28&amp;dateEnd=2024-09-28&amp;location=as17501&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;united-states\&quot;&gt;United States&lt;/h3&gt;\n            &lt;a href=\&quot;#united-states\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;A disruption to traffic from &lt;a href=\&quot;https://radar.cloudflare.com/as11427\&quot;&gt;&lt;u&gt;AS11427 (Charter Communications/Spectrum)&lt;/u&gt;&lt;/a&gt; in Texas that occurred between 12:30 and 19:30 local time on July 9 (17:30 - 00:30 UTC) was caused by “&lt;i&gt;a third-party infrastructure issue caused by the impact of Hurricane Beryl&lt;/i&gt;”, according to a July 9 &lt;a href=\&quot;https://x.com/Ask_Spectrum/status/1810804196112806016\&quot;&gt;&lt;u&gt;post on X&lt;/u&gt;&lt;/a&gt; from the provider. Spectrum &lt;a href=\&quot;https://x.com/Ask_Spectrum/status/1810735748410396680\&quot;&gt;&lt;u&gt;acknowledged the issue&lt;/u&gt;&lt;/a&gt; shortly after it began, and &lt;a href=\&quot;https://x.com/Ask_Spectrum/status/1810851153053118568\&quot;&gt;&lt;u&gt;followed up again&lt;/u&gt;&lt;/a&gt; after service had been restored.&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-07-09&amp;dateEnd=2024-07-10&amp;location=as11427&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;p&gt;Hurricane Helene &lt;a href=\&quot;https://www.wistv.com/2024/10/03/reviewing-hurricane-helenes-destructive-path-through-southeast/\&quot;&gt;&lt;u&gt;made landfall in northern Florida&lt;/u&gt;&lt;/a&gt; as a Category 4 storm late in the evening (local time) on September 26, and over the following hours and days, &lt;a href=\&quot;https://www.usatoday.com/story/graphics/2024/09/29/hurricane-helene-damage-maps/75440587007/\&quot;&gt;&lt;u&gt;continued north&lt;/u&gt;&lt;/a&gt; through Georgia, South Carolina, and North Carolina, and into Tennessee. Even as it weakened, it caused historic flooding and damage to roads, homes, power lines, and telecommunications infrastructure. Below, we review the traffic impacts observed at a state level in three of the most impacted states, as well as exploring the impact at a network level for selected providers. (&lt;a href=\&quot;https://www.kentik.com/blog/author/doug-madory/\&quot;&gt;Doug Madory at Kentik&lt;/a&gt; published an excellent &lt;a href=\&quot;https://www.kentik.com/blog/hurricane-helene-devastates-network-connectivity-in-parts-of-the-south/\&quot;&gt;&lt;u&gt;blog post exploring the impact of Helene&lt;/u&gt;&lt;/a&gt; from the perspective of their data, and the networks referenced below were informed by that post.)&lt;/p&gt;&lt;h4&gt;Georgia&lt;/h4&gt;&lt;p&gt;Helene entered Georgia early morning on Friday, September 27, and by midday (local time), peak traffic was approximately 20% lower than peak levels seen in the days ahead of the storm. (The lower peaks on September 28 &amp;amp; 29 are likely due to it being a weekend.) At a state level, peak traffic remained lower over the following week, with more recovery seen heading into the week of October 6.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3aYsyZNt5qCWqJhgK8yt1g/0f8be9f2ed8c2ab5121caef9b8e079ff/SEVERE_WEATHER_-_UNITED_STATES_-_Helene_-_Georgia.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;900\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;One of the most significantly impacted network providers in Georgia was &lt;a href=\&quot;https://radar.cloudflare.com/as11240?dateStart=2024-09-24&amp;dateEnd=2024-10-07\&quot;&gt;&lt;u&gt;AS11240 (ATC Broadband)&lt;/u&gt;&lt;/a&gt;, which saw traffic start to drop around 22:00 local time on September 26 (02:00 UTC on September 27). Subscribers and customers experienced a near complete outage until around 08:00 local time on September 30 (12:00 UTC), when traffic volumes slowly started to recover. The normal diurnal traffic pattern became more clear in the following days, with peak traffic levels continuing to increase over the next week as well.&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-09-24&amp;dateEnd=2024-10-07&amp;location=as11240&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Afalse%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;p&gt;Other network providers in Georgia that experienced significant impacts include &lt;a href=\&quot;https://radar.cloudflare.com/as400511?dateStart=2024-09-24&amp;dateEnd=2024-10-07\&quot;&gt;&lt;u&gt;AS400511 (Clearwave Fiber)&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as394473?dateStart=2024-09-24&amp;dateEnd=2024-10-07\&quot;&gt;&lt;u&gt;AS394473 (Brantley Telephone Company)&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as40285?dateStart=2024-09-24&amp;dateEnd=2024-10-07\&quot;&gt;&lt;u&gt;AS40285 (Northland Cable Television)&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as15313?dateStart=2024-09-24&amp;dateEnd=2024-10-07\&quot;&gt;&lt;u&gt;AS15313 (Pembroke Telephone Company)&lt;/u&gt;&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/as397118?dateStart=2024-09-24&amp;dateEnd=2024-10-07\&quot;&gt;&lt;u&gt;AS397118 (Glenwood Telephone Company)&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;h4&gt;South Carolina&lt;/h4&gt;&lt;p&gt;The midday traffic peak on September 27 in South Carolina was just 65% of the preceding days, with the peaks remaining lower over the following two weekend days. Traffic remained somewhat lower during the week following Helene, with peak increases becoming more evident the week of October 6.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/40euoNqEw8bwaAqVgmsmaQ/ccf5c7114e26a85f6445ce9eaf21b00c/SEVERE_WEATHER_-_UNITED_STATES_-_Helene_-_South_Carolina.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;900\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;At &lt;a href=\&quot;https://radar.cloudflare.com/as19212?dateStart=2024-09-24&amp;dateEnd=2024-10-07\&quot;&gt;&lt;u&gt;AS19212 (Piedmont Rural Telephone)&lt;/u&gt;&lt;/a&gt; in South Carolina, traffic began to fall rapidly around midnight local time on September 27 (04:00 UTC), reaching a state of near complete outage over the next eight hours. A gradual recovery is visible over the following several days, with a more regular pattern becoming evident on October 1, with rapid growth over the following week, accelerating towards the end of the week.&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-09-24&amp;dateEnd=2024-10-07&amp;location=as19212&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Afalse%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;p&gt;Other network providers in South Carolina, including &lt;a href=\&quot;https://radar.cloudflare.com/as397068?dateStart=2024-09-24&amp;dateEnd=2024-10-07\&quot;&gt;&lt;u&gt;AS397068 (Carolina Connect)&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as10279?dateStart=2024-09-24&amp;dateEnd=2024-10-07\&quot;&gt;&lt;u&gt;AS10279 (West Carolina Communications)&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as20222?dateStart=2024-09-24&amp;dateEnd=2024-10-07\&quot;&gt;&lt;u&gt;AS20222&lt;/u&gt;&lt;/a&gt; &amp;amp; &lt;a href=\&quot;https://radar.cloudflare.com/as21898?dateStart=2024-09-24&amp;dateEnd=2024-10-07\&quot;&gt;&lt;u&gt;AS21898 (TruVista)&lt;/u&gt;&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/as14615?dateStart=2024-09-24&amp;dateEnd=2024-10-07\&quot;&gt;&lt;u&gt;AS14615 (Rock Hill Telephone)&lt;/u&gt;&lt;/a&gt;, also experienced significant disruptions to connectivity in the wake of Helene.&lt;/p&gt;&lt;h4&gt;North Carolina&lt;/h4&gt;&lt;p&gt;Although a drop in traffic is visible in the graph for North Carolina on September 27, it occurs after a midday peak in line with previous days, and the magnitude is not as significant as that seen in South Carolina and Georgia. Traffic peaks over the following week are in line with the week preceding Helene’s arrival, with higher peaks seen the week of October 6.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4ggc01nO3m5J85jNwm5rSF/13af760fe7a839472ae5c14116042f9c/SEVERE_WEATHER_-_UNITED_STATES_-_Helene_-_North_Carolina.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;900\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;North Carolina providers &lt;a href=\&quot;https://radar.cloudflare.com/as53488?dateStart=2024-09-24&amp;dateEnd=2024-10-07\&quot;&gt;&lt;u&gt;AS53488 (Morris Broadband)&lt;/u&gt;&lt;/a&gt; and &lt;a href=\&quot;https://radar.cloudflare.com/as53274?dateStart=2024-09-24&amp;dateEnd=2024-10-07\&quot;&gt;&lt;u&gt;AS53274 (Skyrunner)&lt;/u&gt;&lt;/a&gt; both experienced multi-day disruptions, likely related to damage from Helene. However, these disruptions took Morris Broadband completely offline several times over the course of a week — the announced IP address space graph below shows three distinct drops to zero, aligning with outages visible in the traffic graph, when the network was effectively disconnected from the Internet. A similar but less severe pattern was seen at Skyrunner, which lost 75-80% of announced IP address space for a two-day period covering September 27-29, aligning with an outage visible in the associated traffic graph.&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-09-24&amp;dateEnd=2024-10-07&amp;location=as53488&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Afalse%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/BgpRoutesTimeseriesXY?dateStart=2024-09-24&amp;dateEnd=2024-10-07&amp;location=as53488&amp;chartState=%7B%22bgpSignalsMinMax%22%3Afalse%2C%22bgpSignalsIpVersionParam%22%3A%22ipv4%22%2C%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Announced IP Address Space\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-09-24&amp;dateEnd=2024-10-07&amp;location=as53274&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Afalse%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/BgpRoutesTimeseriesXY?dateStart=2024-09-24&amp;dateEnd=2024-10-07&amp;location=as53274&amp;chartState=%7B%22bgpSignalsMinMax%22%3Afalse%2C%22bgpSignalsIpVersionParam%22%3A%22ipv4%22%2C%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Announced IP Address Space\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;p&gt;Other impacted network providers in North Carolina included &lt;a href=\&quot;https://radar.cloudflare.com/as22191?dateStart=2024-09-24&amp;dateEnd=2024-10-07\&quot;&gt;&lt;u&gt;AS22191 (Wilkes Communications)&lt;/u&gt;&lt;/a&gt; and &lt;a href=\&quot;https://radar.cloudflare.com/as23118?dateStart=2024-09-24&amp;dateEnd=2024-10-07\&quot;&gt;&lt;u&gt;AS23118 (Skyline Telephone)&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;power-outages\&quot;&gt;Power outages&lt;/h2&gt;\n            &lt;a href=\&quot;#power-outages\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          \n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;venezuela\&quot;&gt;Venezuela&lt;/h3&gt;\n            &lt;a href=\&quot;#venezuela\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;A nationwide power outage in &lt;a href=\&quot;https://radar.cloudflare.com/ve\&quot;&gt;&lt;u&gt;Venezuela&lt;/u&gt;&lt;/a&gt; on August 30 was, &lt;a href=\&quot;https://www.reuters.com/business/energy/venezuelas-capital-caracas-other-regions-face-power-outage-2024-08-30/\&quot;&gt;&lt;u&gt;according to President Nicolás Maduro&lt;/u&gt;&lt;/a&gt;, the result of an attack on the Guri Reservoir, Venezuela&amp;#39;s largest hydroelectric project. A &lt;a href=\&quot;https://www.reuters.com/business/energy/venezuelas-capital-caracas-other-regions-face-power-outage-2024-08-30/\&quot;&gt;&lt;u&gt;published report&lt;/u&gt;&lt;/a&gt; indicated that all 24 of the country&amp;#39;s states reported a total or partial loss of electricity supply. The loss of power unsurprisingly caused an Internet disruption, with country-level traffic dropping 82%, starting around 04:45 local time (08:45 UTC). Traffic began to increase as electricity returned to various parts of the country throughout the day, and returned to expected levels just after midnight local time on August 31 (04:00 UTC). &lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-28&amp;dateEnd=2024-09-03&amp;location=ve&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;kenya\&quot;&gt;Kenya&lt;/h3&gt;\n            &lt;a href=\&quot;#kenya\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;On August 30, Kenya Power Care &lt;a href=\&quot;https://www.facebook.com/KenyaPowerLtd/posts/pfbid0krBvZqWT7AfF8HjTPdm9Y84QmmkgfUzPjhtgxZjzEpyVqRLFS6VBt5vR43s5dxiHl\&quot;&gt;&lt;u&gt;posted a Customer Alert on its Facebook page&lt;/u&gt;&lt;/a&gt;, issued at 21:57 local time (18:57 UTC), stating that “&lt;i&gt;We have lost power supply to various parts of the country except North Rift region and sections of Western region.&lt;/i&gt;” Approximately a half hour before that alert, Kenya’s Internet traffic began to drop, falling as much as 61%. Just two hours later, Kenya Power Care &lt;a href=\&quot;https://www.facebook.com/KenyaPowerLtd/posts/pfbid0m4kP2NwdiDPnH4UpWH39QkpLANTWc6SR3bpiHxnwCUdBvwwou7p1skfaWbghRFWml\&quot;&gt;&lt;u&gt;posted a follow up&lt;/u&gt;&lt;/a&gt;, stating “&lt;i&gt;Following the partial outage affecting several parts of the country this evening, we are pleased to report that power supply has now been restored to the entire Western region, as well as parts of Central Rift, South Nyanza, and Nairobi regions.&lt;/i&gt;” However, traffic did not return to expected levels for several more hours, taking until 06:00 local time (03:00 UTC).&lt;/p&gt;&lt;p&gt;A week later, on September 6, Kenya Power Care &lt;a href=\&quot;https://www.facebook.com/KenyaPowerLtd/posts/pfbid02BcJVt9uu1N3mmGzf9mivyXev4FSJVpPZ5ni1VkZC9WSdYyYyk7MCMtignBPzcVnyl\&quot;&gt;&lt;u&gt;posted another similar Customer Alert&lt;/u&gt;&lt;/a&gt;, noting that “&lt;i&gt;We are experiencing a power outage affecting several parts of the country, except sections of North Rift and Western regions.&lt;/i&gt;” This alert was issued at 09:20 local time (06:20 UTC), and follows a drop in Internet traffic that started around 09:00 local time (06:00 UTC). Traffic dropped approximately 45% during this power outage, and returned to expected levels around 16:00 local time (13:00 UTC). Traffic recovery aligns with a &lt;a href=\&quot;https://www.facebook.com/KenyaPowerLtd/posts/pfbid02VzrAMQeuTrmfyywXeB7qXFyAmeM1eEQCBX6dvY3DHbyfUoTjgTJATcg9cToBk7zal\&quot;&gt;&lt;u&gt;subsequent Customer Alert posted on Facebook&lt;/u&gt;&lt;/a&gt;, where Kenya Power Care stated “&lt;i&gt;We are glad to report that normal electricity supply was restored across the country as at 3:49pm”.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;A statement from Energy and Petroleum Cabinet Secretary Opiyo Wandayi, &lt;a href=\&quot;https://www.facebook.com/KenyaPowerLtd/posts/pfbid02Nck9kx6NFmvFRdLEpzPxk1UPW3HtNw41PHNhHd3PMR2Y73BpkMALZmNU3mkar8DPl\&quot;&gt;&lt;u&gt;shared on Facebook by Kenya Power Care&lt;/u&gt;&lt;/a&gt;, explained the cause of the power outage: “&lt;i&gt;Today, Friday 6th September 2024 at 8.56 am, the 220kV High Voltage Loiyangalani transmission line tripped at Suswa substation while evacuating 288MW from Lake Turkana Wind Power (LTWP) plant. This was followed by a trip on the Ethiopia – Kenya 500kV DC interconnector that was then carrying 200MW, resulting to a total loss of 488MW…&lt;/i&gt;” &lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-30&amp;dateEnd=2024-09-07&amp;location=ke&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;ecuador\&quot;&gt;Ecuador&lt;/h3&gt;\n            &lt;a href=\&quot;#ecuador\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;According to a (translated) September 7 &lt;a href=\&quot;https://x.com/OperadorCenace/status/1832431918563872871\&quot;&gt;&lt;u&gt;post on X from CENACE&lt;/u&gt;&lt;/a&gt;, the national electricity operator in &lt;a href=\&quot;https://radar.cloudflare.com/ec\&quot;&gt;&lt;u&gt;Ecuador&lt;/u&gt;&lt;/a&gt;, “&lt;i&gt;We inform the public that due to a fault in the Molino substation bar, which is connected to the Paute generation, there has been a power outage in some provinces of the country. Cenace&amp;#39;s technical team, in coordination with the distribution companies, is working to gradually restore electrical service. It is estimated that it will take 3 to 4 hours maximum for the supply to return to normal.&lt;/i&gt;” The post was published at 09:53 local time (14:53 UTC), approximately an hour after Internet traffic from the country began to drop. Traffic returned to expected levels just under four hours later, at around 12:30 local time (17:30 UTC), in line with CENACE’s predicted time for power to be fully restored.&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-09-04&amp;dateEnd=2024-09-10&amp;location=ec&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;p&gt;On September 18/19, the first of several planned nightly power outages to enable needed grid maintenance in Ecuador disrupted Internet connectivity. Traffic dropped by over 60% as compared to the same time the prior week starting around 21:30 local (02:30 UTC), with the power outages &lt;a href=\&quot;https://www.americaeconomia.com/en/node/288653\&quot;&gt;&lt;u&gt;reportedly&lt;/u&gt;&lt;/a&gt; scheduled for 22:00 - 06:00 local time. Internet traffic recovered to expected levels around 06:00 local time (11:00 UTC) as power was restored. Similar power cuts were &lt;a href=\&quot;https://ec.usembassy.gov/alert-series-of-nationwide-overnight-power-outages-and-curfews/\&quot;&gt;&lt;u&gt;reportedly planned from September 23 to September 27&lt;/u&gt;&lt;/a&gt;, but these power outages did not appear to impact &lt;a href=\&quot;https://radar.cloudflare.com/explorer?dataSet=netflows&amp;loc=ec&amp;dt=2024-09-22_2024-09-28&amp;timeCompare=1\&quot;&gt;&lt;u&gt;traffic levels in Ecuador as compared to the previous week&lt;/u&gt;&lt;/a&gt;. &lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-09-15&amp;dateEnd=2024-09-21&amp;location=ec&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;senegal\&quot;&gt;Senegal&lt;/h3&gt;\n            &lt;a href=\&quot;#senegal\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;&lt;a href=\&quot;https://radar.cloudflare.com/sn\&quot;&gt;&lt;u&gt;Senegal’s&lt;/u&gt;&lt;/a&gt; power company, Senelec, &lt;a href=\&quot;https://x.com/Senelecofficiel/status/1834245424787394629\&quot;&gt;&lt;u&gt;posted a communiqué on X&lt;/u&gt;&lt;/a&gt; on September 12 that stated (translated) “&lt;i&gt;Senelec informs its valued customers that an incident that occurred this morning at the Hann substation resulted in the loss of the OMVS interconnected network and disruptions to electricity distribution.&lt;/i&gt;” This disruption to electricity distribution also resulted in a disruption to Internet traffic, which dropped sharply at 13:00 local time (13:00 UTC), falling as much as 80%. Traffic recovered to expected levels by 20:00 local time (20:00 UTC) around the same time that Senelec &lt;a href=\&quot;https://x.com/Senelecofficiel/status/1834320225954922533\&quot;&gt;&lt;u&gt;posted a followup about the incident&lt;/u&gt;&lt;/a&gt; that stated (translated) “&lt;i&gt;Effective restoration of electricity supply in all localities.&lt;/i&gt;”&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-09-12&amp;dateEnd=2024-09-13&amp;location=sn&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;maintenance\&quot;&gt;Maintenance&lt;/h2&gt;\n            &lt;a href=\&quot;#maintenance\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          \n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;syria\&quot;&gt;Syria&lt;/h3&gt;\n            &lt;a href=\&quot;#syria\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;As we discussed above, Internet users in &lt;a href=\&quot;https://radar.cloudflare.com/sy\&quot;&gt;&lt;u&gt;Syria&lt;/u&gt;&lt;/a&gt; were impacted by an exam-related Internet shutdown from 07:00 - 10:15 local time (04:00 - 07:15 UTC) on July 30. However, just an hour after connectivity was restored, another disruption occurred, as seen in both the traffic and announced IP address space graphs below. According to a (translated) &lt;a href=\&quot;https://www.facebook.com/photo?fbid=868145108679350&amp;set=a.449047403922458\&quot;&gt;&lt;u&gt;Facebook post from Syrian Telecom&lt;/u&gt;&lt;/a&gt;, “...&lt;i&gt;during the periodic maintenance of one of the air conditioners in one of the technical halls, an explosion occurred, which caused the internet circuits to be temporarily out of service.&lt;/i&gt;” Traffic remained depressed for approximately eight hours, recovering to expected levels around 19:00 local time (16:00 UTC).&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-07-30&amp;dateEnd=2024-07-30&amp;location=sy&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/BgpRoutesTimeseriesXY?dateStart=2024-07-30&amp;dateEnd=2024-07-30&amp;location=sy&amp;chartState=%7B%22bgpSignalsMinMax%22%3Afalse%2C%22bgpSignalsIpVersionParam%22%3A%22ipv4%22%2C%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Announced IP Address Space\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;cyberattack\&quot;&gt;Cyberattack&lt;/h2&gt;\n            &lt;a href=\&quot;#cyberattack\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          \n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;russia\&quot;&gt;Russia&lt;/h3&gt;\n            &lt;a href=\&quot;#russia\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Roskomnadzor, Russia’s Internet regulate, &lt;a href=\&quot;https://t.me/roskomnadzorro/1897\&quot;&gt;&lt;u&gt;blamed&lt;/u&gt;&lt;/a&gt; a brief disruption in traffic observed in &lt;a href=\&quot;https://radar.cloudflare.com/ru\&quot;&gt;&lt;u&gt;Russia&lt;/u&gt;&lt;/a&gt; and on &lt;a href=\&quot;https://radar.cloudflare.com/as12389\&quot;&gt;&lt;u&gt;AS12389 (Rostelecom)&lt;/u&gt;&lt;/a&gt; on August 21 on a distributed denial-of-service (DDoS) attack that targeted Russian telecommunications operators. The disruption was brief, lasting from around 13:45 until 14:30 Moscow time (10:45 - 11:30 UTC). Roskomnadzor &lt;a href=\&quot;https://www.uawire.org/massive-internet-outage-in-russia-kremlin-s-attempt-to-block-messaging-apps-causes-nationwide-disruption\&quot;&gt;&lt;u&gt;subsequently stated&lt;/u&gt;&lt;/a&gt; &amp;quot;&lt;i&gt;As of 3 PM Moscow time, the attack has been repelled, and services are operating normally.&lt;/i&gt;&amp;quot; The disruption &lt;a href=\&quot;https://www.barrons.com/news/large-scale-outages-hit-telegram-whatsapp-in-russia-3a08695c\&quot;&gt;&lt;u&gt;reportedly&lt;/u&gt;&lt;/a&gt; impacted messaging services Telegram and WhatsApp, &lt;a href=\&quot;https://www.uawire.org/massive-internet-outage-in-russia-kremlin-s-attempt-to-block-messaging-apps-causes-nationwide-disruption\&quot;&gt;&lt;u&gt;as well as&lt;/u&gt;&lt;/a&gt; Wikipedia, Yandex, VKontakte, telecom support services, and mobile banking apps. Some experts &lt;a href=\&quot;https://www.uawire.org/massive-internet-outage-in-russia-kremlin-s-attempt-to-block-messaging-apps-causes-nationwide-disruption\&quot;&gt;&lt;u&gt;questioned the official explanation&lt;/u&gt;&lt;/a&gt;, suggesting instead that the disruption was due to &lt;a href=\&quot;https://therecord.media/russia-blames-websites-apps-outages-on-ddos\&quot;&gt;&lt;u&gt;centralized interference from Roskomnadzor&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-21&amp;dateEnd=2024-08-21&amp;location=ru&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-21&amp;dateEnd=2024-08-21&amp;location=as12389&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;military-action\&quot;&gt;Military action&lt;/h2&gt;\n            &lt;a href=\&quot;#military-action\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          \n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;palestine\&quot;&gt;Palestine&lt;/h3&gt;\n            &lt;a href=\&quot;#palestine\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;We have covered Internet disruptions related to the ongoing conflict in Gaza multiple times since October 2023, both on &lt;a href=\&quot;https://x.com/search?q=gaza%20internet%20(from%3Acloudflareradar)&amp;src=typed_query&amp;f=live\&quot;&gt;&lt;u&gt;Cloudflare Radar’s presence on X&lt;/u&gt;&lt;/a&gt;, and on the Cloudflare blog (&lt;a href=\&quot;https://blog.cloudflare.com/internet-traffic-patterns-in-israel-and-palestine-following-the-october-2023-attacks/\&quot;&gt;&lt;u&gt;1&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://blog.cloudflare.com/q4-2023-internet-disruption-summary/\&quot;&gt;&lt;u&gt;2&lt;/u&gt;&lt;/a&gt;, &lt;a href=\&quot;https://blog.cloudflare.com/q1-2024-internet-disruption-summary/\&quot;&gt;&lt;u&gt;3&lt;/u&gt;&lt;/a&gt;). In many of these cases, Paltel (AS12975) has posted notices on social media regarding service disruptions and outages. On September 8, &lt;a href=\&quot;https://www.facebook.com/paltel.970/posts/pfbid036YptxzF77Rk5U7tVGT5Xh4Yx4897BVoeb4qsZNhGkLh1XxLCTLMzDjp1RLAkBfJHl\&quot;&gt;&lt;u&gt;Paltel posted a message on its Facebook page&lt;/u&gt;&lt;/a&gt;, stating (translated) “&lt;i&gt;We regret to announce the suspension of home internet services in the central and southern areas of the Gaza Strip, due to the ongoing aggression.&lt;/i&gt;”&lt;/p&gt;&lt;p&gt;Within the Gaza, Rafah, Deir al-Balah Governorates, we observed a sharp drop in traffic at 18:00 local time (16:00 UTC). The impact appeared to be most significant in Rafah and Deir al-Balah. Traffic returned to expected levels around 23:00 local time (21:00 UTC), and Paltel &lt;a href=\&quot;https://www.facebook.com/paltel.970/posts/pfbid0hJxQReZimYRnNxbMNeyscVCtwhS2wnA4Us6fucJ4WntFuQeS3BAKqhMWxJJqFzaVl\&quot;&gt;&lt;u&gt;confirmed the service restoration in a subsequent Facebook post&lt;/u&gt;&lt;/a&gt;, stating (translated) “&lt;i&gt;We would like to announce the return of home Internet services in central and southern Gaza Strip to the way it was before it was interrupted hours ago.&lt;/i&gt;”\t&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2QELKmNYaZC5NmvkTDreST/f913dde97df36d81772756d528745980/MILITARY_ACTION_-_PALESTINE_-_Gaza_-_Gaza_Governorate.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;900\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3zALCKZTWs6E62cptuxPjq/cd71ff38103f4574b7d2f6e3c3b66ab6/MILITARY_ACTION_-_PALESTINE_-_Gaza_-_Rafah_Governorate.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;900\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7yvARj41pkM60UhcfNtEEC/4963c76fe2ef45802211ae2b6ebbe5ff/MILITARY_ACTION_-_PALESTINE_-_Gaza_-_Deir_al-Balah_Governorate.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;900\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;lebanon\&quot;&gt;Lebanon&lt;/h3&gt;\n            &lt;a href=\&quot;#lebanon\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;&lt;a href=\&quot;https://www.cnn.com/world/live-news/israel-lebanon-war-hezbollah-09-27-24#cm1lbrhcd001k3b6mxt9ij3lb\&quot;&gt;&lt;u&gt;Israeli airstrikes targeting the Lebanese capital of Beirut&lt;/u&gt;&lt;/a&gt; on September 28 likely knocked local network provider &lt;a href=\&quot;https://radar.cloudflare.com/as42852\&quot;&gt;&lt;u&gt;Solidere (AS42852)&lt;/u&gt;&lt;/a&gt; offline for several hours. The graph below shows a loss of traffic starting around 12:15 local time (10:15 UTC), at the same time a complete loss of announced IP address space occurred. Most of Solidere’s IP address space started to get announced again at 14:45 local time (12:45 UTC), and a slight increase in traffic was seen at that time as well. Traffic levels fully recovered just after 18:00 local time (16:00 UTC), and announced IP address space had stabilized by that time as well. &lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-09-28&amp;dateEnd=2024-09-29&amp;location=as42852&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/BgpRoutesTimeseriesXY?dateStart=2024-09-28&amp;dateEnd=2024-09-29&amp;location=as42852&amp;chartState=%7B%22bgpSignalsMinMax%22%3Afalse%2C%22bgpSignalsIpVersionParam%22%3A%22ipv4%22%2C%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Announced IP Address Space\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;fire\&quot;&gt;Fire&lt;/h2&gt;\n            &lt;a href=\&quot;#fire\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          \n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;algeria\&quot;&gt;Algeria&lt;/h3&gt;\n            &lt;a href=\&quot;#algeria\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;A fire near a data center in Blida Province, &lt;a href=\&quot;https://radar.cloudflare.com/dz\&quot;&gt;&lt;u&gt;Algeria&lt;/u&gt;&lt;/a&gt; disrupted connectivity on AS327931 (Djezzy) at 13:00 and local time (12:00 UTC) on July 24. According to a (translated) &lt;a href=\&quot;https://x.com/djezzy/status/1816272546284855678\&quot;&gt;&lt;u&gt;X post from Djezzy&lt;/u&gt;&lt;/a&gt;, “&lt;i&gt;Djezzy announced fluctuations in its services in some areas of the country, as it was a victim of a fire that broke out on Wednesday, July 24, 2024, in a warehouse of one of the companies located near its technical center in the state of Blida.&lt;/i&gt;” The post from Djezzy predicted that “&lt;i&gt;97% of the sites will be restored by around 3 am [July 25]&lt;/i&gt;”, but traffic did not return to expected levels until the end of the day on July 25.&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-07-24&amp;dateEnd=2024-07-26&amp;location=as327931&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;unknown\&quot;&gt;Unknown&lt;/h2&gt;\n            &lt;a href=\&quot;#unknown\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          \n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;united-states\&quot;&gt;United States&lt;/h3&gt;\n            &lt;a href=\&quot;#united-states\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;On Monday, September 30, customers on Verizon’s mobile network in multiple cities across the United States &lt;a href=\&quot;https://apnews.com/article/verizon-outage-sos-mode-phone-service-b03c9b8615e0650669339daa2eaa1713\&quot;&gt;&lt;u&gt;reported&lt;/u&gt;&lt;/a&gt; experiencing a loss of connectivity. Impacted phones showed “SOS” instead of the usual bar-based signal strength indicator, and customers complained of an inability to make or receive calls on their mobile devices. Although initial reports of connectivity problems started around 09:00 ET (13:00 UTC), we didn’t see a noticeable change in request volume at an ASN level until about two hours later. &lt;a href=\&quot;https://radar.cloudflare.com/as6167\&quot;&gt;&lt;u&gt;AS6167 (CELLCO)&lt;/u&gt;&lt;/a&gt; is the &lt;a href=\&quot;https://www.cloudflare.com/learning/network-layer/what-is-an-autonomous-system/\&quot;&gt;&lt;u&gt;autonomous system&lt;/u&gt;&lt;/a&gt; used by Verizon for its mobile network.&lt;/p&gt;&lt;p&gt;Just before 12:00 ET (16:00 UTC), Verizon &lt;a href=\&quot;https://x.com/VerizonNews/status/1840780785084985777\&quot;&gt;&lt;u&gt;published a social media post acknowledging the problem&lt;/u&gt;&lt;/a&gt;, stating “We are aware of an issue impacting service for some customers. Our engineers are engaged, and we are working quickly to identify and solve the issue.” As the &lt;a href=\&quot;https://radar.cloudflare.com/explorer?dataSet=http&amp;loc=as6167&amp;dt=2024-09-30_2024-09-30&amp;timeCompare=2024-09-23\&quot;&gt;&lt;u&gt;graph&lt;/u&gt;&lt;/a&gt; below shows, a slight decline (-5%) in HTTP traffic as compared to traffic at the same time a week prior is first visible around 11:00 ET (15:00 UTC), and request volume fell as much as 9% below expected levels at 13:45 ET (17:45 UTC).&lt;/p&gt;&lt;p&gt;Media reports listed cities including Chicago, Indianapolis, New York City, Atlanta, Cincinnati, Omaha, Phoenix, Denver, Minneapolis, Seattle, Los Angeles, and Las Vegas as being most impacted. Traffic graphs illustrating the impacts seen in these cities can be found in our &lt;a href=\&quot;https://blog.cloudflare.com/impact-of-verizons-september-30-outage-on-internet-traffic/\&quot;&gt;&lt;i&gt;&lt;u&gt;Impact of Verizon’s September 30 outage on Internet traffic&lt;/u&gt;&lt;/i&gt;&lt;/a&gt; blog post.&lt;/p&gt;&lt;p&gt;Traffic appeared to return to expected levels around 17:15 ET (21:15 UTC). At 19:18 ET (23:18 UTC), a &lt;a href=\&quot;https://x.com/VerizonNews/status/1840893978411221191\&quot;&gt;&lt;u&gt;social media post&lt;/u&gt;&lt;/a&gt; from Verizon noted “&lt;i&gt;Verizon engineers have fully restored today&amp;#39;s network disruption that impacted some customers. Service has returned to normal levels.&lt;/i&gt;”&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;536\&quot; src=\&quot;https://radar.cloudflare.com/embed/DataExplorerVisualizer?path=http%2Ftimeseries&amp;dateStart=2024-09-30&amp;dateEnd=2024-09-30&amp;mainLocation=6167&amp;timeCompare=2024-09-23&amp;param_limitPerGroup=10&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - HTTP requests time series for AS6167\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;pakistan\&quot;&gt;Pakistan&lt;/h3&gt;\n            &lt;a href=\&quot;#pakistan\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;On July 31, &lt;a href=\&quot;https://radar.cloudflare.com/pk\&quot;&gt;&lt;u&gt;Pakistan&lt;/u&gt;&lt;/a&gt; experienced a wide-scale Internet disruption that lasted approximately two hours, between 13:30 - 15:30 local time (08:30 - 10:30 UTC). Traffic only dropped ~45% at a country level, but &lt;a href=\&quot;https://radar.cloudflare.com/as17557\&quot;&gt;&lt;u&gt;AS17557 (PTCL)&lt;/u&gt;&lt;/a&gt; experienced a near complete loss of traffic, while traffic at &lt;a href=\&quot;https://radar.cloudflare.com/as24499\&quot;&gt;&lt;u&gt;AS24499 (Telenor Pakistan)&lt;/u&gt;&lt;/a&gt; dropped nearly 90%. Together, the two network providers serve an estimated nine million users, and are among the top five Internet service providers in the country.&lt;/p&gt;&lt;p&gt;The actual cause of the disruption is disputed. It was &lt;a href=\&quot;https://www.globalvillagespace.com/internet-outage-in-pakistan/\&quot;&gt;&lt;u&gt;reported&lt;/u&gt;&lt;/a&gt; that the Pakistan Telecommunication Authority (PTA) attributed the disruptions to a technical glitch in the international submarine cable affecting the Pakistan Telecommunication Company Limited (PTCL) network. However, another &lt;a href=\&quot;https://incpak.com/national/internet-services-outtage-across-pakistan/\&quot;&gt;&lt;u&gt;published report&lt;/u&gt;&lt;/a&gt; noted “According to our sources, the government’s latest firewall edition to block the content was misconfigured, resulting in Internet connectivity disruption.” Additional details can be found in our August 1 blog post, &lt;a href=\&quot;https://blog.cloudflare.com/a-recent-spate-of-internet-disruptions-july-2024/\&quot;&gt;&lt;i&gt;&lt;u&gt;A recent spate of Internet disruptions&lt;/u&gt;&lt;/i&gt;&lt;/a&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-07-31&amp;dateEnd=2024-07-31&amp;location=pk&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-07-31&amp;dateEnd=2024-07-31&amp;location=as17557&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-07-31&amp;dateEnd=2024-07-31&amp;location=as24499&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;united-kingdom\&quot;&gt;United Kingdom&lt;/h3&gt;\n            &lt;a href=\&quot;#united-kingdom\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;On August 14, subscribers of &lt;a href=\&quot;https://radar.cloudflare.com/gb\&quot;&gt;&lt;u&gt;UK&lt;/u&gt;&lt;/a&gt; service provider &lt;a href=\&quot;https://radar.cloudflare.com/as25135\&quot;&gt;&lt;u&gt;Vodafone (AS25135)&lt;/u&gt;&lt;/a&gt; &lt;a href=\&quot;https://www.dailymail.co.uk/sciencetech/article-13742755/Vodafone-network-crashes-internet.html\&quot;&gt;&lt;u&gt;reported problems&lt;/u&gt;&lt;/a&gt; accessing both mobile and landline Internet connections. Starting around 11:00 local time (10:00 UTC), we observed traffic starting to drop, ultimately falling 43% below the same time the prior week. The disruption was fairly short-lived, as traffic returned to expected levels by 13:30 local time (12:30 UTC). Vodafone did not acknowledge the issue on social media, nor did it provide a public explanation for what caused the disruption.&lt;/p&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;450\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-08-14&amp;dateEnd=2024-08-14&amp;location=as25135&amp;trafficType=HTTP&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.highlightedSeries%22%3Anull%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;conclusion\&quot;&gt;Conclusion&lt;/h2&gt;\n            &lt;a href=\&quot;#conclusion\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;Although Internet disruptions observed during the third quarter had a variety of underlying causes, those caused by power outages due to aging or insufficiently maintained electrical infrastructure are worth highlighting. Of course, widespread power outages always create a massive inconvenience for impacted populations, but over the last several years, as communication, entertainment, commerce, and more have become increasingly reliant on the Internet, the impact of these outages has become even more significant, because losing electrical power largely means losing Internet connectivity. Although mobile connectivity may still be available in some cases, it is decidedly not a complete replacement, not to mention that mobile devices will eventually need to be recharged. While addressing the underlying infrastructure issues require non-trivial amounts of time, resources, and money, governments appear to be taking steps towards doing so.&lt;/p&gt;&lt;p&gt;Visit &lt;a href=\&quot;https://radar.cloudflare.com/\&quot;&gt;&lt;u&gt;Cloudflare Radar&lt;/u&gt;&lt;/a&gt; for additional insights around Internet disruptions, routing issues, Internet traffic trends, security and attacks, and Internet quality. Follow us on social media at &lt;a href=\&quot;https://x.com/CloudflareRadar\&quot;&gt;&lt;u&gt;@CloudflareRadar&lt;/u&gt;&lt;/a&gt; (X), &lt;a href=\&quot;https://noc.social/@cloudflareradar\&quot;&gt;&lt;u&gt;noc.social/@cloudflareradar&lt;/u&gt;&lt;/a&gt; (Mastodon), and &lt;a href=\&quot;https://bsky.app/profile/radar.cloudflare.com\&quot;&gt;&lt;u&gt;radar.cloudflare.com&lt;/u&gt;&lt;/a&gt; (Bluesky), or contact us via e-mail.&lt;/p&gt;&quot;],&quot;published_at&quot;:[0,&quot;2024-10-29T13:05+00:00&quot;],&quot;updated_at&quot;:[0,&quot;2024-11-05T09:47:56.847Z&quot;],&quot;feature_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5sILF0HtExUlG43X3DSmYc/c7045c6cd3c6493ddf876d2ef1ae5c9a/image68.png&quot;],&quot;tags&quot;:[1,[[0,{&quot;id&quot;:[0,&quot;5kZtWqjqa7aOUoZr8NFGwI&quot;],&quot;name&quot;:[0,&quot;Radar&quot;],&quot;slug&quot;:[0,&quot;cloudflare-radar&quot;]}],[0,{&quot;id&quot;:[0,&quot;5DD7GZ0oxjP3NGOaJMwyWq&quot;],&quot;name&quot;:[0,&quot;Internet Quality&quot;],&quot;slug&quot;:[0,&quot;internet-quality&quot;]}],[0,{&quot;id&quot;:[0,&quot;sBnaK06GQyzaHg5OdsV90&quot;],&quot;name&quot;:[0,&quot;Internet Shutdown&quot;],&quot;slug&quot;:[0,&quot;internet-shutdown&quot;]}],[0,{&quot;id&quot;:[0,&quot;4yliZlpBPZpOwBDZzo1tTh&quot;],&quot;name&quot;:[0,&quot;Outage&quot;],&quot;slug&quot;:[0,&quot;outage&quot;]}],[0,{&quot;id&quot;:[0,&quot;0kgHdg1ytbdWl5BNo6bEa&quot;],&quot;name&quot;:[0,&quot;Internet Traffic&quot;],&quot;slug&quot;:[0,&quot;internet-traffic&quot;]}],[0,{&quot;id&quot;:[0,&quot;4nA5kKyA1tOqFyjHMque21&quot;],&quot;name&quot;:[0,&quot;Consumer Services&quot;],&quot;slug&quot;:[0,&quot;consumer-services&quot;]}]]],&quot;relatedTags&quot;:[0],&quot;authors&quot;:[1,[[0,{&quot;name&quot;:[0,&quot;David Belson&quot;],&quot;slug&quot;:[0,&quot;david-belson&quot;],&quot;bio&quot;:[0,null],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/en7vkXf6rLBm4F8IcNHXT/645022bf841fabff7732aa3be3949808/david-belson.jpeg&quot;],&quot;location&quot;:[0,null],&quot;website&quot;:[0,null],&quot;twitter&quot;:[0,&quot;@dbelson&quot;],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}]]],&quot;meta_description&quot;:[0,&quot;The third quarter of 2024 was particularly active, with quite a few significant Internet disruptions. Underlying causes included government-directed shutdowns, power outages, hurricane damage, terrestrial and submarine cable cuts, military action, and more.&quot;],&quot;primary_author&quot;:[0,{}],&quot;localeList&quot;:[0,{&quot;name&quot;:[0,&quot;Forced offline: the Q3 2024 Internet disruption summary - LL - deDE_esES_frFR_nlNL_zhCN_jaJP_koKR_zhTW&quot;],&quot;enUS&quot;:[0,&quot;English for Locale&quot;],&quot;zhCN&quot;:[0,&quot;Translated for Locale&quot;],&quot;zhHansCN&quot;:[0,&quot;English for Locale&quot;],&quot;zhTW&quot;:[0,&quot;Translated for Locale&quot;],&quot;frFR&quot;:[0,&quot;Translated for Locale&quot;],&quot;deDE&quot;:[0,&quot;Translated for Locale&quot;],&quot;itIT&quot;:[0,&quot;English for Locale&quot;],&quot;jaJP&quot;:[0,&quot;Translated for Locale&quot;],&quot;koKR&quot;:[0,&quot;Translated for Locale&quot;],&quot;ptBR&quot;:[0,&quot;English for Locale&quot;],&quot;esLA&quot;:[0,&quot;English for Locale&quot;],&quot;esES&quot;:[0,&quot;Translated for Locale&quot;],&quot;enAU&quot;:[0,&quot;English for Locale&quot;],&quot;enCA&quot;:[0,&quot;English for Locale&quot;],&quot;enIN&quot;:[0,&quot;English for Locale&quot;],&quot;enGB&quot;:[0,&quot;English for Locale&quot;],&quot;idID&quot;:[0,&quot;No Page for Locale&quot;],&quot;ruRU&quot;:[0,&quot;English for Locale&quot;],&quot;svSE&quot;:[0,&quot;No Page for Locale&quot;],&quot;viVN&quot;:[0,&quot;No Page for Locale&quot;],&quot;plPL&quot;:[0,&quot;English for Locale&quot;],&quot;arAR&quot;:[0,&quot;No Page for Locale&quot;],&quot;nlNL&quot;:[0,&quot;Translated for Locale&quot;],&quot;thTH&quot;:[0,&quot;No Page for Locale&quot;],&quot;trTR&quot;:[0,&quot;No Page for Locale&quot;],&quot;heIL&quot;:[0,&quot;No Page for Locale&quot;],&quot;lvLV&quot;:[0,&quot;No Page for Locale&quot;],&quot;etEE&quot;:[0,&quot;No Page for Locale&quot;],&quot;ltLT&quot;:[0,&quot;No Page for Locale&quot;]}],&quot;url&quot;:[0,&quot;https://blog.cloudflare.com/q3-2024-internet-disruption-summary&quot;],&quot;metadata&quot;:[0,{&quot;title&quot;:[0,&quot;Forced offline: the Q3 2024 Internet disruption summary&quot;],&quot;description&quot;:[0,&quot;The third quarter of 2024 was particularly active, with quite a few significant Internet disruptions. Underlying causes included government-directed shutdowns, power outages, hurricane damage, terrestrial and submarine cable cuts, military action, and more.&quot;],&quot;imgPreview&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1OqQ8gWpJRgK7JGu9gqGUN/24de755bdcafb78b25dc5e1ade6065ea/Forced_offline-_the_Q3_2024_Internet_disruption_summary-OG.png&quot;]}],&quot;publicly_index&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;2dMuW3phhA9ClF8ROOAYPH&quot;],&quot;title&quot;:[0,&quot;Impact of Verizon’s September 30 outage on Internet traffic&quot;],&quot;slug&quot;:[0,&quot;impact-of-verizons-september-30-outage-on-internet-traffic&quot;],&quot;excerpt&quot;:[0,&quot;On Monday, September 30, customers on Verizon’s mobile network in multiple cities across the United States reported experiencing a loss of connectivity. HTTP request traffic data from Verizon’s mobile ASN (AS6167) showed nominal declines across impacted cities.\n&quot;],&quot;featured&quot;:[0,false],&quot;html&quot;:[0,&quot;&lt;p&gt;On Monday, September 30, 2024, customers on Verizon’s mobile network in multiple cities across the United States &lt;a href=\&quot;https://apnews.com/article/verizon-outage-sos-mode-phone-service-b03c9b8615e0650669339daa2eaa1713\&quot;&gt;&lt;u&gt;reported&lt;/u&gt;&lt;/a&gt; experiencing a loss of connectivity. Impacted phones showed “SOS” instead of the usual bar-based signal strength indicator, and customers complained of an inability to make or receive calls on their mobile devices.&lt;/p&gt;&lt;p&gt;&lt;a href=\&quot;https://radar.cloudflare.com/as6167\&quot;&gt;&lt;u&gt;AS6167 (CELLCO)&lt;/u&gt;&lt;/a&gt; is the &lt;a href=\&quot;https://www.cloudflare.com/learning/network-layer/what-is-an-autonomous-system/\&quot;&gt;&lt;u&gt;autonomous system&lt;/u&gt;&lt;/a&gt; used by Verizon for its mobile network. To better understand how the outage impacted Internet traffic on Verizon’s network, we took a look at HTTP request volume from AS6167 independent of geography, as well as traffic from AS6167 in various cities that were &lt;a href=\&quot;https://mashable.com/live/verizon-outage-live-updates\&quot;&gt;&lt;u&gt;reported&lt;/u&gt;&lt;/a&gt; to be the most significantly impacted.&lt;/p&gt;&lt;p&gt;Although initial reports of connectivity problems started around 09:00 ET (13:00 UTC), we didn’t see a noticeable change in request volume at an ASN level until about two hours later. Just before 12:00 ET (16:00 UTC), Verizon &lt;a href=\&quot;https://x.com/VerizonNews/status/1840780785084985777\&quot;&gt;&lt;u&gt;published a social media post acknowledging the problem&lt;/u&gt;&lt;/a&gt;, stating “&lt;i&gt;We are aware of an issue impacting service for some customers. Our engineers are engaged and we are working quickly to identify and solve the issue.&lt;/i&gt;”&lt;/p&gt;&lt;p&gt;As the &lt;a href=\&quot;https://radar.cloudflare.com/explorer?dataSet=http&amp;loc=as6167&amp;dt=2024-09-30_2024-09-30&amp;timeCompare=2024-09-23\&quot;&gt;&lt;u&gt;Cloudflare Radar graph&lt;/u&gt;&lt;/a&gt; below shows, a slight decline (-5%) in HTTP traffic as compared to traffic at the same time a week prior is first visible around 11:00 ET (15:00 UTC). Request volume fell as much as 9% below expected levels at 13:45 ET (17:45 UTC).&lt;/p&gt;&lt;p&gt;Just after 17:00 ET (21:00 UTC), Verizon &lt;a href=\&quot;https://x.com/VerizonNews/status/1840860310997254609\&quot;&gt;&lt;u&gt;published a second social media post&lt;/u&gt;&lt;/a&gt; noting, in part, “&lt;i&gt;Verizon engineers are making progress on our network issue and service has started to be restored.&lt;/i&gt;” Request volumes returned to expected levels around the same time, surpassing the previous week’s levels at 17:15 ET (21:15 UTC). At 19:18 ET (23:18 UTC), a &lt;a href=\&quot;https://x.com/VerizonNews/status/1840893978411221191\&quot;&gt;&lt;u&gt;social media post&lt;/u&gt;&lt;/a&gt; from Verizon noted “Verizon engineers have fully restored today&amp;#39;s network disruption that impacted some customers. Service has returned to normal levels.”&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5fwaspr4MBTWT0zf36YEmf/86dfccdab0df85ea90edaa369520c23b/BLOG-2587_2.png\&quot; alt=\&quot;BLOG-2587 2\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;Media reports listed cities including Chicago, Indianapolis, New York City, Atlanta, Cincinnati, Omaha, Phoenix, Denver, Minneapolis, Seattle, Los Angeles, and Las Vegas as being most impacted. In addition to looking at comparative traffic trends across the whole Verizon Wireless network, we also compared request volumes in the listed cities to the same time a week prior (September 23).&lt;/p&gt;&lt;p&gt;Declines in request traffic starting around 11:00 ET (15:00 UTC) are clearly visible in cities including Los Angeles, Seattle, Omaha, Denver, Phoenix, Minneapolis, Indianapolis, and Chicago. In contrast to other cities, Omaha’s request volume was already trending lower than last week heading into today’s outage, but its graph clearly shows the impact of today’s disruption as well. Omaha’s difference in traffic was the most significant, down approximately 30%, while other cities saw declines in the 10-20% range. &lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/wg0aCH9hUSpECGnzs4I9s/c7eeef574e5ba07cf26c7c667a0a9239/BLOG-2587_3.png\&quot; alt=\&quot;BLOG-2587 3\&quot; class=\&quot;kg-image\&quot; width=\&quot;1175\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5kE1kBRS4tTyB5TPY8ain7/5a153b7c7052352e9e44c6d88b1fab1c/BLOG-2587_4.png\&quot; alt=\&quot;BLOG-2587 4\&quot; class=\&quot;kg-image\&quot; width=\&quot;1175\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7gg28UcLpcp92UYvLpykuO/715fa25efcfcdfc6dd18b8dd5b81b0ca/BLOG-2587_5.png\&quot; alt=\&quot;BLOG-2587 5\&quot; class=\&quot;kg-image\&quot; width=\&quot;1175\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7rcGVaVuBsK7oMhPaAfOx3/3b785c2b4d296b6d459e5f50a5d69da7/BLOG-2587_6.png\&quot; alt=\&quot;BLOG-2587 6\&quot; class=\&quot;kg-image\&quot; width=\&quot;1175\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2WuYIbLm9MdkjN5C20JgG2/6784dca790e32ad199f2fb2122e21fcb/BLOG-2587_7.png\&quot; alt=\&quot;BLOG-2587 7\&quot; class=\&quot;kg-image\&quot; width=\&quot;1175\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3YTBl2XO8YDDgFSzAoIAxo/0a9481add616709fa8d95762cfbfc71e/BLOG-2587_8.png\&quot; alt=\&quot;BLOG-2587 8\&quot; class=\&quot;kg-image\&quot; width=\&quot;1175\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3dt2aD35Ipq0eZKuQcF8PB/2f51bd06ee1ced5fab68a76cc71f70ce/BLOG-2587_9.png\&quot; alt=\&quot;BLOG-2587 9\&quot; class=\&quot;kg-image\&quot; width=\&quot;1175\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6NS4Wq7KB0U60IkhyzhwTs/f69159fe84dd373c6905ebe56e570b6d/BLOG-2587_10.png\&quot; alt=\&quot;BLOG-2587 10\&quot; class=\&quot;kg-image\&quot; width=\&quot;1175\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;Request traffic from Las Vegas initially appeared to exhibit a bit of volatility around 11:00 ET (15:00 UTC), but continues to track fairly closely to last week’s levels before exceeding them starting at 16:00 ET (20:00 UTC). Cincinnati was tracking slightly above last week’s request volume before the outage began, and tracked closely to the prior week during the outage period.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4NatjBWUvwgaU2mRRHAEUV/9a21e0c3ce61eb4fc11a0fb1d239c411/BLOG-2587_11.png\&quot; alt=\&quot;BLOG-2587 11\&quot; class=\&quot;kg-image\&quot; width=\&quot;1175\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3jqFrqdvO203QDKMsFUWrM/1d3e538cd3f00b7e522be922eb6b3664/BLOG-2587_12.png\&quot; alt=\&quot;BLOG-2587 12\&quot; class=\&quot;kg-image\&quot; width=\&quot;1175\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;We observed week-over-week traffic increases during the outage period in New York and Atlanta. However, in both cities, traffic was already slightly above last week’s levels, and that trend continued throughout the day. &lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/UnTO0qSD24rreW9LHRk0H/043ebdf603b7604c4018944ad5192f2c/BLOG-2587_13.png\&quot; alt=\&quot;BLOG-2587 13\&quot; class=\&quot;kg-image\&quot; width=\&quot;1175\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1gDfClWDv7hqlgZE30HRjF/b427490198d2ba4fc74c6e84753de502/BLOG-2587_14.png\&quot; alt=\&quot;BLOG-2587 14\&quot; class=\&quot;kg-image\&quot; width=\&quot;1175\&quot; height=\&quot;525\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;Based on our observations, it appears that voice services on Verizon’s network may have been more significantly impacted than data services, as we saw some declines in request traffic across impacted cities, but none experienced full outages.&lt;/p&gt;&lt;p&gt;As of this writing (19:15 ET, 23:15 UTC), no specific information has been made available by Verizon regarding the root cause of the network problems. &lt;/p&gt;&quot;],&quot;published_at&quot;:[0,&quot;2024-09-30T17:32-07:00&quot;],&quot;updated_at&quot;:[0,&quot;2024-10-31T09:36:19.473Z&quot;],&quot;feature_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3OJtqoXNl4hQ9CBy7B0EYj/1a12b4febd5951e0d367b3dcd5a028f7/BLOG-2587_1.png&quot;],&quot;tags&quot;:[1,[[0,{&quot;id&quot;:[0,&quot;5kZtWqjqa7aOUoZr8NFGwI&quot;],&quot;name&quot;:[0,&quot;Radar&quot;],&quot;slug&quot;:[0,&quot;cloudflare-radar&quot;]}],[0,{&quot;id&quot;:[0,&quot;3yArjf0gLKZy8ObEDxbNNi&quot;],&quot;name&quot;:[0,&quot;Trends&quot;],&quot;slug&quot;:[0,&quot;trends&quot;]}],[0,{&quot;id&quot;:[0,&quot;4nA5kKyA1tOqFyjHMque21&quot;],&quot;name&quot;:[0,&quot;Consumer Services&quot;],&quot;slug&quot;:[0,&quot;consumer-services&quot;]}],[0,{&quot;id&quot;:[0,&quot;4yliZlpBPZpOwBDZzo1tTh&quot;],&quot;name&quot;:[0,&quot;Outage&quot;],&quot;slug&quot;:[0,&quot;outage&quot;]}]]],&quot;relatedTags&quot;:[0],&quot;authors&quot;:[1,[[0,{&quot;name&quot;:[0,&quot;David Belson&quot;],&quot;slug&quot;:[0,&quot;david-belson&quot;],&quot;bio&quot;:[0,null],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/en7vkXf6rLBm4F8IcNHXT/645022bf841fabff7732aa3be3949808/david-belson.jpeg&quot;],&quot;location&quot;:[0,null],&quot;website&quot;:[0,null],&quot;twitter&quot;:[0,&quot;@dbelson&quot;],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}]]],&quot;meta_description&quot;:[0,&quot;On Monday, September 30, customers on Verizon’s mobile network in multiple cities across the United States reported experiencing a loss of connectivity. HTTP request traffic data from Verizon’s mobile ASN (AS6167) showed nominal declines across impacted cities.\n&quot;],&quot;primary_author&quot;:[0,{}],&quot;localeList&quot;:[0,{&quot;name&quot;:[0,&quot;blog-english-only&quot;],&quot;enUS&quot;:[0,&quot;English for Locale&quot;],&quot;zhCN&quot;:[0,&quot;No Page for Locale&quot;],&quot;zhHansCN&quot;:[0,&quot;No Page for Locale&quot;],&quot;zhTW&quot;:[0,&quot;No Page for Locale&quot;],&quot;frFR&quot;:[0,&quot;No Page for Locale&quot;],&quot;deDE&quot;:[0,&quot;No Page for Locale&quot;],&quot;itIT&quot;:[0,&quot;No Page for Locale&quot;],&quot;jaJP&quot;:[0,&quot;No Page for Locale&quot;],&quot;koKR&quot;:[0,&quot;No Page for Locale&quot;],&quot;ptBR&quot;:[0,&quot;No Page for Locale&quot;],&quot;esLA&quot;:[0,&quot;No Page for Locale&quot;],&quot;esES&quot;:[0,&quot;No Page for Locale&quot;],&quot;enAU&quot;:[0,&quot;No Page for Locale&quot;],&quot;enCA&quot;:[0,&quot;No Page for Locale&quot;],&quot;enIN&quot;:[0,&quot;No Page for Locale&quot;],&quot;enGB&quot;:[0,&quot;No Page for Locale&quot;],&quot;idID&quot;:[0,&quot;No Page for Locale&quot;],&quot;ruRU&quot;:[0,&quot;No Page for Locale&quot;],&quot;svSE&quot;:[0,&quot;No Page for Locale&quot;],&quot;viVN&quot;:[0,&quot;No Page for Locale&quot;],&quot;plPL&quot;:[0,&quot;No Page for Locale&quot;],&quot;arAR&quot;:[0,&quot;No Page for Locale&quot;],&quot;nlNL&quot;:[0,&quot;No Page for Locale&quot;],&quot;thTH&quot;:[0,&quot;No Page for Locale&quot;],&quot;trTR&quot;:[0,&quot;No Page for Locale&quot;],&quot;heIL&quot;:[0,&quot;No Page for Locale&quot;],&quot;lvLV&quot;:[0,&quot;No Page for Locale&quot;],&quot;etEE&quot;:[0,&quot;No Page for Locale&quot;],&quot;ltLT&quot;:[0,&quot;No Page for Locale&quot;]}],&quot;url&quot;:[0,&quot;https://blog.cloudflare.com/impact-of-verizons-september-30-outage-on-internet-traffic&quot;],&quot;metadata&quot;:[0,{&quot;title&quot;:[0,&quot;Impact of Verizon&#39;s September 30 outage on Internet traffic&quot;],&quot;description&quot;:[0,&quot;On Monday, September 30, customers on Verizon’s mobile network in multiple cities across the United States reported experiencing a loss of connectivity. HTTP request traffic data from Verizon’s mobile ASN (AS6167) showed nominal declines across impacted cities.\n&quot;],&quot;imgPreview&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4riEx6QIoNCWbIgsLUfY6r/5c2793283d5df742c65fe23c8f44b44c/BLOG-2587_OG.png&quot;]}],&quot;publicly_index&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;2SwCyuXYfx1hPgiULhD2Pz&quot;],&quot;title&quot;:[0,&quot;Cloudflare incident on September 17, 2024&quot;],&quot;slug&quot;:[0,&quot;cloudflare-incident-on-september-17-2024&quot;],&quot;excerpt&quot;:[0,&quot;On September 17, 2024, during planned routine maintenance, Cloudflare stopped announcing 15 IPv4 prefixes, affecting some Business plan websites for approximately one hour. During this time, IPv4 traffic for these customers would not have reached Cloudflare and users attempting to connect to websites using addresses within those prefixes would have received errors. &quot;],&quot;featured&quot;:[0,false],&quot;html&quot;:[0,&quot;&lt;p&gt;On September 17, 2024, during routine maintenance, Cloudflare inadvertently stopped announcing fifteen IPv4 prefixes, affecting some Business plan websites for approximately one hour. During this time, IPv4 traffic for these customers would not have reached Cloudflare, and users attempting to connect to websites assigned addresses within those prefixes would have received errors. &lt;/p&gt;&lt;p&gt;We’re very sorry for this outage. &lt;/p&gt;&lt;p&gt;This outage was the result of an internal software error and not the result of an attack. In this blog post, we’re going to talk about what the failure was, why it occurred, and what we’re doing to make sure this doesn’t happen again.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;background\&quot;&gt;Background&lt;/h2&gt;\n            &lt;a href=\&quot;#background\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;Cloudflare assembled a dedicated Addressing team in 2019 to simplify the ways that IP addresses are used across Cloudflare products and services. The team builds and maintains systems that help Cloudflare conserve and manage its own network resources. The Addressing team also manages periodic changes to the assignment of IP addresses across infrastructure and services at Cloudflare. In this case, our goal was to reduce the number of IPv4 addresses used for customer websites, allowing us to free up addresses for other purposes, like deploying infrastructure in new locations. Since IPv4 addresses are a finite resource and are becoming more scarce over time, we carry out these kinds of “renumbering” exercises quite regularly.&lt;/p&gt;&lt;p&gt;Renumbering in Cloudflare is carried out using internal processes that move websites between sets of IP addresses. A set of IP addresses that no longer has websites associated with it is no longer needed, and can be retired. Once that has happened, the associated addresses are free to be used elsewhere.&lt;/p&gt;&lt;p&gt;Back in July 2024, a batch of Business plan websites were moved from their original set of IPv4 addresses to a new, smaller set, appropriate to the forecast requirements of that particular plan. On September 17, after confirming that all of the websites using those addresses had been successfully renumbered, the next step was to be carried out: detach the IPv4 prefixes associated with those addresses from Cloudflare’s network and to withdraw them from service. That last part was to be achieved by removing those IPv4 prefixes from the Internet’s global routing table using the Border Gateway Protocol (&lt;a href=\&quot;https://www.cloudflare.com/learning/security/glossary/what-is-bgp/\&quot;&gt;&lt;u&gt;BGP&lt;/u&gt;&lt;/a&gt;), so that traffic to those addresses is no longer routed towards Cloudflare. The prefixes concerned would then be ready to be deployed for other purposes.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;what-was-released-and-how-did-it-break\&quot;&gt;What was released and how did it break?&lt;/h2&gt;\n            &lt;a href=\&quot;#what-was-released-and-how-did-it-break\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;When we migrated customer websites out of their existing assigned address space in July, we used a one time migration template that cycles through all the websites associated with the old IP addresses and moves them to new ones. This calls a function that updates the IP assignment mechanism to synchronize the IP address-to-website mapping.&lt;/p&gt;&lt;p&gt;A couple of months prior to the July migration, the relevant function code was updated as part of a separate project related to legacy SSL configurations. That update contained a fix that replaced legacy code to synchronize two address pools with a call to an existing synchronization function. The update was reviewed, approved, merged, and released.&lt;/p&gt;&lt;p&gt;Unfortunately, the fix had consequences for the subsequent renumbering work. Upon closer inspection (we’ve done some very close post-incident inspection), a side effect of the change was to suppress updates in cases where there was no linked reference to a legacy SSL certificate. Since not all websites use legacy certificates, the effect was that not all websites were renumbered — 1,661 customer websites remained linked to old addresses in the address pools that were intended to be withdrawn. This was not noticed during the renumbering work in July, which had concluded with the assumption that every website linked to the old addresses had been renumbered, and that assumption was not checked.&lt;/p&gt;&lt;p&gt;At 2024-09-17 17:51 UTC, fifteen IPv4 prefixes corresponding to the addresses that were thought to be safely unused were withdrawn using BGP. Cloudflare operates a &lt;a href=\&quot;https://www.cloudflare.com/network/\&quot;&gt;&lt;u&gt;global network&lt;/u&gt;&lt;/a&gt; with hundreds of data centers, and there was some variation in the precise time when the prefixes were withdrawn from particular parts of the world. In the following ten minutes, we observed an aggregate 10 Gbps drop in traffic to the 1,661 affected websites network-wide.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/74QVf9RH9rOHLTc2FDzZ5l/f6cdd7faccb943a15b9eea344f2e1e94/BLOG-2577_2.png\&quot; alt=\&quot;The graph above shows traffic volume (in bits per second) for each individual prefix that was affected by the incident\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;761\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;sub&gt;&lt;i&gt;The graph above shows traffic volume (in bits per second) for each individual prefix that was affected by the incident.&lt;/i&gt;&lt;/sub&gt;&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;incident-timeline-and-impact\&quot;&gt;Incident timeline and impact&lt;/h2&gt;\n            &lt;a href=\&quot;#incident-timeline-and-impact\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;All timestamps are UTC on 2024-09-17.&lt;/p&gt;&lt;p&gt;At 17:41, the Addressing engineering team initiated the release that disabled prefixes in production.&lt;/p&gt;&lt;p&gt;At 17:51, BGP announcements began to be withdrawn and traffic to Cloudflare on the impacted prefixes started to drop.&lt;/p&gt;&lt;p&gt;At 17:57, the SRE team noticed alerts triggered by an increase in unreachable IP address space and began investigating. The investigation ended shortly afterwards, since it is generally expected that IP addresses will become unreachable when they are being removed from service, and consequently the alerts did not seem to indicate an abnormal situation.&lt;/p&gt;&lt;p&gt;At 18:36, Cloudflare received escalations from two customers, and an incident was declared. A limited deployment window was quickly implemented once the severity of the incident was assessed.&lt;/p&gt;&lt;p&gt;At 18:46, Addressing team engineers confirmed that the change introduced in the renumbering release triggered the incident and began preparing the rollback procedure to revert changes.&lt;/p&gt;&lt;p&gt;At 18:50, the release was rolled back, prefixes were re-announced in BGP to the Internet, and traffic began flowing back through Cloudflare.&lt;/p&gt;&lt;p&gt;At 18:50:27, the affected routes were restored and prefixes began receiving traffic again.&lt;/p&gt;&lt;p&gt;There was no impact to IPv6 traffic. 1,661 customer websites that were associated with addresses in the withdrawn IPv4 prefixes were affected. There was no impact to other customers or services.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;how-did-we-fix-it\&quot;&gt;How did we fix it?&lt;/h2&gt;\n            &lt;a href=\&quot;#how-did-we-fix-it\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;The immediate fix to the problem was to roll back the release that was determined to be the proximal cause. Since all approved changes have tested roll back procedures, this is often a pragmatic first step to fix whatever has just been found to be broken. In this case, as in many, it was an effective way to resolve the immediate impact and return things to normal.&lt;/p&gt;&lt;p&gt;Identifying the root cause took more effort. The code mentioned above that had been modified earlier this year is quite old, and part of a legacy system that the Addressing team has been working on moving away from since the team’s inception. Much of the engineering effort during that time has been on building the modern replacement, rather than line-level dives into the legacy code.&lt;/p&gt;&lt;p&gt;We have since fixed the specific bug that triggered this incident. However, to address the more general problem of relying on old code that is not as well understood as the code in modern systems, we will do more. Sometimes software has bugs, and sometimes software is old, and these are not useful excuses; they are just the way things are. It’s our job to maintain the agility and confidence in our release processes while living in this reality, maintaining the level of safety and stability that our customers and their customers rely on.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;what-are-we-doing-to-prevent-this-from-happening-again\&quot;&gt;What are we doing to prevent this from happening again?&lt;/h2&gt;\n            &lt;a href=\&quot;#what-are-we-doing-to-prevent-this-from-happening-again\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;We take incidents like this seriously, and we recognise the impact that this incident had. Though this specific bug has been resolved, we have identified several steps we can take to mitigate the risk of a similar problem occurring in the future. We are implementing the following plan as a result of this incident:&lt;/p&gt;&lt;p&gt;&lt;b&gt;Test:&lt;/b&gt; The Addressing Team is adding tests that check for the existence of outstanding assignments of websites to IP addresses as part of future renumbering exercises. These tests will verify that there are no remaining websites that inadvertently depend on the old addresses being in service. The changes that prompted this incident made incorrect assumptions that all websites had been renumbered. In the future, we will avoid making assumptions like those, and instead do explicit checks to make sure.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Process:&lt;/b&gt; The Addressing team is improving the processes associated with the withdrawal of Cloudflare-owned prefixes, regardless of whether the withdrawal is associated with a renumbering event, to include automated and manual verification of traffic levels associated with the addresses that are intended to be withdrawn. Where traffic is attached to a service that provides more detailed logging, service-specific request logs will be checked for signs that the addresses thought to be unused are not associated with active traffic.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Implementation:&lt;/b&gt; The Addressing Team is reviewing every use of stored procedures and functions associated with legacy systems. Where there is doubt, functionality will be re-implemented with present-day standards of documentation and test coverage.&lt;/p&gt;&lt;p&gt;We are sorry for the disruption this incident caused for our customers. We are actively making these improvements to ensure improved stability moving forward and to prevent this problem from happening again.&lt;/p&gt;&quot;],&quot;published_at&quot;:[0,&quot;2024-09-20T14:00+00:00&quot;],&quot;updated_at&quot;:[0,&quot;2024-10-09T23:05:14.760Z&quot;],&quot;feature_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2ihOrO67cRtAtPYeRNQufP/e61655422b9080faf6329138c8c436c5/BLOG-2577_1.png&quot;],&quot;tags&quot;:[1,[[0,{&quot;id&quot;:[0,&quot;4yliZlpBPZpOwBDZzo1tTh&quot;],&quot;name&quot;:[0,&quot;Outage&quot;],&quot;slug&quot;:[0,&quot;outage&quot;]}],[0,{&quot;id&quot;:[0,&quot;1QMcB7xjiP8Z1YK6WX3jn8&quot;],&quot;name&quot;:[0,&quot;IPv4&quot;],&quot;slug&quot;:[0,&quot;ipv4&quot;]}],[0,{&quot;id&quot;:[0,&quot;3aRZvV7ApVpkYKGhnNQH4w&quot;],&quot;name&quot;:[0,&quot;CDN&quot;],&quot;slug&quot;:[0,&quot;cdn&quot;]}]]],&quot;relatedTags&quot;:[0],&quot;authors&quot;:[1,[[0,{&quot;name&quot;:[0,&quot;Joe Abley&quot;],&quot;slug&quot;:[0,&quot;joe-abley&quot;],&quot;bio&quot;:[0],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/vPySolwjyVmkKeRU57vpP/caf3be9b556e2723ad51c0c7bfb81fda/_tmp_mini_magick20230522-2-nmh55z.jpg&quot;],&quot;location&quot;:[0],&quot;website&quot;:[0],&quot;twitter&quot;:[0],&quot;facebook&quot;:[0],&quot;publiclyIndex&quot;:[0,true]}]]],&quot;meta_description&quot;:[0,&quot;On September 17, 2024, during planned routine maintenance, Cloudflare stopped announcing 15 IPv4 prefixes, affecting some Business plan websites for approximately one hour. During this time, IPv4 traffic for these customers would not have reached Cloudflare and users attempting to connect to websites using addresses within those prefixes would have received errors. \n&quot;],&quot;primary_author&quot;:[0,{}],&quot;localeList&quot;:[0,{&quot;name&quot;:[0,&quot;blog-english-only&quot;],&quot;enUS&quot;:[0,&quot;English for Locale&quot;],&quot;zhCN&quot;:[0,&quot;No Page for Locale&quot;],&quot;zhHansCN&quot;:[0,&quot;No Page for Locale&quot;],&quot;zhTW&quot;:[0,&quot;No Page for Locale&quot;],&quot;frFR&quot;:[0,&quot;No Page for Locale&quot;],&quot;deDE&quot;:[0,&quot;No Page for Locale&quot;],&quot;itIT&quot;:[0,&quot;No Page for Locale&quot;],&quot;jaJP&quot;:[0,&quot;No Page for Locale&quot;],&quot;koKR&quot;:[0,&quot;No Page for Locale&quot;],&quot;ptBR&quot;:[0,&quot;No Page for Locale&quot;],&quot;esLA&quot;:[0,&quot;No Page for Locale&quot;],&quot;esES&quot;:[0,&quot;No Page for Locale&quot;],&quot;enAU&quot;:[0,&quot;No Page for Locale&quot;],&quot;enCA&quot;:[0,&quot;No Page for Locale&quot;],&quot;enIN&quot;:[0,&quot;No Page for Locale&quot;],&quot;enGB&quot;:[0,&quot;No Page for Locale&quot;],&quot;idID&quot;:[0,&quot;No Page for Locale&quot;],&quot;ruRU&quot;:[0,&quot;No Page for Locale&quot;],&quot;svSE&quot;:[0,&quot;No Page for Locale&quot;],&quot;viVN&quot;:[0,&quot;No Page for Locale&quot;],&quot;plPL&quot;:[0,&quot;No Page for Locale&quot;],&quot;arAR&quot;:[0,&quot;No Page for Locale&quot;],&quot;nlNL&quot;:[0,&quot;No Page for Locale&quot;],&quot;thTH&quot;:[0,&quot;No Page for Locale&quot;],&quot;trTR&quot;:[0,&quot;No Page for Locale&quot;],&quot;heIL&quot;:[0,&quot;No Page for Locale&quot;],&quot;lvLV&quot;:[0,&quot;No Page for Locale&quot;],&quot;etEE&quot;:[0,&quot;No Page for Locale&quot;],&quot;ltLT&quot;:[0,&quot;No Page for Locale&quot;]}],&quot;url&quot;:[0,&quot;https://blog.cloudflare.com/cloudflare-incident-on-september-17-2024&quot;],&quot;metadata&quot;:[0,{&quot;title&quot;:[0],&quot;description&quot;:[0],&quot;imgPreview&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1D3CfNLYt8WycwIUCmsQry/ea6385e2bb02c7d112edda4c1fae3c81/BLOG-2577_OG.png&quot;]}],&quot;publicly_index&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;6y7qBZ7MBe4IwACXynz3bJ&quot;],&quot;title&quot;:[0,&quot;A recent spate of Internet disruptions&quot;],&quot;slug&quot;:[0,&quot;a-recent-spate-of-internet-disruptions-july-2024&quot;],&quot;excerpt&quot;:[0,&quot;Cloudflare Radar is constantly monitoring the Internet for widespread disruptions. Here we examine several recent noteworthy disruptions detected in the first month of Q3, including traffic anomalies observed in Bangladesh, Syria, Pakistan, and Venezuela.&quot;],&quot;featured&quot;:[0,false],&quot;html&quot;:[0,&quot;&lt;p&gt;Cloudflare Radar is constantly monitoring the Internet for widespread disruptions. In mid-July, we published our &lt;a href=\&quot;http://blog.cloudflare.com/q2-2024-internet-disruption-summary\&quot;&gt;&lt;i&gt;Q2 2024 Internet Disruption Summary&lt;/i&gt;&lt;/a&gt;, and here we examine several recent noteworthy disruptions detected in the first month of Q3, including traffic anomalies observed in Bangladesh, Syria, Pakistan, and Venezuela.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;bangladesh\&quot;&gt;Bangladesh&lt;/h3&gt;\n            &lt;a href=\&quot;#bangladesh\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;&lt;a href=\&quot;https://timesofindia.indiatimes.com/world/south-asia/internet-shut-nationwide-bandh-announced-why-is-bangladesh-experiencing-deadly-protests/articleshow/111829956.cms\&quot;&gt;Violent student protests&lt;/a&gt; in Bangladesh against quotas in government jobs and rising unemployment rates led the government to order the nationwide shutdown of mobile Internet connectivity on July 18, &lt;a href=\&quot;https://therecord.media/bangladesh-mobile-internet-social-media-outages-student-protests\&quot;&gt;reportedly&lt;/a&gt; to “ensure the security of citizens.” This government-directed shutdown ultimately became a near-complete Internet outage for the country, as broadband networks were taken offline as well. At a country level, &lt;a href=\&quot;https://radar.cloudflare.com/traffic/bd?dateStart=2024-07-14&amp;dateEnd=2024-07-20\&quot;&gt;Internet traffic in Bangladesh dropped to near zero&lt;/a&gt; just before 21:00 local time (15:00 UTC). &lt;a href=\&quot;https://radar.cloudflare.com/routing/bd?dateStart=2024-07-14&amp;dateEnd=2024-07-20\&quot;&gt;Announced IP address space from the country dropped to near zero&lt;/a&gt; at that time as well, meaning that nearly every network in the country was disconnected from the Internet.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7HVxLTcXlB5mWm28ZSthZX/4aabc2b169c5f6e93343d6e311e6c675/1.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3XhqV4R4Is7w92GscnzqmT/d42e806f8061026808ea8c27de013bef/2.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6OPTe1uK4Ff6tI5IpD0KZE/b85178c819255e016a6881538f927f01/3.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;However, ahead of this nationwide shutdown, we observed outages across several Bangladeshi network providers, perhaps foreshadowing what was to come. At &lt;a href=\&quot;https://radar.cloudflare.com/as24389\&quot;&gt;AS24389 (Grameenphone)&lt;/a&gt;, a complete Internet outage started at 01:30 local time on July 18 (19:30 UTC on July 17), with a total loss of both &lt;a href=\&quot;https://radar.cloudflare.com/traffic/as24389?dateStart=2024-07-14&amp;dateEnd=2024-07-20\&quot;&gt;Internet traffic&lt;/a&gt; and &lt;a href=\&quot;https://radar.cloudflare.com/routing/as24389?dateStart=2024-07-14&amp;dateEnd=2024-07-20\&quot;&gt;announced IP address space&lt;/a&gt;.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5A3tYcwgeLS4JLqEmWc6XS/9473a77048fe1165cc544bb10935671f/4.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;The outage at &lt;a href=\&quot;https://radar.cloudflare.com/as45245\&quot;&gt;AS25245 (Banglalink)&lt;/a&gt; started at 02:15 local time on July 18 (20:15 UTC on July 17) as both &lt;a href=\&quot;https://radar.cloudflare.com/traffic/as45245?dateStart=2024-07-14&amp;dateEnd=2024-07-20\&quot;&gt;Internet traffic&lt;/a&gt; and &lt;a href=\&quot;https://radar.cloudflare.com/routing/as45245?dateStart=2024-07-14&amp;dateEnd=2024-07-20\&quot;&gt;announced IP address space&lt;/a&gt; dropped to zero.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/37sQXgIRxUxpMTdVPRWjsS/538b061418f4e0dbe374de64ccd3ef0f/5.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;At &lt;a href=\&quot;https://radar.cloudflare.com/as24432\&quot;&gt;AS24432 (Robi Axiata)&lt;/a&gt;, an Internet outage was observed starting around 06:30 local time on July 18 (00:30 UTC), with both &lt;a href=\&quot;https://radar.cloudflare.com/traffic/as24432?dateStart=2024-07-14&amp;dateEnd=2024-07-20\&quot;&gt;Internet traffic&lt;/a&gt; and &lt;a href=\&quot;https://radar.cloudflare.com/routing/as24432?dateStart=2024-07-14&amp;dateEnd=2024-07-20\&quot;&gt;announced IP address space&lt;/a&gt; disappearing at that time.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/75GBLfiuf6AmfHrE2UrrGA/ede0627e64a99227855f67a22e8c66d9/6.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;a href=\&quot;https://radar.cloudflare.com/traffic/as58715?dateStart=2024-07-14&amp;dateEnd=2024-07-20\&quot;&gt;Internet traffic&lt;/a&gt; at &lt;a href=\&quot;https://radar.cloudflare.com/as58715\&quot;&gt;AS58715 (Earth Telecommunication)&lt;/a&gt; began to fall at 18:00 local time on July 18 (12:00 UTC), reaching zero four hours later. &lt;a href=\&quot;https://radar.cloudflare.com/routing/as58715?dateStart=2024-07-14&amp;dateEnd=2024-07-20\&quot;&gt;Announced IP address space&lt;/a&gt; began to fall at 21:00 local time (15:00 UTC), and was completely gone by 21:25 local time (15:25 UTC).&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3Hi0Hw3G0xi8LVNRvmVWqc/b40b38b2fa193187c8d42d9cf1060fc5/7.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;a href=\&quot;https://radar.cloudflare.com/as63526\&quot;&gt;AS63526 (Carnival Internet)&lt;/a&gt; was one of the last to fall before the complete shutdown, &lt;a href=\&quot;https://radar.cloudflare.com/traffic/as63526?dateStart=2024-07-14&amp;dateEnd=2024-07-20\&quot;&gt;losing traffic&lt;/a&gt; at 20:45 local time (14:45 UTC), and seeing all of its &lt;a href=\&quot;https://radar.cloudflare.com/routing/as63526?dateStart=2024-07-14&amp;dateEnd=2024-07-20\&quot;&gt;announced IP address space&lt;/a&gt; withdrawn over the following hour.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/zhVSvxVogVry8xownHJmY/b33cfc2b1000cf1edaa5560a5abb15b6/8.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;In the days before the shutdown, both median bandwidth and latency at a country level for Bangladesh were fairly stable. However, Cloudflare Radar’s &lt;a href=\&quot;https://radar.cloudflare.com/quality/bd?dateStart=2024-07-14&amp;dateEnd=2024-07-20\&quot;&gt;Internet Quality measurements&lt;/a&gt; at a country level show a clear increase in median bandwidth and a concurrent drop in median latency, both likely due to the loss of measurements from mobile network providers as they disconnected from the Internet.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5VY2SSPy6xbB9kRB2dp8Yc/dd50cfed43d3e96edfce5f48dc4a4f93/9.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4ztJow8PNDMXP8gj7I76r0/c6d01ade8d42c7613a03fc2ca679bdb5/10.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;Five days after the full Internet shutdown started, broadband Internet services providers in Bangladesh began to restore connectivity on July 23. The initial restoration was characterized as a “trial run”, prioritizing banking, commercial sectors, technology firms, exporters, outsourcing providers and media outlets, &lt;a href=\&quot;https://www.dhakatribune.com/bangladesh/352554/broadband-internet-restored-in-limited-areas-after\&quot;&gt;according to&lt;/a&gt; the state minister for post, telecommunication and information technology. &lt;a href=\&quot;https://radar.cloudflare.com/routing/bd?dateStart=2024-07-23&amp;dateEnd=2024-07-23\&quot;&gt;Announced IP address space&lt;/a&gt; began to increase around 19:00 local time (13:00 UTC), with traffic volumes beginning to trend upwards at that same time, as selected networks reconnected to the Internet.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2PLUoGGpk9Qq94fLUqB1TD/f14357d946020f3d474e438333ed88f3/11.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3yvJpELkazG8Fhlv6joEV5/dbc29fbe61f75316ff7567e35810643a/12.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6MUTWbGAsgSEIVUZWjfeSJ/1bfe68e439c32f7c91b37fb1044ae11e/13.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;Looking at the network providers discussed above, traffic on &lt;a href=\&quot;https://radar.cloudflare.com/traffic/as63526?dateStart=2024-07-26&amp;dateEnd=2024-07-27\&quot;&gt;AS63526 (Carnival Internet)&lt;/a&gt; and &lt;a href=\&quot;https://radar.cloudflare.com/traffic/as58715?dateStart=2024-07-26&amp;dateEnd=2024-07-27\&quot;&gt;AS58715 (Earth Telecommunication)&lt;/a&gt; began to increase around 06:00 local time (00:00 UTC) on July 27, with these providers apparently included in a later phase of broadband restoration. However, traffic on mobile providers did not begin to recover until &lt;a href=\&quot;https://www.tbsnews.net/bangladesh/mobile-data-be-restored-3pm-today-palak-904901\&quot;&gt;around 15:00 local time&lt;/a&gt; (09:00 UTC) on July 28, with &lt;a href=\&quot;https://radar.cloudflare.com/traffic/as24389?dateStart=2024-07-26&amp;dateEnd=2024-07-28\&quot;&gt;AS24389 (Grameenphone)&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/traffic/as45245?dateStart=2024-07-26&amp;dateEnd=2024-07-28\&quot;&gt;AS45245 (Banglalink)&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/traffic/as24432?dateStart=2024-07-26&amp;dateEnd=2024-07-28\&quot;&gt;AS24432 (Robi Axiata)&lt;/a&gt;, all seeing traffic starting to grow significantly at or slightly after that time.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;syria\&quot;&gt;Syria&lt;/h3&gt;\n            &lt;a href=\&quot;#syria\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Unfortunately, Syria is no stranger to Internet shutdowns, as they occur yearly during nationwide exams, implemented with the intent of preventing cheating on those exams. Our recent blog post titled &lt;a href=\&quot;http://blog.cloudflare.com/syria-iraq-algeria-exam-internet-shutdown\&quot;&gt;&lt;i&gt;Exam-ining recent Internet shutdowns in Syria, Iraq, and Algeria&lt;/i&gt;&lt;/a&gt; examined the first round of 2024 exams, which took place between May 26 and June 13. A second round of exams, and with them, multi-hour Internet shutdowns, began on July 25, and seen in the schedules below, &lt;a href=\&quot;https://www.facebook.com/photo/?fbid=862569062570288&amp;set=a.449047400589125\&quot;&gt;published by Syrian Telecom on its Facebook page&lt;/a&gt; (English translation via Google Lens). &lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5RQy6gdlWDOWyylCczdt3v/9748be3bd7e7d8281f960f5fa27b78fb/14.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;2116\&quot; height=\&quot;956\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;The Internet shutdowns implemented for the first four days of tests are clearly visible in the graph below, occurring on July 25, 28, 29, and 30. &lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/30SW8L7XEco9ql905icJrJ/6046e1aa4d2bbdd183d2058a699827c9/15.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/12xtbn8XSMOC5KQKan7TDd/0ff3024b0a9dab8b91b4f0c170d0d3e2/16.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;However, you will also note another disruption is visible in both Syria’s Internet traffic and announced IP address space shortly after the planned shutdown on July 30. According to a (translated) &lt;a href=\&quot;https://www.facebook.com/photo?fbid=868145108679350&amp;set=a.449047403922458\&quot;&gt;Facebook post from Syrian Telecom&lt;/a&gt;, “&lt;i&gt;while performing regular maintenance on one of the air conditioners located in one of the technical halls [data centers], an explosion occurred, causing the Internet circuits to temporarily go out of service.&lt;/i&gt;” This issue resulted in a disruption lasting approximately eight hours, between 11:00 - 19:00 local time (08:00 - 16:00 UTC) seen in both &lt;a href=\&quot;https://radar.cloudflare.com/traffic/as29256?dateStart=2024-07-30&amp;dateEnd=2024-07-30\&quot;&gt;traffic&lt;/a&gt; and &lt;a href=\&quot;https://radar.cloudflare.com/routing/as29256?dateStart=2024-07-30&amp;dateEnd=2024-07-30\&quot;&gt;announced IP address space&lt;/a&gt; graphs for AS29256 (Syrian Telecom).&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6vuBJeQridjrHlxZ83RNQf/f7b4b3fe98309bb1fabf6383163a8245/17.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2j5b6kzwlPDAMs54GEQkqa/6dc42fa8eba4749912039d50894eb64e/18.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;pakistan\&quot;&gt;Pakistan&lt;/h3&gt;\n            &lt;a href=\&quot;#pakistan\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Closing out the month, on July 31, Pakistan experienced a wide-scale Internet disruption that lasted approximately two hours, between 13:30 - 15:30 local time (08:30 - 10:30 UTC). Traffic only dropped ~45% at a country level, but &lt;a href=\&quot;https://radar.cloudflare.com/as17557\&quot;&gt;AS17557 (PTCL)&lt;/a&gt; experienced a near complete loss of traffic, while traffic at &lt;a href=\&quot;https://radar.cloudflare.com/as24499\&quot;&gt;AS24499 (Telenor Pakistan)&lt;/a&gt; dropped nearly 90%. Together, the two network providers serve an estimated nine million users, and are among the top five Internet service providers in the country.&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6BndoxddFfzJYBXPn0VigV/81b24ada71457970c7a3870e4411592d/19.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4F1LGoTsDivOYRlqCaDZ0y/e6cda3a549c42e5003c8b6b4f7307bcf/20.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4ZMgn7gN9IypTZgvQF2EoN/2c6cacdcfc23d724d9e83a44a5a446f0/21.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;It was &lt;a href=\&quot;https://www.globalvillagespace.com/internet-outage-in-pakistan/\&quot;&gt;reported&lt;/a&gt; that the Pakistan Telecommunication Authority (PTA) attributed the disruptions to a technical glitch in the international submarine cable affecting the Pakistan Telecommunication Company Limited (PTCL) network. However, another &lt;a href=\&quot;https://incpak.com/national/internet-services-outtage-across-pakistan/\&quot;&gt;published report&lt;/a&gt; noted “&lt;i&gt;According to our sources, the government’s latest firewall edition to block the content was misconfigured, resulting in Internet connectivity disruption.&lt;/i&gt;” (Some additional information about the firewall can be found in &lt;a href=\&quot;https://www.dawn.com/news/1847040\&quot;&gt;this article&lt;/a&gt;.) The graphs below are from forthcoming TCP reset/timeout data on Cloudflare Radar, and show increased numbers of connections terminating immediately after the initial synchronization (SYN) packet used to establish new TCP connections (“&lt;a href=\&quot;https://developers.cloudflare.com/radar/glossary/#tcp-resets-and-timeouts\&quot;&gt;Post SYN&lt;/a&gt;”) between 13:30 - 15:30 local time (08:30 - 10:30 UTC) on PTCL and Telenor Pakistan, coincident with the observed disruption. In other words, the rate of SYN packets arriving at Cloudflare was mostly consistent during the disruption, but there was a drop in other TCP packets, suggesting that the firewall explanation may be plausible. A &lt;a href=\&quot;https://www.facebook.com/PTAOfficialPK/posts/pfbid0VR44dAeAbo4ciChBVWzxUSkkxR3XGPmjppwJbV7UxsNStqiPMAtRpf7QtdcWq5tAl\&quot;&gt;Facebook post&lt;/a&gt; from the Pakistan Telecommunication Authority (PTA) simply highlighted that the issue had been resolved, and that “&lt;i&gt;The exact issue is being investigated by PTA to avoid such instances in future.&lt;/i&gt;”&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/58LZktG6qGk0TjMbezTqnb/c3e8181067abfcfe1da4c153976ba51d/22.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;811\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1byG7WW6C8hihGsVI4A99X/c8a9e3d3fd634b2e9574d08a6924d721/23.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;811\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;Regardless of the actual cause, the disruption had a clear impact on the country’s financial markets, with a &lt;a href=\&quot;https://www.thenews.com.pk/print/1215321-kse-100-loses-740-points-amid-nationwide-internet-outage\&quot;&gt;published report&lt;/a&gt; stating “&lt;i&gt;The KSE-100 index suffered a sharp decline on Wednesday, plummeting over 740 points in the final hour of trading amid a nationwide internet outage. Analysts attributed the sudden drop to panic selling as investors struggled with limited market data.&amp;quot;&lt;/i&gt;&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;venezuela\&quot;&gt;Venezuela&lt;/h3&gt;\n            &lt;a href=\&quot;#venezuela\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;In the past, some countries have implemented government-directed Internet shutdowns as a means of limiting communication about or organizing of protests and demonstrations associated with contested elections. Although such protests and demonstrations sprang up in the wake of a &lt;a href=\&quot;https://apnews.com/article/venezuela-presidential-election-maduro-machado-edmundo-results-acee6c8cd3a8fc88086c2dd71963b759\&quot;&gt;contested presidential election in Venezuela&lt;/a&gt; that took place on July 28, Internet shutdowns did not follow. However, in monitoring Internet traffic in Venezuela during the days around the election, the Cloudflare Radar team did observe several notable drops in traffic, as compared to the same times the week prior. After &lt;a href=\&quot;https://x.com/CloudflareRadar/status/1817968310191038670\&quot;&gt;surging 35%&lt;/a&gt; at 05:00 local time (09:00 UTC) on Sunday, July 28 (election day), traffic dropped after the polls opened, down by as much as 23% at 09:00 local time (13:00 UTC). &lt;a href=\&quot;https://x.com/CloudflareRadar/status/1818218146903236799\&quot;&gt;On July 29&lt;/a&gt;, the day following the election, traffic was as much as 28% lower than the same time the previous week at 06:15 local time (10:15 UTC) and 18:45 local time (22:45 UTC).&lt;/p&gt;\n          &lt;figure class=\&quot;kg-card kg-image-card\&quot;&gt;\n          &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/OiQJTVdPCUpORBVXlj2AW/3a8a7da8ab550fa71675fb0fe1b1b3a7/24.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;515\&quot; loading=\&quot;lazy\&quot;/&gt;\n          &lt;/figure&gt;&lt;p&gt;And while the observed drops in traffic appeared to be organic, and not caused by an Internet shutdown, it is worth noting that multiple websites are being blocked in Venezuela. An &lt;a href=\&quot;https://pulse.internetsociety.org/blog/internet-censorship-verging-on-service-blocking-ahead-of-venezuela-elections\&quot;&gt;Internet Society Pulse blog post&lt;/a&gt;, published two days ahead of the election, reports that “&lt;i&gt;Around 60 websites are currently blocked in Venezuela, including eight media sites and three that fact-check news and misinformation.&lt;/i&gt;”, citing data from the &lt;a href=\&quot;https://explorer.ooni.org/chart/mat?test_name=web_connectivity&amp;axis_x=measurement_start_day&amp;since=2024-07-01&amp;until=2024-07-26&amp;time_grain=day&amp;probe_cc=VE&amp;axis_y=domain\&quot;&gt;Open Observatory of Network Interference (OONI)&lt;/a&gt;.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;conclusion\&quot;&gt;Conclusion&lt;/h3&gt;\n            &lt;a href=\&quot;#conclusion\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Visit &lt;a href=\&quot;https://radar.cloudflare.com/\&quot;&gt;Cloudflare Radar&lt;/a&gt; for additional insights around Internet disruptions, routing issues, Internet traffic trends, security and attacks, and Internet quality. Follow us on social media at &lt;a href=\&quot;https://x.com/CloudflareRadar\&quot;&gt;@CloudflareRadar&lt;/a&gt; (X), &lt;a href=\&quot;https://noc.social/@cloudflareradar\&quot;&gt;noc.social/@cloudflareradar&lt;/a&gt; (Mastodon), and &lt;a href=\&quot;https://bsky.app/profile/radar.cloudflare.com\&quot;&gt;radar.cloudflare.com&lt;/a&gt; (Bluesky), or contact us &lt;a href=\&quot;mailto:radar@cloudflare.com\&quot;&gt;via email&lt;/a&gt;.&lt;/p&gt;&quot;],&quot;published_at&quot;:[0,&quot;2024-08-01T15:21+00:00&quot;],&quot;updated_at&quot;:[0,&quot;2024-10-09T23:05:35.668Z&quot;],&quot;feature_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7xdwlnhDhydbJal5EyABTh/76505bc778257df9822efc07bfa7afcd/image25.png&quot;],&quot;tags&quot;:[1,[[0,{&quot;id&quot;:[0,&quot;sBnaK06GQyzaHg5OdsV90&quot;],&quot;name&quot;:[0,&quot;Internet Shutdown&quot;],&quot;slug&quot;:[0,&quot;internet-shutdown&quot;]}],[0,{&quot;id&quot;:[0,&quot;5kZtWqjqa7aOUoZr8NFGwI&quot;],&quot;name&quot;:[0,&quot;Radar&quot;],&quot;slug&quot;:[0,&quot;cloudflare-radar&quot;]}],[0,{&quot;id&quot;:[0,&quot;0kgHdg1ytbdWl5BNo6bEa&quot;],&quot;name&quot;:[0,&quot;Internet Traffic&quot;],&quot;slug&quot;:[0,&quot;internet-traffic&quot;]}],[0,{&quot;id&quot;:[0,&quot;4yliZlpBPZpOwBDZzo1tTh&quot;],&quot;name&quot;:[0,&quot;Outage&quot;],&quot;slug&quot;:[0,&quot;outage&quot;]}],[0,{&quot;id&quot;:[0,&quot;sBnaK06GQyzaHg5OdsV90&quot;],&quot;name&quot;:[0,&quot;Internet Shutdown&quot;],&quot;slug&quot;:[0,&quot;internet-shutdown&quot;]}]]],&quot;relatedTags&quot;:[0],&quot;authors&quot;:[1,[[0,{&quot;name&quot;:[0,&quot;David Belson&quot;],&quot;slug&quot;:[0,&quot;david-belson&quot;],&quot;bio&quot;:[0,null],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/en7vkXf6rLBm4F8IcNHXT/645022bf841fabff7732aa3be3949808/david-belson.jpeg&quot;],&quot;location&quot;:[0,null],&quot;website&quot;:[0,null],&quot;twitter&quot;:[0,&quot;@dbelson&quot;],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}]]],&quot;meta_description&quot;:[0,&quot;Cloudflare Radar is constantly monitoring the Internet for widespread disruptions. In mid-July, we published our Q2 2024 Internet Disruption Summary, and here we examine several recent noteworthy disruptions detected in the first month of Q3, including traffic anomalies observed in Bangladesh, Syria, Pakistan, and Venezuela.&quot;],&quot;primary_author&quot;:[0,{}],&quot;localeList&quot;:[0,{&quot;name&quot;:[0,&quot;Loc - A recent spate of Internet disruptions&quot;],&quot;enUS&quot;:[0,&quot;English for Locale&quot;],&quot;zhCN&quot;:[0,&quot;Translated for Locale&quot;],&quot;zhHansCN&quot;:[0,&quot;No Page for Locale&quot;],&quot;zhTW&quot;:[0,&quot;Translated for Locale&quot;],&quot;frFR&quot;:[0,&quot;Translated for Locale&quot;],&quot;deDE&quot;:[0,&quot;Translated for Locale&quot;],&quot;itIT&quot;:[0,&quot;No Page for Locale&quot;],&quot;jaJP&quot;:[0,&quot;Translated for Locale&quot;],&quot;koKR&quot;:[0,&quot;Translated for Locale&quot;],&quot;ptBR&quot;:[0,&quot;Translated for Locale&quot;],&quot;esLA&quot;:[0,&quot;No Page for Locale&quot;],&quot;esES&quot;:[0,&quot;Translated for Locale&quot;],&quot;enAU&quot;:[0,&quot;No Page for Locale&quot;],&quot;enCA&quot;:[0,&quot;No Page for Locale&quot;],&quot;enIN&quot;:[0,&quot;No Page for Locale&quot;],&quot;enGB&quot;:[0,&quot;No Page for Locale&quot;],&quot;idID&quot;:[0,&quot;No Page for Locale&quot;],&quot;ruRU&quot;:[0,&quot;No Page for Locale&quot;],&quot;svSE&quot;:[0,&quot;No Page for Locale&quot;],&quot;viVN&quot;:[0,&quot;No Page for Locale&quot;],&quot;plPL&quot;:[0,&quot;No Page for Locale&quot;],&quot;arAR&quot;:[0,&quot;No Page for Locale&quot;],&quot;nlNL&quot;:[0,&quot;No Page for Locale&quot;],&quot;thTH&quot;:[0,&quot;No Page for Locale&quot;],&quot;trTR&quot;:[0,&quot;No Page for Locale&quot;],&quot;heIL&quot;:[0,&quot;No Page for Locale&quot;],&quot;lvLV&quot;:[0,&quot;No Page for Locale&quot;],&quot;etEE&quot;:[0,&quot;No Page for Locale&quot;],&quot;ltLT&quot;:[0,&quot;No Page for Locale&quot;]}],&quot;url&quot;:[0,&quot;https://blog.cloudflare.com/a-recent-spate-of-internet-disruptions-july-2024&quot;],&quot;metadata&quot;:[0,{&quot;title&quot;:[0],&quot;description&quot;:[0],&quot;imgPreview&quot;:[0,&quot;&quot;]}],&quot;publicly_index&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;5ka42ShR5MS2QH9vV2Dpn&quot;],&quot;title&quot;:[0,&quot;Q2 2024 Internet disruption summary&quot;],&quot;slug&quot;:[0,&quot;q2-2024-internet-disruption-summary&quot;],&quot;excerpt&quot;:[0,&quot;Government directed shutdowns and cable cuts were both significant sources of Internet outages in Q2 2024. This post explores these disruptions, as well as others caused by power outages, maintenance, technical problems, military action, and unknown causes&quot;],&quot;featured&quot;:[0,false],&quot;html&quot;:[0,&quot;&lt;p&gt;&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/13osnhr90gaeVDq8cqWvrT/8db883d01943aef26c2387ec4bf956b0/radar-report.png\&quot; alt=\&quot;Q2 2024 Internet disruption summary\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;901\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;Cloudflare’s network spans more than 320 cities in over 120 countries, where we interconnect with over 13,000 network providers in order to provide a broad range of services to millions of customers. The breadth of both our network and our customer base provides us with a unique perspective on Internet resilience, enabling us to observe the impact of Internet disruptions. Thanks to &lt;a href=\&quot;https://radar.cloudflare.com/\&quot;&gt;Cloudflare Radar&lt;/a&gt; functionality released earlier this year, we can explore the impact from a &lt;a href=\&quot;https://developers.cloudflare.com/radar/glossary/#bgp-announcements\&quot;&gt;routing&lt;/a&gt; perspective, as well as a traffic perspective, at both a &lt;a href=\&quot;https://twitter.com/CloudflareRadar/status/1768654743742579059\&quot;&gt;network&lt;/a&gt; and &lt;a href=\&quot;https://twitter.com/CloudflareRadar/status/1773704264650543416\&quot;&gt;location&lt;/a&gt; level.&lt;/p&gt;&lt;p&gt;As we have seen in previous years, nationwide exams take place across several MENA countries in the second quarter, and with them come &lt;a href=\&quot;#governmentdirected\&quot;&gt;government directed Internet shutdowns&lt;/a&gt;. &lt;a href=\&quot;#cablecuts\&quot;&gt;Cable cuts&lt;/a&gt;, both terrestrial and submarine, caused Internet outages across a number of countries, with the ACE submarine cable being a particular source of problems. &lt;a href=\&quot;#maintenance\&quot;&gt;Maintenance&lt;/a&gt;, &lt;a href=\&quot;#poweroutages\&quot;&gt;power outages&lt;/a&gt;, and &lt;a href=\&quot;#technicalproblems\&quot;&gt;technical problems&lt;/a&gt; also disrupted Internet connectivity, as did &lt;a href=\&quot;#unknown\&quot;&gt;unknown&lt;/a&gt; issues. And as we have frequently seen in the two-plus years since the conflict began, Internet connectivity in Ukraine suffers as a result of Russian &lt;a href=\&quot;#attacks\&quot;&gt;attacks&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;As we have noted in the past, this post is intended as a summary overview of observed disruptions, and is not an exhaustive or complete list of issues that have occurred during the quarter.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;h2 id=\&quot;governmentdirected\&quot;&gt;Government directed&lt;/h2&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;syria-algeria-iraq\&quot;&gt;Syria, Algeria, Iraq&lt;/h3&gt;\n            &lt;a href=\&quot;#syria-algeria-iraq\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Each spring, governments in several countries in the Middle East and North Africa (MENA) region order local telecommunications providers to shut down or disrupt Internet connectivity across the country in an effort to prevent students from cheating on national secondary and high school exams. These shutdowns/disruptions generally occur for several hours per day over a multi-week period. We covered such events in &lt;a href=\&quot;/exam-internet-shutdowns-iraq-algeria\&quot;&gt;2023&lt;/a&gt;, &lt;a href=\&quot;/syria-sudan-algeria-exam-internet-shutdown\&quot;&gt;2022&lt;/a&gt;, and &lt;a href=\&quot;/syria-exam-related-internet-shutdowns/\&quot;&gt;2021&lt;/a&gt;, as they occurred in locations including Syria, Sudan, Algeria, and Iraq.&lt;/p&gt;&lt;p&gt;In June, we published &lt;a href=\&quot;/syria-iraq-algeria-exam-internet-shutdown\&quot;&gt;&lt;i&gt;Exam-ining recent Internet shutdowns in Syria, Iraq, and Algeria&lt;/i&gt;&lt;/a&gt;, which examined the daily Internet shutdowns that took place in Iraq and Syria, as well as the two multi-hour daily disruptions in Algeria, which appeared to be pursuing a content blocking strategy, rather than a full nationwide shutdown. The post examined the impact that these shutdowns have on Internet traffic, and also analyzed routing information and traffic from other Cloudflare services in an effort to better understand how these shutdowns are being implemented.&lt;/p&gt;&lt;p&gt;In addition to the shutdowns covered in the previously referenced blog post, Iraq implemented a second round of shutdowns that started on June 23, and ran through at least July 14. Some of these shutdowns impacted the same set of networks seen in the first round, and some impacted networks in the autonomous Kurdistan region in the north.&lt;/p&gt;&lt;p&gt;Among the latter set, &lt;a href=\&quot;https://radar.cloudflare.com/as206206\&quot;&gt;AS206206 (Kurdistan Net)&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as59625\&quot;&gt;AS59625 (Korek Telecom)&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as48492\&quot;&gt;AS48492 (IQ-Online)&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/as21277\&quot;&gt;AS21277 (Newroz Telecom)&lt;/a&gt; all implemented shutdowns on June 23, June 26, June 30, July 3, July 7, and July 10, between 06:00 - 08:00 local time (03:00 - 05:00 UTC).&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-06-23&amp;dateEnd=2024-07-14&amp;location=as206206&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n\n&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-06-23&amp;dateEnd=2024-07-14&amp;location=as59625&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n\n&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-06-23&amp;dateEnd=2024-07-14&amp;location=as48492&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n\n&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-06-23&amp;dateEnd=2024-07-14&amp;location=as21277&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n&lt;!--kg-card-end: html--&gt;&lt;p&gt;Outside the autonomous Kurdistan region, networks including &lt;a href=\&quot;https://radar.cloudflare.com/as59588\&quot;&gt;AS59588 (Zainas)&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as199739\&quot;&gt;AS199739 (Earthlink)&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as203214\&quot;&gt;AS203214 (HulumTele)&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as51684\&quot;&gt;AS51684 (Asiacell)&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/as58322\&quot;&gt;AS58322 (Halasat)&lt;/a&gt; implemented Internet shutdowns between 06:00 - 08:00 local time (03:00 - 05:00 UTC) on June 23, June 24, June 26, June 27, June 29, June 30, July 1, and July 2.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-06-23&amp;dateEnd=2024-07-07&amp;location=as59588&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n\n&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-06-23&amp;dateEnd=2024-07-07&amp;location=as199739&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n\n&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-06-23&amp;dateEnd=2024-07-07&amp;location=as203214&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n\n&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-06-23&amp;dateEnd=2024-07-07&amp;location=as51684&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n\n&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-06-23&amp;dateEnd=2024-07-07&amp;location=as58322&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;&lt;p&gt;Both sets of shutdowns reviewed above appeared to have followed the same approach as the first round covered in the earlier blog post.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;kenya-burundi-uganda-rwanda-tanzania\&quot;&gt;Kenya, Burundi, Uganda, Rwanda, Tanzania&lt;/h3&gt;\n            &lt;a href=\&quot;#kenya-burundi-uganda-rwanda-tanzania\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Concerns over a potential Internet shutdown during planned protests against tax increases proposed in “&lt;a href=\&quot;https://en.wikipedia.org/wiki/Kenya_Finance_Bill_2024\&quot;&gt;Finance Bill 2024&lt;/a&gt;” by the Kenyan government led to the publication of a joint statement signed by multiple organizations. The statement strongly urged the Kenyan government to refrain from enforcing any&lt;/p&gt;&lt;p&gt;Internet shutdowns or information controls, and highlighted the “disastrous economic effects” such a move could have. In response, the Communications Authority of Kenya &lt;a href=\&quot;https://x.com/CA_Kenya/status/1805311316719993274\&quot;&gt;issued a press release&lt;/a&gt; stating that “&lt;i&gt;For the avoidance of doubt, the Authority has no intention whatsoever to shut down Internet traffic or interfere with the quality of connectivity. Such actions would be a betrayal of the Constitution as a whole, the freedom of expression in particular and our own ethos.&lt;/i&gt;”&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/18VUH92c3DCiuL6Tlb9Ex1/d19d8a28302c53690fdd7ee8904d85d1/10.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1131\&quot; height=\&quot;1096\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;As &lt;a href=\&quot;https://en.wikipedia.org/wiki/Kenya_Finance_Bill_protests\&quot;&gt;protests escalated&lt;/a&gt; on June 25, Internet traffic in &lt;a href=\&quot;https://radar.cloudflare.com/ke\&quot;&gt;Kenya&lt;/a&gt; dropped at 16:30 local time (13:30 UTC). Initially, this outage was thought to be due to issues with &lt;a href=\&quot;https://www.submarinecablemap.com/country/kenya\&quot;&gt;one or more undersea cables&lt;/a&gt; that provide international connectivity to the country, with the potential cause supported by social media posts from &lt;a href=\&quot;https://x.com/SafaricomPLC/status/1805615681951375595\&quot;&gt;Safaricom&lt;/a&gt; and &lt;a href=\&quot;https://x.com/AIRTEL_KE/status/1805635373680193836\&quot;&gt;Airtel&lt;/a&gt;.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-06-25&amp;dateEnd=2024-06-25&amp;location=ke&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4nseWjxCypENox62FqSzFt/ca5f0eb0e634fca9597c1482b0834459/Screenshot-2024-07-14-at-10.56.25-PM.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1212\&quot; height=\&quot;632\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;Similar concurrent drops in Internet traffic were observed in &lt;a href=\&quot;https://radar.cloudflare.com/bi\&quot;&gt;Burundi&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/ug\&quot;&gt;Uganda&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/rw\&quot;&gt;Rwanda&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/tz\&quot;&gt;Tanzania&lt;/a&gt;, as shown below. Issues with submarine cables connected to one country can impact Internet connectivity in other countries if there is a dependency on that country/cable for upstream Internet connectivity. As such, the observed disruptions in those four countries were not that unusual. To that end, a (subsequently deleted) &lt;a href=\&quot;https://twitter.com/mtnug/status/1805707549385044057\&quot;&gt;post on X from MTN Uganda&lt;/a&gt; noted: &amp;quot;&lt;i&gt;Our esteemed customers, We are experiencing a degraded service on all our internet services due to an outage caused by our connectivity supply through Kenya. Our technical teams and partners are working jointly to resolve the issue in the shortest time possible. In the interim, we kindly advise our customers to use *165# to access Mobile Money and other app based services. Thank you.&lt;/i&gt;&amp;quot;&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-06-25&amp;dateEnd=2024-06-25&amp;location=bi&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n\n&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-06-25&amp;dateEnd=2024-06-25&amp;location=ug&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n\n&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-06-25&amp;dateEnd=2024-06-25&amp;location=rw&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n\n&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-06-25&amp;dateEnd=2024-06-25&amp;location=tz&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;\n&lt;!--kg-card-end: html--&gt;&lt;p&gt;However, other participants in the Internet infrastructure community in Africa called the undersea cable outage explanation into question. Kyle Spencer, Executive Director of the &lt;a href=\&quot;https://www.uixp.co.ug/\&quot;&gt;Uganda Internet eXchange Point&lt;/a&gt;, &lt;a href=\&quot;https://x.com/kyleville/status/1805614461190906295\&quot;&gt;posted on X&lt;/a&gt; that “&lt;i&gt;I am told the Kenyan government ordered sea cable landing stations to disconnect circuits.&lt;/i&gt;” Ben Roberts, Group CTIO at &lt;a href=\&quot;https://liquid.tech/\&quot;&gt;Liquid Intelligent Technologies&lt;/a&gt; (a pan-African network infrastructure provider), &lt;a href=\&quot;https://x.com/benliquidkenya/status/1805851264082751756\&quot;&gt;posted&lt;/a&gt; “&lt;i&gt;No cables are damaged this week.&lt;/i&gt;” In addition, outages on undersea cables are rarely, if ever, resolved in a matter of hours, as this disruption was – they frequently last for days or weeks.&lt;/p&gt;&lt;p&gt;On June 26, Safaricom’s CEO &lt;a href=\&quot;https://www.standardmedia.co.ke/sports/business/article/2001497896/why-there-was-network-outage-during-protests-safaricom-ceo-explains\&quot;&gt;claimed&lt;/a&gt; “This outage was occasioned by reduced bandwidth on some cables that carry Internet traffic”, contradicting the company’s original claim. No additional information was forthcoming from Airtel or the Communications Authority of Kenya, but as noted above, some within the industry believe that the disruption that impacted connectivity in Kenya, Burundi, Uganda, Rwanda, and Tanzania was directed by the government of Kenya, and was not caused by submarine cable outages.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;h2 id=\&quot;cablecuts\&quot;&gt;Cable cuts&lt;/h2&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;haiti\&quot;&gt;Haiti&lt;/h3&gt;\n            &lt;a href=\&quot;#haiti\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;At 17:36 local time (21:36 UTC) on April 28, &lt;a href=\&quot;https://x.com/DigicelHT/status/1784698298290376936\&quot;&gt;Digicel Haiti posted an “important note” on X&lt;/a&gt; that stated in part (translated) “&lt;i&gt;On April 27, 2024, the company suffered several attacks on its international optical infrastructure in the Drouya area on National Road #1. The optical fiber was damaged by the impact of cartridges after the armed clashes in the area for a few days. It affected several services such as internet (data), SMS, MonCash and international calling. For now, we are happy to inform the population that all services are restored to 100%.&lt;/i&gt;” The graph below shows the impact of the fiber damage, &lt;a href=\&quot;https://radar.cloudflare.com/as27653\&quot;&gt;with AS27653 (Digicel Haiti)&lt;/a&gt; suffering an Internet outage lasting nearly 24 hours, from around 17:30 local time (21:30 UTC) on April 27 through approximately 16:00 local time (20:00 UTC) on April 28, after which traffic quickly recovered.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-04-27&amp;dateEnd=2024-04-28&amp;location=as27653&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;&lt;p&gt;Then on May 3, The Director General of Digicel Haiti &lt;a href=\&quot;https://x.com/jpbrun30/status/1786368179440079102\&quot;&gt;posted on X&lt;/a&gt; that (translated) “&lt;i&gt;Digicel is informing the general public that it suffered two more damages to its international fiber infrastructure at 2am this morning. We have restored Moncash services, SMS, and Fiber Optic connections. Our crews are already on their way to address the apparent landslide in the Canaan area.&lt;/i&gt;” The disruption caused by this fiber damage lasted for approximately eight hours, between 02:15 - 10:30 local time (06:15 - 14:30 UTC), and as seen in the graph below, appeared to have a nominal impact on traffic.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-05-01&amp;dateEnd=2024-05-04&amp;location=ht&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;kenya-madagascar-malawi-mozambique-rwanda-tanzania-uganda\&quot;&gt;Kenya, Madagascar, Malawi, Mozambique, Rwanda, Tanzania, Uganda&lt;/h3&gt;\n            &lt;a href=\&quot;#kenya-madagascar-malawi-mozambique-rwanda-tanzania-uganda\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;On Sunday, May 12, issues with the &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/eastern-africa-submarine-system-eassy\&quot;&gt;EASSy&lt;/a&gt; and &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/seacomtata-tgn-eurasia\&quot;&gt;Seacom&lt;/a&gt; submarine cables again disrupted connectivity to East Africa, impacting a number of countries previously affected by a set of cable cuts that occurred nearly three months earlier. Insight into these earlier cable cuts and the initial impact of May’s cable damage was covered in our &lt;a href=\&quot;/east-african-internet-connectivity-again-impacted-by-submarine-cable-cuts\&quot;&gt;&lt;i&gt;East African Internet connectivity again impacted by submarine cable cuts&lt;/i&gt;&lt;/a&gt; blog post.&lt;/p&gt;&lt;p&gt;Traffic levels across a number of the impacted countries dropped just before 11:00 local time (08:00 UTC).  The magnitude of the initial impact varied by country, with traffic initially dropping by 10-25% in &lt;a href=\&quot;https://radar.cloudflare.com/traffic/ke?dateStart=2024-05-12\&quot;&gt;Kenya&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/traffic/ug?dateStart=2024-05-12\&quot;&gt;Uganda&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/traffic/mg?dateStart=2024-05-12\&quot;&gt;Madagascar&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/traffic/mz?dateStart=2024-05-12\&quot;&gt;Mozambique&lt;/a&gt;, while traffic in &lt;a href=\&quot;https://radar.cloudflare.com/traffic/rw?dateStart=2024-05-12\&quot;&gt;Rwanda&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/traffic/mw?dateStart=2024-05-12\&quot;&gt;Malawi&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/traffic/tz?dateStart=2024-05-12\&quot;&gt;Tanzania&lt;/a&gt; dropped by one-third or more than compared to the previous week. The overall impact was most significant in Tanzania, Madagascar, and Rwanda, as seen in the graphs below. Traffic returned to expected levels at various times over the following week, ranging from a day and a half later (May 13) in Kenya to a week later (May 19) in Rwanda.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-05-05&amp;dateEnd=2024-05-18&amp;location=ug&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;&lt;p&gt;Repairs to the EASSy and Seacom cables &lt;a href=\&quot;https://www.linkedin.com/posts/philippe-devaux-218423199_31may24-east-africa-eassy-seacom-subsea-activity-7202342753345650688-ll0q?utm_source=share&amp;utm_medium=member_desktop\&quot;&gt;were completed on May 31&lt;/a&gt;. Repairs to the cables damaged in February were &lt;a href=\&quot;https://www.linkedin.com/posts/philippe-devaux-218423199_09jul24-red-sea-subsea-cables-tentative-activity-7216513121945841664-towG?utm_source=share&amp;utm_medium=member_desktop\&quot;&gt;ongoing as of July 9&lt;/a&gt;, as their location in a war zone complicates repair efforts.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;chad\&quot;&gt;Chad&lt;/h3&gt;\n            &lt;a href=\&quot;#chad\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;A &lt;a href=\&quot;https://x.com/LeNdjam_Post/status/1794475979567505735\&quot;&gt;reported&lt;/a&gt; fiber optic cable cut in Cameroon disrupted Internet connectivity for customers of &lt;a href=\&quot;https://radar.cloudflare.com/as327802\&quot;&gt;Moov Africa TChad&lt;/a&gt; on May 25. The outage lasted three hours, between 15:15 -18:15 local time (14:15 - 17:15 UTC), with the impact visible at a country level as well. Routing was disrupted too, as the number of IPv4 /24 prefixes (256 IPv4 addresses) announced by Moov Africa Tchad fell from eight to three during the disruption.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/BgpRoutesTimeseriesXY?dateStart=2024-05-25&amp;dateEnd=2024-05-25&amp;location=as327802&amp;chartState=%7B%22bgpSignalsMinMax%22%3Afalse%2C%22bgpSignalsIpVersionParam%22%3A%22ipv4%22%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Announced IP Address Space\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;&lt;p&gt;The event was similar to one that &lt;a href=\&quot;https://www.facebook.com/moovafrica.td/posts/pfbid0kB9W5CkhVJqBq34agPWqG81yeCfLBijKYc6WiLDKLE79nPmhie4T9idZVStc8f6Xl\&quot;&gt;occurred on January 10&lt;/a&gt;, when Moov Africa Tchad and country-level traffic was disrupted for over 12 hours “due to a cut in the optical fiber coming from Cameroon through which Chad has access to the Internet”. During that event, significant volatility was also observed from a routing perspective, as the volume of announced IPv4 address space shifted frequently at a &lt;a href=\&quot;https://radar.cloudflare.com/routing/as327802?dateStart=2024-01-10&amp;dateEnd=2024-01-11\&quot;&gt;network&lt;/a&gt; and &lt;a href=\&quot;https://radar.cloudflare.com/routing/td?dateStart=2024-01-10&amp;dateEnd=2024-01-11\&quot;&gt;country&lt;/a&gt; level during the disruption. As we noted last quarter, as a landlocked country, Chad is dependent on terrestrial Internet connections to/through neighboring countries, and the &lt;a href=\&quot;https://afterfibre.nsrc.org/\&quot;&gt;AfTerFibre cable map&lt;/a&gt; illustrates Chad’s reliance on limited cable paths through Cameroon and Sudan.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;gambia-mauritania-senegal\&quot;&gt;Gambia, Mauritania, Senegal&lt;/h3&gt;\n            &lt;a href=\&quot;#gambia-mauritania-senegal\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;A &lt;a href=\&quot;https://x.com/CloudflareRadar/status/1798546000258417082\&quot;&gt;reported&lt;/a&gt; “network interruption” on the &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/africa-coast-to-europe-ace\&quot;&gt;Africa Coast to Europe (ACE) submarine cable&lt;/a&gt; disrupted traffic across networks in the Gambia, Mauritania, and Senegal on June 5. &lt;a href=\&quot;https://radar.cloudflare.com/as25250\&quot;&gt;AS25250 (Gamtel)&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as29544\&quot;&gt;AS29544 (Mauritel)&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/as37649\&quot;&gt;AS37649 (Free/Tigo)&lt;/a&gt; all saw traffic drop around 23:00 local time (23:00 UTC). As seen in the graphs below, the outage lasted for nearly 11 hours, with traffic recovering just 10:00 local time on June 6 (10:00 UTC). Mauritel saw a near complete outage, while Gamtel and Free/Tigo saw less severe impacts, possibly because they were able to &lt;a href=\&quot;https://x.com/Gamtel/status/1798513818873831562\&quot;&gt;shift traffic to back up links&lt;/a&gt;.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;h2 id=\&quot;maintenance\&quot;&gt;Maintenance&lt;/h2&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;guinea-gambia-sierra-leone-liberia\&quot;&gt;Guinea, Gambia, Sierra Leone, Liberia&lt;/h3&gt;\n            &lt;a href=\&quot;#guinea-gambia-sierra-leone-liberia\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Above, we discussed an unexpected network interruption on the ACE submarine cable that caused outages across multiple countries on June 5. However, two months earlier, a planned outage for repair work on the cable also disrupted connectivity across multiple African countries. A &lt;a href=\&quot;https://twitter.com/jeanfrancis/status/1777231780002615593\&quot;&gt;communiqúe&lt;/a&gt; issued by the Ministry of Posts, Telecommunications and the Digital Economy in Guinea noted in part (translated) “&lt;i&gt;...the ACE (Africa Coast to Europe) network will undergo a planned outage on April 8, 2024, between midnight and 2:00 a.m. morning in the following countries: Guinea, Senegal, Gambia, Sierra Leone and Liberia. This total outage of approximately 2 hours will affect Internet traffic and international calls.&lt;/i&gt;”&lt;/p&gt;&lt;p&gt;The graphs below show the impact to traffic in the listed countries for the planned two-hour repair window, though it appears that traffic did not return fully to expected levels after the repair window concluded – it is unclear why it remained slightly depressed. In addition, despite being listed as one of the impacted countries, no impact to traffic was observed in &lt;a href=\&quot;https://radar.cloudflare.com/sn?dateStart=2024-04-07&amp;dateEnd=2024-04-08\&quot;&gt;Senegal&lt;/a&gt;.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-04-07&amp;dateEnd=2024-04-08&amp;location=lr&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;guinea\&quot;&gt;Guinea&lt;/h3&gt;\n            &lt;a href=\&quot;#guinea\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Rounding out a trifecta of entries about the ACE submarine cable, planned maintenance work on the cable by &lt;a href=\&quot;https://guilab.com.gn/\&quot;&gt;GUILAB&lt;/a&gt; reportedly caused a multi-hour outage at &lt;a href=\&quot;https://radar.cloudflare.com/as37461\&quot;&gt;AS37461 (Orange Guinea)&lt;/a&gt; and at a country level as well, lasting from 12:15 - 15:45 local time (12:15 - 15:45 UTC). (GUILAB is the company in charge of managing the capacity allocated to Guinea on the ACE submarine cable.) The maintenance work was reported by Orange Guinea in two X posts (&lt;a href=\&quot;https://web.archive.org/web/20240601134921/https://twitter.com/orangeguinee_gn/status/1796901855705907676\&quot;&gt;1&lt;/a&gt;, &lt;a href=\&quot;https://web.archive.org/web/20240601134922/https://twitter.com/orangeguinee_gn/status/1796901858444755127\&quot;&gt;2&lt;/a&gt;), although these posts were subsequently deleted.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;h2 id=\&quot;poweroutages\&quot;&gt;Power outage&lt;/h2&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;kenya\&quot;&gt;Kenya&lt;/h3&gt;\n            &lt;a href=\&quot;#kenya\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;At 18:30 local time (15:30 UTC) on May 2, &lt;a href=\&quot;https://x.com/KenyaPower_Care/status/1786058653058961589\&quot;&gt;Kenya Power posted a “Power Outage Alert” on X&lt;/a&gt; that stated “&lt;i&gt;At 5:40 PM (EAT) today, Thursday, 2nd May 2024, we experienced a system disturbance on the grid, resulting in power supply disruption in most parts of the country.&lt;/i&gt;” The graph below shows the resultant impact on Internet connectivity in the country, with traffic dropping sharply between 17:30 - 17:45 local time (14:30 - 14:45 UTC). The drop in traffic lasted until approximately 21:30 local time (18:30 UTC), the same time that &lt;a href=\&quot;https://x.com/KenyaPower_Care/status/1786104840990437749\&quot;&gt;Kenya Power posted a “Power Supply Restoration” notice on X&lt;/a&gt;, highlighting the restoration of power to parts of the country. Although the post-outage spike seen in the graph would suggest pent-up demand for online content, a &lt;a href=\&quot;https://radar.cloudflare.com/ke?dateStart=2024-04-28&amp;dateEnd=2024-05-04\&quot;&gt;longer-term view&lt;/a&gt; of Kenya&amp;#39;s Internet traffic shows traffic peaks at the same time (22:00 local time, 19:00 UTC) during the preceding two days as well.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-05-02&amp;dateEnd=2024-05-02&amp;location=ke&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;ecuador\&quot;&gt;Ecuador&lt;/h3&gt;\n            &lt;a href=\&quot;#ecuador\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;A nationwide &lt;a href=\&quot;https://www.cnn.com/2024/06/19/americas/ecuador-nationwide-blackout-intl-latam/index.html\&quot;&gt;power outage in Ecuador on June 19&lt;/a&gt; impacted hospitals, homes, and the subway, in addition to causing a major disruption to Internet connectivity. The graph below shows Ecuador’s Internet traffic dropping sharply just after 15:00 local time (20:00 UTC). A &lt;a href=\&quot;https://x.com/RobertoLuqueN/status/1803531032978661816\&quot;&gt;post on X from Public Works Minister Roberto Luque&lt;/a&gt; explained (translated) “&lt;i&gt;The immediate report that we received from CENACE is that there is a failure in the transmission line that caused a cascade disconnection, so there is no energy service on a national scale.&lt;/i&gt;” A subsequent post pointed at a lack of investment in the underlying systems, and noted that as of 18:41 pm local time (23:41 UTC), “&lt;i&gt;95% of the energy has already been restored&lt;/i&gt;”. After the initial sharp drop, traffic began to recover fairly quickly, and was effectively back to expected levels by the stated time.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-06-19&amp;dateEnd=2024-06-20&amp;location=ec&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;albania-bosnia-montenegro\&quot;&gt;Albania, Bosnia, Montenegro&lt;/h3&gt;\n            &lt;a href=\&quot;#albania-bosnia-montenegro\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;A sudden increase in power consumption related to increased usage due to high temperatures, as well electrical systems being impacted by the heat, caused a &lt;a href=\&quot;https://www.reuters.com/world/europe/power-blackout-hits-montenegro-bosnia-albania-croatias-adriatic-coast-2024-06-21/\&quot;&gt;widespread power outage&lt;/a&gt; across Montenegro, Bosnia, and Montenegro on June 21. The outage &lt;a href=\&quot;https://www.msn.com/en-gb/news/world/several-countries-across-europe-have-been-hit-by-a-massive-power-cut/ar-BB1oDYDy\&quot;&gt;reportedly&lt;/a&gt; originated in Montenegro after a 400-kilowatt transmission line exploded. While power outages are generally more localized to a single country, or region within a country, power distribution systems are linked across Balkan countries as part of the &lt;a href=\&quot;https://international-partnerships.ec.europa.eu/policies/global-gateway/electricity-corridor-western-balkans_en\&quot;&gt;Trans-Balkan Electricity Corridor&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Published reports (&lt;a href=\&quot;https://www.msn.com/en-gb/news/world/several-countries-across-europe-have-been-hit-by-a-massive-power-cut/ar-BB1oDYDy\&quot;&gt;MSN&lt;/a&gt;, &lt;a href=\&quot;https://www.reuters.com/world/europe/power-blackout-hits-montenegro-bosnia-albania-croatias-adriatic-coast-2024-06-21/\&quot;&gt;Reuters&lt;/a&gt;) noted that electrical networks went down 12:00 - 13:00 local time (10:00 - 11:00 UTC), and that electricity suppliers in the impacted countries started restoring power by mid-afternoon, and had it largely restored by the evening. The graphs below show traffic from Albania, Bosnia, and Montenegro starting to drop around 12:00 local time (10:00 UTC), reaching its nadir in Albania and Bosnia at 12:30 local time (10:30 UTC) and at 13:00 local time (11:00 UTC) in Montenegro. Traffic recovered gradually over the next several hours as power was restored, returning to expected levels by 15:30 local time (13:30 UTC).&lt;/p&gt;&lt;p&gt;Croatia was reportedly impacted by the power outage as well, but &lt;a href=\&quot;https://radar.cloudflare.com/hr?dateStart=2024-06-21&amp;dateEnd=2024-06-21\&quot;&gt;no adverse impact to traffic&lt;/a&gt; at a country level is visible during the timeframe that connectivity in the other countries was disrupted.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;h2 id=\&quot;attacks\&quot;&gt;Military action&lt;/h2&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;ukraine\&quot;&gt;Ukraine&lt;/h3&gt;\n            &lt;a href=\&quot;#ukraine\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;During the two-plus years of the Russia-Ukraine conflict, Ukraine’s power grid has been a frequent target for Russian air attacks. When damage to Ukraine’s electrical power infrastructure occurs as a result of these attacks, Internet connectivity is also disrupted. &lt;a href=\&quot;https://apnews.com/article/ukraine-power-grid-russian-attacks-c763050237bcc1388747283bf336f8ad\&quot;&gt;Attacks on May 21&lt;/a&gt; caused power outages across a number of areas in Ukraine. The most significant impact was in Sumy, where traffic dropped as low as 82% below the previous week at 00:00 on May 22 local time (21:00 UTC). As the graphs below illustrate, traffic was also lower than the previous week for several hours in Kyiv, Kharkiv, and Vinnytsia, with traffic returning to expected levels by around 08:00 local time (05:00 UTC) on May 22.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6glDuBLv30DAkA6PoUrx3S/0bd46f992616c555f1a339f17f4202f3/11.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;438\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4pmAMdj3lv6eOeXHyB9D9Z/39888ca8908236c61a9e012bd265f4f2/12.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;447\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/640mnWgGRtUsIHSeoILNWV/63ead0b3dfc430f651eb8dcc6cd02c3f/13.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;445\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;\\&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6afAZfCn0vxaQbr81eAFGv/6bb391de75e320ac0a5f851df9733a49/14.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;434\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;!--kg-card-begin: html--&gt;&lt;h2 id=\&quot;technicalproblems\&quot;&gt;Technical problems&lt;/h2&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;malaysia\&quot;&gt;Malaysia&lt;/h3&gt;\n            &lt;a href=\&quot;#malaysia\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;As we’ve covered in previous quarterly posts, Internet outages and disruptions aren’t always due to significant wide-scale events like severe weather, power outages, or cable cuts. Sometimes more mundane technical issues can cause problems when users try to access the Internet. One example of this occurred on April 15 in Malaysia, when customers of &lt;a href=\&quot;https://radar.cloudflare.com/as9930\&quot;&gt;Time Internet&lt;/a&gt; experienced a network outage for nearly two hours. The company explained the reason for the outage in a &lt;a href=\&quot;https://www.facebook.com/TimeInternet/posts/pfbid0RbJE44cgJvxA9FQSKFTVoe4NbJBdGuwkyXjuB5URiAW78zmgS5x1V8YPUt91ym9Al\&quot;&gt;contrite post on their Facebook page&lt;/a&gt;, stating in part “&lt;i&gt;This Internet service outage was by far the worst in our history - affecting approximately 40% of our customers. … At 5.38pm today, both our primary and secondary Secure DNS servers became unreachable. This means that any browser or service requiring a DNS address resolution was not able to reach its intended site.&lt;/i&gt;” Because subscribers could not reach Time Internet’s DNS resolvers, they were unable to resolve hostnames for Internet services, sites, and applications, including those delivered by Cloudflare. This resulted in the drop in traffic seen in the graph below, which started just after 17:00 local time (05:00 UTC), and began to recover approximately an hour later. The company did not provide any additional information on what caused the DNS servers to fail.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-04-15&amp;dateEnd=2024-04-15&amp;location=as9930&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;nepal\&quot;&gt;Nepal&lt;/h3&gt;\n            &lt;a href=\&quot;#nepal\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;In Nepal, a number of local Internet service providers including &lt;a href=\&quot;https://radar.cloudflare.com/as45650\&quot;&gt;AS45650 (Vianet)&lt;/a&gt; and &lt;a href=\&quot;https://radar.cloudflare.com/as139922\&quot;&gt;AS139922 (Dishhome)&lt;/a&gt; rely on Indian provider &lt;a href=\&quot;https://radar.cloudflare.com/as9498\&quot;&gt;Bharti Airtel&lt;/a&gt; for upstream connectivity, enabling them to reach the rest of the Internet. A &lt;a href=\&quot;https://kathmandupost.com/money/2024/05/01/isps-warn-of-possible-internet-disruption\&quot;&gt;published report&lt;/a&gt; underscores the reliance, noting “&lt;i&gt;Nepali ISPs buy 70 percent of their internet from Airtel.&lt;/i&gt;”&lt;/p&gt;&lt;p&gt;On April 25, these ISPs &lt;a href=\&quot;https://www.nepalitelecom.com/latest-internet-shutdown-saga-in-nepal\&quot;&gt;warned&lt;/a&gt; that their services could be interrupted because the Nepali government had not provided them with foreign exchange services that would enable them to pay bandwidth vendors such as Airtel, whom they reportedly owed USD $30 million to. On May 1, Airtel informed the delinquent Nepali providers that Internet services may be interrupted at any time due to the overdue payment, and on May 2, Airtel took that step. The graphs below show Vianet’s traffic dropping to near zero at 16:15 local time (10:30 UTC), recovering to expected levels six hours later. An hour later, at 17:15 local time (11:30 UTC), Dishhome’s traffic dropped significantly, though not as severely as Vianet’s. Dishhome’s traffic also recovered approximately six hours later.&lt;/p&gt;&lt;p&gt;Dishhome may not have experienced a near-complete outage like Vianet did because Bharti Airtel is one of &lt;a href=\&quot;https://radar.cloudflare.com/routing/as132799?dateStart=2024-05-02&amp;dateEnd=2024-05-02\&quot;&gt;four upstream providers used by its parent company&lt;/a&gt;, whereas Bharti Airtel is &lt;a href=\&quot;https://radar.cloudflare.com/routing/as45650?dateStart=2024-05-02&amp;dateEnd=2024-05-02\&quot;&gt;one of Vianet&amp;#39;s two upstream providers&lt;/a&gt;.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-05-02&amp;dateEnd=2024-05-02&amp;location=as139922&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;&lt;p&gt;A month later, on June 3, &lt;a href=\&quot;https://radar.cloudflare.com/as45650\&quot;&gt;AS45650 (Vianet)&lt;/a&gt; and &lt;a href=\&quot;https://radar.cloudflare.com/as17501\&quot;&gt;AS17501 (Worldlink)&lt;/a&gt; in Nepal experienced Internet disruptions that were &lt;a href=\&quot;https://myrepublica.nagariknetwork.com/news/internet-slowdown-across-nepal-due-to-airtel-network-issues/\&quot;&gt;reportedly&lt;/a&gt; caused by routing issues on Bharti Airtel’s network. On Worldlink, a drop in traffic occurred between 12:15 - 14:00 local time (06:30 - 08:15 UTC), while on Vianet, the loss of traffic took place between 12:15 - 13:15 local time (06:30 - 07:30 UTC).&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;h2 id=\&quot;unknown\&quot;&gt;Unknown&lt;/h2&gt;&lt;!--kg-card-end: html--&gt;&lt;p&gt;Most of the Internet disruptions covered in this blog post series have a known root cause, whether admitted/stated by the impacted provider(s) or closely associated with a real world event (severe weather, power outage, etc.) However, other disruptions are observed and even publicized by the impacted provider, but no underlying reason for the outage is ever made public.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;malaysia\&quot;&gt;Malaysia&lt;/h3&gt;\n            &lt;a href=\&quot;#malaysia\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;On May 21, &lt;a href=\&quot;https://radar.cloudflare.com/as10030\&quot;&gt;CelcomDigi (AS10030)&lt;/a&gt; &lt;a href=\&quot;https://x.com/CelcomDigi/status/1792912132406657448\&quot;&gt;posted on X&lt;/a&gt; that it was experiencing an outage on its network, and that it was working to resolve the issue as soon as possible. However. just 12 minutes later, it &lt;a href=\&quot;https://x.com/CelcomDigi/status/1792915174468301241\&quot;&gt;published a second post&lt;/a&gt; stating that it had fully restored Celcom Internet service. These posts were made at 21:35 and 21:47 local time (13:35 and 13:47) respectively. However, as the graph below shows, traffic volumes had returned to expected levels over an hour earlier, as the observed Internet disruption on Celcom’s network lasted between 18:00 - 20:15 local time (10:00 - 12:15 UTC). (Note that the second disruption shown in the graph below was due to an internal Cloudflare data pipeline issue, and not any sort of problem with Celcom’s network.)&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-05-21&amp;dateEnd=2024-05-21&amp;location=as10030&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;starlink\&quot;&gt;Starlink&lt;/h3&gt;\n            &lt;a href=\&quot;#starlink\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;SpaceX Starlink’s satellite Internet service is unique in that it has an international subscriber base, so outages on its network have a more wide-reaching impact than issues with an ISP that covers a single country. At 01:59 UTC on May 29, &lt;a href=\&quot;https://radar.cloudflare.com/as14593\&quot;&gt;Starlink&lt;/a&gt; &lt;a href=\&quot;https://x.com/Starlink/status/1795636172972314730\&quot;&gt;shared on X&lt;/a&gt; that it was currently experiencing a network outage, and that it was actively implementing a solution. Twenty-eight minutes later, it &lt;a href=\&quot;https://x.com/Starlink/status/1795643144094285883\&quot;&gt;posted&lt;/a&gt; “&lt;i&gt;The network issue has been fully resolved.&lt;/i&gt;” This brief outage is visible in the graph below as a slight dip in traffic. However, what is particularly interesting is the spike in traffic to Cloudflare from Starlink’s network following the resolution of the outage. The sharp increase and rapid decline of the traffic curve after service was restored suggests that it may be related to an automated connectivity check of some kind, rather than pent-up user demand for content.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-05-28&amp;dateEnd=2024-05-29&amp;location=as14593&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;chad\&quot;&gt;Chad&lt;/h3&gt;\n            &lt;a href=\&quot;#chad\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;A near-complete Internet outage was observed in &lt;a href=\&quot;https://radar.cloudflare.com/td\&quot;&gt;Chad&lt;/a&gt; on June 5 between 08:15 - 12:00 local time (07:15 - 11:00 UTC), as seen in the graph below. Routing was also impacted, as the number of IPv4 /24 address blocks (256 IPv4 addresses) announced by network providers in the country dropped by as much as 75% during the outage.&lt;/p&gt;&lt;p&gt;A &lt;a href=\&quot;https://fr.apanews.net/news/tchad-linternet-coupe-pendant-des-heures/\&quot;&gt;news item covering the outage&lt;/a&gt; noted that only Starlink subscribers retained Internet access during the outage. It also noted that Chad has faced recurring Internet disruptions since 2016, either because of problems with fiber-optic cables, or due to government directed shutdowns in the name of national security. It is unclear what ultimately caused this particular outage.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/BgpRoutesTimeseriesXY?dateStart=2024-06-05&amp;dateEnd=2024-06-05&amp;location=td&amp;chartState=%7B%22bgpSignalsMinMax%22%3Afalse%2C%22bgpSignalsIpVersionParam%22%3A%22ipv4%22%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Announced IP Address Space\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;india\&quot;&gt;India&lt;/h3&gt;\n            &lt;a href=\&quot;#india\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;With an &lt;a href=\&quot;https://www.businessinsider.in/business/telecom/news/reliance-jio-and-airtel-add-nearly-5-million-subscribers-in-january-2024/articleshow/109040220.cms\&quot;&gt;estimated subscriber base in excess of over 460 million&lt;/a&gt;, any Internet disruption affecting &lt;a href=\&quot;https://radar.cloudflare.com/as55836\&quot;&gt;Reliance Jio’s network (AS55836)&lt;/a&gt; is going to have a widespread impact across India. On June 18, Reliance Jio experienced two disruptions that occurred between 13:15 - 17:15 local time (07:45 - 11:45 UTC). Each disruption lasted less than an hour, and dropped traffic levels to approximately half of those seen at the same time a week prior. &lt;a href=\&quot;https://www.editorji.com/tech-news/reliance-jio-down-big-outage-disrupts-services-1718706733637\&quot;&gt;Both mobile and fiber connectivity was affected&lt;/a&gt;, and no additional information has been provided by Reliance Jio regarding the root cause of the connectivity issues.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-06-18&amp;dateEnd=2024-06-18&amp;location=as55836&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;conclusion\&quot;&gt;Conclusion&lt;/h2&gt;\n            &lt;a href=\&quot;#conclusion\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;As we become increasingly dependent on reliable Internet connectivity, we must recognize that that connectivity is itself reliant on a complex and interconnected foundation of physical, technical, and political factors. A failure in any one of these foundational components, whether due to a cable cut, power outage, misconfiguration, or government action, can have a significant impact, disrupting Internet connectivity for millions of users, potentially across multiple countries. While the resilience and reliability of the physical and technical components can be improved through redundancy and best practices, political factors have arguably proven to be the hardest to address. However, organizations like &lt;a href=\&quot;https://www.accessnow.org/\&quot;&gt;AccessNow&lt;/a&gt;, through their &lt;a href=\&quot;https://www.accessnow.org/campaign/keepiton/\&quot;&gt;#KeepItOn&lt;/a&gt; campaign, mobilize people, communities, and civil society actors globally to fight against government-directed Internet shutdowns, which can have &lt;a href=\&quot;https://pulse.internetsociety.org/en/netloss/\&quot;&gt;significant financial consequences&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Visit &lt;a href=\&quot;https://radar.cloudflare.com/\&quot;&gt;Cloudflare Radar&lt;/a&gt; for additional insights around Internet disruptions, routing issues, Internet traffic trends, security and attacks, and Internet quality. Follow us on social media at &lt;a href=\&quot;https://x.com/CloudflareRadar\&quot;&gt;@CloudflareRadar&lt;/a&gt; (X), &lt;a href=\&quot;https://noc.social/@cloudflareradar\&quot;&gt;noc.social/@cloudflareradar&lt;/a&gt; (Mastodon), and &lt;a href=\&quot;https://bsky.app/profile/radar.cloudflare.com\&quot;&gt;radar.cloudflare.com&lt;/a&gt; (Bluesky), or &lt;a href=\&quot;mailto:radar@cloudflare.com\&quot;&gt;contact us via e-mail&lt;/a&gt;.&lt;/p&gt;&quot;],&quot;published_at&quot;:[0,&quot;2024-07-16T14:00:01.000+01:00&quot;],&quot;updated_at&quot;:[0,&quot;2024-10-09T23:28:43.791Z&quot;],&quot;feature_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4H84eq94w3v5W8NbC2Ke9P/df148eb95f8db5c16dea6450cd8fa2cb/q2-2024-internet-disruption-summary.png&quot;],&quot;tags&quot;:[1,[[0,{&quot;id&quot;:[0,&quot;5kZtWqjqa7aOUoZr8NFGwI&quot;],&quot;name&quot;:[0,&quot;Radar&quot;],&quot;slug&quot;:[0,&quot;cloudflare-radar&quot;]}],[0,{&quot;id&quot;:[0,&quot;0kgHdg1ytbdWl5BNo6bEa&quot;],&quot;name&quot;:[0,&quot;Internet Traffic&quot;],&quot;slug&quot;:[0,&quot;internet-traffic&quot;]}],[0,{&quot;id&quot;:[0,&quot;sBnaK06GQyzaHg5OdsV90&quot;],&quot;name&quot;:[0,&quot;Internet Shutdown&quot;],&quot;slug&quot;:[0,&quot;internet-shutdown&quot;]}],[0,{&quot;id&quot;:[0,&quot;5DD7GZ0oxjP3NGOaJMwyWq&quot;],&quot;name&quot;:[0,&quot;Internet Quality&quot;],&quot;slug&quot;:[0,&quot;internet-quality&quot;]}],[0,{&quot;id&quot;:[0,&quot;4yliZlpBPZpOwBDZzo1tTh&quot;],&quot;name&quot;:[0,&quot;Outage&quot;],&quot;slug&quot;:[0,&quot;outage&quot;]}],[0,{&quot;id&quot;:[0,&quot;4nA5kKyA1tOqFyjHMque21&quot;],&quot;name&quot;:[0,&quot;Consumer Services&quot;],&quot;slug&quot;:[0,&quot;consumer-services&quot;]}]]],&quot;relatedTags&quot;:[0],&quot;authors&quot;:[1,[[0,{&quot;name&quot;:[0,&quot;David Belson&quot;],&quot;slug&quot;:[0,&quot;david-belson&quot;],&quot;bio&quot;:[0,null],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/en7vkXf6rLBm4F8IcNHXT/645022bf841fabff7732aa3be3949808/david-belson.jpeg&quot;],&quot;location&quot;:[0,null],&quot;website&quot;:[0,null],&quot;twitter&quot;:[0,&quot;@dbelson&quot;],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}]]],&quot;meta_description&quot;:[0,&quot;Government directed shutdowns and cable cuts were both significant sources of Internet outages in Q2 2024. This post explores these disruptions, as well as others caused by power outages, maintenance, technical problems, military action, and unknown causes.&quot;],&quot;primary_author&quot;:[0,{}],&quot;localeList&quot;:[0,{&quot;name&quot;:[0,&quot;Q2 2024 Internet disruption summary Config&quot;],&quot;enUS&quot;:[0,&quot;English for Locale&quot;],&quot;zhCN&quot;:[0,&quot;Translated for Locale&quot;],&quot;zhHansCN&quot;:[0,&quot;No Page for Locale&quot;],&quot;zhTW&quot;:[0,&quot;Translated for Locale&quot;],&quot;frFR&quot;:[0,&quot;Translated for Locale&quot;],&quot;deDE&quot;:[0,&quot;Translated for Locale&quot;],&quot;itIT&quot;:[0,&quot;No Page for Locale&quot;],&quot;jaJP&quot;:[0,&quot;Translated for Locale&quot;],&quot;koKR&quot;:[0,&quot;Translated for Locale&quot;],&quot;ptBR&quot;:[0,&quot;No Page for Locale&quot;],&quot;esLA&quot;:[0,&quot;No Page for Locale&quot;],&quot;esES&quot;:[0,&quot;Translated for Locale&quot;],&quot;enAU&quot;:[0,&quot;No Page for Locale&quot;],&quot;enCA&quot;:[0,&quot;No Page for Locale&quot;],&quot;enIN&quot;:[0,&quot;No Page for Locale&quot;],&quot;enGB&quot;:[0,&quot;No Page for Locale&quot;],&quot;idID&quot;:[0,&quot;No Page for Locale&quot;],&quot;ruRU&quot;:[0,&quot;No Page for Locale&quot;],&quot;svSE&quot;:[0,&quot;No Page for Locale&quot;],&quot;viVN&quot;:[0,&quot;No Page for Locale&quot;],&quot;plPL&quot;:[0,&quot;No Page for Locale&quot;],&quot;arAR&quot;:[0,&quot;No Page for Locale&quot;],&quot;nlNL&quot;:[0,&quot;No Page for Locale&quot;],&quot;thTH&quot;:[0,&quot;No Page for Locale&quot;],&quot;trTR&quot;:[0,&quot;No Page for Locale&quot;],&quot;heIL&quot;:[0,&quot;No Page for Locale&quot;],&quot;lvLV&quot;:[0,&quot;No Page for Locale&quot;],&quot;etEE&quot;:[0,&quot;No Page for Locale&quot;],&quot;ltLT&quot;:[0,&quot;No Page for Locale&quot;]}],&quot;url&quot;:[0,&quot;https://blog.cloudflare.com/q2-2024-internet-disruption-summary&quot;],&quot;metadata&quot;:[0,{&quot;title&quot;:[0,&quot;Q2 2024 Internet disruption summary&quot;],&quot;description&quot;:[0,&quot;Government directed shutdowns and cable cuts were both significant sources of Internet outages in Q2 2024. This post explores these disruptions, as well as others caused by power outages, maintenance, technical problems, military action, and unknown causes.&quot;],&quot;imgPreview&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3QBgWM7IqD57EoeFuM74Zf/41dbd1770a4d8e7b4309ce3667b5a259/q2-2024-internet-disruption-summary-D1f42X.png&quot;]}],&quot;publicly_index&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;IyAM1csW8ynZvyJrQtmvS&quot;],&quot;title&quot;:[0,&quot;Cloudflare 1.1.1.1 incident on June 27, 2024&quot;],&quot;slug&quot;:[0,&quot;cloudflare-1111-incident-on-june-27-2024&quot;],&quot;excerpt&quot;:[0,&quot;On June 27, 2024, a small number of users globally may have noticed that 1.1.1.1 was unreachable or degraded. The root cause was a mix of BGP (Border Gateway Protocol) hijacking and a route leak&quot;],&quot;featured&quot;:[0,false],&quot;html&quot;:[0,&quot;&lt;p&gt;&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6kBrAZxRvJnPmEMCYY9KuL/b998cbe27bf1b851f48ca7c75d12d565/image2-4.png\&quot; alt=\&quot;Cloudflare 1.1.1.1 incident on June 27, 2024\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;introduction\&quot;&gt;Introduction&lt;/h2&gt;\n            &lt;a href=\&quot;#introduction\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;On June 27, 2024, a small number of users globally may have noticed that 1.1.1.1 was unreachable or degraded. The root cause was a mix of BGP (Border Gateway Protocol) &lt;a href=\&quot;https://www.cloudflare.com/learning/security/glossary/bgp-hijacking/\&quot;&gt;hijacking&lt;/a&gt; and a route leak.&lt;/p&gt;&lt;p&gt;Cloudflare was an &lt;a href=\&quot;/rpki-and-the-rtr-protocol\&quot;&gt;early adopter&lt;/a&gt; of Resource Public Key Infrastructure (RPKI) for route origin validation (ROV). With RPKI, IP prefix owners can store and share ownership information securely, and other operators can validate BGP announcements by comparing received BGP routes with what is stored in the form of Route Origin Authorizations (ROAs). When Route Origin Validation is enforced by networks properly and prefixes are signed via ROA, the impact of a BGP hijack is greatly limited. Despite increased adoption of RPKI over the past several years and 1.1.1.0/24 being a &lt;a href=\&quot;https://rpki.cloudflare.com/?view=explorer&amp;prefix=1.1.1.0%2F24\&quot;&gt;signed resource&lt;/a&gt;, during the incident 1.1.1.1/32 was originated by ELETRONET S.A. (AS267613) and accepted by multiple networks, including at least one &lt;a href=\&quot;https://en.wikipedia.org/wiki/Tier_1_network\&quot;&gt;Tier 1 provider&lt;/a&gt; who accepted 1.1.1.1/32 as a &lt;a href=\&quot;https://datatracker.ietf.org/doc/html/rfc3882\&quot;&gt;blackhole route&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;This caused immediate unreachability for the DNS resolver address from over 300 networks in 70 countries, although the impact on the overall percentage of users was quite low (less than 1% of users in the UK and Germany, for example), and in some countries no users noticed an impact.&lt;/p&gt;&lt;p&gt;Route leaks are something Cloudflare &lt;a href=\&quot;/route-leak-incident-on-october-2-2014\&quot;&gt;has written and talked about before&lt;/a&gt;, and unfortunately there are only best-effort safeguards in wide deployment today, such as IRR (Internet Routing Registry) prefix-list filtering by providers. During the same period of time as the 1.1.1.1/32 hijack, 1.1.1.0/24 was erroneously leaked upstream by Nova Rede de Telecomunicações Ltda (AS262504). The leak was further and widely propagated by Peer-1 Global Internet Exchange (AS1031), which also contributed to the impact felt by customers during the incident.&lt;/p&gt;&lt;p&gt;We apologize for the impact felt by users of 1.1.1.1, and take the operation of the service very seriously. Although the root cause of the impact was external to Cloudflare, we will continue to improve the detection methods in place to yield quicker response times, and will use our stance within the Internet community to further encourage adoption of RPKI-based hijack and leak prevention mechanisms such as Route Origin Validation (ROV) and Autonomous Systems Provider Authorization (&lt;a href=\&quot;https://datatracker.ietf.org/doc/draft-ietf-sidrops-aspa-verification/\&quot;&gt;ASPA&lt;/a&gt;) objects for BGP.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;background\&quot;&gt;Background&lt;/h2&gt;\n            &lt;a href=\&quot;#background\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;Cloudflare &lt;a href=\&quot;/announcing-1111\&quot;&gt;introduced&lt;/a&gt; the &lt;a href=\&quot;https://one.one.one.one/\&quot;&gt;1.1.1.1&lt;/a&gt; public DNS resolver service in 2018. Since the announcement, 1.1.1.1 has become one of the most popular resolver IP addresses that is free-to-use by anyone. Along with the popularity and easily recognized IP address comes some operational difficulties. The difficulties stem from &lt;a href=\&quot;https://youtu.be/vR4GbRMAWj8?si=HTH8nvxVvyLYYjF2\&quot;&gt;historical use of 1.1.1.1 by networks in labs or as a testing IP address&lt;/a&gt;, resulting in some residual unexpected traffic or blackholed routing behavior. Because of this, Cloudflare is no stranger to dealing with the effects of BGP misrouting traffic, two of which are covered below.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;bgp-hijacks\&quot;&gt;BGP hijacks&lt;/h3&gt;\n            &lt;a href=\&quot;#bgp-hijacks\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Some of the difficulty comes from potential &lt;a href=\&quot;https://www.cloudflare.com/learning/security/glossary/bgp-hijacking/\&quot;&gt;routing hijacks&lt;/a&gt; of 1.1.1.1. For example, if some fictitious FooBar Networks assigns 1.1.1.1/32 to one of their routers and shares this prefix within their internal network, their customers will have difficulty routing to the 1.1.1.1 DNS service. If they advertise the 1.1.1.1/32 prefix outside their immediate network, the impact can be even greater. The reason 1.1.1.1/32 would be selected instead of the 1.1.1.0/24 BGP-announced by Cloudflare is due to &lt;a href=\&quot;https://en.wikipedia.org/wiki/Longest_prefix_match\&quot;&gt;Longest Prefix Matching (LPM)&lt;/a&gt;. While many prefixes in a route table could match the 1.1.1.1 address, such as 1.1.1.0/24, 1.1.1.0/29, and 1.1.1.1/32, 1.1.1.1/32 is considered the “longest match” by the LPM algorithm because it has the highest number of identical bits and longest &lt;a href=\&quot;https://en.wikipedia.org/wiki/Subnet\&quot;&gt;subnet&lt;/a&gt; mask while matching the 1.1.1.1 address. In simple terms, we would call 1.1.1.1/32 the “most specific” route available to 1.1.1.1.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7n3Xe0tgkW3a2cZuVI0bAs/4d192f979294dc2f6b758994ac512b71/image4-1.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1920\&quot; height=\&quot;1080\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;Instead of traffic toward 1.1.1.1 routing to Cloudflare via anycast and landing on one of our servers globally, it will instead land somewhere on a device within FooBar Networks where 1.1.1.1 is terminated, and a legitimate response will fail to be served back to clients. This would be considered a hijack of requests to 1.1.1.1, either done purposefully or accidentally by network operators within FooBar Networks.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;bgp-route-leaks\&quot;&gt;BGP route leaks&lt;/h3&gt;\n            &lt;a href=\&quot;#bgp-route-leaks\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Another source of impact we sometimes face for 1.1.1.1 is BGP route leaks. A route leak occurs when a network becomes an upstream, in terms of BGP announcement, for a network it shouldn’t be an upstream provider for.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6Nw7KaaD49t0Drer2H1kbd/1e61b336c901e2f4b4c9cd3d70843adf/image3-2.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1920\&quot; height=\&quot;1080\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;Here is an example of a route leak where a customer forward routes learned from one provider to another, causing a type 1 leak (defined in &lt;a href=\&quot;https://www.rfc-editor.org/rfc/rfc7908.html\&quot;&gt;RFC7908&lt;/a&gt;).&lt;/p&gt;&lt;p&gt;If enough networks within the &lt;a href=\&quot;https://en.wikipedia.org/wiki/Default-free_zone\&quot;&gt;Default-Free Zone (DFZ)&lt;/a&gt; accept a route leak, it may be used widely for forwarding traffic along the &lt;i&gt;bad&lt;/i&gt; path. Often this will cause the network leaking the prefixes to overload, as they aren’t prepared for the amount of global traffic they are now attracting. We &lt;a href=\&quot;/how-verizon-and-a-bgp-optimizer-knocked-large-parts-of-the-internet-offline-today/\&quot;&gt;wrote&lt;/a&gt; about a wide-scale route leak that knocked off a large portion of the Internet, when a provider in Pennsylvania attracted traffic toward global destinations it would have typically never transited traffic for. Even though Cloudflare interconnects with over 13,000 networks globally, the BGP local-preference assigned to a leaked route could be higher than the route received by a network directly from Cloudflare. This sounds counterproductive, but unfortunately it can happen.&lt;/p&gt;&lt;p&gt;To explain why this happens, it helps to think of BGP as a business policy engine along with the routing protocol for the Internet. A transit provider has customers who pay them to transport their data, so logically they assign a higher BGP local-preference than connections with either private or Internet Exchange (IX) peers, so the connection being paid for is most utilized. Think of local-preference as a way of influencing priority of which outgoing connection to send traffic to. Different networks also may choose to prefer Private Network Interconnects (PNIs) over Internet Exchange (IX) received routes. Part of the reason for this is reliability, as a private connection can be viewed as a point-to-point connection between two networks with no third-party managed fabric in between to worry about. Another reason could be cost efficiency, as if you’ve gone to the trouble to allocate a router port and purchase a cross connect between yourself and another peer, you’d like to make use of it to get the best return on your investment.&lt;/p&gt;&lt;p&gt;It is worth noting that both BGP hijacks and route leaks can happen to any IP and prefix on the Internet, not just 1.1.1.1. But as mentioned earlier, 1.1.1.1 is such a recognizable and historically misappropriated address that it tends to be more prone to accidental hijacks or leaks than other IP resources.&lt;/p&gt;&lt;p&gt;During the Cloudflare 1.1.1.1 incident that happened on June 27, 2024, we ended up fighting the impact caused by a combination of both BGP hijacking and a route leak.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;incident-timeline-and-impact\&quot;&gt;Incident timeline and impact&lt;/h2&gt;\n            &lt;a href=\&quot;#incident-timeline-and-impact\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;All timestamps are in UTC.&lt;/p&gt;&lt;p&gt;&lt;b&gt;2024-06-27 18:51:00&lt;/b&gt; AS267613 (Eletronet) begins announcing 1.1.1.1/32 to peers, providers, and customers. 1.1.1.1/32 is announced with the AS267613 origin AS&lt;/p&gt;&lt;p&gt;&lt;b&gt;2024-06-27 18:52:00&lt;/b&gt; AS262504 (Nova) leaks 1.1.1.0/24, also received from AS267613, upstream to AS1031 (PEER 1 Global Internet Exchange) with AS path “1031 262504 267613 13335”&lt;/p&gt;&lt;p&gt;&lt;b&gt;2024-06-27 18:52:00&lt;/b&gt; AS1031 (upstream of Nova) propagates 1.1.1.0/24 to various Internet Exchange peers and route-servers, widening impact of the leak&lt;/p&gt;&lt;p&gt;&lt;b&gt;2024-06-27 18:52:00&lt;/b&gt; One tier 1 provider receives the 1.1.1.1/32 announcement from AS267613 as a RTBH (Remote Triggered Blackhole) route, causing blackholed traffic for all the tier 1’s customers&lt;/p&gt;&lt;p&gt;&lt;b&gt;2024-06-27 20:03:00&lt;/b&gt; Cloudflare raises internal incident for 1.1.1.1 reachability issues from various countries&lt;/p&gt;&lt;p&gt;&lt;b&gt;2024-06-27 20:08:00&lt;/b&gt; Cloudflare disables a partner peering location with AS267613 that is receiving traffic toward 1.1.1.0/24&lt;/p&gt;&lt;p&gt;&lt;b&gt;2024-06-27 20:08:00&lt;/b&gt; Cloudflare team engages peering partner AS267613 about the incident&lt;/p&gt;&lt;p&gt;&lt;b&gt;2024-06-27 20:10:00&lt;/b&gt; AS262504 leaks 1.1.1.0/24 with a new AS path, “262504 53072 7738 13335” which is also redistributed by AS1031. Traffic is being delivered successfully to Cloudflare when along this path, but with high latency for affected clients&lt;/p&gt;&lt;p&gt;&lt;b&gt;2024-06-27 20:17:00&lt;/b&gt; Cloudflare engages AS262504 regarding the route leak of 1.1.1.0/24 to their upstream providers&lt;/p&gt;&lt;p&gt;&lt;b&gt;2024-06-27 21:56:00&lt;/b&gt; Cloudflare engineers disable a second peering point with AS267613 that is receiving traffic meant for 1.1.1.0/24 from multiple sources not in Brazil&lt;/p&gt;&lt;p&gt;&lt;b&gt;2024-06-27 22:16:00&lt;/b&gt; AS262504 leaks 1.1.1.0/24 again, attracting some traffic to a Cloudflare peering with AS267613 in São Paulo. Some 1.1.1.1 requests as a result are returned with higher latency, but the hijack of 1.1.1.1/32 and traffic blackholing appears resolved&lt;/p&gt;&lt;p&gt;&lt;b&gt;2024-06-28 02:28:00&lt;/b&gt; AS262504 fully resolves the route leak of 1.1.1.0/24&lt;/p&gt;&lt;p&gt;The impact to customers surfaced in one of two ways: unable to reach 1.1.1.1 at all; Able to reach 1.1.1.1, but with high latency per request.&lt;/p&gt;&lt;p&gt;Since AS267613 was hijacking the 1.1.1.1/32 address somewhere within their network, many requests failed at some device in their autonomous system. There were intermittent periods, or flaps, during the incident where they successfully routed requests toward 1.1.1.1 to Cloudflare data centers, albeit with high latency.&lt;/p&gt;&lt;p&gt;Looking at two source countries during the incident, Germany and the United States, impacted traffic to 1.1.1.1 looked like this:&lt;/p&gt;&lt;p&gt;&lt;i&gt;Source Country of Users:&lt;/i&gt;&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/492JYYYPZzxjjmGk2IF5Sb/5d6762775689439de1aca2f868bf67cd/image5-1.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1426\&quot; height=\&quot;332\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;&lt;i&gt;Keep in mind that overall this may represent a relatively small amount of total requests per source country, but normally no requests would route from the US or Germany to Brazil at all for 1.1.1.1.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;Cloudflare Data Center city:&lt;/i&gt;&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/61Bq2eHhu5HZzGNcIs8tZS/4dcaa35237709fb1b9af4abfde382303/image6-1.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1426\&quot; height=\&quot;332\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;Looking at the graphs, requests to 1.1.1.1 were landing in Brazilian data centers. The gaps between the spikes are when 1.1.1.1 requests were blackholed prior to or within AS267613, and the spikes themselves are when traffic was delivered to Cloudflare with high latency invoked on the request and response. The brief spikes of traffic successfully carried to the Cloudflare peering location with AS267613 could be explained by the 1.1.1.1/32 route flapping within their network, occasionally letting traffic through to Cloudflare instead of it dropping somewhere in the intermediate path.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;technical-description-of-the-error-and-how-it-happened\&quot;&gt;Technical description of the error and how it happened&lt;/h2&gt;\n            &lt;a href=\&quot;#technical-description-of-the-error-and-how-it-happened\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;Normally, a request to 1.1.1.1 from users routes to the nearest data center via BGP anycast. During the incident, AS267613 (Eletronet) advertised 1.1.1.1/32 to their peers and upstream providers, and AS262504 leaked 1.1.1.0/24 upstream, changing the normal path of BGP anycast for multiple eyeball networks drastically.&lt;/p&gt;&lt;p&gt;With public route collectors and the &lt;a href=\&quot;https://github.com/bgpkit/monocle\&quot;&gt;monocle tool&lt;/a&gt;, we can search for the rogue BGP updates.&lt;/p&gt;\n            &lt;pre class=\&quot;language-bash\&quot;&gt;&lt;code class=\&quot;language-bash\&quot;&gt;monocle search --start-ts 2024-06-27T18:51:00Z --end-ts 2024-06-27T18:55:00Z --prefix &amp;#039;1.1.1.1/32&amp;#039;\n\nA|1719514377.130203|206.126.236.209|398465|1.1.1.1/32|398465 267613|IGP|206.126.236.209|0|0||false|||route-views.eqix\n–\nA|1719514377.681932|206.82.104.185|398465|1.1.1.1/32|398465 267613|IGP|206.82.104.185|0|0|13538:1|false|||route-views.ny\n–\nA|1719514388.996829|198.32.132.129|13760|1.1.1.1/32|13760 267613|IGP|198.32.132.129|0|0||false|||route-views.telxatl&lt;/pre&gt;&lt;/code&gt;\n            &lt;p&gt;We see above that AS398465 and AS13760 reported to the route-views collectors that they received 1.1.1.1/32 from AS267613 around the time impact begins. Normally, the longest IPv4 prefix accepted in the Default-Free-Zone (DFZ) is a /24, but in this case we observed multiple networks using the 1.1.1.1/32 route from AS267613 for forwarding, made apparent by the blackholing of traffic that never arrived at a Cloudflare POP (Point of Presence). The origination of 1.1.1.1/32 by AS267613 is a BGP route hijack. They were announcing the prefix with origin AS267613 even though the Route Origin Authorization (ROA) is only signed for origin AS13335 (Cloudflare) with a maximum prefix length of /24.&lt;/p&gt;&lt;p&gt;We even saw BGP updates for 1.1.1.1/32 when looking at our own BMP (BGP Monitoring Protocol) data at Cloudflare. From at least a couple different route servers, we received our own 1.1.1.1/32 announcement via BGP. Thankfully, Cloudflare rejects these routes on import as both RPKI Invalid and DFZ Invalid due to invalid AS origin and prefix length. The BMP data display is pre-policy, meaning even though we rejected the route we can see where we receive the BGP update over a peering session.&lt;/p&gt;&lt;p&gt;So not only are multiple networks accepting prefixes that should not exist in the global routing table, but they are also accepting an &lt;a href=\&quot;https://rpki.cloudflare.com/?view=explorer&amp;prefix=1.1.1.0%2F24\&quot;&gt;RPKI (Resource Public Key Infrastructure) Invalid route&lt;/a&gt;. To make matters worse, one Tier-1 transit provider accepted the 1.1.1.1/32 announcement as a RTBH (Remote-Triggered Blackhole) route from AS267613, discarding all traffic at their edge that would normally route to Cloudflare. This alone caused wide impact, as any networks leveraging this particular Tier-1 provider in routing to 1.1.1.1 would have been unable to reach the IP address during the incident.&lt;/p&gt;&lt;p&gt;For those unfamiliar with Remote-Triggered Blackholing, it is a method of signaling to a provider a set of destinations you would like traffic to be dropped for within their network. It exists as a blunt method of fighting off DDoS attacks. When you are being attacked on a specific IP or prefix, you can tell your upstream provider to absorb all traffic toward that destination IP address or prefix by discarding it before it comes to your network port. The problem during this incident was AS267613 was unauthorized to blackhole 1.1.1.1/32. Cloudflare only should have the sole right to leverage RTBH for discarding of traffic destined for AS13335, which is something we would in reality never do.&lt;/p&gt;&lt;p&gt;Looking now at BGP updates for 1.1.1.0/24 multiple networks received the prefix from AS262504 and accepted it.&lt;/p&gt;\n            &lt;pre class=\&quot;language-bash\&quot;&gt;&lt;code class=\&quot;language-bash\&quot;&gt;~&amp;gt; monocle search --start-ts 2024-06-27T20:10:00Z --end-ts 2024-06-27T20:13:00Z --prefix &amp;#039;1.1.1.0/24&amp;#039; --as-path &amp;quot;.* 267613 13335&amp;quot; --include-sub\n\n.. some advertisements removed for brevity ..\n\nA|1719519011.378028|187.16.217.158|1031|1.1.1.0/24|1031 262504 267613 13335|IGP|187.16.217.158|0|0|1031:1031 1031:4209 1031:6045 1031:7019 1031:8010|false|13335|162.158.177.1|route-views2.saopaulo\n–\nA|1719519011.629398|45.184.147.17|1031|1.1.1.0/24|1031 262504 267613 13335|IGP|45.184.147.17|0|0|1031:1031 1031:4209 1031:4259 1031:6045 1031:7019 1031:8010|false|13335|162.158.177.1|route-views.fortaleza\n–\nA|1719519036.943174|80.249.210.99|50763|1.1.1.0/24|50763 1031 262504 267613 13335|IGP|80.249.210.99|0|0|1031:1031 50763:400|false|13335|162.158.177.1|route-views.amsix\n–\nA|1719519037|80.249.210.99|50763|1.1.1.0/24|50763 1031 262504 267613 13335|IGP|80.249.210.99|0|0|1031:1031 50763:400|false|13335|162.158.177.1|rrc03\n–\nA|1719519087.4546|45.184.146.59|199524|1.1.1.0/24|199524 1031 262504 267613 13335|IGP|45.184.147.17|0|0||false|13335|162.158.177.1|route-views.fortaleza\nA|1719519087.464375|45.184.147.74|264409|1.1.1.0/24|264409 1031 262504 267613 13335|IGP|45.184.147.74|0|0|65100:7010|false|13335|162.158.177.1|route-views.fortaleza\n–\nA|1719519096.059558|190.15.124.18|61568|1.1.1.0/24|61568 262504 267613 13335|IGP|190.15.124.18|0|0|1031:1031 1031:4209 1031:6045 1031:7019 1031:8010|false|13335|162.158.177.1|route-views3\n–\nA|1719519128.843415|190.15.124.18|61568|1.1.1.0/24|61568 262504 267613 13335|IGP|190.15.124.18|0|0|1031:1031 1031:4209 1031:6045 1031:7019 1031:8010|false|13335|162.158.177.1|route-views3&lt;/pre&gt;&lt;/code&gt;\n            &lt;p&gt;Here we pay attention to the AS path again. This time, AS13335 is the origin AS at the very end of the announcements. This BGP announcement is RPKI &lt;b&gt;Valid&lt;/b&gt;, because the origin is correctly AS13335, but this is a route leak of 1.1.1.0/24 because the path itself is invalid.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;how-do-we-know-its-a-route-leak\&quot;&gt;How do we know it’s a route leak?&lt;/h3&gt;\n            &lt;a href=\&quot;#how-do-we-know-its-a-route-leak\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Looking at an example path, “199524 1031 262504 267613 13335”, AS267613 is functionally a peer of AS13335 and should not share the 1.1.1.0/24 announcement with their peers or upstreams, only their customers (&lt;a href=\&quot;https://www.manrs.org/wp-content/uploads/2021/11/AS-Cones-MANRS.pdf\&quot;&gt;AS Cone&lt;/a&gt;). AS262504 is a customer of AS267613 and the next adjacent ASN in the path, so that particular announcement is fine up until this point. Where the 1.1.1.0/24 goes wrong is AS262504, when they announce the prefix to their upstream AS1031. Furthermore, AS1031 redistributed the advertisement to their peers.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7fWhrQoqfJzgS7EEaK05Gw/2de5227144de75d232012c0029540af4/image1-3.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1920\&quot; height=\&quot;781\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;This means AS262504 is the leaking network. AS1031 accepted the leak from their customer, AS262504, and caused wide impact by distributing the route in multiple peering locations globally. AS1031 (Peer-1 Global Internet Exchange) advertises themselves as a global peering exchange. Cloudflare is not a customer of AS1031, so 1.1.1.0/24 should have never been redistributed to peers, route-servers, or upstreams of AS1031. It appears that AS1031 does not perform any extensive filtering for customer BGP sessions, and instead just matches on adjacency (in this case, AS262504) and redistributes everything that meets this criteria. Unfortunately, this is irresponsible of AS1031 and causes direct impact to 1.1.1.1 and potentially other services that fall victim to the unguarded route propagation. While the original leaking network was AS262504, impact was greatly amplified by AS1031 and others when they accepted the hijack or leak and further distributed the announcements.&lt;/p&gt;&lt;p&gt;During the majority of the incident, the leak by AS262504 eventually landed requests within AS267613, which was discarding 1.1.1.1/32 traffic somewhere in their network. To that end, AS262504 really just amplified the impact in terms of 1.1.1.1 unreachability by leaking routes upstream.&lt;/p&gt;&lt;p&gt;To limit impact of the route leak, Cloudflare disabled peering in multiple locations with AS267613. The problem did not completely go away, as AS262504 was still leaking a stale path pointing to São Paulo. Requests landing in São Paulo were able to be served, albeit with a high round-trip time back to users. Cloudflare has been engaging with all networks mentioned throughout this post in regard to the leak and future prevention mechanisms, as well as at least one &lt;a href=\&quot;https://en.wikipedia.org/wiki/Tier_1_network\&quot;&gt;Tier 1 transit provider&lt;/a&gt; who accepted 1.1.1.1/32 from AS267613 as a blackhole route that was unauthorized by Cloudflare and caused widespread impact.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;remediation-and-follow-up-steps\&quot;&gt;Remediation and follow-up steps&lt;/h2&gt;\n            &lt;a href=\&quot;#remediation-and-follow-up-steps\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          \n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;bgp-hijacks\&quot;&gt;BGP hijacks&lt;/h3&gt;\n            &lt;a href=\&quot;#bgp-hijacks\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;&lt;b&gt;RPKI origin validation&lt;/b&gt;RPKI has recently reached a major milestone at 50% deployment in terms of prefixes signed by Route Origin Authorization (ROA). While RPKI certainly helps limit the spread of a hijacked BGP prefix throughout the Internet, we need all networks to do their part, especially major networks with a large sum of downstream Autonomous Systems (AS’s). During the hijack of 1.1.1.1/32, multiple networks accepted and used the route announced by AS267613 for traffic forwarding.&lt;/p&gt;&lt;p&gt;&lt;b&gt;RPKI and Remote-Triggered Blackholing (RTBH)&lt;/b&gt;A significant amount of the impact caused during this incident was due to a Tier 1 provider accepting 1.1.1.1/32 as a blackhole route from a third party that is not Cloudflare. This in itself is a hijack of 1.1.1.1, and a very dangerous one. RTBH is a useful tool used by many networks when desperate for a mitigation against large DDoS attacks. The problem is the BGP filtering used for RTBH is loose in nature, relying often only on &lt;a href=\&quot;https://www.apnic.net/manage-ip/using-whois/guide/as-set/\&quot;&gt;AS-SET&lt;/a&gt; objects found in Internet Routing Registries. Relying on Route Origin Authorization (ROA) would be infeasible for RTBH filtering, as that would require thousands of potential ROAs be created for the network the size of Cloudflare. Not only this, but creating specific /32 entries opens up the potential for an individual address such as 1.1.1.1/32 being announced by someone pretending to be AS13335, becoming the best route to 1.1.1.1 on the Internet and causing severe impact.&lt;/p&gt;&lt;p&gt;AS-SET filtering is not representative of authority to blackhole a route, such as 1.1.1.1/32. Only Cloudflare should be able to blackhole a destination it has the rights to operate. A potential way to fix the lenient filtering of providers on RTBH sessions would again be leveraging an RPKI. Using an example from the IETF, the expired &lt;a href=\&quot;https://datatracker.ietf.org/doc/draft-spaghetti-sidrops-rpki-doa/\&quot;&gt;draft-spaghetti-sidrops-rpki-doa-00&lt;/a&gt; proposal specified a Discard Origin Authorization (DOA) object that would be used to authorize only specific origins to authorize a blackhole action for a prefix. If such an object was signed, and RTBH requests validated against the object, the unauthorized blackhole attempt of 1.1.1.1/32 by AS267613 would have been invalid instead of accepted by the Tier 1 provider.&lt;/p&gt;&lt;p&gt;&lt;b&gt;BGP best practices&lt;/b&gt;Simply following BGP best practices laid out by &lt;a href=\&quot;https://manrs.org/netops/guide/\&quot;&gt;MANRS&lt;/a&gt;, and rejecting IPv4 prefixes that are longer than a /24 in the Default-Free Zone (DFZ) would have reduced impact to 1.1.1.1. Rejecting invalid prefix lengths within the wider Internet should be part of a standard BGP policy for all networks.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;bgp-route-leaks\&quot;&gt;BGP route leaks&lt;/h2&gt;\n            &lt;a href=\&quot;#bgp-route-leaks\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          \n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;route-leak-detection\&quot;&gt;Route leak detection&lt;/h3&gt;\n            &lt;a href=\&quot;#route-leak-detection\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;While route leaks are not unavoidable for Cloudflare today, because the Internet inherently relies on trust for interconnection, there are some steps we will take to limit impact.&lt;/p&gt;&lt;p&gt;We have expanded data sources to use for our &lt;a href=\&quot;/route-leak-detection-with-cloudflare-radar/\&quot;&gt;route leak detection system&lt;/a&gt; to cover more networks and are in the process of incorporating real-time data into the detection system to allow more timely response toward similar events in the future.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;aspa-for-bgp\&quot;&gt;ASPA for BGP&lt;/h3&gt;\n            &lt;a href=\&quot;#aspa-for-bgp\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;We will continue advocating for the adoption of RPKI into AS Path based route leak prevention. Autonomous System Provider Authorization (ASPA) objects are similar to ROAs, except instead of signing prefixes with an authorized origin AS, the AS itself is signed with a list of provider networks that are allowed to propagate their routes. So, in the case of Cloudflare, only valid upstream transit providers would be signed as authorized to advertise AS13335 prefixes such as 1.1.1.0/24 upstream.&lt;/p&gt;&lt;p&gt;In the route leak example where AS262504 (customer of AS267613) shared 1.1.1.0/24 upstream, BGP ASPA would see this leak if AS267613 had signed their authorized providers and AS1031 had validated paths against that list. Similar to RPKI origin validation, however, this will be a long-term effort and dependent on networks, especially large providers, rejecting invalid AS paths as based on ASPA objects.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;other-potential-approaches\&quot;&gt;Other potential approaches&lt;/h3&gt;\n            &lt;a href=\&quot;#other-potential-approaches\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;There are alternative approaches to ASPA that do exist, in various stages of adoption that may be worth noting. There is no guarantee that the following make it to a stage of wide Internet deployment, however.&lt;/p&gt;&lt;p&gt;&lt;a href=\&quot;https://rfc.hashnode.dev/rfc9234-observed-in-the-wild\&quot;&gt;RFC9234&lt;/a&gt;, for example, uses a concept of peer roles within BGP capabilities and attributes, and depending on the configuration of routers along a path for updates, an “Only-To-Customer” (OTC) attribute can be added to prefixes that will prevent the upstream spread of a prefix such as 1.1.1.0/24 along a leaked path. The downside is BGP configuration needs to be completed to assign the various roles to each peering session, and vendor adoption still has to be fully ironed out to make this feasible for actual use in production with positive results.&lt;/p&gt;&lt;p&gt;Like all approaches to solving route leaks, cooperation amongst network operators on the Internet is required for success.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;conclusion\&quot;&gt;Conclusion&lt;/h2&gt;\n            &lt;a href=\&quot;#conclusion\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;Cloudflare’s 1.1.1.1 DNS resolver service fell victim to a simultaneous BGP hijack and BGP route leak event. While the actions of external networks are outside of Cloudflare’s direct control, we intend to take every step within both the Internet community and internally at Cloudflare to detect impact more quickly and lessen impact to our users.&lt;/p&gt;&lt;p&gt;Long term, Cloudflare continues to support adoption of RPKI-based origin validation, as well as AS path validation. The former exists with deployment across a wide array of the world’s largest networks, and the latter is still in draft phase at the IETF (Internet Engineering Task Force). In the meantime, to check if your ISP is enforcing RPKI origin validation, you can always visit &lt;a href=\&quot;http://isbgpsafeyet.com\&quot;&gt;isbgpsafeyet.com&lt;/a&gt; and &lt;i&gt;Test Your ISP&lt;/i&gt;.&lt;/p&gt;&quot;],&quot;published_at&quot;:[0,&quot;2024-07-04T14:00:50.000+01:00&quot;],&quot;updated_at&quot;:[0,&quot;2024-10-09T23:28:36.265Z&quot;],&quot;feature_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2UTNMYcfJWijYPxvcc6zJh/163dc1b93b5d89bf6edc719281d0906e/cloudflare-1111-incident-on-june-27-2024.png&quot;],&quot;tags&quot;:[1,[[0,{&quot;id&quot;:[0,&quot;2FQK880QI5lKEUCjVHBber&quot;],&quot;name&quot;:[0,&quot;1.1.1.1&quot;],&quot;slug&quot;:[0,&quot;1-1-1-1&quot;]}],[0,{&quot;id&quot;:[0,&quot;4yliZlpBPZpOwBDZzo1tTh&quot;],&quot;name&quot;:[0,&quot;Outage&quot;],&quot;slug&quot;:[0,&quot;outage&quot;]}]]],&quot;relatedTags&quot;:[0],&quot;authors&quot;:[1,[[0,{&quot;name&quot;:[0,&quot;Bryton Herdes&quot;],&quot;slug&quot;:[0,&quot;bryton&quot;],&quot;bio&quot;:[0,null],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2CtRZInMXDzWbBSlJZq6ob/cc0d484943cf18a7d24debb3d01a3ece/bryton.jpeg&quot;],&quot;location&quot;:[0,null],&quot;website&quot;:[0,&quot;https://next-hopself.net/&quot;],&quot;twitter&quot;:[0,&quot;@next_hopself&quot;],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}],[0,{&quot;name&quot;:[0,&quot;Mingwei Zhang&quot;],&quot;slug&quot;:[0,&quot;mingwei&quot;],&quot;bio&quot;:[0,&quot;Senior Systems Engineer&quot;],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5QnUBSretQguH6rvS2M2T/d1f5ade5702d47e9b582b700df51b9e4/mingwei.jpeg&quot;],&quot;location&quot;:[0,null],&quot;website&quot;:[0,null],&quot;twitter&quot;:[0,&quot;@heymingwei&quot;],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}],[0,{&quot;name&quot;:[0,&quot;Tanner Ryan&quot;],&quot;slug&quot;:[0,&quot;tanner&quot;],&quot;bio&quot;:[0,&quot;I work on global infrastructure at Cloudflare, helping to build a better Internet.&quot;],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3iETWecBBWy6tZtJS3gUGI/4bb0b2d0ad262f17985031e9660c292e/tanner.jpg&quot;],&quot;location&quot;:[0,&quot;Austin, TX&quot;],&quot;website&quot;:[0,&quot;https://txryan.com&quot;],&quot;twitter&quot;:[0,&quot;@TheTannerRyan&quot;],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}]]],&quot;meta_description&quot;:[0,&quot;On June 27, 2024, a small number of users globally may have noticed that 1.1.1.1 was unreachable or degraded. The root cause was a mix of BGP (Border Gateway Protocol) hijacking and a route leak. &quot;],&quot;primary_author&quot;:[0,{}],&quot;localeList&quot;:[0,{&quot;name&quot;:[0,&quot;Cloudflare 1.1.1.1 incident on June 27, 2024 Config&quot;],&quot;enUS&quot;:[0,&quot;English for Locale&quot;],&quot;zhCN&quot;:[0,&quot;Translated for Locale&quot;],&quot;zhHansCN&quot;:[0,&quot;No Page for Locale&quot;],&quot;zhTW&quot;:[0,&quot;Translated for Locale&quot;],&quot;frFR&quot;:[0,&quot;Translated for Locale&quot;],&quot;deDE&quot;:[0,&quot;Translated for Locale&quot;],&quot;itIT&quot;:[0,&quot;No Page for Locale&quot;],&quot;jaJP&quot;:[0,&quot;Translated for Locale&quot;],&quot;koKR&quot;:[0,&quot;Translated for Locale&quot;],&quot;ptBR&quot;:[0,&quot;No Page for Locale&quot;],&quot;esLA&quot;:[0,&quot;No Page for Locale&quot;],&quot;esES&quot;:[0,&quot;Translated for Locale&quot;],&quot;enAU&quot;:[0,&quot;No Page for Locale&quot;],&quot;enCA&quot;:[0,&quot;No Page for Locale&quot;],&quot;enIN&quot;:[0,&quot;No Page for Locale&quot;],&quot;enGB&quot;:[0,&quot;No Page for Locale&quot;],&quot;idID&quot;:[0,&quot;No Page for Locale&quot;],&quot;ruRU&quot;:[0,&quot;No Page for Locale&quot;],&quot;svSE&quot;:[0,&quot;No Page for Locale&quot;],&quot;viVN&quot;:[0,&quot;No Page for Locale&quot;],&quot;plPL&quot;:[0,&quot;No Page for Locale&quot;],&quot;arAR&quot;:[0,&quot;No Page for Locale&quot;],&quot;nlNL&quot;:[0,&quot;No Page for Locale&quot;],&quot;thTH&quot;:[0,&quot;No Page for Locale&quot;],&quot;trTR&quot;:[0,&quot;No Page for Locale&quot;],&quot;heIL&quot;:[0,&quot;No Page for Locale&quot;],&quot;lvLV&quot;:[0,&quot;No Page for Locale&quot;],&quot;etEE&quot;:[0,&quot;No Page for Locale&quot;],&quot;ltLT&quot;:[0,&quot;No Page for Locale&quot;]}],&quot;url&quot;:[0,&quot;https://blog.cloudflare.com/cloudflare-1111-incident-on-june-27-2024&quot;],&quot;metadata&quot;:[0,{&quot;title&quot;:[0,&quot;Cloudflare 1.1.1.1 incident on June 27, 2024&quot;],&quot;description&quot;:[0,&quot;On June 27, 2024, a small number of users globally may have noticed that 1.1.1.1 was unreachable or degraded. The root cause was a mix of BGP (Border Gateway Protocol) hijacking and a route leak. &quot;],&quot;imgPreview&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5Ls5tsDqf1PkvLxBwZlMyu/74d87f7cb20c453194ddd42a54a0a505/cloudflare-1111-incident-on-june-27-2024-QyB9G4.png&quot;]}],&quot;publicly_index&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;1J7iIhkUBWQNj3JpbBTVEU&quot;],&quot;title&quot;:[0,&quot;Cloudflare incident on June 20, 2024&quot;],&quot;slug&quot;:[0,&quot;cloudflare-incident-on-june-20-2024&quot;],&quot;excerpt&quot;:[0,&quot;A new DDoS rule resulted in an increase in error responses and latency for Cloudflare customers. Here’s how it went wrong, and what we’ve learned&quot;],&quot;featured&quot;:[0,false],&quot;html&quot;:[0,&quot;&lt;p&gt;&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/18peGsB3IdmJIUOoqJalSs/b69735394144edb57ba12ff8e8516518/2459.png\&quot; alt=\&quot;Cloudflare incident on June 20, 2024\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;On Thursday, June 20, 2024, two independent events caused an increase in latency and error rates for Internet properties and Cloudflare services that lasted 114 minutes. During the 30-minute peak of the impact, we saw that 1.4 - 2.1% of HTTP requests to our CDN received a generic error page, and observed a 3x increase for the 99th percentile Time To First Byte (TTFB) latency.&lt;/p&gt;&lt;p&gt;These events occurred because:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;a href=\&quot;https://www.cloudflare.com/network-services/solutions/network-monitoring-tools/\&quot;&gt;Automated network monitoring&lt;/a&gt; detected performance degradation, re-routing traffic suboptimally and &lt;a href=\&quot;https://www.cloudflarestatus.com/incidents/k7d4c79c63lq\&quot;&gt;causing backbone congestion between 17:33 and 17:50 UTC&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A new Distributed Denial-of-Service (DDoS) mitigation mechanism deployed between 14:14 and 17:06 UTC triggered a latent bug in our rate limiting system that allowed a specific form of HTTP request to cause a process handling it to enter an infinite loop &lt;a href=\&quot;https://www.cloudflarestatus.com/incidents/p7l6rrbhysck\&quot;&gt;between 17:47 and 19:27 UTC&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Impact from these events were observed in many Cloudflare data centers around the world.&lt;/p&gt;&lt;p&gt;With respect to the backbone congestion event, we were already working on expanding backbone capacity in the affected data centers, and improving our network mitigations to use more information about the available capacity on alternative network paths when taking action. In the remainder of this blog post, we will go into more detail on the second and more impactful of these events.&lt;/p&gt;&lt;p&gt;As part of routine updates to our protection mechanisms, we created a new DDoS rule to prevent a specific type of abuse that we observed on our infrastructure. This DDoS rule worked as expected, however in a specific suspect traffic case it exposed a latent bug in our existing rate-limiting component. To be absolutely clear, we have no reason to believe this suspect traffic was intentionally exploiting this bug, and there is no evidence of a breach of any kind.&lt;/p&gt;&lt;p&gt;We are sorry for the impact and have already made changes to help prevent these problems from occurring again.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;background\&quot;&gt;Background&lt;/h2&gt;\n            &lt;a href=\&quot;#background\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          \n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;rate-limiting-suspicious-traffic\&quot;&gt;Rate-limiting suspicious traffic&lt;/h3&gt;\n            &lt;a href=\&quot;#rate-limiting-suspicious-traffic\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Depending on the profile of an HTTP request and the configuration of the requested Internet property, Cloudflare may protect our network and our customer’s origins by applying a limit to the number of requests a visitor can make within a certain time window. These &lt;a href=\&quot;https://www.cloudflare.com/en-gb/learning/bots/what-is-rate-limiting/\&quot;&gt;rate limits&lt;/a&gt; can activate through customer configuration or in response to DDoS rules detecting suspicious activity.&lt;/p&gt;&lt;p&gt;Usually, these rate limits will be applied based on the IP address of the visitor. As many institutions and Internet Service Providers (ISPs) can have &lt;a href=\&quot;https://en.wikipedia.org/wiki/Carrier-grade_NAT\&quot;&gt;many devices and individual users behind a single IP address&lt;/a&gt;, rate limiting based on the IP address is a broad brush that can unintentionally block legitimate traffic.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;balancing-traffic-across-our-network\&quot;&gt;Balancing traffic across our network&lt;/h3&gt;\n            &lt;a href=\&quot;#balancing-traffic-across-our-network\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Cloudflare has several systems that together provide continuous real-time capacity monitoring and rebalancing to ensure we serve as much traffic as we can as quickly and efficiently as we can.&lt;/p&gt;&lt;p&gt;The first of these is &lt;a href=\&quot;/unimog-cloudflares-edge-load-balancer\&quot;&gt;Unimog, Cloudflare’s edge load balancer&lt;/a&gt;. Every packet that reaches our anycast network passes through Unimog, which delivers it to an appropriate server to process that packet. That server may be in a different location from where the packet originally arrived into our network, depending on the availability of compute capacity. Within each data center, Unimog aims to keep the CPU load uniform across all active servers.&lt;/p&gt;&lt;p&gt;For a global view of our network, we rely on &lt;a href=\&quot;/meet-traffic-manager\&quot;&gt;Traffic Manager&lt;/a&gt;. Across all of our data center locations, it takes in a variety of signals, such as overall CPU utilization, HTTP request latency, and bandwidth utilization to instruct rebalancing decisions. It has built-in safety limits to prevent causing outsized traffic shifts, and also considers the expected resulting load in destination locations when making any decisions.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;incident-timeline-and-impact\&quot;&gt;Incident timeline and impact&lt;/h2&gt;\n            &lt;a href=\&quot;#incident-timeline-and-impact\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;All timestamps are UTC on 2024-06-20.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;14:14 DDoS rule gradual deployment starts&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;17:06 DDoS rule deployed globally&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;17:47 First HTTP request handling process is poisoned&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;18:04 Incident declared automatically based on detected high CPU load&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;18:34 Service restart shown to recover on a server, full restart tested in one data center&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;18:44 CPU load normalized in data center after service restart&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;18:51 Continual global reloads of all servers with many stuck processes begin&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;19:05 Global eyeball HTTP error rate peaks at 2.1% service unavailable / 3.45% total&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;19:05 First Traffic Manager actions recovering service&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;19:11 Global eyeball HTTP error rate halved to 1% service unavailable / 1.96% total&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;19:27 Global eyeball HTTP error rate reduced to baseline levels&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;19:29 DDoS rule deployment identified as likely cause of process poisoning&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;19:34 DDoS rule is fully disabled&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;19:43 Engineers stop routine restarts of services on servers with many stuck processes&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;20:16 Incident response stood down&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Below, we provide a view of the impact from some of Cloudflare’s internal metrics. The first graph illustrates the percentage of all eyeball (inbound from external devices) HTTP requests that were served an error response because the service suffering poisoning could not be reached. We saw an initial increase to 0.5% of requests, and then later a larger one reaching as much as 2.1% before recovery started due to our service reloads.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1EoCaNBt1Bss8RhwKO5s5B/155382a7f8eba337c39f48c803c9979b/image7-3.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1880\&quot; height=\&quot;442\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;For a broader view of errors, we can see all 5xx responses our network returned to eyeballs during the same window, including those from origin servers. These peaked at 3.45%, and you can more clearly see the gradual recovery between 19:25 and 20:00 UTC as Traffic Manager finished its re-routing activities. The dip at 19:25 UTC aligns with the last large reload, with the error increase afterwards primarily consisting of upstream DNS timeouts and connection limits which are consistent with high and unbalanced load.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7G1ZnlpW9Qbw8DgW5MfsLv/9758cb94e7d6be79dcfac41e482114ea/image4-6.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1886\&quot; height=\&quot;446\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;And here’s what our TTFB measurements looked like at the 50th, 90th and 99th percentiles, showing an almost 3x increase in latency at p99:&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/16tMNhSZdhkV3wH6MtAWd6/44a638b8f639d39026112c32cb80dc2e/image2-10.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1253\&quot; height=\&quot;295\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;technical-description-of-the-error-and-how-it-happened\&quot;&gt;Technical description of the error and how it happened&lt;/h2&gt;\n            &lt;a href=\&quot;#technical-description-of-the-error-and-how-it-happened\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          \n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/MQYpmg1O82vEURJNsl2VU/da0b8e5c1afd70998bc928a533ee4160/image5-5.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1256\&quot; height=\&quot;294\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;&lt;i&gt;Global percentage of HTTP Request handling processes that were using excessive CPU during the event&lt;/i&gt;&lt;/p&gt;&lt;p&gt;Earlier on June 20, between 14:14 - 17:06 UTC, we gradually activated a new DDoS rule on our network. Cloudflare has recently been building a new way of mitigating HTTP DDoS attacks. This method is using a combination of rate-limits and cookies in order to allow legitimate clients that were falsely identified as being part of an attack to proceed anyway.&lt;/p&gt;&lt;p&gt;With this new method, an HTTP request that is considered suspicious runs through these key steps:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;Check for the presence of a valid cookie, otherwise block the request&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;If a valid cookie is found, add a rate-limit rule based on the cookie value to be evaluated at a later point&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Once all the currently applied DDoS mitigation are run, apply rate-limit rules&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;We use this &amp;quot;asynchronous&amp;quot; workflow because it is more efficient to block a request without a rate-limit rule, so it gives a chance for other rule types to be applied.&lt;/p&gt;&lt;p&gt;So overall, the flow can be summarized with this pseudocode:&lt;/p&gt;\n            &lt;pre class=\&quot;language-bash\&quot;&gt;&lt;code class=\&quot;language-bash\&quot;&gt;for (rule in active_mitigations) {\n   // ... (ignore other rule types)\n   if (rule.match_current_request()) {\n       if (!has_valid_cookie()) {\n           // no cookie: serve error page\n           return serve_error_page();\n       } else {\n           // add a rate-limit rule to be evaluated later\n           add_rate_limit_rule(rule);\n       }\n   }\n}\n\n\nevaluate_rate_limit_rules();&lt;/pre&gt;&lt;/code&gt;\n            &lt;p&gt;When evaluating rate-limit rules, we need to make a &lt;i&gt;key&lt;/i&gt; for each client that is used to look up the correct counter and compare it with the target rate. Typically, this key is the client IP address, but other options are available, such as the value of a cookie as used here. We actually reused an existing portion of the rate-limit logic to achieve this. In pseudocode, it looks like:&lt;/p&gt;\n            &lt;pre class=\&quot;language-bash\&quot;&gt;&lt;code class=\&quot;language-bash\&quot;&gt;function get_cookie_key() {\n   // Validate that the cookie is valid before taking its value.\n   // Here the cookie has been checked before already, but this code is\n   // also used for &amp;quot;standalone&amp;quot; rate-limit rules.\n   if (!has_valid_cookie_broken()) { // more on the &amp;quot;broken&amp;quot; part later\n       return cookie_value;\n   } else {\n       return parent_key_generator();\n   }\n}&lt;/pre&gt;&lt;/code&gt;\n            &lt;p&gt;This simple &lt;i&gt;key&lt;/i&gt; generation function had two issues that, combined with a specific form of client request, caused an infinite loop in the process handling the HTTP request:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;The rate-limit rules generated by the DDoS logic are using internal APIs in ways that haven&amp;#39;t been anticipated. This caused the &lt;code&gt;parent_key_generator&lt;/code&gt; in the pseudocode above to point to the &lt;code&gt;get_cookie_key&lt;/code&gt; function itself, meaning that if that code path was taken, the function would call itself indefinitely&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;As these rate-limit rules are added only after validating the cookie, validating it a second time should give the same result. The problem is that the &lt;code&gt;has_valid_cookie_broken&lt;/code&gt; function used here is actually different and both can disagree if the client sends multiple cookies where some are valid but not others&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;So, combining these two issues: the broken validation function tells &lt;code&gt;get_cookie_key&lt;/code&gt; that the cookie is invalid, causing the &lt;code&gt;else&lt;/code&gt; branch to be taken and calling the same function over and over.&lt;/p&gt;&lt;p&gt;A protection many programming languages have in place to help prevent loops like this is a run-time protection limit on how deep the stack of function calls can get. An attempt to call a function once already at this limit will result in a runtime error. When reading the logic above, an initial analysis might suggest we were reaching the limit in this case, and so requests eventually resulted in an error, with a stack containing those same function calls over and over.&lt;/p&gt;&lt;p&gt;However, this isn’t the case here. Some languages, including Lua, in which this logic is written, also implement an optimization called proper tail calls. A tail call is when the final action a function takes is to execute another function. Instead of adding that function as another layer in the stack, as we know for sure that we will not be returning execution context to the parent function afterwards, nor using any of its local variables, we can replace the top frame in the stack with this function call instead.&lt;/p&gt;&lt;p&gt;The end result is a loop in the request processing logic which never increases the size of the stack. Instead, it simply consumes 100% of available CPU resources, and never terminates. Once a process handling HTTP requests receives a single request on which the action should be applied and has a mixture of valid and invalid cookies, that process is poisoned and is never able to process any further requests.&lt;/p&gt;&lt;p&gt;Every Cloudflare server has dozens of such processes, so a single poisoned process does not have much of an impact. However, then some other things start happening:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;The increase in CPU utilization for the server causes Unimog to lower the amount of new traffic that server receives, moving traffic to other servers, so at a certain point, more new connections are directed away from servers with a subset of their processes poisoned to those with fewer or no poisoned processes, and therefore lower CPU utilization.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The gradual increase in CPU utilization in the data center starts to cause Traffic Manager to redirect traffic to other data centers. As this movement does not fix the poisoned processes, CPU utilization remains high, and so Traffic Manager continues to redirect more and more traffic away.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The redirected traffic in both cases includes the requests that are poisoning processes, causing the servers and data centers to which this redirected traffic was sent to start failing in the same way.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Within a few minutes, multiple data centers had many poisoned processes, and Traffic Manager had redirected as much traffic away from them as possible, but was restricted from doing more. This was partly due to its built-in automation safety limits, but also because it was becoming more difficult to find a data center with sufficient available capacity to use as a target.&lt;/p&gt;&lt;p&gt;The first case of a poisoned process was at 17:47 UTC, and by 18:09 UTC – five minutes after the incident was declared – Traffic Manager was re-routing a lot of traffic out of Europe:&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2AVE8fJsh1ODNjAoAtduon/6d77ac4385ba78ddd251c887ef02b74a/image3-14.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1305\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;&lt;i&gt;A summary map of Traffic Manager capacity actions as of 18:09 UTC. Each circle represents a data center that traffic is being re-routed towards or away from. The color of the circle indicates the CPU load of that data center. The orange ribbons between them show how much traffic is re-routed, and where from/to.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;It’s obvious to see why, if we look at the percentage of the HTTP request service’s processes that were saturating their CPUs. 10% of our capacity in Western Europe was already gone, and 4% in Eastern Europe, during peak traffic time for those timezones:&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7A71NY1brim2rjGowoewXo/a1c7f316d465b7dfb6c844b14c6408c3/image1-21.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1888\&quot; height=\&quot;438\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;&lt;i&gt;Percentage of all the HTTP request handling processes saturating their CPU, by geographic region&lt;/i&gt;&lt;/p&gt;&lt;p&gt;Partially poisoned servers in many locations struggled with the request load, and the remaining processes could not keep up, resulting in Cloudflare returning minimal HTTP error responses.&lt;/p&gt;&lt;p&gt;Cloudflare engineers were automatically notified at 18:04 UTC, once our global CPU utilization reached a certain sustained level, and started to investigate. Many of our on-duty incident responders were already working on the open incident caused by backbone network congestion, and in the early minutes we looked into likely correlation with the network congestion events. It took some time for us to realize that locations where the CPU was highest is where traffic was the lowest, drawing the investigation away from a network event being the trigger. At this point, the focus moved to two main streams:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;Evaluating if restarting poisoned processes allowed them to recover, and if so, instigating mass-restarts of the service on affected servers&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Identifying the trigger of processes entering this CPU saturation state&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;It was 25 minutes after the initial incident was declared when we validated that restarts helped on one sample server. Five minutes after this, we started executing wider restarts – initially to entire data centers at once, and then as the identification method was refined, on servers with a large number of poisoned processes. Some engineers continued regular routine restarts of the affected service on impacted servers, whilst others moved to join the ongoing parallel effort to identify the trigger. At 19:36 UTC, the new DDoS rule was disabled globally, and the incident was declared resolved after executing one more round of mass restarts and monitoring.&lt;/p&gt;&lt;p&gt;At the same time, conditions presented by the incident triggered a latent bug in Traffic Manager. When triggered, the system would attempt to recover from the exception by initiating a graceful restart, halting its activity. The bug was first triggered at 18:17 UTC, then numerous times between 18:35 and 18:57 UTC. During two periods in this window (18:35-18:52 UTC and 18:56-19:05 UTC) the system did not issue any new traffic routing actions. This meant whilst we had recovered service in the most affected data centers, almost all traffic was still being re-routed away from them. Alerting notified on-call engineers of the issue at 18:34 UTC. By 19:05 UTC the Traffic team had written, tested, and deployed a fix. The first actions following restoration showed a positive impact on restoring service.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;remediation-and-follow-up-steps\&quot;&gt;Remediation and follow-up steps&lt;/h2&gt;\n            &lt;a href=\&quot;#remediation-and-follow-up-steps\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;To resolve the immediate impact to our network from the request poisoning, Cloudflare instigated mass rolling restarts of the affected service until the change that triggered the condition was identified and rolled back. The change, which was the activation of a new type of DDoS rule, remains fully rolled back, and the rule will not be reactivated until we have fixed the broken cookie validation check and are fully confident this situation cannot recur.&lt;/p&gt;&lt;p&gt;We take these incidents very seriously, and recognize the magnitude of impact they had. We have identified several steps we can take to address these specific situations, and the risk of these sorts of problems from recurring in the future.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Design:&lt;/b&gt; The rate limiting implementation in use for our DDoS module is a legacy component, and rate limiting rules customers configure for their Internet properties use a newer engine with more modern technologies and protections.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Design:&lt;/b&gt; We are exploring options within and around the service which experienced process poisoning to limit the ability to loop forever through tail calls. Longer term, Cloudflare is entering the early implementation stages of replacing this service entirely. The design of this replacement service will allow us to apply limits on the non-interrupted and total execution time of a single request.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Process:&lt;/b&gt; The activation of the new rule for the first time was staged in a handful of production data centers for validation, and then to all data centers a few hours later. We will continue to enhance our staging and rollout procedures to minimize the potential change-related blast radius.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;conclusion\&quot;&gt;Conclusion&lt;/h2&gt;\n            &lt;a href=\&quot;#conclusion\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;Cloudflare experienced two back-to-back incidents that affected a significant set of customers using our CDN and network services. The first was network backbone congestion that our systems automatically remediated. We mitigated the second by regularly restarting the faulty service whilst we identified and deactivated the DDoS rule that was triggering the fault. We are sorry for any disruption this caused our customers and to end users trying to access services.&lt;/p&gt;&lt;p&gt;The conditions necessary to activate the latent bug in the faulty service are no longer possible in our production environment, and we are putting further fixes and detections in place as soon as possible.&lt;/p&gt;&quot;],&quot;published_at&quot;:[0,&quot;2024-06-26T14:00:22.000+01:00&quot;],&quot;updated_at&quot;:[0,&quot;2024-11-06T17:20:01.691Z&quot;],&quot;feature_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4cc09s6OD4CKawAsjgK3OJ/b7e75c41e30a7474401cbce97c6117fb/cloudflare-incident-on-june-20-2024.png&quot;],&quot;tags&quot;:[1,[[0,{&quot;id&quot;:[0,&quot;3cCNoJJ5uusKFBLYKFX1jB&quot;],&quot;name&quot;:[0,&quot;Post Mortem&quot;],&quot;slug&quot;:[0,&quot;post-mortem&quot;]}],[0,{&quot;id&quot;:[0,&quot;4yliZlpBPZpOwBDZzo1tTh&quot;],&quot;name&quot;:[0,&quot;Outage&quot;],&quot;slug&quot;:[0,&quot;outage&quot;]}]]],&quot;relatedTags&quot;:[0],&quot;authors&quot;:[1,[[0,{&quot;name&quot;:[0,&quot;Lloyd Wallis&quot;],&quot;slug&quot;:[0,&quot;lloyd&quot;],&quot;bio&quot;:[0,null],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1xDgId76v9OdjGsVHH31ed/b9c21c8e9f4e47e492bdb450e4817512/lloyd.jpg&quot;],&quot;location&quot;:[0,&quot;London, UK&quot;],&quot;website&quot;:[0,null],&quot;twitter&quot;:[0,&quot;@LloydW93&quot;],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}],[0,{&quot;name&quot;:[0,&quot;Julien Desgats&quot;],&quot;slug&quot;:[0,&quot;julien-desgats&quot;],&quot;bio&quot;:[0,null],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7rDtCt8aM8HBmfsg6xuTiV/703907f4801e2b832079d9f78d019654/julien-desgats.jpg&quot;],&quot;location&quot;:[0,null],&quot;website&quot;:[0,null],&quot;twitter&quot;:[0,null],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}],[0,{&quot;name&quot;:[0,&quot;Manish Arora&quot;],&quot;slug&quot;:[0,&quot;manish&quot;],&quot;bio&quot;:[0,null],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4u7fayYeIfvEDkEviluW6O/62548ae5a3f678a8e8f1ae566dbdb54d/manish.png&quot;],&quot;location&quot;:[0,null],&quot;website&quot;:[0,null],&quot;twitter&quot;:[0,null],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}]]],&quot;meta_description&quot;:[0,&quot;A new DDoS rule resulted in an increase in error responses and latency for Cloudflare customers. Here’s how it went wrong, and what we’ve learned&quot;],&quot;primary_author&quot;:[0,{}],&quot;localeList&quot;:[0,{&quot;name&quot;:[0,&quot;Cloudflare incident on June 20, 2024 Config&quot;],&quot;enUS&quot;:[0,&quot;English for Locale&quot;],&quot;zhCN&quot;:[0,&quot;Translated for Locale&quot;],&quot;zhHansCN&quot;:[0,&quot;No Page for Locale&quot;],&quot;zhTW&quot;:[0,&quot;Translated for Locale&quot;],&quot;frFR&quot;:[0,&quot;No Page for Locale&quot;],&quot;deDE&quot;:[0,&quot;No Page for Locale&quot;],&quot;itIT&quot;:[0,&quot;No Page for Locale&quot;],&quot;jaJP&quot;:[0,&quot;Translated for Locale&quot;],&quot;koKR&quot;:[0,&quot;Translated for Locale&quot;],&quot;ptBR&quot;:[0,&quot;No Page for Locale&quot;],&quot;esLA&quot;:[0,&quot;No Page for Locale&quot;],&quot;esES&quot;:[0,&quot;No Page for Locale&quot;],&quot;enAU&quot;:[0,&quot;No Page for Locale&quot;],&quot;enCA&quot;:[0,&quot;No Page for Locale&quot;],&quot;enIN&quot;:[0,&quot;No Page for Locale&quot;],&quot;enGB&quot;:[0,&quot;No Page for Locale&quot;],&quot;idID&quot;:[0,&quot;No Page for Locale&quot;],&quot;ruRU&quot;:[0,&quot;No Page for Locale&quot;],&quot;svSE&quot;:[0,&quot;No Page for Locale&quot;],&quot;viVN&quot;:[0,&quot;No Page for Locale&quot;],&quot;plPL&quot;:[0,&quot;No Page for Locale&quot;],&quot;arAR&quot;:[0,&quot;No Page for Locale&quot;],&quot;nlNL&quot;:[0,&quot;No Page for Locale&quot;],&quot;thTH&quot;:[0,&quot;No Page for Locale&quot;],&quot;trTR&quot;:[0,&quot;No Page for Locale&quot;],&quot;heIL&quot;:[0,&quot;No Page for Locale&quot;],&quot;lvLV&quot;:[0,&quot;No Page for Locale&quot;],&quot;etEE&quot;:[0,&quot;No Page for Locale&quot;],&quot;ltLT&quot;:[0,&quot;No Page for Locale&quot;]}],&quot;url&quot;:[0,&quot;https://blog.cloudflare.com/cloudflare-incident-on-june-20-2024&quot;],&quot;metadata&quot;:[0,{&quot;title&quot;:[0,&quot;Cloudflare incident on June 20, 2024&quot;],&quot;description&quot;:[0,&quot;A new DDoS rule resulted in an increase in error responses and latency for Cloudflare customers. Here’s how it went wrong, and what we’ve learned&quot;],&quot;imgPreview&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7JbteaUQFsFtVENbpaWebp/c67300fe5ef42861ecb2b788ba164d1c/cloudflare-incident-on-june-20-2024-yMwJXB.png&quot;]}],&quot;publicly_index&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;7I3aMukuPURTotjQ1Njiei&quot;],&quot;title&quot;:[0,&quot;Exam-ining recent Internet shutdowns in Syria, Iraq, and Algeria&quot;],&quot;slug&quot;:[0,&quot;syria-iraq-algeria-exam-internet-shutdown&quot;],&quot;excerpt&quot;:[0,&quot;Similar to actions taken over the last several years, governments in Syria, Iraq, and Algeria have again disrupted Internet connectivity nationwide in an attempt to prevent cheating on exams. We investigate how these disruptions were implemented, and their impact&quot;],&quot;featured&quot;:[0,false],&quot;html&quot;:[0,&quot;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/F2HeWDG5hL7dR2ymHqC5x/4d6c22d726e7460769e9feed3e052284/Magic-Network-Monitoring.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;2401\&quot; height=\&quot;1351\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;The practice of cheating on exams (or at least attempting to) is presumably as old as the concept of exams itself, especially when the results of the exam can have significant consequences for one’s academic future or career. As access to the Internet became more ubiquitous with the growth of mobile connectivity, and communication easier with an assortment of social media and messaging apps, a new avenue for cheating on exams emerged, potentially facilitating the sharing of test materials or answers. &lt;a href=\&quot;https://www.theguardian.com/technology/2016/may/18/iraq-shuts-down-internet-to-stop-pupils-cheating-in-exams\&quot;&gt;Over the last decade&lt;/a&gt;, some governments have reacted to this perceived risk by taking aggressive action to prevent cheating, ranging from targeted DNS-based blocking/filtering to multi-hour nationwide shutdowns across multi-week exam periods.&lt;/p&gt;&lt;p&gt;Syria and Iraq are well-known practitioners of the latter approach, and we have covered past exam-related Internet shutdowns in Syria (&lt;a href=\&quot;/syria-exam-related-internet-shutdowns\&quot;&gt;2021&lt;/a&gt;, &lt;a href=\&quot;/syria-sudan-algeria-exam-internet-shutdown\&quot;&gt;2022&lt;/a&gt;, &lt;a href=\&quot;/q2-2023-internet-disruption-summary\&quot;&gt;2023&lt;/a&gt;) and Iraq (&lt;a href=\&quot;/syria-sudan-algeria-exam-internet-shutdown\&quot;&gt;2022&lt;/a&gt;, &lt;a href=\&quot;/exam-internet-shutdowns-iraq-algeria\&quot;&gt;2023&lt;/a&gt;) here on the Cloudflare blog. It is now mid-June 2024, and exams in both countries took place over the last several weeks, and with those exams, regular nationwide Internet shutdowns. In addition, Baccalaureate exams also took place in Algeria, and we have written about related Internet disruptions there in the past (&lt;a href=\&quot;/syria-sudan-algeria-exam-internet-shutdown\&quot;&gt;2022&lt;/a&gt;, &lt;a href=\&quot;/exam-internet-shutdowns-iraq-algeria\&quot;&gt;2023&lt;/a&gt;). However, in contrast to the single daily shutdowns in Syria and Iraq, the Algerian government opted instead for two multi-hour disruptions each day – one in the morning, one in the afternoon – and appears to be pursuing a content blocking strategy, rather than a full nationwide shutdown.&lt;/p&gt;&lt;p&gt;As we have done in past year’s posts, we will examine the impact that these shutdowns have on Internet traffic, but also analyze routing information and traffic from other Cloudflare services in an effort to better understand how these shutdowns are being implemented.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;syria\&quot;&gt;Syria&lt;/h3&gt;\n            &lt;a href=\&quot;#syria\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;The Syrian Telecom Company, to their credit, publishes an exam schedule on social media, with the image below &lt;a href=\&quot;https://www.facebook.com/photo/?fbid=827972736029921&amp;set=a.449047400589125\&quot;&gt;published to their Facebook page&lt;/a&gt;. The English version was created by applying Google Translate to the image. The schedule shows the date &amp;amp; time of each Internet shutdown (“disconnection”), in addition to the subject(s) of that day’s exam(s). In 2024, exams started on May 26, and went through June 13.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/9lgp9NIpBSo2RWII1nUmh/1331a833433eda16be39e4fda41d3413/Screenshot-2024-06-20-at-1.00.58-PM.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1209\&quot; height=\&quot;857\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;In Syria, &lt;a href=\&quot;https://radar.cloudflare.com/as29256\&quot;&gt;AS29256 (Syrian Telecom)&lt;/a&gt; is effectively the Internet, as shown &lt;a href=\&quot;https://radar.cloudflare.com/routing/as29256\&quot;&gt;in the table below&lt;/a&gt;. While there are a few other &lt;a href=\&quot;https://www.cloudflare.com/learning/network-layer/what-is-an-autonomous-system/\&quot;&gt;autonomous systems&lt;/a&gt; (ASNs/ASes) registered in Syria, there are only two that currently announce IP address space to the public Internet. As such, the trends seen at a country level for Syria reflect those seen for AS29256, and this is clearly evident in the traffic graphs below.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2XEcIEFQPHIKevCJZkVbaM/3be900a49f17d26e90505a2c77704bc0/unnamed--1--2.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;679\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;Nationwide Internet shutdowns in Syria began on May 26, taking place for varying multi-hour periods from Sunday to Thursday for three consecutive weeks. The graphs below show Internet traffic from the country, as well as AS29256, dropping to zero during the scheduled shutdowns.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6uW4E8cmeiDolFehpOFXaE/113ee0007138f1eccebd2cec87ae2891/image42.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/FjHhDRQjGou5kNsIZNzQp/3cb60e3a92c1142f1c483b942db5afa2/image5-3.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;In addition, graphs from the Cloudflare Radar &lt;a href=\&quot;https://radar.cloudflare.com/routing/\&quot;&gt;Routing&lt;/a&gt; pages for &lt;a href=\&quot;https://radar.cloudflare.com/routing/sy\&quot;&gt;Syria&lt;/a&gt; and &lt;a href=\&quot;https://radar.cloudflare.com/routing/as29256\&quot;&gt;AS29256&lt;/a&gt; show the number of IPv4 and IPv6 prefixes being announced country-wide and by AS29256 dropping to at or near zero during each shutdown. This ultimately means that there is no Internet path back to systems (IP addresses) connected to Syrian Telecom. Below, we explore why this is important and problematic.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5xFTZkPlwMrvEhmn5Tnz42/b7eaffa70e91993663d39a1b5fff9682/image4-4.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1NhFb2khiuAhEJ9Fo8QN19/95f146770a68bf63b87726099eff0143/image47.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3QesstGGtNnaKfBMpRO6GL/f1ea77bb39c751aae45de68096426e00/image15-1.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7yXJYfsxpfK1mwQs5a2ZLw/b7432284cdd28841c22041eb1d4e323a/image30.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;As has been &lt;a href=\&quot;/syria-sudan-algeria-exam-internet-shutdown\&quot;&gt;observed in the past&lt;/a&gt;, the shutdowns in Syria are &lt;a href=\&quot;https://x.com/DougMadory/status/1138064496008806400\&quot;&gt;asymmetrical&lt;/a&gt;. That is, traffic can exit the country (via AS29256), but there are no paths for responses to return. The impact of this approach is clearly evident in traffic to &lt;a href=\&quot;https://one.one.one.one/dns/\&quot;&gt;Cloudflare’s 1.1.1.1 DNS Resolver&lt;/a&gt;. We continue to see traffic to the resolver when the shutdowns take place, and in fact, we see the traffic spike during the shutdowns, as the graph below shows.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2LSn47S6TsjvoLuDx5fKPU/6cc2d335fcbdf706e26887b84d873824/image49.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;910\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;If we dig into traffic to 1.1.1.1 by protocol, we can see that it is driven by requests over &lt;a href=\&quot;https://www.cloudflare.com/learning/ddos/glossary/user-datagram-protocol-udp/\&quot;&gt;UDP&lt;/a&gt; port 53, the &lt;a href=\&quot;https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml?&amp;page=2\&quot;&gt;standard port&lt;/a&gt; used for DNS requests over UDP and TCP. (Given the request pattern, that also appears to be the primary way that we see traffic to the resolver from Syria.)&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4CDPlKnjVUF6ViD75S2Zwa/e27da9a43911fd9808bbcadbd097477a/image12-1.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;994\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;If we remove the UDP line from the graph, we see that request volume for DNS over TCP port 53, as well as &lt;a href=\&quot;https://developers.cloudflare.com/1.1.1.1/encryption/dns-over-https/\&quot;&gt;DNS over HTTPS (DoH)&lt;/a&gt; and &lt;a href=\&quot;https://developers.cloudflare.com/1.1.1.1/encryption/dns-over-tls/\&quot;&gt;DNS over TLS (DoT)&lt;/a&gt;, all drops to zero during the shutdowns.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/vWtoXnCHPogP4HfSjm2G5/ea6f8b6fb58f58cff01c70d9ee592f75/image1-18.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;994\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;Similarly, we can clearly see the shutdowns in HTTP(S) request-based traffic graphs as well, since HTTP(S) is also a TCP-based protocol.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7phbRNoQ9Kg4L1n5F7chjg/572136f844df3879c4486374f5bc5092/image35.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1008\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;Why do we see this impact? With DNS over UDP, the client simply makes a request to the resolver – no multi-step handshake is involved, as with TCP. So in this case, 1.1.1.1 is receiving these requests, but as shown above, there’s no path for the response to reach the client. Because it hasn’t received a response, the client retries the request, and this flood of retries is manifested as the spike seen in the graphs above.&lt;/p&gt;&lt;p&gt;However, as we see above, request volume for DNS over TCP, as well as DoH, DoT, and HTTP(S) (which all use TCP), falls to zero during the shutdowns. The lack of a path back to the client means that the &lt;a href=\&quot;https://www.geeksforgeeks.org/tcp-3-way-handshake-process/\&quot;&gt;TCP 3-way handshake&lt;/a&gt; can’t complete, and thus we don’t see DNS requests over these protocols.&lt;/p&gt;&lt;p&gt;In looking at 1.1.1.1 Resolver request volume from Syria for popular social media and messaging applications, we can see traffic for facebook.com most closely matches the spikes shown above. Removing facebook.com from the graph, we can also see similar, though more limited, increases for domains used by popular messaging applications WhatsApp, Signal, and Telegram. Facebook and WhatsApp are &lt;a href=\&quot;https://medialandscapes.org/country/syria/media/social-networks\&quot;&gt;reportedly&lt;/a&gt; the most popular social media and messaging applications in Syria.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7nmo0Zbae88h2VZhbRpd8f/85eaf702c9f638ce544d2b485114aa65/image18.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;920\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3gKoz2uKoz2kVIchd0C2vV/7a2a6107c35d3e1433d7d956e0af9fb6/image33.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;920\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;Although we have focused on the analysis of traffic to Cloudflare’s DNS resolver, and the patterns seen within that traffic, it is also worth highlighting an interesting pattern observed in traffic to Cloudflare’s &lt;a href=\&quot;https://www.cloudflare.com/application-services/products/dns/\&quot;&gt;Authoritative DNS&lt;/a&gt; platform. (&lt;a href=\&quot;https://www.cloudflare.com/en-gb/learning/dns/dns-server-types/\&quot;&gt;DNS resolvers&lt;/a&gt; act as a middleman between clients, such as a laptop or phone, and an authoritative DNS server. &lt;a href=\&quot;https://www.cloudflare.com/en-gb/learning/dns/dns-server-types/\&quot;&gt;Authoritative DNS servers&lt;/a&gt; contain information specific to the domain names they serve, including IP addresses and other types of records.)&lt;/p&gt;&lt;p&gt;The graph below shows bits/second traffic from Syria for Cloudflare’s &lt;a href=\&quot;https://www.cloudflare.com/application-services/products/dns/\&quot;&gt;authoritative DNS service&lt;/a&gt; on June 13. (Similar patterns were observed during the other days when shutdowns occurred, but data volume limits the ability to create a graph showing an extended period of time.) In this graph, we can see that at the start of the shutdown (03:00 UTC), traffic rises sharply, effectively plateaus for the duration of the shutdown, and then returns to normal levels. We believe that the traffic pattern illustrated here could be the result of some local resolvers in Syria having the IP addresses for our authoritative DNS servers cached, and are making requests to them. The increased traffic level could be because they are retrying their queries after not receiving responses, but in a less aggressive fashion than the client applications driving the resolver traffic spikes shown above.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2fOqZ4ORPIY4znUD1HRb70/06d1cc0e24f13bbb23886eedea3a89a0/unnamed-2.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;354\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;In summary, Syria appears to be implementing their Internet shutdowns not through filtering, but rather by simply not announcing their IP address space for the duration of the shutdown, thereby preventing any responses from returning to the originating requestor, whether client application, web browser, or local DNS resolver.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;iraq\&quot;&gt;Iraq&lt;/h3&gt;\n            &lt;a href=\&quot;#iraq\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;On May 19, the Iraqi Ministry of Communication &lt;a href=\&quot;https://moc.gov.iq/?article=767\&quot;&gt;posted an update&lt;/a&gt; that stated (translated) &lt;i&gt;“The Ministry of Communications would like to note that the Internet service will be cut off for two hours during the general exams for intermediate studies, from six in the morning until eight in the morning, based on higher directives and at the request of the Ministry of Education.”&lt;/i&gt; The post came nearly a year after the Iraqi Ministry of Communication &lt;a href=\&quot;https://www.kurdistan24.net/en/story/31453-Iraq%E2%80%99s-communication-ministry-refuses-to-enforce-internet-blackout-for-final-exams\&quot;&gt;refused a request from the Ministry of Education to shut down the Internet&lt;/a&gt; during the baccalaureate exams as part of efforts to prevent cheating. On May 20, the Iraqi Ministry of Education &lt;a href=\&quot;https://www.facebook.com/Iraq.Ministry.of.Education/posts/pfbid07ny6LazyvGJED37iCmRkk9h9rNPWeEPtANVu8vaL8gknoaBmwgmVZX9a7LkSbhy2l\&quot;&gt;posted the schedule&lt;/a&gt; for the upcoming set of exams to its Facebook page.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6Wb00a9bDq0VYe1zhqFHAR/22aecee54a71bfd430789e976315b040/Screenshot-2024-06-21-at-11.07.18.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;2000\&quot; height=\&quot;980\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;Iraq has a much richer network service provider environment than Syria does, with &lt;a href=\&quot;https://radar.cloudflare.com/routing/iq#a-ses-registered-in-iraq\&quot;&gt;over 150&lt;/a&gt; &lt;a href=\&quot;https://www.cloudflare.com/en-gb/learning/network-layer/what-is-an-autonomous-system/\&quot;&gt;autonomous systems (ASNs)&lt;/a&gt; registered in the country and announcing IP address space, compared to just &lt;a href=\&quot;https://radar.cloudflare.com/routing/sy#a-ses-registered-in-syria\&quot;&gt;two&lt;/a&gt; ASNs (both Syrian Telecom) in Syria announcing IP address space. Although traffic in Iraq is generally concentrated among the larger providers, shutdowns are rarely “complete” at a country level because not every autonomous system (network provider) in the country implements a shutdown. (This is due in part to the autonomous Kurdistan region in the north, which often implements similar shutdowns on their own schedule. Network providers in this region are included in Iraq’s country-level graphs.)&lt;/p&gt;&lt;p&gt;We can see this in a Cloudflare Radar traffic graph that shows the shutdowns at a country level, where traffic is dropping by around 87% during each multi-hour shutdown. In addition to the five networks also shown here (&lt;a href=\&quot;https://radar.cloudflare.com/as203214\&quot;&gt;AS203214 (HulumTele)&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as199739\&quot;&gt;AS199739 (Earthlink)&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as58322\&quot;&gt;AS58322 (Halasat)&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as51684\&quot;&gt;AS51684 (Asiacell)&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/as59588\&quot;&gt;AS59588 (Zainas)&lt;/a&gt;), further analysis finds more than 30 where we observed a complete loss of traffic during the shutdowns, with a number of them downstream of these providers.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6YkIihynKuDtI63g32YJ0u/3c6f135f0e890145f3b0be6ba6659553/image45.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6W7vWmG8ivneqIJavrTLCU/1b0248818877d395987fca076af52ce6/image28.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/ezNpiALAh32m1LyOng14j/ecb5d055692266f0f9c758976204baae/image38.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3bRSpefwBNbcdvMQ2kOkO1/1b072bfd9ffc362923d9a2db06908068/image8-3.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2WqSWExs5iBdfDlGTqjXlK/63c853a1b688e0bd4a328881a2b3c280/image22.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5iUNjwfTlp0hz8lqgEnaAV/caf0caa06f14d277ce9a874b0fb9738d/image44.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;In contrast to Syria, the changes to announced IP address space during the shutdowns are much less severe in Iraq. Several of the shutdowns are correlated with a drop of ~20-25% in announced IPv4 address space, while a few others saw a drop closer to just 2%.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/kAYLZYHK3wnfSh5KNfc33/309f01763d1815a38bf55e1aa42e9725/image51.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;At an ASN level, the changes in announced address space were mixed – &lt;a href=\&quot;https://radar.cloudflare.com/routing/as59588\&quot;&gt;AS59588 (Zainas)&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/routing/as199739\&quot;&gt;AS199739 (Earthlink)&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/routing/as51684\&quot;&gt;AS51684 (Asiacell)&lt;/a&gt; experienced a significant loss, while &lt;a href=\&quot;https://radar.cloudflare.com/routing/as203214\&quot;&gt;AS203214 (HulumTele)&lt;/a&gt; and &lt;a href=\&quot;https://radar.cloudflare.com/routing/as58322\&quot;&gt;AS58322 (Halasat)&lt;/a&gt; experienced little to no change.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3HoWb2U5b8uBf9aZX5PJAb/e4ae72f055f2f9fd627251769b16d6bd/image13-3.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1jJpJYqXgDGeb8So4bMWee/34ba179a6e9fff7b311e057134c34d97/image50.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6sVOgW0xr4mwXUU3id092u/6c198aeb32b840f1142e84ec06822f79/image39.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5H64bnOria4mzCtW7VEs40/178e8f4e060b3be172c97b762c334207/image20.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6k1oSwvj9pwTyHD9OMesEV/a28168e19e0f21ce771166872153c9a4/image24.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;Similar to Syria, we can also look at 1.1.1.1 resolver traffic data to better understand how the shutdowns are being implemented. The country-level graphs below suggest that UDP traffic patterns are not visibly changing, suggesting that responses from the resolver are, in fact, getting back to the clients. However, this likely isn’t the case, and such a conclusion is at least in part an artifact of the graph’s time frame and hourly granularity, as well as the inclusion of resolver traffic from Kurdish network providers (ASNs). The shutdowns are more clearly evident in the DNS-over-TCP and DNS-over-HTTPS graphs below, as well as in the graph for HTTP(S) request traffic (both mobile &amp;amp; desktop), which is also TCP-based. In these graphs, the troughs on days that shutdowns occurred generally dip lower than those on the days that the Internet remained available.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/o1NrRFgAMr5FLKa2j4Ktb/b85d5ccf7a9cd7e560229b58130fc91e/image41.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;910\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4pD02P65uRmaiL73oLzAm9/44ab4e57a7e90ce367e2fc3c3f9e467a/image3-8.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;994\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2AscDvWNoxmwWeTGcKyDds/a36e4278a86f651bb75f3a789bb4840b/image27.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;994\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/51pfAyJ519aXX0w6KYCm5I/d055dafda12380a3b3b46e748e198ded/image32.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;994\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3XlAjHrSgzngJulJRIP36J/b5e8b3058c5441e8dcdff18b347c64e8/image16-1.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;994\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4zO7k4idsNJRtohBPYgXhD/676ddfe345adfcab86ea380bdcfa7e54/image43.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1008\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;In looking at authoritative DNS traffic from Iraq during a shutdown (for June 13 as an example day, as above), we see evidence of a decline in traffic during the time the shutdown occurs.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5LQtyB4CbJBlUjw2PrIBjI/76cdc488ae2d8a0cc46c4441f9ac08ee/image34.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1828\&quot; height=\&quot;430\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;The decline in authoritative DNS traffic is more evident at an ASN level, such as in the graph below for AS203214 (Hulum), effectively confirming that UDP traffic is not getting through here either.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/14fZ29LuL3wsJpTnTVbeku/466dd9542998c77af044647e5e3d49ac/image48.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1822\&quot; height=\&quot;426\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;Considering the traffic, 1.1.1.1 Resolver, and authoritative DNS observations reviewed here, it suggests that the Internet shutdowns taking place in Iraq are more complex than Syria’s, as it appears that both UDP and TCP traffic are unable to egress from impacted network providers. As not all impacted network providers are showing a complete loss of announced IP address space during the shutdowns, Iraq is taking a different approach to disrupting Internet connectivity. Although analysis of our data doesn’t provide a definitive conclusion, there are several likely options, and network providers in the country may be combining several. These options revolve around:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;IP:&lt;/b&gt; Block packets from reaching IP addresses. This may be done by withdrawing prefix announcements from the routing table (a brute force approach) or by blocking access to specific IP addresses, such as those associated with a specific application or service (a more surgical approach).&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Connection:&lt;/b&gt; Block connections based on &lt;a href=\&quot;https://www.cloudflare.com/learning/ssl/what-is-sni/\&quot;&gt;SNI&lt;/a&gt;/HTTP headers, or other application data. If a network or on-path device is able to observe the server name (or other relevant headers/data), then the connection can be terminated.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;DNS:&lt;/b&gt; Operators of private or ‘internal’ DNS resolvers, offered by ISPs and enterprise environments for use by their own users, can apply content restrictions, blocking the resolution of hostnames associated with websites and other applications.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;The consequences of these options are covered in more detail &lt;a href=\&quot;/consequences-of-ip-blocking\&quot;&gt;in a blog post&lt;/a&gt;. In addition, applying them at common network chokepoints, such as &lt;a href=\&quot;https://iraqixp.com/\&quot;&gt;AS212330 (IRAQIXP)&lt;/a&gt; or &lt;a href=\&quot;https://radar.cloudflare.com/routing/as208293\&quot;&gt;AS208293&lt;/a&gt; (&lt;a href=\&quot;https://alsalam.gov.iq/\&quot;&gt;AlSalam State Company&lt;/a&gt;, associated with the Iraqi Ministry of Communications), can disrupt connectivity at multiple downstream ISPs, without those providers necessarily having to take action themselves.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;algeria\&quot;&gt;Algeria&lt;/h3&gt;\n            &lt;a href=\&quot;#algeria\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;As we noted in blog posts in &lt;a href=\&quot;/syria-sudan-algeria-exam-internet-shutdown\&quot;&gt;2022&lt;/a&gt; and &lt;a href=\&quot;/exam-internet-shutdowns-iraq-algeria\&quot;&gt;2023&lt;/a&gt;, Algeria has a history of disrupting Internet connectivity during Baccalaureate exams. This has been taking place since &lt;a href=\&quot;https://www.bbc.com/news/world-africa-44557028\&quot;&gt;2018&lt;/a&gt;, following widespread cheating in 2016 that saw questions leaked online both before and during tests. On March 13, the Algerian Ministry of Education &lt;a href=\&quot;https://www.aps.dz/en/health-science-technology/51394-ministry-of-education-announces-dates-for-middle-school-and-high-school-final-exams\&quot;&gt;announced&lt;/a&gt; that the Baccalaureate exams would be held June 9-13. As expected, Internet disruptions were observed both country-wide and at a network level. Similar to previous years, two disruptions were observed each day. The first one began at 08:00 local time (07:00 UTC), and except for June 9, lasted three hours, ending at 11:00 local time (10:00 UTC). (On June 9, it lasted until 13:00 local time (12:00 UTC).) The second one began between 14:00-14:30 local time (13:00-13:30 UTC), and lasted until 16:00-17:00 local time (15:00-16:00 UTC) – the end time varied by day.&lt;/p&gt;&lt;p&gt;As seen in the graphs below, the impact to traffic was fairly nominal, suggesting that wide scale Internet shutdowns similar to those seen in Syria were not being implemented. While this is in line with 2023’s &lt;a href=\&quot;https://x.com/TheAlgiersPost/status/1535917324485656576\&quot;&gt;pronouncement&lt;/a&gt; by the Minister of Education that there would be no Internet shutdown on exam days, &lt;a href=\&quot;https://x.com/search?f=live&amp;q=algeria%20exam%20until%3A2024-06-13%20since%3A2024-06-09&amp;src=typed_query\&quot;&gt;a number of posts on X&lt;/a&gt; complained of broader cuts to Internet connectivity.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5b4bFM6GwqaslpXJNGxCSu/063e3729ef3197b88dfe367cc91fc0f4/image14-2.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5I0HpVYB36DNHhycNbRUjp/ecc17427d720b5ca90ed554946924dfc/image17.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1pOO1TV09EyRfv5hRlV3sX/950600eac0cd068804f2ce990e93e112/image25.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1brvTsdkG8vlUDB7CNQ6vL/2c4ba312f499adc4893fb8afa5378ca6/image2-6.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4mOPVdahSJQ0n6gzs7cGSL/86fa9d9e06718da3fa7a291c055773b3/image37.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;Similar to the analysis above of the shutdowns in Syria and Iraq, we can also review changes to announced IP address space to better understand how connectivity was being disrupted. In this case, as the graphs below show, no meaningful changes to announced IPv4 address space were observed during the days the Baccalaureate exams were given. As such, the observed drops in traffic were not caused by routing changes.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7l6qUEMRcrdvShbzdd8y5I/5696832adbe82ab92cef0265df11bdc9/image52.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3gEPeuP0l9czg2nipM8Jjb/8f49d22da1c031d1db5ed2577ec8462f/image21.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6m0XeCwN3lYLot6AutTNaS/7b0034f1106d4e99eaaec28b1cd8e9a5/image6-3.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3oiRlajqzZGBY5Io0dbXkj/234f0120c0002f7ffcf69b6a8bbe0038/image40.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5Kv6LndNtCYpsJUhUPF8UT/ae8359550b84298abd5d0994b475cd76/AD_4nXdmsCY4R4OwP5lh6E6PgQdXYDxwUTWl8o5A-sRdNCSBmRNe0Zq7-OlWczYH8tr8q75P8WLqOsd3Po-03gykFfJDJNgqXcOkX4i3KuVp73q1GW7aLXeTNAzkK7yU\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;In the HTTP(S) request traffic graph below, the twice-daily disruptions are highlighted, with the morning one appearing as a nominal drop in traffic, and the afternoon one causing a more severe decline. (The graph shows request traffic aggregated at a country level, but the graphs for the ASNs listed above also show similar patterns.)&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7afFEaI4r2fREfV0o54f2/68f9fe97d63624a99e0868d0de5df096/image19.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;994\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;In addition, similar patterns are observed in 1.1.1.1 resolver traffic at a country and ASN level, but only for DNS over TCP, DNS over TLS, and DNS over HTTPS, all of which leverage TCP. In the graph below showing only resolver traffic over UDP, there’s no clear evidence of disruptions. However, in the graph that shows resolver traffic over HTTPS, TCP, and TLS, a slight perturbation is visible in the morning, as traffic begins to rise for the day, and a sharper decrease is visible in the afternoon, with both disruptions aligning with the twice daily drops in traffic discussed above.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/ydmjTs8hCqfZ4W969jSSy/4120e9a30b2c0c2015c6f097c1f8ee8b/image31.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;994\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7qSu9orpg29sE5T2cawABq/1ec368088682d0f3d34f1287b3ed7d03/image7-2.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;994\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;These observations support the conjecture that the Algerian government is likely taking a more nuanced approach to restricting access to content, interfering in some fashion with TCP-based traffic. The conjecture is also supported by an internal tool that helps to understand connection tampering that is based on research co-designed and developed by members of the &lt;a href=\&quot;https://research.cloudflare.com/\&quot;&gt;Cloudflare Research&lt;/a&gt; team. We will be launching insights into TCP connection tampering on Cloudflare Radar later in 2024 and, in the meantime, technical details can be found in the peer-reviewed paper titled &lt;a href=\&quot;https://research.cloudflare.com/publications/SundaraRaman2023/\&quot;&gt;Global, Passive Detection of Connection Tampering&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The graph below, taken from the internal tool, highlights observed TCP connection tampering in connections from Algeria during the week that the Baccalaureate exams took place. While some baseline level of post-ACK and post-PSH tampering is consistently visible, we see significant increases in post-ACK twice a day during the exam period, at the times that align with the shifts in traffic discussed above. Technical descriptions of post-ACK and post-PSH tampering can be found in the &lt;a href=\&quot;https://developers.cloudflare.com/radar/glossary/#tcp-resets-and-timeouts\&quot;&gt;Cloudflare Radar glossary&lt;/a&gt;, but in short, tampering post-ACK means an established TCP connection to Cloudflare’s server has been abruptly ended by one or more RST packets &lt;i&gt;before&lt;/i&gt; the server sees data packets. Although clients do use RSTs, clients are more likely to close connections with a FIN (as specified by the &lt;a href=\&quot;https://datatracker.ietf.org/doc/html/rfc9293\&quot;&gt;RFC&lt;/a&gt;). The RST method can also be used by middleboxes that  (i) sees the data packet, then (ii) drops the data packet, then (iii) sends an RST to the server to force the server to close the connection (and very likely another RST to the client too for the same reason). Tampering post-PSH means that something on the path, like a middlebox, (i) saw something it didn&amp;#39;t like on an established connection, then (ii) permitted the data to pass but then, (iii) it sends the RST to force endpoints to close the connection.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/75i4amnWWtCkUaMhftCllH/a612735891aef71331339b9164171d48/image11-1.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;598\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;Looking beyond Cloudflare-sourced data, aggregated test results from the &lt;a href=\&quot;https://ooni.org/\&quot;&gt;Open Observatory of Network Interference (OONI)&lt;/a&gt; also show evidence of anomalous behavior. Using &lt;a href=\&quot;https://ooni.org/install/\&quot;&gt;OONI Probe&lt;/a&gt;, a mobile and desktop app, can probe for potential blocking of websites, instant messaging apps, and censorship circumvention tools. Examining test results from users in Algeria for popular messaging platforms &lt;a href=\&quot;https://explorer.ooni.org/chart/mat?probe_cc=DZ&amp;since=2024-06-01&amp;until=2024-06-15&amp;time_grain=day&amp;axis_x=measurement_start_day&amp;test_name=whatsapp\&quot;&gt;WhatsApp&lt;/a&gt;, &lt;a href=\&quot;https://explorer.ooni.org/chart/mat?probe_cc=DZ&amp;since=2024-06-01&amp;until=2024-06-15&amp;time_grain=day&amp;axis_x=measurement_start_day&amp;test_name=telegram\&quot;&gt;Telegram&lt;/a&gt;, &lt;a href=\&quot;https://explorer.ooni.org/chart/mat?probe_cc=DZ&amp;since=2024-06-01&amp;until=2024-06-15&amp;time_grain=day&amp;axis_x=measurement_start_day&amp;test_name=signal\&quot;&gt;Signal&lt;/a&gt;, and &lt;a href=\&quot;https://explorer.ooni.org/chart/mat?probe_cc=DZ&amp;since=2024-06-01&amp;until=2024-06-15&amp;time_grain=day&amp;axis_x=measurement_start_day&amp;test_name=facebook_messenger\&quot;&gt;Facebook Messenger&lt;/a&gt; for the first two weeks of June, we clearly see the appearance of test results marked as “Anomaly” starting on June 9. (OONI defines “Anomaly” results as “&lt;i&gt;Measurements that provided signs of potential blocking&lt;/i&gt;”.) OONI &lt;a href=\&quot;https://ooni.org/nettest/tor/\&quot;&gt;Tor test&lt;/a&gt; &lt;a href=\&quot;https://explorer.ooni.org/chart/mat?probe_cc=DZ&amp;since=2024-06-01&amp;until=2024-06-20&amp;time_grain=day&amp;axis_x=measurement_start_day&amp;test_name=tor\&quot;&gt;results&lt;/a&gt; also show a similar “Anomaly” pattern. Anomalous traffic patterns are also visible for &lt;a href=\&quot;https://transparencyreport.google.com/traffic/overview?hl=en&amp;fraction_traffic=start:1717200000000;product:19;region:DZ;end:1718495999999&amp;lu=fraction_traffic\&quot;&gt;Google Web Search&lt;/a&gt;, &lt;a href=\&quot;https://transparencyreport.google.com/traffic/overview?hl=en&amp;fraction_traffic=start:1717200000000;product:21;region:DZ;end:1718495999999&amp;lu=fraction_traffic\&quot;&gt;YouTube&lt;/a&gt;, and &lt;a href=\&quot;https://transparencyreport.google.com/traffic/overview?hl=en&amp;fraction_traffic=start:1717200000000;product:6;region:DZ;end:1718495999999&amp;lu=fraction_traffic\&quot;&gt;GMail&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Although the analysis of these observations and data sets doesn’t provide us with specific details around exactly how the observed Internet disruptions are being implemented, it strongly supports the supposition that network providers in Algeria are, in some fashion, interfering with TCP connections, but not blocking them outright nor shutting down their networks completely. Given that popular messaging platforms, Google properties, Cloudflare’s 1.1.1.1 DNS resolver, and some number of Cloudflare customer sites all appear to be impacted, it suggests that a list of hostnames are being targeted for disruption/interference, &lt;a href=\&quot;/consequences-of-ip-blocking\&quot;&gt;either by the SNI or the destination IP address&lt;/a&gt;.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;conclusion\&quot;&gt;Conclusion&lt;/h3&gt;\n            &lt;a href=\&quot;#conclusion\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Perhaps recognizing the broad negative impact that brute-force nationwide Internet shutdowns have as a response to cheating on exams, some governments appear to be turning to more nuanced techniques, such as content blocking or connection tampering. However, because these are widely applied as well, they are arguably just as disruptive as a full nationwide Internet shutdown. The cause of full shutdowns, such as those seen in Syria, are arguably easier to diagnose than the disruptions to connectivity seen in Iraq and Algeria, which appear to use approaches that are hard to specifically identify from the outside.&lt;/p&gt;&lt;p&gt;Visit &lt;a href=\&quot;https://radar.cloudflare.com/\&quot;&gt;Cloudflare Radar&lt;/a&gt; for additional insights around these, and other, Internet disruptions. Follow us on social media at &lt;a href=\&quot;https://x.com/CloudflareRadar\&quot;&gt;@CloudflareRadar&lt;/a&gt; (X), &lt;a href=\&quot;https://noc.social/@cloudflareradar\&quot;&gt;noc.social/@cloudflareradar&lt;/a&gt; (Mastodon), and &lt;a href=\&quot;https://bsky.app/profile/radar.cloudflare.com\&quot;&gt;radar.cloudflare.com&lt;/a&gt; (Bluesky), or contact us via email.&lt;/p&gt;&quot;],&quot;published_at&quot;:[0,&quot;2024-06-21T14:00:02.000+01:00&quot;],&quot;updated_at&quot;:[0,&quot;2024-10-09T23:28:29.062Z&quot;],&quot;feature_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5ZdbBpXelSYwLsVZO7oncv/6b8871f6fea4de6fd5310627c780eb44/syria-iraq-algeria-exam-internet-shutdown.png&quot;],&quot;tags&quot;:[1,[[0,{&quot;id&quot;:[0,&quot;5kZtWqjqa7aOUoZr8NFGwI&quot;],&quot;name&quot;:[0,&quot;Radar&quot;],&quot;slug&quot;:[0,&quot;cloudflare-radar&quot;]}],[0,{&quot;id&quot;:[0,&quot;0kgHdg1ytbdWl5BNo6bEa&quot;],&quot;name&quot;:[0,&quot;Internet Traffic&quot;],&quot;slug&quot;:[0,&quot;internet-traffic&quot;]}],[0,{&quot;id&quot;:[0,&quot;4yliZlpBPZpOwBDZzo1tTh&quot;],&quot;name&quot;:[0,&quot;Outage&quot;],&quot;slug&quot;:[0,&quot;outage&quot;]}],[0,{&quot;id&quot;:[0,&quot;sBnaK06GQyzaHg5OdsV90&quot;],&quot;name&quot;:[0,&quot;Internet Shutdown&quot;],&quot;slug&quot;:[0,&quot;internet-shutdown&quot;]}],[0,{&quot;id&quot;:[0,&quot;5O7yCWW0RgXMAc5MVjwcGS&quot;],&quot;name&quot;:[0,&quot;BGP&quot;],&quot;slug&quot;:[0,&quot;bgp&quot;]}],[0,{&quot;id&quot;:[0,&quot;4nA5kKyA1tOqFyjHMque21&quot;],&quot;name&quot;:[0,&quot;Consumer Services&quot;],&quot;slug&quot;:[0,&quot;consumer-services&quot;]}]]],&quot;relatedTags&quot;:[0],&quot;authors&quot;:[1,[[0,{&quot;name&quot;:[0,&quot;David Belson&quot;],&quot;slug&quot;:[0,&quot;david-belson&quot;],&quot;bio&quot;:[0,null],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/en7vkXf6rLBm4F8IcNHXT/645022bf841fabff7732aa3be3949808/david-belson.jpeg&quot;],&quot;location&quot;:[0,null],&quot;website&quot;:[0,null],&quot;twitter&quot;:[0,&quot;@dbelson&quot;],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}]]],&quot;meta_description&quot;:[0,&quot;Similar to actions taken over the last several years, governments in Syria, Iraq, and Algeria have again disrupted Internet connectivity nationwide in an attempt to prevent cheating on exams. We investigate how these disruptions were implemented, and their impact&quot;],&quot;primary_author&quot;:[0,{}],&quot;localeList&quot;:[0,{&quot;name&quot;:[0,&quot;Exam-ining recent Internet shutdowns in Syria, Iraq, and Algeria Config&quot;],&quot;enUS&quot;:[0,&quot;English for Locale&quot;],&quot;zhCN&quot;:[0,&quot;No Page for Locale&quot;],&quot;zhHansCN&quot;:[0,&quot;No Page for Locale&quot;],&quot;zhTW&quot;:[0,&quot;No Page for Locale&quot;],&quot;frFR&quot;:[0,&quot;No Page for Locale&quot;],&quot;deDE&quot;:[0,&quot;No Page for Locale&quot;],&quot;itIT&quot;:[0,&quot;No Page for Locale&quot;],&quot;jaJP&quot;:[0,&quot;No Page for Locale&quot;],&quot;koKR&quot;:[0,&quot;No Page for Locale&quot;],&quot;ptBR&quot;:[0,&quot;No Page for Locale&quot;],&quot;esLA&quot;:[0,&quot;No Page for Locale&quot;],&quot;esES&quot;:[0,&quot;No Page for Locale&quot;],&quot;enAU&quot;:[0,&quot;No Page for Locale&quot;],&quot;enCA&quot;:[0,&quot;No Page for Locale&quot;],&quot;enIN&quot;:[0,&quot;No Page for Locale&quot;],&quot;enGB&quot;:[0,&quot;No Page for Locale&quot;],&quot;idID&quot;:[0,&quot;No Page for Locale&quot;],&quot;ruRU&quot;:[0,&quot;No Page for Locale&quot;],&quot;svSE&quot;:[0,&quot;No Page for Locale&quot;],&quot;viVN&quot;:[0,&quot;No Page for Locale&quot;],&quot;plPL&quot;:[0,&quot;No Page for Locale&quot;],&quot;arAR&quot;:[0,&quot;No Page for Locale&quot;],&quot;nlNL&quot;:[0,&quot;No Page for Locale&quot;],&quot;thTH&quot;:[0,&quot;No Page for Locale&quot;],&quot;trTR&quot;:[0,&quot;No Page for Locale&quot;],&quot;heIL&quot;:[0,&quot;No Page for Locale&quot;],&quot;lvLV&quot;:[0,&quot;No Page for Locale&quot;],&quot;etEE&quot;:[0,&quot;No Page for Locale&quot;],&quot;ltLT&quot;:[0,&quot;No Page for Locale&quot;]}],&quot;url&quot;:[0,&quot;https://blog.cloudflare.com/syria-iraq-algeria-exam-internet-shutdown&quot;],&quot;metadata&quot;:[0,{&quot;title&quot;:[0,&quot;Exam-ining recent Internet shutdowns in Syria, Iraq, and Algeria&quot;],&quot;description&quot;:[0,&quot;Similar to actions taken over the last several years, governments in Syria, Iraq, and Algeria have again disrupted Internet connectivity nationwide in an attempt to prevent cheating on exams. We investigate how these disruptions were implemented, and their impact&quot;],&quot;imgPreview&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6sxwiOjx3qp1ibLjTZY4kF/d031cc8103f701cf3d895c5dc2598926/syria-iraq-algeria-exam-internet-shutdown-awN1no.png&quot;]}],&quot;publicly_index&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;6s5NVIgDAZRwC6FINYEME1&quot;],&quot;title&quot;:[0,&quot;East African Internet connectivity again impacted by submarine cable cuts&quot;],&quot;slug&quot;:[0,&quot;east-african-internet-connectivity-again-impacted-by-submarine-cable-cuts&quot;],&quot;excerpt&quot;:[0,&quot;On Sunday, May 12, issues with the EASSy and Seacom submarine cables again disrupted connectivity to East Africa, impacting a number of countries previously affected by a set of cable cuts that occurred nearly three months earlier&quot;],&quot;featured&quot;:[0,false],&quot;html&quot;:[0,&quot;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/nzGCGsJzxhO0d2enNMNp0/92fe557681aafbfbe475f99485f0cb69/image9.png\&quot; alt=\&quot;Undersea cable failures cause Internet disruptions for multiple African countries\&quot; class=\&quot;kg-image\&quot; width=\&quot;1800\&quot; height=\&quot;1013\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;On Sunday, May 12, issues with the &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/eastern-africa-submarine-system-eassy\&quot;&gt;ESSAy&lt;/a&gt; and &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/seacomtata-tgn-eurasia\&quot;&gt;Seacom&lt;/a&gt; submarine cables again disrupted connectivity to East Africa, impacting a number of countries previously affected by a set of cable cuts that occurred nearly three months earlier.&lt;/p&gt;&lt;p&gt;On February 24, three submarine cables that run through the Red Sea were damaged: the &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/seacomtata-tgn-eurasia\&quot;&gt;Seacom/Tata cable&lt;/a&gt;, the &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/asia-africa-europe-1-aae-1\&quot;&gt;Asia Africa Europe-1&lt;/a&gt; (AAE-1), and the &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/europe-india-gateway-eig\&quot;&gt;Europe India Gateway&lt;/a&gt; (EIG). It is &lt;a href=\&quot;https://www.bloomberg.com/news/articles/2024-03-06/anchor-from-houthi-sunk-ship-likely-damaged-undersea-cables\&quot;&gt;believed&lt;/a&gt; that the cables were cut by the anchor of the &lt;a href=\&quot;https://www.wired.com/story/houthi-internet-cables-ship-anchor-path/\&quot;&gt;Rubymar&lt;/a&gt;, a cargo ship that was damaged by a ballistic missile on February 18. These cable cuts &lt;a href=\&quot;https://www.wired.com/story/houthi-internet-cables-ship-anchor-path/#:~:text=impacted%20countries%20in%20East%20Africa\&quot;&gt;reportedly&lt;/a&gt; impacted countries in East Africa, including &lt;a href=\&quot;https://radar.cloudflare.com/traffic/tz?dateStart=2024-02-22&amp;dateEnd=2024-02-28\&quot;&gt;Tanzania&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/traffic/ke?dateStart=2024-02-22&amp;dateEnd=2024-02-28\&quot;&gt;Kenya&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/traffic/ug?dateStart=2024-02-22&amp;dateEnd=2024-02-28\&quot;&gt;Uganda&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/traffic/mz?dateStart=2024-02-22&amp;dateEnd=2024-02-28\&quot;&gt;Mozambique&lt;/a&gt;. As of this writing (May 13), &lt;a href=\&quot;https://www.bloomberg.com/news/articles/2024-05-07/repairs-to-damaged-red-sea-internet-cables-delayed-by-yemen-political-splits\&quot;&gt;these cables remain unrepaired&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Already suffering from reduced capacity due to the February cable cuts, these countries were impacted by a second set of cable cuts that occurred on Sunday, May 12. According to a &lt;a href=\&quot;https://twitter.com/benliquidkenya/status/1789622798907843058\&quot;&gt;social media post from Ben Roberts&lt;/a&gt;, Group CTIO at Liquid Intelligent Technologies in Kenya, faults on the &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/eastern-africa-submarine-system-eassy\&quot;&gt;EASSy&lt;/a&gt; and &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/seacomtata-tgn-eurasia\&quot;&gt;Seacom&lt;/a&gt; cables again disrupted connectivity to East Africa, as he noted “&lt;i&gt;All sub sea capacity between East Africa and South Africa is down.&lt;/i&gt;” A &lt;a href=\&quot;https://www.bbc.com/news/articles/cprg0yn8q81o\&quot;&gt;BBC article&lt;/a&gt; citing Roberts stated that the EASSy cable had been cut approximately 45km (28 miles) north of the South African port city of Durban. A subsequent &lt;a href=\&quot;https://twitter.com/CA_Kenya/status/1790022989913727121\&quot;&gt;press release issued by the Communications Authority of Kenya&lt;/a&gt; stated that the cut had occurred at the Mtunzini teleport station (in South Africa). As seen in the map below, both the EASSy and Seacom cables land in Mtunzini.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3wrAt6mGIBYnbFcx2sFE1R/2c96f84be734c07870cf9a162221478a/image7.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;800\&quot; height=\&quot;757\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;_Map of African undersea cables, April 2024.&lt;i&gt;‌ ‌_Source: &lt;/i&gt;&lt;a href=\&quot;https://manypossibilities.net/african-undersea-cables/\&quot;&gt;&lt;i&gt;https://manypossibilities.net/african-undersea-cables/&lt;/i&gt;&lt;/a&gt;&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;impacts-to-country-level-internet-traffic\&quot;&gt;Impacts to country-level Internet traffic&lt;/h2&gt;\n            &lt;a href=\&quot;#impacts-to-country-level-internet-traffic\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;Cloudflare Radar saw traffic levels across a number of the impacted countries drop just before 11:00 local time (08:00 UTC).  As seen in the graphs below, the magnitude of impact varied by country, with traffic initially dropping by 10-25% in &lt;a href=\&quot;https://radar.cloudflare.com/traffic/ke?dateStart=2024-05-12\&quot;&gt;Kenya&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/traffic/ug?dateStart=2024-05-12\&quot;&gt;Uganda&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/traffic/mg?dateStart=2024-05-12\&quot;&gt;Madagascar&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/traffic/mz?dateStart=2024-05-12\&quot;&gt;Mozambique&lt;/a&gt;, while traffic in &lt;a href=\&quot;https://radar.cloudflare.com/traffic/rw?dateStart=2024-05-12\&quot;&gt;Rwanda&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/traffic/mw?dateStart=2024-05-12\&quot;&gt;Malawi&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/traffic/tz?dateStart=2024-05-12\&quot;&gt;Tanzania&lt;/a&gt; dropped by one-third or more as compared to the previous week.&lt;/p&gt;&lt;p&gt;In Kenya and Uganda, the overall impact appeared to be low, with traffic generally remaining just below expected levels in the day and a half following the cable faults. In the other countries, the overnight trough of the diurnal traffic patterns remained consistent with the previous week’s traffic levels, but otherwise traffic remains significantly lower than expected.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4ZZSQENjYypEHSVoQb0MNF/0131718492fb600090fae297677b5bc1/image5-5.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3WNVYVTEeCUI7w8x3QWsK6/98a6884e29a43f94b77e786cb5136358/image3-2.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6s29MABCM7bdO9kIBFqeh0/1fa6f64251f108389520bb189cf49c09/image6.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/sDtrPwYPYxvEdgeN9pTcy/8ac732739ea45f256a9b4ccda67c0609/image2-6.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2wWCX0FqYlOYthV4KLojje/f4e240a92ef690889d701430fcc0de1b/image4-2.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2MdVAuma3M0sHkpRObm7S9/da67554d7d900b1102beed306290545b/image8.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3aYMwtsV2mAWbThzrUqNVJ/a749187107446ddbe1f7f6ccfb2dd514/image1-5.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1125\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;the-importance-of-redundancy\&quot;&gt;The importance of redundancy&lt;/h2&gt;\n            &lt;a href=\&quot;#the-importance-of-redundancy\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;In Kenya, the impact may have been nominal due to steps taken by providers like Safaricom and Airtel Kenya. In a May 12 social media post, &lt;a href=\&quot;https://twitter.com/SafaricomPLC/status/1789672918437200266\&quot;&gt;Safaricom noted&lt;/a&gt; “&lt;i&gt;...We have since activated redundancy measures to minimise service interruption and keep you connected as we await the full restoration of the cable.&lt;/i&gt;” In a subsequent social media post on May 13, &lt;a href=\&quot;https://twitter.com/SafaricomPLC/status/1789992420836307292/photo/1\&quot;&gt;Safaricom noted&lt;/a&gt; “&lt;i&gt;Thanks to our redundancy plans and capacity investment across multiple undersea cables our services continue to be available, however some customers may experience slow connectivity and speeds.&lt;/i&gt;” Similarly, a social media post from &lt;a href=\&quot;https://twitter.com/AIRTEL_KE/status/1790097275970019693/photo/1\&quot;&gt;Airtel Kenya noted&lt;/a&gt; “&lt;i&gt;Following yesterday&amp;#39;s undersea fiber cut that has impacted internet connectivity, we would like to update you that we have taken measures to improve your browsing experience through additional capacity enhancement.&lt;/i&gt;”&lt;/p&gt;&lt;p&gt;Similarly, the previously referenced &lt;a href=\&quot;https://twitter.com/CA_Kenya/status/1790022989913727121/photo/1\&quot;&gt;press release&lt;/a&gt; from the Communications Authority of Kenya talked about actions being taken, stating “&lt;i&gt;Meanwhile, the Authority has directed service providers to take proactive steps to secure alternative routes for their traffic and is monitoring the situation closely to ensure that incoming and outbound internet connectivity is available. The East Africa Marine System (TEAMS) cable, which has not been affected by the cut, is currently being utilised for local traffic flow while redundancy on the South Africa route has been activated to minimise the impact.&lt;/i&gt;”&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;whats-next\&quot;&gt;What’s next?&lt;/h2&gt;\n            &lt;a href=\&quot;#whats-next\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;Once the necessary permits are secured and the cable faults are located, repairs can often be completed in several days. However, because cable repair ships are &lt;a href=\&quot;https://www.iscpc.org/information/cableships-of-the-world/?items=0\&quot;&gt;something of a scarce resource&lt;/a&gt;, there is &lt;a href=\&quot;https://www.theverge.com/c/24070570/internet-cables-undersea-deep-repair-ships\&quot;&gt;often a delay&lt;/a&gt; to both engage a vessel and for it to travel to the area where the cable damage occurred, whether from its baseport or the location of a previous repair. However, in this case that delay may be comparatively short, as submarine cable industry observer &lt;a href=\&quot;https://twitter.com/philBE2/status/1790051184578871524\&quot;&gt;@philBE2 predicts&lt;/a&gt; “&lt;i&gt;Expecting the usual suspect,&lt;/i&gt; &lt;a href=\&quot;https://www.vesselfinder.com/vessels/details/8108676\&quot;&gt;&lt;i&gt;CS Leon Thevenin&lt;/i&gt;&lt;/a&gt;&lt;i&gt;, now moored in Cape Town, to be swiftly mobilized for an expeditious repair mission…&lt;/i&gt;”&lt;/p&gt;&lt;p&gt;The Cloudflare Radar team will continue to monitor traffic recovery and the status of Internet connectivity in the impacted countries. We will share our observations on the &lt;a href=\&quot;https://radar.cloudflare.com/outage-center\&quot;&gt;Cloudflare Radar Outage Center&lt;/a&gt;, via social media, and in posts on &lt;a href=\&quot;/tag/cloudflare-radar/\&quot;&gt;blog.cloudflare.com&lt;/a&gt;. Follow us on social media at &lt;a href=\&quot;https://twitter.com/CloudflareRadar\&quot;&gt;@CloudflareRadar&lt;/a&gt; (X), &lt;a href=\&quot;https://noc.social/@cloudflareradar\&quot;&gt;https://noc.social/@cloudflareradar&lt;/a&gt; (Mastodon), and &lt;a href=\&quot;https://bsky.app/profile/radar.cloudflare.com\&quot;&gt;radar.cloudflare.com&lt;/a&gt; (Bluesky), or contact us via email.&lt;/p&gt;&quot;],&quot;published_at&quot;:[0,&quot;2024-05-13T23:37:25.000+01:00&quot;],&quot;updated_at&quot;:[0,&quot;2024-10-10T00:22:00.045Z&quot;],&quot;feature_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6bKPQSkJQwU645VznEPV9y/61ed7176fb3a52f8bb9cb7f93afa91bc/east-african-internet-connectivity-again-impacted-by-submarine-cable-cuts.png&quot;],&quot;tags&quot;:[1,[[0,{&quot;id&quot;:[0,&quot;5kZtWqjqa7aOUoZr8NFGwI&quot;],&quot;name&quot;:[0,&quot;Radar&quot;],&quot;slug&quot;:[0,&quot;cloudflare-radar&quot;]}],[0,{&quot;id&quot;:[0,&quot;0kgHdg1ytbdWl5BNo6bEa&quot;],&quot;name&quot;:[0,&quot;Internet Traffic&quot;],&quot;slug&quot;:[0,&quot;internet-traffic&quot;]}],[0,{&quot;id&quot;:[0,&quot;4yliZlpBPZpOwBDZzo1tTh&quot;],&quot;name&quot;:[0,&quot;Outage&quot;],&quot;slug&quot;:[0,&quot;outage&quot;]}]]],&quot;relatedTags&quot;:[0],&quot;authors&quot;:[1,[[0,{&quot;name&quot;:[0,&quot;David Belson&quot;],&quot;slug&quot;:[0,&quot;david-belson&quot;],&quot;bio&quot;:[0,null],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/en7vkXf6rLBm4F8IcNHXT/645022bf841fabff7732aa3be3949808/david-belson.jpeg&quot;],&quot;location&quot;:[0,null],&quot;website&quot;:[0,null],&quot;twitter&quot;:[0,&quot;@dbelson&quot;],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}]]],&quot;meta_description&quot;:[0,null],&quot;primary_author&quot;:[0,{}],&quot;localeList&quot;:[0,{&quot;name&quot;:[0,&quot;East African Internet connectivity again impacted by submarine cable cuts Config&quot;],&quot;enUS&quot;:[0,&quot;English for Locale&quot;],&quot;zhCN&quot;:[0,&quot;No Page for Locale&quot;],&quot;zhHansCN&quot;:[0,&quot;No Page for Locale&quot;],&quot;zhTW&quot;:[0,&quot;No Page for Locale&quot;],&quot;frFR&quot;:[0,&quot;No Page for Locale&quot;],&quot;deDE&quot;:[0,&quot;No Page for Locale&quot;],&quot;itIT&quot;:[0,&quot;No Page for Locale&quot;],&quot;jaJP&quot;:[0,&quot;No Page for Locale&quot;],&quot;koKR&quot;:[0,&quot;No Page for Locale&quot;],&quot;ptBR&quot;:[0,&quot;No Page for Locale&quot;],&quot;esLA&quot;:[0,&quot;No Page for Locale&quot;],&quot;esES&quot;:[0,&quot;No Page for Locale&quot;],&quot;enAU&quot;:[0,&quot;No Page for Locale&quot;],&quot;enCA&quot;:[0,&quot;No Page for Locale&quot;],&quot;enIN&quot;:[0,&quot;No Page for Locale&quot;],&quot;enGB&quot;:[0,&quot;No Page for Locale&quot;],&quot;idID&quot;:[0,&quot;No Page for Locale&quot;],&quot;ruRU&quot;:[0,&quot;No Page for Locale&quot;],&quot;svSE&quot;:[0,&quot;No Page for Locale&quot;],&quot;viVN&quot;:[0,&quot;No Page for Locale&quot;],&quot;plPL&quot;:[0,&quot;No Page for Locale&quot;],&quot;arAR&quot;:[0,&quot;No Page for Locale&quot;],&quot;nlNL&quot;:[0,&quot;No Page for Locale&quot;],&quot;thTH&quot;:[0,&quot;No Page for Locale&quot;],&quot;trTR&quot;:[0,&quot;No Page for Locale&quot;],&quot;heIL&quot;:[0,&quot;No Page for Locale&quot;],&quot;lvLV&quot;:[0,&quot;No Page for Locale&quot;],&quot;etEE&quot;:[0,&quot;No Page for Locale&quot;],&quot;ltLT&quot;:[0,&quot;No Page for Locale&quot;]}],&quot;url&quot;:[0,&quot;https://blog.cloudflare.com/east-african-internet-connectivity-again-impacted-by-submarine-cable-cuts&quot;],&quot;metadata&quot;:[0,{&quot;title&quot;:[0,&quot;East African Internet connectivity again impacted by submarine cable cuts&quot;],&quot;description&quot;:[0,null],&quot;imgPreview&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/28bxG30oKHTtkNWiRYphHS/2f67e22a3f98849aac8f9860bfe4acd5/east-african-internet-connectivity-again-impacted-by-submarine-cable-cuts-xwkPxb.png&quot;]}],&quot;publicly_index&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;48Rzo73JqvkA5I3YzT2Coi&quot;],&quot;title&quot;:[0,&quot;Q1 2024 Internet disruption summary&quot;],&quot;slug&quot;:[0,&quot;q1-2024-internet-disruption-summary&quot;],&quot;excerpt&quot;:[0,&quot;The first quarter of 2024 kicked off with quite a few Internet disruptions. Perhaps most interestingly, RPKI, DNS, and DNSSEC issues were among the technical problems that disrupted connectivity for subscribers across multiple network providers&quot;],&quot;featured&quot;:[0,false],&quot;html&quot;:[0,&quot;&lt;p&gt;&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6k1NK6vOkPAt8lFkq7iKEQ/3e38a7a4846ea723b9227e974d91600b/image1-21.png\&quot; alt=\&quot;Q1 2024 Internet Disruption Summary\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1126\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;Cloudflare’s network spans more than 310 cities in over 120 countries, where we interconnect with over 13,000 network providers in order to provide a broad range of services to millions of customers. The breadth of both our network and our customer base provides us with a unique perspective on Internet resilience, enabling us to observe the impact of Internet disruptions. Thanks to recently released Cloudflare Radar &lt;a href=\&quot;https://developers.cloudflare.com/radar/glossary/#bgp-announcements\&quot;&gt;functionality&lt;/a&gt;, this quarter we have started to explore the impact from a routing perspective, as well as a traffic perspective, at both a &lt;a href=\&quot;https://twitter.com/CloudflareRadar/status/1768654743742579059\&quot;&gt;network&lt;/a&gt; and &lt;a href=\&quot;https://twitter.com/CloudflareRadar/status/1773704264650543416\&quot;&gt;location&lt;/a&gt; level.&lt;/p&gt;&lt;p&gt;The first quarter of 2024 kicked off with quite a few Internet disruptions. &lt;a href=\&quot;#cablecuts\&quot;&gt;Damage to both terrestrial and submarine cables&lt;/a&gt; caused problems in a number of locations, while &lt;a href=\&quot;#militaryaction\&quot;&gt;military action&lt;/a&gt; related to ongoing geopolitical conflicts impacted connectivity in other areas. &lt;a href=\&quot;#governmentdirected\&quot;&gt;Governments&lt;/a&gt; in several African countries, as well as Pakistan, ordered Internet shutdowns, focusing heavily on mobile connectivity. Malicious actors known as &lt;a href=\&quot;https://www.cloudflare.com/learning/ddos/glossary/anonymous-sudan/\&quot;&gt;Anonymous Suda&lt;/a&gt;n claimed responsibility for &lt;a href=\&quot;#cyberattacks\&quot;&gt;cyberattacks&lt;/a&gt; that disrupted Internet connectivity in Israel and Bahrain. &lt;a href=\&quot;#maintenance\&quot;&gt;Maintenance&lt;/a&gt; and &lt;a href=\&quot;#poweroutages\&quot;&gt;power outages&lt;/a&gt; forced users offline, resulting in observed drops in traffic. And in a more unusual turn, &lt;a href=\&quot;#orangeespana\&quot;&gt;RPKI&lt;/a&gt;, &lt;a href=\&quot;#plusnetuk\&quot;&gt;DNS&lt;/a&gt;, and &lt;a href=\&quot;#russia\&quot;&gt;DNSSEC&lt;/a&gt; issues were among the &lt;a href=\&quot;#technicalproblems\&quot;&gt;technical problems&lt;/a&gt; that disrupted connectivity for subscribers across multiple network providers.&lt;/p&gt;&lt;p&gt;As we have noted in the past, this post is intended as a summary overview of observed disruptions, and is not an exhaustive or complete list of issues that have occurred during the quarter.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;h2 id=\&quot;cablecuts\&quot;&gt;Cable cuts&lt;/h2&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;moov-africa-tchad\&quot;&gt;Moov Africa Tchad&lt;/h3&gt;\n            &lt;a href=\&quot;#moov-africa-tchad\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Reported fiber optic cable damage that occurred in &lt;a href=\&quot;https://radar.cloudflare.com/cm\&quot;&gt;Cameroon&lt;/a&gt; on January 10 further disrupted connectivity for customers of &lt;a href=\&quot;https://radar.cloudflare.com/as327802\&quot;&gt;AS327802 (Moov Africa Tchad / Millicom)&lt;/a&gt; a telecommunications provider in Chad. According to a (translated) &lt;a href=\&quot;https://www.facebook.com/moovafrica.td/posts/pfbid0kB9W5CkhVJqBq34agPWqG81yeCfLBijKYc6WiLDKLE79nPmhie4T9idZVStc8f6Xl\&quot;&gt;Facebook post from Moov Africa Tchad&lt;/a&gt;, “&lt;i&gt;On the afternoon of January 10, 2024, there was a breakdown of the internet due to a cut in the optical fiber coming from Cameroon through which Chad has access to the internet, the one coming from Sudan being unavailable for a while.&lt;/i&gt;” It is unclear whether the referenced cable cut occurred in Cameroon or Chad, and the mentioned &lt;a href=\&quot;https://radar.cloudflare.com/sd\&quot;&gt;Sudan&lt;/a&gt; cable issue may be &lt;a href=\&quot;/q4-2023-internet-disruption-summary#:~:text=of%20Internet%20service.-,Chad,-On\&quot;&gt;the one covered in our Q4 2023 summary post&lt;/a&gt;. As a landlocked country, Chad is dependent on terrestrial Internet connections to/through neighboring countries, and the &lt;a href=\&quot;https://afterfibre.nsrc.org/\&quot;&gt;AfTerFibre cable map&lt;/a&gt; illustrates Chad’s reliance on limited cable paths through Cameroon and Sudan.&lt;/p&gt;&lt;p&gt;The graphs below show that Moov Africa Tchad traffic was disrupted for over 12 hours starting midday (UTC) on January 10, and the disruption was visible at a country level as well. The fiber cut also resulted in significant volatility from a routing perspective, as the volume of announced IPv4 address space shifted frequently at a &lt;a href=\&quot;https://radar.cloudflare.com/routing/as327802?dateStart=2024-01-10&amp;dateEnd=2024-01-11\&quot;&gt;network&lt;/a&gt; and &lt;a href=\&quot;https://radar.cloudflare.com/routing/td?dateStart=2024-01-10&amp;dateEnd=2024-01-11\&quot;&gt;country&lt;/a&gt; level during the disruption.&lt;/p&gt;&lt;p&gt;A second less severe disruption was also observed during the morning (UTC) of January 11. That disruption was &lt;a href=\&quot;https://twitter.com/DarkWebDispatch/status/1745080174519923165\&quot;&gt;reportedly&lt;/a&gt; due to an &lt;a href=\&quot;https://crisis24.garda.com/alerts/2024/01/chad-residual-internet-service-disruptions-possible-over-coming-hours-following-hours-long-outage-across-country-jan-10\&quot;&gt;alleged cyberattack&lt;/a&gt; by Anonymous Sudan that targeted &lt;a href=\&quot;https://radar.cloudflare.com/as328594\&quot;&gt;AS328594 (SudaChad Telecom)&lt;/a&gt;, which is an &lt;a href=\&quot;https://radar.cloudflare.com/routing/as327802\&quot;&gt;upstream provider for Moov Africa Tchad&lt;/a&gt;.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-01-10&amp;dateEnd=2024-01-11&amp;location=td&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;orange-burkina-faso\&quot;&gt;Orange Burkina Faso&lt;/h3&gt;\n            &lt;a href=\&quot;#orange-burkina-faso\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;On February 15, a brief (~30 minute) but complete significant Internet disruption was observed at &lt;a href=\&quot;https://radar.cloudflare.com/as37577\&quot;&gt;AS37577 (Orange Burkina Faso)&lt;/a&gt;. According to the translation of a communiqué &lt;a href=\&quot;https://twitter.com/OrangeBurkina/status/1758179417065464103\&quot;&gt;posted by the provider on social media&lt;/a&gt;, “&lt;i&gt;The incident is due to a fiber cut, which causes a disruption of Internet services for certain customers.&lt;/i&gt;” Orange did not specify whether it was a more localized fiber cut, or damage to one of the terrestrial fibers that cross the country. The incident took the network completely offline, as the ASN’s amount of announced IPv4 address space &lt;a href=\&quot;https://radar.cloudflare.com/routing/as37577?dateStart=2024-02-15&amp;dateEnd=2024-02-15\&quot;&gt;dropped to zero&lt;/a&gt; for the duration.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/BgpRoutesTimeseriesXY?dateStart=2024-02-15&amp;dateEnd=2024-02-15&amp;location=as37577&amp;chartState=%7B%22bgpSignalsMinMax%22%3Atrue%2C%22bgpSignalsIpVersionParam%22%3A%22ipv4%22%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Announced IP Address Space\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;mtn-nigeria\&quot;&gt;MTN Nigeria&lt;/h3&gt;\n            &lt;a href=\&quot;#mtn-nigeria\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;&lt;a href=\&quot;https://twitter.com/MTNNG/status/1762909655620063594\&quot;&gt;MTN Nigeria turned to social media&lt;/a&gt; on February 28 to let customers know that “&lt;i&gt;You have been experiencing challenges connecting to the network due to a major service outage caused by multiple fibre cuts, affecting voice and data services.&lt;/i&gt;” A &lt;a href=\&quot;https://crisis24.garda.com/alerts/2024/02/nigeria-lingering-internet-and-telecommunications-disruptions-likely-in-areas-across-country-following-nationwide-outage-feb-28\&quot;&gt;published report&lt;/a&gt; described the impact, noting “&lt;i&gt;Millions of customers nationwide were impacted by the hours-long outage, especially in Lagos.&lt;/i&gt;” Connectivity was disrupted for approximately seven hours between 13:30 - 20:30 local time (12:30 - 19:30 UTC), and the provider &lt;a href=\&quot;https://twitter.com/MTNNG/status/1762972229195702692\&quot;&gt;posted a followup note&lt;/a&gt; just before midnight local time stating that service had been fully restored.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-02-28&amp;dateEnd=2024-02-28&amp;location=as29465&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;digicel-haiti\&quot;&gt;Digicel Haiti&lt;/h3&gt;\n            &lt;a href=\&quot;#digicel-haiti\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;A 16-hour Internet disruption on March 2/3 at &lt;a href=\&quot;https://radar.cloudflare.com/as27653\&quot;&gt;AS27653 (Digicel Haiti)&lt;/a&gt; was due to a double fiber cut &lt;a href=\&quot;https://www.reuters.com/world/americas/haitian-police-unions-plead-help-after-attack-main-prison-2024-03-03/\&quot;&gt;as a result of violence&lt;/a&gt; related to attempts to oust Prime Minister Ariel Henry. Starting around 22:00 local time on March 2 (03:00 on March 3), a complete outage was observed for approximately nine hours. Some recovery in traffic occurred for approximately two-and-a-half hours, followed by a three hour near-complete disruption. Digicel Haiti effectively disappeared from the Internet during the nine-hour outage, as no IPv4 or IPv6 address space was announced by the network during that time.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/BgpRoutesTimeseriesXY?dateStart=2024-03-03&amp;dateEnd=2024-03-03&amp;location=as27653&amp;chartState=%7B%22bgpSignalsMinMax%22%3Atrue%2C%22bgpSignalsIpVersionParam%22%3A%22ipv6%22%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Announced IP Address Space\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;sky-philippines\&quot;&gt;SKY (Philippines)&lt;/h3&gt;\n            &lt;a href=\&quot;#sky-philippines\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;A brief traffic disruption observed on &lt;a href=\&quot;https://radar.cloudflare.com/as23944\&quot;&gt;AS23944 (SKY)&lt;/a&gt; in the &lt;a href=\&quot;https://radar.cloudflare.com/ph\&quot;&gt;Philippines&lt;/a&gt; on March 18 was likely related to a fiber cut. In an &lt;a href=\&quot;https://twitter.com/SKYserves/status/1769688520124227960\&quot;&gt;advisory posted by SKY&lt;/a&gt; on social media, they stated that “&lt;i&gt;SKY services in several areas in Marikina, Pasig and Quezon City are currently affected by a cut-fiber issue&lt;/i&gt;”, listing 45 affected areas. Traffic was most significantly impacted between 20:00 - 21:00 local time (12:00 - 13:00 UTC), although full recovery took several more hours. Only a &lt;a href=\&quot;https://radar.cloudflare.com/routing/as23944?dateStart=2024-03-18&amp;dateEnd=2024-03-18\&quot;&gt;minor impact to routing&lt;/a&gt; resulting from the fiber cut was observed.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-03-18&amp;dateEnd=2024-03-18&amp;location=as23944&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;multiple-african-countries\&quot;&gt;Multiple African countries&lt;/h3&gt;\n            &lt;a href=\&quot;#multiple-african-countries\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;On March 14, damage to multiple submarine cables off the west coast of Africa impacted Internet connectivity across multiple countries in West and Southern Africa. The damage was &lt;a href=\&quot;https://www.itweb.co.za/article/news-analysis-why-undersea-cables-broke-sas-public-cloud/G98Yd7LGK4pvX2PD\&quot;&gt;reportedly&lt;/a&gt; caused by underwater rock falls, and in addition to disrupting Internet connectivity, also &lt;a href=\&quot;https://web.archive.org/web/20240314144626/https://status.cloud.microsoft/\&quot;&gt;caused availability issues for Microsoft Azure and Office 365 cloud services&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/africa-coast-to-europe-ace\&quot;&gt;Africa Coast to Europe (ACE)&lt;/a&gt;, &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/sat-3wasc\&quot;&gt;Submarine Atlantic 3/West Africa Submarine Cable (SAT-3/WASC)&lt;/a&gt;, &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/west-africa-cable-system-wacs\&quot;&gt;West Africa Cable System (WACS)&lt;/a&gt;, and &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/mainone\&quot;&gt;MainOne&lt;/a&gt; cables &lt;a href=\&quot;https://www.internetsociety.org/resources/doc/2024/2024-west-africa-submarine-cable-outage-report/\&quot;&gt;were all damaged&lt;/a&gt;, and impacted 13 African countries including &lt;a href=\&quot;https://radar.cloudflare.com/bj\&quot;&gt;Benin&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/bf\&quot;&gt;Burkina Faso&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/cm\&quot;&gt;Cameroon&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/ci\&quot;&gt;Côte d’Ivoire&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/gm\&quot;&gt;Gambia&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/gh\&quot;&gt;Ghana&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/gn\&quot;&gt;Guinea&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/lr\&quot;&gt;Liberia&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/na\&quot;&gt;Namibia&lt;/a&gt;, &lt;a href=\&quot;http://radar.cloudflare.com/ne\&quot;&gt;Niger&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/ng\&quot;&gt;Nigeria&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/za\&quot;&gt;South Africa&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/tg\&quot;&gt;Togo&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Comparatively brief disruptions were observed in &lt;a href=\&quot;https://radar.cloudflare.com/ne?dateStart=2024-03-14&amp;dateEnd=2024-03-14\&quot;&gt;Niger&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/traffic/gn?dateStart=2024-03-14&amp;dateEnd=2024-03-14\&quot;&gt;Guinea&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/traffic/gm?dateStart=2024-03-14&amp;dateEnd=2024-03-14\&quot;&gt;Gambia&lt;/a&gt;, lasting from under an hour to approximately two hours.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-03-14&amp;dateEnd=2024-03-14&amp;location=gm&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;&lt;p&gt;However, the disruptions stretched out across multiple days in countries including &lt;a href=\&quot;https://radar.cloudflare.com/traffic/tg?dateStart=2024-03-11&amp;dateEnd=2024-03-17\&quot;&gt;Togo&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/traffic/lr?dateStart=2024-03-11&amp;dateEnd=2024-03-17\&quot;&gt;Liberia&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/traffic/gh?dateStart=2024-03-11&amp;dateEnd=2024-03-31\&quot;&gt;Ghana&lt;/a&gt;, where it took several weeks for traffic to return to previously observed peak levels.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-03-11&amp;dateEnd=2024-03-31&amp;location=gh&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;&lt;p&gt;Operators in impacted countries attempted to maintain availability by shifting traffic to Google’s &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/equiano\&quot;&gt;Equiano&lt;/a&gt; submarine cable, which &lt;a href=\&quot;https://www.capacitymedia.com/article/2czls1jc2s3jtornuuhvk/news/exclusive-equianos-togo-landing-station-sees-4x-increase-in-traffic\&quot;&gt;reportedly&lt;/a&gt; experienced a 4x increase in traffic, and &lt;a href=\&quot;https://www.moroccoworldnews.com/2024/03/361490/west-africa-internet-outage-highlights-moroccos-crucial-role-in-regional-connectivity\&quot;&gt;Morocco’s&lt;/a&gt; &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/maroc-telecom-west-africa\&quot;&gt;Maroc Telecom West Africa&lt;/a&gt; submarine cable. Service on the &lt;a href=\&quot;https://www.linkedin.com/posts/philippe-devaux-218423199_08apr24-west-africa-multiple-cables-outages-activity-7183050367440441344-iyTI?utm_source=share&amp;utm_medium=member_desktop\&quot;&gt;SAT-3&lt;/a&gt; cable was fully restored as of April 6, with repairs on &lt;a href=\&quot;https://www.linkedin.com/posts/philippe-devaux-218423199_wacsabrcable-sat3abrcable-activity-7187430036432408576-404i?utm_source=share&amp;utm_medium=member_desktop\&quot;&gt;ACE&lt;/a&gt; completed on April 17, repairs to &lt;a href=\&quot;https://www.linkedin.com/feed/update/urn:li:activity:7187430036432408576/\&quot;&gt;WACS&lt;/a&gt; and &lt;a href=\&quot;https://www.linkedin.com/posts/philippe-devaux-218423199_wacsabrcable-sat3abrcable-activity-7185980538434801664-dfa3?utm_source=share&amp;utm_medium=member_desktop\&quot;&gt;MainOne&lt;/a&gt; expected to be done by April 28.&lt;/p&gt;&lt;p&gt;Additional details and observations can be found in our blog post &lt;a href=\&quot;/undersea-cable-failures-cause-internet-disruptions-across-africa-march-14-2024/\&quot;&gt;&lt;i&gt;Undersea cable failures cause Internet disruptions for multiple African countries&lt;/i&gt;&lt;/a&gt;.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;red-sea\&quot;&gt;Red Sea&lt;/h3&gt;\n            &lt;a href=\&quot;#red-sea\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;On February 24, three submarine cables that run through the Red Sea were damaged: the &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/seacomtata-tgn-eurasia\&quot;&gt;Seacom/Tata cable&lt;/a&gt;, the &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/asia-africa-europe-1-aae-1\&quot;&gt;Asia Africa Europe-1&lt;/a&gt; (AAE-1), and the &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/europe-india-gateway-eig\&quot;&gt;Europe India Gateway&lt;/a&gt; (EIG). It is &lt;a href=\&quot;https://www.bloomberg.com/news/articles/2024-03-06/anchor-from-houthi-sunk-ship-likely-damaged-undersea-cables\&quot;&gt;believed&lt;/a&gt; that the cables were cut by the anchor of the &lt;a href=\&quot;https://www.wired.com/story/houthi-internet-cables-ship-anchor-path/\&quot;&gt;Rubymar&lt;/a&gt;, a cargo ship that was damaged by a ballistic missile on February 18. At the time of the disruption, Seacom &lt;a href=\&quot;https://www.itweb.co.za/article/seacom-confirms-cable-outage-in-red-sea/KPNG8v8NyDNM4mwD\&quot;&gt;confirmed&lt;/a&gt; the damage to their cable, while the owners of the other two cables did not publish similar confirmations.&lt;/p&gt;&lt;p&gt;While the cable cuts &lt;a href=\&quot;https://www.wired.com/story/houthi-internet-cables-ship-anchor-path/#:~:text=impacted%20countries%20in%20East%20Africa\&quot;&gt;reportedly&lt;/a&gt; impacted countries in East Africa, including &lt;a href=\&quot;https://radar.cloudflare.com/traffic/tz?dateStart=2024-02-22&amp;dateEnd=2024-02-28\&quot;&gt;Tanzania&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/traffic/ke?dateStart=2024-02-22&amp;dateEnd=2024-02-28\&quot;&gt;Kenya&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/traffic/ug?dateStart=2024-02-22&amp;dateEnd=2024-02-28\&quot;&gt;Uganda&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/traffic/mz?dateStart=2024-02-22&amp;dateEnd=2024-02-28\&quot;&gt;Mozambique&lt;/a&gt;, no loss of traffic was observed across these countries in &lt;a href=\&quot;https://radar.cloudflare.com/\&quot;&gt;Cloudflare Radar&lt;/a&gt;.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;h2 id=\&quot;militaryaction\&quot;&gt;Military action&lt;/h2&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;sudan\&quot;&gt;Sudan&lt;/h3&gt;\n            &lt;a href=\&quot;#sudan\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;On February 2, Cloudflare observed a loss of traffic at &lt;a href=\&quot;https://radar.cloudflare.com/as15706\&quot;&gt;AS15706 (Sudatel)&lt;/a&gt; and &lt;a href=\&quot;https://radar.cloudflare.com/as36972\&quot;&gt;AS36972 (MTN Sudan)&lt;/a&gt;, with a similar loss occurring on February 7 at &lt;a href=\&quot;https://radar.cloudflare.com/as36998\&quot;&gt;AS36998 (Zain Sudan / SDN Mobitel)&lt;/a&gt;. The disruption at MTN Sudan aligns with a &lt;a href=\&quot;https://twitter.com/MTNSudan1/status/1753528636949274956\&quot;&gt;social media post&lt;/a&gt; from the provider, in which they stated (translated) “&lt;i&gt;We regret the interruption of all services due to circumstances beyond our control. While we apologize for the inconvenience caused by this interruption, we assure you of our endeavor to restore the service as soon as possible, and you will be notified of the return of the service.&lt;/i&gt;” On February 5, several days after their outage started, Zain Sudan published a &lt;a href=\&quot;https://twitter.com/ZainSudan/status/1754487740102533170\&quot;&gt;social media post&lt;/a&gt; that stated (translated) “&lt;i&gt;Zain Sudan has been constantly striving to maintain communication and Internet service to serve its valued subscribers, and we would like to point out that the current network outage is due to circumstances beyond its control, with our hopes that safety will prevail, and that service will be restored as soon as possible.&lt;/i&gt;” Sudatel did not share any information about the status of its network. On February 4, Digital Rights Lab - Sudan &lt;a href=\&quot;https://twitter.com/drlab_sudan/status/1754134933772128326\&quot;&gt;posted on social media&lt;/a&gt; that “&lt;i&gt;Our sources confirmed that&lt;/i&gt; &lt;a href=\&quot;https://twitter.com/RSFSudan\&quot;&gt;&lt;i&gt;@RSFSudan&lt;/i&gt;&lt;/a&gt; &lt;i&gt;forces tookover data centers of ISPs in Khartoum, #Sudan.&lt;/i&gt;” It is likely that the Internet outages observed across these providers are related to these takeovers, part of the &lt;a href=\&quot;https://www.cfr.org/global-conflict-tracker/conflict/power-struggle-sudan\&quot;&gt;military conflict that has been underway in the country&lt;/a&gt; since April 15, 2023.&lt;/p&gt;&lt;p&gt;The disruptions on these networks varied in length. At Sudatel, traffic started to return on February 11. At Zain Sudan, traffic began to return on March 3, corroborated by a &lt;a href=\&quot;https://twitter.com/ZainSudan/status/1764217865530376300\&quot;&gt;social media post&lt;/a&gt; that stated (translated) “&lt;i&gt;Zain network is gradually returning to work and allows its subscribers to communicate for free for a limited time. Zain promises to continue working to restore its network in the rest of the states.&lt;/i&gt;” Traffic had not yet returned on MTN Sudan by the end of the first quarter.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-02-01&amp;dateEnd=2024-03-05&amp;location=as36998&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;ukraine\&quot;&gt;Ukraine&lt;/h3&gt;\n            &lt;a href=\&quot;#ukraine\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;In February, the Ukraine/Russia war reached the two-year mark, and over that time, we have covered a number of Internet outages in Ukraine caused by conflict-related attacks. On February 22, &lt;a href=\&quot;https://therecord.media/massive-missile-russian-barrage-internet-outages-blackouts\&quot;&gt;Russian air strikes on critical infrastructure in Ukraine&lt;/a&gt; damaged energy facilities across the country, resulting in widespread power outages. These power outages caused Internet disruptions across multiple regions in Ukraine, including Kharkiv, Zaporizhzhia, Odessa, Dnipropetrovsk Oblast, and Khmelnytskyi Oblast. Traffic initially dropped around 05:00 local time (03:00 UTC), falling as much as 68% in Kharkiv. However, all regions saw lower traffic levels for several days as compared to the week before.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/TBMLgZ73lfMRAB4Jpey7d/222ffab926e47c66ce043ab3fda388b4/Mar-22---Ukraine---Kharkiv.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;920\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/VQ0RIhitP3TNnn3pkVtT2/fcbd02cae5fb89c3737bf3bf0309eec4/Mar-22---Ukraine---Khmel.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;920\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4s3Twlv8ycp3hRwoTfq7Vd/244fdea99065f2ecf3072ccb2f0d7cb7/Mar-22---Ukraine---Dnipro.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;920\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2LDrhWYS0DOwOYd93MRiJH/70f2cf5561ae703f40581303feb058ca/Mar-22---Ukraine---Odessa.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;920\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3Ej2ZJcMsl0b4pSzOJZYHI/fdd67fe3d9fb0d6caadc0cce0b2f9e17/Mar-22---Ukraine---Zap.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;920\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;gaza-strip\&quot;&gt;Gaza Strip&lt;/h3&gt;\n            &lt;a href=\&quot;#gaza-strip\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;In our &lt;a href=\&quot;/q4-2023-internet-disruption-summary\&quot;&gt;&lt;i&gt;Q4 2023 Internet disruption summary&lt;/i&gt;&lt;/a&gt; blog post, we &lt;a href=\&quot;/q4-2023-internet-disruption-summary#:~:text=In%20addition%20to%20the%20outages%20illustrated%20above\&quot;&gt;noted that&lt;/a&gt; throughout October, November, and December, &lt;a href=\&quot;https://paltel.ps/en/home\&quot;&gt;Paltel (Palestine Telecommunications Company)&lt;/a&gt; had published several social media posts about disruptions to its landline, mobile, and Internet services. During the first quarter of 2024, similar outages were observed on &lt;a href=\&quot;https://twitter.com/Paltelco/status/1745813735627727091\&quot;&gt;January 12&lt;/a&gt;, &lt;a href=\&quot;https://twitter.com/Paltelco/status/1749464176756449631\&quot;&gt;January 22&lt;/a&gt;, and &lt;a href=\&quot;https://twitter.com/QudsNen/status/1765100306353017128\&quot;&gt;March 5&lt;/a&gt;. Paltel attributes these outages to the ongoing aggression related to the war with Israel.&lt;/p&gt;&lt;p&gt;The associated outages during the quarter varied in length, from just a few hours to over a week. Each outage is shown in the graphs below, which show Paltel traffic within four Palestinian governorates in the Gaza Strip region. While it appears that the Gaza governorate suffered a disruption to traffic as connectivity remained available, complete outages occurred in the Khan Yunis, Rafah, and Deir al-Balah governorates.&lt;/p&gt;&lt;p&gt;&lt;b&gt;January 12-19&lt;/b&gt;&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;figure class=\&quot;table\&quot; style=\&quot;width:100%;\&quot;&gt;\n    &lt;table class=\&quot;ck-table-resized\&quot; style=\&quot;border:1px solid hsl(0, 0%, 30%);\&quot;&gt;\n        &lt;colgroup&gt;\n            &lt;col style=\&quot;width:50%;\&quot;&gt;\n            &lt;col style=\&quot;width:50%;\&quot;&gt;\n        &lt;/colgroup&gt;\n        &lt;tbody&gt;\n            &lt;tr&gt;\n                &lt;td&gt;\n                    &lt;figure class=\&quot;image\&quot;&gt;&lt;a href=\&quot;https://images.ctfassets.net/slt3lc6tev37/3awubGpVqUX91wiBfu72l8/b0f6d073446e830b304fb1e80f14d963/Jan_12-19_-_Gaza_-_Gaza.png\&quot; target=\&quot;_blank\&quot; rel=\&quot;noopener noreferrer\&quot;&gt;&lt;img style=\&quot;aspect-ratio:920/360;\&quot; src=\&quot;https://images.ctfassets.net/slt3lc6tev37/3awubGpVqUX91wiBfu72l8/b0f6d073446e830b304fb1e80f14d963/Jan_12-19_-_Gaza_-_Gaza.png\&quot; width=\&quot;920\&quot; height=\&quot;360\&quot;&gt;&lt;/a&gt;&lt;/figure&gt;\n                &lt;/td&gt;\n                &lt;td&gt;\n                    &lt;figure class=\&quot;image\&quot;&gt;&lt;a href=\&quot;https://images.ctfassets.net/slt3lc6tev37/1yxGzVFOk0gVLyZtje7gnw/e188aa8a748e5fe73218cc98950a22a5/Jan_12-19_-_Gaza_-_Khan_Yunis.png\&quot; target=\&quot;_blank\&quot; rel=\&quot;noopener noreferrer\&quot;&gt;&lt;img style=\&quot;aspect-ratio:920/360;\&quot; src=\&quot;https://images.ctfassets.net/slt3lc6tev37/1yxGzVFOk0gVLyZtje7gnw/e188aa8a748e5fe73218cc98950a22a5/Jan_12-19_-_Gaza_-_Khan_Yunis.png\&quot; width=\&quot;920\&quot; height=\&quot;360\&quot;&gt;&lt;/a&gt;&lt;/figure&gt;\n                &lt;/td&gt;\n            &lt;/tr&gt;\n            &lt;tr&gt;\n                &lt;td&gt;\n                    &lt;figure class=\&quot;image\&quot;&gt;&lt;a href=\&quot;https://images.ctfassets.net/slt3lc6tev37/3ZCHTnNigLCapNMRp6Du9R/17600648639a68925b04ee3158f4384b/Jan_12-19_-_Gaza_-_Rafah.png\&quot; target=\&quot;_blank\&quot; rel=\&quot;noopener noreferrer\&quot;&gt;&lt;img style=\&quot;aspect-ratio:920/360;\&quot; src=\&quot;https://images.ctfassets.net/slt3lc6tev37/3ZCHTnNigLCapNMRp6Du9R/17600648639a68925b04ee3158f4384b/Jan_12-19_-_Gaza_-_Rafah.png\&quot; width=\&quot;920\&quot; height=\&quot;360\&quot;&gt;&lt;/a&gt;&lt;/figure&gt;\n                &lt;/td&gt;\n                &lt;td&gt;\n                    &lt;figure class=\&quot;image\&quot;&gt;&lt;a href=\&quot;https://images.ctfassets.net/slt3lc6tev37/2dy1u4WsydG2TtEaBFmOPF/07ea2b4e3c94c3fa4afbdbc8771a1aa8/Jan_12-19_-_Gaza_-_Deir_al-Balah.png\&quot; target=\&quot;_blank\&quot; rel=\&quot;noopener noreferrer\&quot;&gt;&lt;img style=\&quot;aspect-ratio:920/360;\&quot; src=\&quot;https://images.ctfassets.net/slt3lc6tev37/2dy1u4WsydG2TtEaBFmOPF/07ea2b4e3c94c3fa4afbdbc8771a1aa8/Jan_12-19_-_Gaza_-_Deir_al-Balah.png\&quot; width=\&quot;920\&quot; height=\&quot;360\&quot;&gt;&lt;/a&gt;&lt;/figure&gt;\n                &lt;/td&gt;\n            &lt;/tr&gt;\n        &lt;/tbody&gt;\n    &lt;/table&gt;\n&lt;/figure&gt;&lt;!--kg-card-end: html--&gt;&lt;p&gt;&lt;b&gt;January 22-24&lt;/b&gt;&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;figure class=\&quot;table\&quot; style=\&quot;width:100%;\&quot;&gt;\n    &lt;table class=\&quot;ck-table-resized\&quot; style=\&quot;border:1px solid hsl(0, 0%, 30%);\&quot;&gt;\n        &lt;colgroup&gt;\n            &lt;col style=\&quot;width:50%;\&quot;&gt;\n            &lt;col style=\&quot;width:50%;\&quot;&gt;\n        &lt;/colgroup&gt;\n        &lt;tbody&gt;\n            &lt;tr&gt;\n                &lt;td&gt;\n                    &lt;figure class=\&quot;image\&quot;&gt;&lt;a href=\&quot;https://images.ctfassets.net/slt3lc6tev37/4csFWELPuqnSc6nVcpYc5K/a250d1fd1d71cd547bb9b1100ece5a79/Jan_22-24_-_Gaza_-_Gaza.png\&quot; target=\&quot;_blank\&quot; rel=\&quot;noopener noreferrer\&quot;&gt;&lt;img style=\&quot;aspect-ratio:920/360;\&quot; src=\&quot;https://images.ctfassets.net/slt3lc6tev37/4csFWELPuqnSc6nVcpYc5K/a250d1fd1d71cd547bb9b1100ece5a79/Jan_22-24_-_Gaza_-_Gaza.png\&quot; width=\&quot;920\&quot; height=\&quot;360\&quot;&gt;&lt;/a&gt;&lt;/figure&gt;\n                &lt;/td&gt;\n                &lt;td&gt;\n                    &lt;figure class=\&quot;image\&quot;&gt;&lt;a href=\&quot;https://images.ctfassets.net/slt3lc6tev37/2ogmrVWjlFTErdAmNUSGCr/1c109227deb6863c52b3e447d8b6a6c5/Jan_22-24_-_Gaza_-_Khan_Yunis.png\&quot; target=\&quot;_blank\&quot; rel=\&quot;noopener noreferrer\&quot;&gt;&lt;img style=\&quot;aspect-ratio:920/360;\&quot; src=\&quot;https://images.ctfassets.net/slt3lc6tev37/2ogmrVWjlFTErdAmNUSGCr/1c109227deb6863c52b3e447d8b6a6c5/Jan_22-24_-_Gaza_-_Khan_Yunis.png\&quot; width=\&quot;920\&quot; height=\&quot;360\&quot;&gt;&lt;/a&gt;&lt;/figure&gt;\n                &lt;/td&gt;\n            &lt;/tr&gt;\n            &lt;tr&gt;\n                &lt;td&gt;\n                    &lt;figure class=\&quot;image\&quot;&gt;&lt;a href=\&quot;https://images.ctfassets.net/slt3lc6tev37/2wINE0xDB1VPPf9fcG3Gcd/203de374fad17372fa68cd2c7ac5dde9/Jan_22-24_-_Gaza_-_Rafah.png\&quot; target=\&quot;_blank\&quot; rel=\&quot;noopener noreferrer\&quot;&gt;&lt;img style=\&quot;aspect-ratio:920/360;\&quot; src=\&quot;https://images.ctfassets.net/slt3lc6tev37/2wINE0xDB1VPPf9fcG3Gcd/203de374fad17372fa68cd2c7ac5dde9/Jan_22-24_-_Gaza_-_Rafah.png\&quot; width=\&quot;920\&quot; height=\&quot;360\&quot;&gt;&lt;/a&gt;&lt;/figure&gt;\n                &lt;/td&gt;\n                &lt;td&gt;\n                    &lt;figure class=\&quot;image\&quot;&gt;&lt;a href=\&quot;https://images.ctfassets.net/slt3lc6tev37/3H88zS4AETXDokBSY2HwYt/d90233525244dac1cb5dbcd3c12f8869/Jan_22-24_-_Gaza_-_Deir_al-Balah.png\&quot; target=\&quot;_blank\&quot; rel=\&quot;noopener noreferrer\&quot;&gt;&lt;img style=\&quot;aspect-ratio:920/360;\&quot; src=\&quot;https://images.ctfassets.net/slt3lc6tev37/3H88zS4AETXDokBSY2HwYt/d90233525244dac1cb5dbcd3c12f8869/Jan_22-24_-_Gaza_-_Deir_al-Balah.png\&quot; width=\&quot;920\&quot; height=\&quot;360\&quot;&gt;&lt;/a&gt;&lt;/figure&gt;\n                &lt;/td&gt;\n            &lt;/tr&gt;\n        &lt;/tbody&gt;\n    &lt;/table&gt;\n&lt;/figure&gt;&lt;!--kg-card-end: html--&gt;&lt;p&gt;&lt;b&gt;March 5&lt;/b&gt;&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;h2 id=\&quot;cyberattacks\&quot;&gt;Cyberattacks&lt;/h2&gt;&lt;!--kg-card-end: html--&gt;&lt;p&gt;In addition to the previously discussed cyberattack that impacted connectivity for &lt;a href=\&quot;https://radar.cloudflare.com/as327802\&quot;&gt;AS327802 (Moov Africa Tchad / Millicom)&lt;/a&gt; on January 11, several other observed Internet disruptions were caused by cyberattacks in the first quarter.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;hotnet-internet-services-israel\&quot;&gt;HotNet Internet Services (Israel)&lt;/h3&gt;\n            &lt;a href=\&quot;#hotnet-internet-services-israel\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Anonymous Sudan &lt;a href=\&quot;https://twitter.com/DailyDarkWeb/status/1760266153467760708\&quot;&gt;reportedly&lt;/a&gt; launched an attack against &lt;a href=\&quot;https://radar.cloudflare.com/as12849\&quot;&gt;AS12849 (HotNet Internet Services)&lt;/a&gt;, a major &lt;a href=\&quot;https://en.wikipedia.org/wiki/Hot_(Israel)\&quot;&gt;Israeli telecommunications provider&lt;/a&gt;. The attack was apparently brief, as it only disrupted traffic between 22:00 on February 20 and 00:00 on February 21 local time (20:00 to 22:00 UTC on February 20). Although brief, the attack succeeded in knocking the provider offline as the &lt;a href=\&quot;https://radar.cloudflare.com/routing/as12849?dateStart=2024-02-20&amp;dateEnd=2024-02-21\&quot;&gt;volume of IPv4 and IPv6 address space announced by HotNet&lt;/a&gt; fell to zero during the period the attack occurred.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/BgpRoutesTimeseriesXY?dateStart=2024-02-20&amp;dateEnd=2024-02-21&amp;location=as12849&amp;chartState=%7B%22bgpSignalsMinMax%22%3Atrue%2C%22bgpSignalsIpVersionParam%22%3A%22ipv6%22%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Announced IP Address Space\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;zain-bahrain\&quot;&gt;Zain Bahrain&lt;/h3&gt;\n            &lt;a href=\&quot;#zain-bahrain\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Anonymous Sudan also &lt;a href=\&quot;https://twitter.com/FalconFeedsio/status/1764364189492236676?s=20\&quot;&gt;reportedly&lt;/a&gt; targeted &lt;a href=\&quot;https://radar.cloudflare.com/as31452\&quot;&gt;AS31452 (Zain Bahrain)&lt;/a&gt; with a cyber attack. This attack appeared to be less severe than the one that targeted HotNet in Israel, but it also lasted significantly longer, with traffic disrupted between 20:45 on March 3 and 18:15 on March 4 local time (17:45 on March 3 to 15:15 on March 4 UTC). No impact to &lt;a href=\&quot;https://radar.cloudflare.com/routing/as31452?dateStart=2024-03-03&amp;dateEnd=2024-03-04\&quot;&gt;announced IP address space&lt;/a&gt; was observed. Zain Bahrain acknowledged the connectivity disruption in a &lt;a href=\&quot;https://twitter.com/ZainBahrain/status/1764678419147538492\&quot;&gt;social media post on March 4&lt;/a&gt;, noting (translated) “&lt;i&gt;We would like to inform you that some customers may encounter difficulties in using some of our services. Our technical team works to avoid these difficulties as quickly as possible.&lt;/i&gt;”&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-03-03&amp;dateEnd=2024-03-04&amp;location=as31452&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;multiple-networks-in-ukraine\&quot;&gt;Multiple networks in Ukraine&lt;/h3&gt;\n            &lt;a href=\&quot;#multiple-networks-in-ukraine\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;On March 13, &lt;a href=\&quot;https://therecord.media/ukraine-isps-attacks-solntsepek-sandworm-gru\&quot;&gt;an attack targeted a number of Ukrainian telecommunications providers&lt;/a&gt;, including &lt;a href=\&quot;https://radar.cloudflare.com/as16066\&quot;&gt;AS16066 (Triangulum)&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as34359\&quot;&gt;AS34359 (Link Telecom Ukraine)&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as197522\&quot;&gt;AS197522 (Kalush Information Network)&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as52074\&quot;&gt;AS52074 (Mandarun)&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/as29013\&quot;&gt;AS29013 (LinkKremen)&lt;/a&gt;. Triangulum appeared to be the most significantly impacted, experiencing a near complete loss of traffic between March 13 and March 20, as seen below. Triangulum posted a notice on its &lt;a href=\&quot;https://www.triangulum.ua/\&quot;&gt;website&lt;/a&gt;, noting in part “&lt;i&gt;On March 13, 2024, a hacker attack was carried out on a number of Ukrainian providers. At 10:28 a.m. on March 13, 2024, a large-scale technical failure occurred on our Company&amp;#39;s network, as a result of which it became impossible to provide electronic communication services. The Company&amp;#39;s employees, together with employees of the Cyber ​​Police and the National Cyber ​​Security Coordination Center, are taking comprehensive measures around the clock aimed at restoring the entire range of services as soon as possible. Services are being restored gradually. Full recovery may take several days.&lt;/i&gt;”&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-03-13&amp;dateEnd=2024-03-20&amp;location=as16066&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;&lt;p&gt;Other affected providers experienced comparatively shorter connectivity disruptions. The near complete outage at Mandarun lasted approximately a day, while the others saw outages lasting around seven hours, starting around 11:30 local time (09:30 UTC) on March 13, with connectivity returning to typical levels around 08:00 local time (06:00 UTC) on March 14.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;h2 id=\&quot;governmentdirected\&quot;&gt;Government directed&lt;/h2&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;comoros\&quot;&gt;Comoros&lt;/h3&gt;\n            &lt;a href=\&quot;#comoros\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Following protests against the re-election of President Azali Assoumani, authorities in &lt;a href=\&quot;https://radar.cloudflare.com/km\&quot;&gt;Comoros&lt;/a&gt; &lt;a href=\&quot;https://www.bbc.com/news/world-africa-68027892\&quot;&gt;reportedly&lt;/a&gt; shut down Internet connectivity on January 17. While some disruption was visible to traffic at a country level between 12:00 local time on January 17 (09:00 UTC) and 17:30 local time on January 19 (14:30 UTC), it was significantly more noticeable in the traffic from &lt;a href=\&quot;https://radar.cloudflare.com/as36939\&quot;&gt;AS36939 (Comores Telecom)&lt;/a&gt;, which saw several periods of near-complete outage across the two-day span. Although Comores Telecom announces a limited amount of IPv4 address space, it saw significant volatility on January 17 &amp;amp; 18, dropping to zero several times.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/BgpRoutesTimeseriesXY?dateStart=2024-01-14&amp;dateEnd=2024-01-19&amp;location=as36939&amp;chartState=%7B%22bgpSignalsMinMax%22%3Atrue%2C%22bgpSignalsIpVersionParam%22%3A%22ipv4%22%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Announced IP Address Space\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;sudatel-senegal-expresso-telecom-and-tigo-free-senegal\&quot;&gt;Sudatel Senegal/Expresso Telecom and Tigo/Free (Senegal)&lt;/h3&gt;\n            &lt;a href=\&quot;#sudatel-senegal-expresso-telecom-and-tigo-free-senegal\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;On February 4, the Minister of Communication, Telecommunications, and Digital Affairs in &lt;a href=\&quot;https://radar.cloudflare.com/sn\&quot;&gt;Senegal&lt;/a&gt; &lt;a href=\&quot;https://twitter.com/samirasawlani/status/1754453336894415340\&quot;&gt;ordered&lt;/a&gt; the suspension of mobile Internet connectivity starting at 22:00 local time (22:00 UTC). The suspension followed protests that erupted in the wake of the postponement of the presidential election. Traffic from &lt;a href=\&quot;https://radar.cloudflare.com/as37196\&quot;&gt;AS37196 (Sudatel Senegal/Expresso Telecom)&lt;/a&gt; fell sharply at the time the suspension went into effect, recovering around 07:30 local time (07:30 UTC) on February 7. Traffic from &lt;a href=\&quot;https://radar.cloudflare.com/as37649\&quot;&gt;AS37649 (Tigo/Free)&lt;/a&gt; fell at around 09:30 local time (09:30 UTC) on February 5, with the provider &lt;a href=\&quot;https://twitter.com/free_senegal/status/1754521065894633896\&quot;&gt;notifying subscribers of the suspension via social media&lt;/a&gt;. Traffic on Tigo/Free recovered around midnight local time (00:00 UTC) on February 7, and the provider again &lt;a href=\&quot;https://twitter.com/free_senegal/status/1755188473781211523\&quot;&gt;used social media to inform subscribers of service availability&lt;/a&gt;. No changes were observed to announced IP address space for either provider, indicating that the suspension of mobile Internet connectivity was not done at a routing level.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-02-05&amp;dateEnd=2024-02-07&amp;location=as37649&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;&lt;p&gt;A little more than a week later, on February 13, the government in Senegal &lt;a href=\&quot;https://intlmonitor.com/africa/internet-shutdown-in-senegal-ahead-of-protests-over-vote-delay/\&quot;&gt;again ordered&lt;/a&gt; the suspension of mobile Internet connectivity in an effort to prevent &amp;quot;the spread of hateful and subversive messages online.&amp;quot; ahead of a march planned by activist groups which aimed to express dissent against the postponement of the presidential election. The mobile Internet shutdown was most visible on Tigo/Free, which saw a significant disruption between 10:15 and 19:45 local time (10:15 - 19:45 UTC).&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-02-13&amp;dateEnd=2024-02-13&amp;location=as37649&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;pakistan\&quot;&gt;Pakistan&lt;/h3&gt;\n            &lt;a href=\&quot;#pakistan\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;According to a &lt;a href=\&quot;https://www.business-standard.com/world-news/no-govt-instructions-to-block-internet-during-polls-pakistan-telecom-body-124020800226_1.html\&quot;&gt;published report&lt;/a&gt;, The Pakistan Telecommunication Authority (PTA) said that Internet services would remain available as citizens went to the polls on February 8 to elect a new government. However, on that day, &lt;a href=\&quot;https://therecord.media/pakistan-cuts-internet-as-voters-head-to-polls\&quot;&gt;Pakistani authorities cut mobile Internet access&lt;/a&gt; across the country as the nation’s voters went to cast their ballots, with the authorities &lt;a href=\&quot;https://therecord.media/pakistan-cuts-internet-as-voters-head-to-polls\&quot;&gt;attributing the move&lt;/a&gt; &amp;quot;to maintain law and order&amp;quot; in the wake of the violence that occurred the previous day. The impact of the ordered shutdown was visible across multiple Internet providers in &lt;a href=\&quot;https://radar.cloudflare.com/pk\&quot;&gt;Pakistan&lt;/a&gt;, including &lt;a href=\&quot;https://radar.cloudflare.com/traffic/as59257?dateStart=2024-02-08&amp;dateEnd=2024-02-09\&quot;&gt;AS59257 (Zong/CMPak)&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/traffic/as24499?dateStart=2024-02-08&amp;dateEnd=2024-02-09\&quot;&gt;AS24499 (Telenor Pakistan)&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/traffic/as45669?dateStart=2024-02-08&amp;dateEnd=2024-02-09\&quot;&gt;AS45669 (Jazz/Mobilink)&lt;/a&gt;, lasting from 07:00 until 20:00 (02:00 - 15:00 UTC), with traffic returning to expected levels approximately nine hours later. A &lt;a href=\&quot;https://pulse.internetsociety.org/blog/pakistan-elections-2024-the-unexpected-cost-of-mobile-service-disruptions\&quot;&gt;post on the Internet Society’s Pulse blog&lt;/a&gt; estimated that the shutdown cost Pakistan nearly USD $18.5M in lost Gross Domestic Product.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-02-08&amp;dateEnd=2024-02-09&amp;location=as45669&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;chad\&quot;&gt;Chad&lt;/h3&gt;\n            &lt;a href=\&quot;#chad\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Several Internet disruptions were observed in &lt;a href=\&quot;https://radar.cloudflare.com/td\&quot;&gt;Chad&lt;/a&gt; between February 28 and March 7. The first one started at 10:45 local time on February 28 and lasted until 18:00 local time on March 1 (09:45 on February 28 - 17:00 on March 1). Shorter disruptions lasting just a few hours each were also observed on March 3, 4, and 7. The apparent shutdowns came in the &lt;a href=\&quot;https://www.aljazeera.com/news/2024/2/28/chad-announces-several-deaths-after-foiled-intelligence-office-attack\&quot;&gt;wake of political violence&lt;/a&gt; in the country. Notable drops in announced IPv4 address space aggregated across networks in the country were observed coincident with the February 28, March 3, and March 4 shutdowns, although it isn’t clear why a similar drop did not occur on March 7.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;h2 id=\&quot;poweroutages\&quot;&gt;Power outages&lt;/h2&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;tajikistan\&quot;&gt;Tajikistan&lt;/h3&gt;\n            &lt;a href=\&quot;#tajikistan\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;According to a &lt;a href=\&quot;https://eurasianet.org/swathes-of-tajikistan-crippled-by-unexplained-power-outage\&quot;&gt;published report&lt;/a&gt;, a widespread multi-hour power outage occurred in &lt;a href=\&quot;https://radar.cloudflare.com/tj\&quot;&gt;Tajikistan&lt;/a&gt; on March 1, possibly related to increased electricity usage by electric heaters as temperatures across the country neared freezing. The outage began around 11:00 local time (06:00 UTC), and lasted for approximately three hours. The impact on Internet traffic from the country is visible in the graph below. Although power was restored around 14:00 local time (09:00 UTC), Internet traffic did not return to expected levels until around 05:00 local time the next day (midnight UTC on March 2).&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-02-29&amp;dateEnd=2024-03-01&amp;location=tj&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;&lt;p&gt;Although power outages most often have the biggest impact on Internet traffic, as computers and home/office routers shut down, this outage also appeared to impact network infrastructure within the country, as the aggregate volume of announced IPv4 address space across the country dipped slightly when the power was out.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/BgpRoutesTimeseriesXY?dateStart=2024-02-29&amp;dateEnd=2024-03-01&amp;location=tj&amp;chartState=%7B%22bgpSignalsMinMax%22%3Afalse%2C%22bgpSignalsIpVersionParam%22%3A%22ipv4%22%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Announced IP Address Space\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;tanzania\&quot;&gt;Tanzania&lt;/h3&gt;\n            &lt;a href=\&quot;#tanzania\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;On March 4, the &lt;a href=\&quot;https://www.tanesco.co.tz\&quot;&gt;Tanzania Electricity Corporation (TANESCO)&lt;/a&gt; &lt;a href=\&quot;https://twitter.com/tanescoyetutz/status/1764632209409949938\&quot;&gt;posted a notice on social media&lt;/a&gt; regarding an ongoing power outage. It stated (translated) “&lt;i&gt;The Tanzania Electricity Corporation (TANESCO) has notified the public that there has been an error in the National Grid system, resulting in a lack of electricity service in some areas of the country including Zanzibar. Our experts are continuing their efforts to ensure that the electricity service returns to its normal state. The organization apologizes for any inconvenience caused.&lt;/i&gt;” The power outage disrupted Internet connectivity in &lt;a href=\&quot;https://radar.cloudflare.com/tz\&quot;&gt;Tanzania&lt;/a&gt;, causing an observed drop in traffic between 13:30 and 23:00 local time (10:30 - 20:00 UTC).&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;h3 id=\&quot;orangeespana\&quot;&gt;Orange España&lt;/h2&gt;&lt;!--kg-card-end: html--&gt;&lt;p&gt;Network &lt;a href=\&quot;https://www.cloudflare.com/learning/network-layer/what-is-routing/\&quot;&gt;routing&lt;/a&gt; is the process of selecting a path across one or more networks, and on the Internet, routing relies on the &lt;a href=\&quot;https://www.cloudflare.com/learning/security/glossary/what-is-bgp/\&quot;&gt;Border Gateway Protocol (BGP)&lt;/a&gt;. Historically, the exchange of BGP routing information was based on trust between providers, but over time, security mechanisms such as &lt;a href=\&quot;/rpki/\&quot;&gt;Resource Public Key Infrastructure (RPKI)&lt;/a&gt; have been developed to prevent abuse of the system by bad actors. RPKI is a cryptographic method of signing records that associate a BGP route announcement with the correct originating AS number. ROA (Route Origin Authorization) records provide a means of verifying that an IP address block holder has authorized an &lt;a href=\&quot;https://www.cloudflare.com/learning/network-layer/what-is-an-autonomous-system/\&quot;&gt;AS (Autonomous System)&lt;/a&gt; to originate routes to that one or more prefixes within the address block. Cloudflare has &lt;a href=\&quot;/tag/rpki\&quot;&gt;published a number of blog posts&lt;/a&gt; over the years about the importance of, and our support for, RPKI. Properly implemented and configured, RPKI and ROAs help support routing security, effectively preventing behavior like &lt;a href=\&quot;https://www.cloudflare.com/learning/security/glossary/bgp-hijacking/\&quot;&gt;BGP hijacking&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The &lt;a href=\&quot;https://www.ripe.net/\&quot;&gt;RIPE NCC&lt;/a&gt; (“RIPE”) is one of five &lt;a href=\&quot;https://en.wikipedia.org/wiki/Regional_Internet_registry\&quot;&gt;Regional Internet Registries (RIRs)&lt;/a&gt; that provides Internet resource allocation and registration, and coordination activities. RIPE’s region covers Europe, the Middle East, and Central Asia. On January 3, a malicious actor took advantage of lax account security on the part of RIPE and &lt;a href=\&quot;https://radar.cloudflare.com/as12479\&quot;&gt;AS12479 (Orange España)&lt;/a&gt; and &lt;a href=\&quot;https://blog.benjojo.co.uk/post/rpki-signed-but-not-secure\&quot;&gt;used credentials found on the public Internet&lt;/a&gt; to log into Orange España’s RIPE account. Once in control of the account, the attacker published multiple ROAs with “bogus” origins, rendering thousands of routes originated by AS12479 “RPKI-invalid”, which &lt;a href=\&quot;https://www.kentik.com/blog/digging-into-the-orange-espana-hack/\&quot;&gt;resulted in carriers that reject RPKI-invalid routes to stop carrying a large amount of Orange España’s IP space&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Because Cloudflare enforces RPKI validation, we also rejected the RPKI-invalid routes. We would have started trying to reach Orange España over our default route toward some of our transit providers, but because they also perform RPKI validation, traffic would have been dropped within those provider networks as well. Because of this, from Cloudflare’s perspective, this incident caused a drop in traffic from Orange España between 16:45 and 19:45 local time (14:45 - 17:45 UTC) as well as a &lt;a href=\&quot;https://radar.cloudflare.com/routing/as12479?dateStart=2024-01-03&amp;dateEnd=2024-01-03\&quot;&gt;notable drop in announced IPv4 address space from AS12479&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Orange España &lt;a href=\&quot;https://twitter.com/orange_es/status/1742616775647265035\&quot;&gt;confirmed on social media&lt;/a&gt; that its RIPE account had been improperly accessed, and as a result of the incident, &lt;a href=\&quot;https://www.ripe.net/publications/news/mandatory-2fa-on-ripe-ncc-access-accounts/\&quot;&gt;RIPE has made two-factor authentication (2FA) mandatory&lt;/a&gt; for logins. For additional insights into the incident, &lt;a href=\&quot;https://www.kentik.com/blog/digging-into-the-orange-espana-hack/\&quot;&gt;Doug Madory at Kentik&lt;/a&gt; and &lt;a href=\&quot;https://blog.benjojo.co.uk/post/rpki-signed-but-not-secure\&quot;&gt;Ben Cartwright-Cox at bgp.tools&lt;/a&gt; have both published detailed analyses and timelines.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/BgpRoutesTimeseriesXY?dateStart=2024-01-03&amp;dateEnd=2024-01-03&amp;location=as12479&amp;chartState=%7B%22bgpSignalsMinMax%22%3Afalse%2C%22bgpSignalsIpVersionParam%22%3A%22ipv4%22%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Announced IP Address Space\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;maxnet-ukraine\&quot;&gt;MaxNet (Ukraine)&lt;/h3&gt;\n            &lt;a href=\&quot;#maxnet-ukraine\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;On January 11, subscribers of &lt;a href=\&quot;https://radar.cloudflare.com/as34700\&quot;&gt;AS34700 (MaxNet)&lt;/a&gt; in &lt;a href=\&quot;https://radar.cloudflare.com/ua\&quot;&gt;Ukraine&lt;/a&gt; experienced a nine-hour Internet outage. Initial traffic loss occurred around 16:00 local time (14:00 UTC), and recovered around 01:00 local time on January 12 (23:00 UTC on January 11). An initial &lt;a href=\&quot;https://www.facebook.com/maxnetua/posts/pfbid0Y3chUrPemhcBgEhFERwEWi6muqzUeoSkas4M8EgiFpwT3Jkgy5M3jUh6wknHJan2l\&quot;&gt;social media post&lt;/a&gt; from the provider explained the reason for the outage, noting (translated) “&lt;i&gt;Dear subscribers! Due to the flooding of one of the hub sites due to a utility malfunction, some areas of the city may be without services, partially or completely. We are doing our best to restore services, but it takes time. Further information regarding the opening times will be published as soon as the emergency works have been completed.&lt;/i&gt;” A &lt;a href=\&quot;https://www.facebook.com/maxnetua/posts/pfbid012Nymu8ft9NPFi9fkQHrd9zGHb8un69ceECVXw72irJbBAkB3TXBRju1YqRSzSbLl\&quot;&gt;subsequent post&lt;/a&gt; informed subscribers that Internet connectivity had been restored. The flooding apparently impacted core routing infrastructure as well, as the &lt;a href=\&quot;https://radar.cloudflare.com/routing/as34700?dateStart=2024-01-11&amp;dateEnd=2024-01-12\&quot;&gt;volume of IPv4 address space announced by MaxNet&lt;/a&gt; also fell to zero between 16:00 and 22:00 local time (14:00 - 20:00 UTC).&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;h3 id=\&quot;plusnetuk\&quot;&gt;Plusnet (United Kingdom)&lt;/h3&gt;&lt;!--kg-card-end: html--&gt;&lt;p&gt;A traffic disruption observed on &lt;a href=\&quot;https://radar.cloudflare.com/as6871\&quot;&gt;AS6871 (Plusnet)&lt;/a&gt; in the &lt;a href=\&quot;https://radar.cloudflare.com/gb\&quot;&gt;United Kingdom&lt;/a&gt; on January 15 was initially &lt;a href=\&quot;https://twitter.com/Plusnet/status/1746939378428006549\&quot;&gt;characterized as a “mass outage”&lt;/a&gt; by the provider in replies to customer complaints on social media. However, the underlying cause of the disruption turned out to be significantly less sensational – it was apparently &lt;a href=\&quot;https://www.ispreview.co.uk/index.php/2024/01/broadband-isp-plusnet-recovers-from-dns-linked-mass-outage.html\&quot;&gt;linked to problems with their DNS servers&lt;/a&gt;. Because subscribers were unable to successfully resolve hostnames using Plusnet’s default DNS resolvers, this ultimately manifested itself as a drop in traffic from the network for approximately two hours, between 16:00 and 18:00 local time (and UTC). Users that had configured their systems to use a third-party DNS resolver, such as &lt;a href=\&quot;https://one.one.one.one/dns/\&quot;&gt;Cloudflare’s 1.1.1.1 service&lt;/a&gt;, did not experience a service disruption.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;h3 id=\&quot;russia\&quot;&gt;Russia&lt;/h3&gt;&lt;!--kg-card-end: html--&gt;&lt;p&gt;DNS issues also impacted users in Russia during January, though in a different way than Plusnet subscribers in the UK experienced. A &lt;a href=\&quot;https://circleid.com/posts/20240130-dnssec-failure-causes-massive-website-outages-on-russian-internet\&quot;&gt;reported&lt;/a&gt; &lt;a href=\&quot;https://www.cloudflare.com/dns/dnssec/how-dnssec-works/\&quot;&gt;DNSSEC&lt;/a&gt; failure on January 30 resulted in .ru domains becoming inaccessible for several hours. (DNSSEC creates a secure domain name system by adding cryptographic signatures to existing DNS records. By checking its associated signature, you can verify that a requested DNS record comes from its authoritative name server and wasn’t altered en-route, as opposed to a fake record injected in a man-in-the-middle attack.)&lt;/p&gt;&lt;p&gt;The &lt;a href=\&quot;https://datatracker.ietf.org/doc/html/rfc8914#name-extended-dns-error-code-6-d\&quot;&gt;DNSSEC validation failure&lt;/a&gt; resulted in &lt;a href=\&quot;/unwrap-the-servfail\&quot;&gt;SERVFAIL&lt;/a&gt; responses to DNS lookups against Cloudflare’s 1.1.1.1 resolver for hostnames in the .ru country code top level domain (ccTLD). At peak, 68.4% of requests received SERVFAIL responses. The Coordination Center for the .ru ccTLD &lt;a href=\&quot;https://t.me/fontankaspb/51445\&quot;&gt;confirmed&lt;/a&gt; that it was working on the “technical problem affecting the .ru zone associated with the global DNSSEC infrastructure” but didn’t provide any additional details around the root cause of the problem, such as a potential issue with a DNSSEC key rollover. The .ru ccTLD experienced a &lt;a href=\&quot;https://ianix.com/pub/dnssec-outages/20190816-ru/\&quot;&gt;similar DNSSEC-related outage&lt;/a&gt; for several hours on August 16, 2019, as well.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4o14ywdQmVwPQqLccSR9ov/8181788b95cf51f492820977417be76a/Jan-30---Russia---ru-DNSSEC.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;910\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;at-t-united-states\&quot;&gt;AT&amp;amp;T (United States)&lt;/h3&gt;\n            &lt;a href=\&quot;#at-t-united-states\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Starting just before 04:00 Eastern / 03:00 Central (09:00 UTC) on February 22, AT&amp;amp;T subscribers in several cities across the United States &lt;a href=\&quot;https://abcnews.go.com/US/att-outage-impacting-us-customers-company/story?id=107440297\&quot;&gt;experienced mobile service interruptions&lt;/a&gt;. Impacted cities included Atlanta, Houston, and Chicago, with connectivity disrupted for approximately eight hours. Cloudflare data showed that as the problem began, &lt;a href=\&quot;https://radar.cloudflare.com/as7018\&quot;&gt;AT&amp;amp;T (AS7018)&lt;/a&gt; traffic &lt;a href=\&quot;https://twitter.com/CloudflareRadar/status/1760694610689442114\&quot;&gt;dropped as much as 45% in Chicago and 18% in Dallas&lt;/a&gt;, as compared with the previous week.&lt;/p&gt;&lt;p&gt;According to a &lt;a href=\&quot;https://web.archive.org/web/20240223235440/https://about.att.com/pages/network-update\&quot;&gt;“network update” published by AT&amp;amp;T&lt;/a&gt;, “&lt;i&gt;Based on our initial review, we believe that today’s outage was caused by the application and execution of an incorrect process used as we were expanding our network, not a cyber attack.&lt;/i&gt;”&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5kg2gdTuPBJ1MPirymlvfG/bd816a37733a151f434d33354b9fd81b/pasted-image-0-4.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;696\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3drORCJTXNtO7IrJMUrjog/4dbc2cc56bdf6581205d03c7475dee16/pasted-image-0--1--2.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;512\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/tTYc2dO4kHkZR4wvUlIzy/466bf1559696466e91072e4f00faa603/pasted-image-0--2--2.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;522\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7BwYMWXW6hGIzZTUIVmBht/6ea7e5bd4093a3b9171b159ff19c7f47/pasted-image-0--3--1.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;519\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;!--kg-card-begin: html--&gt;&lt;h2 id=\&quot;maintenance\&quot;&gt;Maintenance&lt;/h2&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;vodafone-egypt\&quot;&gt;Vodafone Egypt&lt;/h3&gt;\n            &lt;a href=\&quot;#vodafone-egypt\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Between 05:15 and 11:30 local time (03:15 - 09:30 UTC) on March 5, customers of &lt;a href=\&quot;https://radar.cloudflare.com/as36935\&quot;&gt;AS36935 (Vodafone Egypt)&lt;/a&gt; experienced disruptions to their mobile Internet connectivity, with observed traffic from the network &lt;a href=\&quot;https://twitter.com/CloudflareRadar/status/1764951344954122467\&quot;&gt;dropping as much as 70% below expected levels&lt;/a&gt;. A (translated) &lt;a href=\&quot;https://twitter.com/VodafoneEgypt/status/1764947072376074428\&quot;&gt;social media post&lt;/a&gt; from the provider noted in part “&lt;i&gt;We apologize that some areas are currently affected by difficulties in operating the 4G service due to updates that took place this morning.&lt;/i&gt;” &lt;a href=\&quot;https://www.africanwirelesscomms.com/news-details?itemid=7392&amp;post=vodafone-egypt-sees-205-million-egp-fine-509046\&quot;&gt;As a result of the 4G network outage&lt;/a&gt;, Vodafone was required to compensate affected customers, and was also fined by &lt;a href=\&quot;https://www.tra.gov.eg/en/\&quot;&gt;Egypt&amp;#39;s National Telecommunications Regulatory Authority&lt;/a&gt; (NTRA).&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-03-04&amp;dateEnd=2024-03-05&amp;location=as36935&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;ocean-wave-communication-myanmar\&quot;&gt;Ocean Wave Communication (Myanmar)&lt;/h3&gt;\n            &lt;a href=\&quot;#ocean-wave-communication-myanmar\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Just before noon local time (05:15 UTC) on March 12, a significant drop in traffic was observed on &lt;a href=\&quot;https://radar.cloudflare.com/as136442\&quot;&gt;AS136442 (Ocean Wave)&lt;/a&gt;, a consumer fiber and business Internet service provider in &lt;a href=\&quot;https://radar.cloudflare.com/mm\&quot;&gt;Myanmar&lt;/a&gt;. A (translated) social media post from the provider noted “&lt;i&gt;Ocean Wave customers, please be informed that there will be no internet/ slow connection due to network maintenance.&lt;/i&gt;” The connectivity disruption lasted approximately seven hours, with traffic returning to typical levels just before 19:00 local time (12:15 UTC).&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2024-03-11&amp;dateEnd=2024-03-12&amp;location=as136442&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;conclusion\&quot;&gt;Conclusion&lt;/h2&gt;\n            &lt;a href=\&quot;#conclusion\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;Two notable submarine cable damage events during the first quarter again highlighted the importance of protecting submarine cables, and the risks associated with them passing through/near geopolitically sensitive areas. Given the &lt;a href=\&quot;https://blog.telegeography.com/2023-mythbusting-part-3\&quot;&gt;reliance on submarine cables for carrying Internet traffic&lt;/a&gt;, this will continue to be an issue for many years to come.&lt;/p&gt;&lt;p&gt;The Orange España incident also shed light on the importance of securing operationally important resources with &lt;a href=\&quot;https://www.cloudflare.com/learning/access-management/what-is-multi-factor-authentication/\&quot;&gt;multi-factor authentication&lt;/a&gt;, a topic that Cloudflare has &lt;a href=\&quot;/how-cloudflare-implemented-fido2-and-zero-trust\&quot;&gt;written about in the past&lt;/a&gt;. Organizations like RIPE play a critically important behind-the-scenes role in functioning of the Internet, arguably obligating them to take all practical precautions when it comes to securing their systems in order to prevent malicious actors from taking actions that could broadly disrupt Internet connectivity.&lt;/p&gt;&lt;p&gt;The Cloudflare Radar team is constantly monitoring for Internet disruptions, sharing our observations on the &lt;a href=\&quot;https://radar.cloudflare.com/outage-center\&quot;&gt;Cloudflare Radar Outage Center&lt;/a&gt;, via social media, and in posts on &lt;a href=\&quot;/tag/cloudflare-radar/\&quot;&gt;blog.cloudflare.com&lt;/a&gt;. Follow us on social media at &lt;a href=\&quot;https://twitter.com/CloudflareRadar\&quot;&gt;@CloudflareRadar&lt;/a&gt; (X), &lt;a href=\&quot;https://noc.social/@cloudflareradar\&quot;&gt;https://noc.social/@cloudflareradar&lt;/a&gt; (Mastodon), and &lt;a href=\&quot;https://bsky.app/profile/radar.cloudflare.com\&quot;&gt;radar.cloudflare.com&lt;/a&gt; (Bluesky), or contact us via &lt;a href=\&quot;mailto:radar@cloudflare.com\&quot;&gt;email&lt;/a&gt;.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;watch-on-cloudflare-tv\&quot;&gt;Watch on Cloudflare TV&lt;/h3&gt;\n            &lt;a href=\&quot;#watch-on-cloudflare-tv\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;!--kg-card-begin: html--&gt;&lt;div style=\&quot;position: relative; padding-top: 56.25%;\&quot;&gt;\n  &lt;iframe\n    src=\&quot;https://customer-rhnwzxvb3mg4wz3v.cloudflarestream.com/a649dcf6e57fc69b8a0ceaf13d96562b/iframe?preload=true&amp;poster=https%3A%2F%2Fcustomer-rhnwzxvb3mg4wz3v.cloudflarestream.com%2Fa649dcf6e57fc69b8a0ceaf13d96562b%2Fthumbnails%2Fthumbnail.jpg%3Ftime%3D%26height%3D600&amp;startTime=4s&amp;primaryColor=%23f6821f\&quot;\n    loading=\&quot;lazy\&quot;\n    style=\&quot;border: none; position: absolute; top: 0; left: 0; height: 100%; width: 100%;\&quot;\n    allow=\&quot;accelerometer; gyroscope; autoplay; encrypted-media; picture-in-picture;\&quot;\n    allowfullscreen=\&quot;true\&quot;\n  &gt;&lt;/iframe&gt;\n&lt;/div&gt;&lt;!--kg-card-end: html--&gt;&lt;p&gt;&lt;/p&gt;&quot;],&quot;published_at&quot;:[0,&quot;2024-04-29T14:00:09.000+01:00&quot;],&quot;updated_at&quot;:[0,&quot;2024-10-09T23:28:12.149Z&quot;],&quot;feature_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4o6fpMsB2KFJwmLZohMTJ3/ca387f75d92f195c8c132e05f2631a7f/q1-2024-internet-disruption-summary.png&quot;],&quot;tags&quot;:[1,[[0,{&quot;id&quot;:[0,&quot;5kZtWqjqa7aOUoZr8NFGwI&quot;],&quot;name&quot;:[0,&quot;Radar&quot;],&quot;slug&quot;:[0,&quot;cloudflare-radar&quot;]}],[0,{&quot;id&quot;:[0,&quot;0kgHdg1ytbdWl5BNo6bEa&quot;],&quot;name&quot;:[0,&quot;Internet Traffic&quot;],&quot;slug&quot;:[0,&quot;internet-traffic&quot;]}],[0,{&quot;id&quot;:[0,&quot;4yliZlpBPZpOwBDZzo1tTh&quot;],&quot;name&quot;:[0,&quot;Outage&quot;],&quot;slug&quot;:[0,&quot;outage&quot;]}],[0,{&quot;id&quot;:[0,&quot;sBnaK06GQyzaHg5OdsV90&quot;],&quot;name&quot;:[0,&quot;Internet Shutdown&quot;],&quot;slug&quot;:[0,&quot;internet-shutdown&quot;]}],[0,{&quot;id&quot;:[0,&quot;5DD7GZ0oxjP3NGOaJMwyWq&quot;],&quot;name&quot;:[0,&quot;Internet Quality&quot;],&quot;slug&quot;:[0,&quot;internet-quality&quot;]}]]],&quot;relatedTags&quot;:[0],&quot;authors&quot;:[1,[[0,{&quot;name&quot;:[0,&quot;David Belson&quot;],&quot;slug&quot;:[0,&quot;david-belson&quot;],&quot;bio&quot;:[0,null],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/en7vkXf6rLBm4F8IcNHXT/645022bf841fabff7732aa3be3949808/david-belson.jpeg&quot;],&quot;location&quot;:[0,null],&quot;website&quot;:[0,null],&quot;twitter&quot;:[0,&quot;@dbelson&quot;],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}]]],&quot;meta_description&quot;:[0,&quot;The first quarter of 2024 kicked off with quite a few Internet disruptions. Perhaps most interestingly, RPKI, DNS, and DNSSEC issues were among the technical problems that disrupted connectivity for subscribers across multiple network providers.&quot;],&quot;primary_author&quot;:[0,{}],&quot;localeList&quot;:[0,{&quot;name&quot;:[0,&quot;Q1 2024 Internet disruption summary Config&quot;],&quot;enUS&quot;:[0,&quot;English for Locale&quot;],&quot;zhCN&quot;:[0,&quot;Translated for Locale&quot;],&quot;zhHansCN&quot;:[0,&quot;No Page for Locale&quot;],&quot;zhTW&quot;:[0,&quot;Translated for Locale&quot;],&quot;frFR&quot;:[0,&quot;Translated for Locale&quot;],&quot;deDE&quot;:[0,&quot;Translated for Locale&quot;],&quot;itIT&quot;:[0,&quot;No Page for Locale&quot;],&quot;jaJP&quot;:[0,&quot;Translated for Locale&quot;],&quot;koKR&quot;:[0,&quot;Translated for Locale&quot;],&quot;ptBR&quot;:[0,&quot;Translated for Locale&quot;],&quot;esLA&quot;:[0,&quot;No Page for Locale&quot;],&quot;esES&quot;:[0,&quot;Translated for Locale&quot;],&quot;enAU&quot;:[0,&quot;No Page for Locale&quot;],&quot;enCA&quot;:[0,&quot;No Page for Locale&quot;],&quot;enIN&quot;:[0,&quot;No Page for Locale&quot;],&quot;enGB&quot;:[0,&quot;No Page for Locale&quot;],&quot;idID&quot;:[0,&quot;No Page for Locale&quot;],&quot;ruRU&quot;:[0,&quot;No Page for Locale&quot;],&quot;svSE&quot;:[0,&quot;No Page for Locale&quot;],&quot;viVN&quot;:[0,&quot;No Page for Locale&quot;],&quot;plPL&quot;:[0,&quot;No Page for Locale&quot;],&quot;arAR&quot;:[0,&quot;No Page for Locale&quot;],&quot;nlNL&quot;:[0,&quot;No Page for Locale&quot;],&quot;thTH&quot;:[0,&quot;No Page for Locale&quot;],&quot;trTR&quot;:[0,&quot;No Page for Locale&quot;],&quot;heIL&quot;:[0,&quot;No Page for Locale&quot;],&quot;lvLV&quot;:[0,&quot;No Page for Locale&quot;],&quot;etEE&quot;:[0,&quot;No Page for Locale&quot;],&quot;ltLT&quot;:[0,&quot;No Page for Locale&quot;]}],&quot;url&quot;:[0,&quot;https://blog.cloudflare.com/q1-2024-internet-disruption-summary&quot;],&quot;metadata&quot;:[0,{&quot;title&quot;:[0,&quot;Q1 2024 Internet disruption summary&quot;],&quot;description&quot;:[0,&quot;The first quarter of 2024 kicked off with quite a few Internet disruptions. Perhaps most interestingly, RPKI, DNS, and DNSSEC issues were among the technical problems that disrupted connectivity for subscribers across multiple network providers.&quot;],&quot;imgPreview&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5jcfY3SywlTsDrSLOAFtms/a2ec1ea0b3e8b8b4e71bf6a24102e9a4/q1-2024-internet-disruption-summary-3v1FKG.png&quot;]}],&quot;publicly_index&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;3jSHB2RGdy2XNScvpyF1oX&quot;],&quot;title&quot;:[0,&quot;Major data center power failure (again): Cloudflare Code Orange tested&quot;],&quot;slug&quot;:[0,&quot;major-data-center-power-failure-again-cloudflare-code-orange-tested&quot;],&quot;excerpt&quot;:[0,&quot;Just four months after a complete power outage at a critical data center we were hit with the exact same scenario.  Here’s how we did this time, and what’s next&quot;],&quot;featured&quot;:[0,false],&quot;html&quot;:[0,&quot;&lt;p&gt;&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4fn80cCKCVWYn0XOOh3eX2/e23f4144cdb106dc80bd3b8a27f27254/image3-11.png\&quot; alt=\&quot;Major data center power failure (again): Cloudflare Code Orange tested\&quot; class=\&quot;kg-image\&quot; width=\&quot;1800\&quot; height=\&quot;1013\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;Here&amp;#39;s a post we never thought we&amp;#39;d need to write: less than five months after one of our major data centers lost power, it happened again to the exact same data center. That sucks and, if you&amp;#39;re thinking &amp;quot;why do they keep using this facility??,&amp;quot; I don&amp;#39;t blame you. We&amp;#39;re thinking the same thing. But, here&amp;#39;s the thing, while a lot may not have changed at the data center, a lot changed over those five months at Cloudflare. So, while five months ago a major data center going offline was really painful, this time it was much less so.&lt;/p&gt;&lt;p&gt;This is a little bit about how a high availability data center lost power for the second time in five months. But, more so, it&amp;#39;s the story of how our team worked to ensure that even if one of our critical data centers lost power it wouldn&amp;#39;t impact our customers.&lt;/p&gt;&lt;p&gt;On November 2, 2023, one of our critical facilities in the Portland, Oregon region lost power for an extended period of time. It happened because of a cascading series of faults that appears to have been caused by maintenance by the electrical grid provider, climaxing with a ground fault at the facility, and was made worse by a series of unfortunate incidents that prevented the facility from getting back online in a timely fashion.&lt;/p&gt;&lt;p&gt;If you want to read all the gory details, they&amp;#39;re available &lt;a href=\&quot;/post-mortem-on-cloudflare-control-plane-and-analytics-outage/\&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;It&amp;#39;s painful whenever a data center has a complete loss of power, but it&amp;#39;s something that we were supposed to expect. Unfortunately, in spite of that expectation, we hadn&amp;#39;t enforced a number of requirements on our products that would ensure they continued running in spite of a major failure.&lt;/p&gt;&lt;p&gt;That was a mistake we were never going to allow to happen again.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;code-orange\&quot;&gt;Code Orange&lt;/h3&gt;\n            &lt;a href=\&quot;#code-orange\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;The incident was painful enough that we declared what we called Code Orange. We borrowed the idea from Google which, when they have an existential threat to their business, reportedly declares a Code Yellow or Code Red. Our logo is orange, so we altered the formula a bit.&lt;/p&gt;&lt;p&gt;Our conception of Code Orange was that the person who led the incident, in this case our SVP of Technical Operations, Jeremy Hartman, would be empowered to charge any engineer on our team to work on what he deemed the highest priority project. (Unless we declared a Code Red, which we actually ended up doing due to a hacking incident, and which would then take even higher priority. If you&amp;#39;re interested, you can read more about that &lt;a href=\&quot;/thanksgiving-2023-security-incident/\&quot;&gt;here&lt;/a&gt;.)&lt;/p&gt;&lt;p&gt;After getting through the immediate incident, Jeremy quickly triaged the most important work that needed to be done in order to ensure we&amp;#39;d be highly available even in the case of another catastrophic failure of a major data center facility. And the team got to work.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4Q7F31g2w6xPxdlq39dpDW/ad9a106fed84e8fcd728e165bfd2767a/image2-15.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1800\&quot; height=\&quot;338\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;howd-we-do\&quot;&gt;How&amp;#39;d we do?&lt;/h3&gt;\n            &lt;a href=\&quot;#howd-we-do\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;We didn’t expect such an extensive real-world test so quickly, but the universe works in mysterious ways. On Tuesday, March 26, 2024, — just shy of five months after the initial incident — the same facility had another major power outage. Below, we&amp;#39;ll get into what caused the outage this time, but what is most important is that it provided a perfect test for the work our team had done under Code Orange. So, what were the results?&lt;/p&gt;&lt;p&gt;First, let’s revisit what functions the Portland data centers at Cloudflare provide. As described in the November 2, 2023, &lt;a href=\&quot;/post-mortem-on-cloudflare-control-plane-and-analytics-outage/\&quot;&gt;post&lt;/a&gt;, the control plane of Cloudflare primarily consists of the customer-facing interface for all of our services including our website and API. Additionally, the underlying services that provide the Analytics and Logging pipelines are primarily served from these facilities.&lt;/p&gt;&lt;p&gt;Just like in November 2023, we were alerted immediately that we had lost connectivity to our PDX01 data center. Unlike in November, we very quickly knew with certainty that we had once again lost all power, putting us in the exact same situation as five months prior. We also knew, based on a successful internal cut test in February, how our systems should react. We had spent months preparing, updating countless systems and activating huge amounts of network and server capacity, culminating with a test to prove the work was having the intended effect, which in this case was an automatic failover to the redundant facilities.&lt;/p&gt;&lt;p&gt;Our Control Plane consists of hundreds of internal services, and the expectation is that when we lose one of the three critical data centers in Portland, these services continue to operate normally in the remaining two facilities, and we continue to operate primarily in Portland. We have the capability to fail over to our European data centers in case our Portland centers are completely unavailable. However, that is a secondary option, and not something we pursue immediately.&lt;/p&gt;&lt;p&gt;On March 26, 2024, at 14:58 UTC, PDX01 lost power and our systems began to react. By 15:05 UTC, our APIs and Dashboards were operating normally, all without human intervention. Our primary focus over the past few months has been to make sure that our customers would still be able to configure and operate their Cloudflare services in case of a similar outage. There were a few specific services that required human intervention and therefore took a bit longer to recover, however the primary interface mechanism was operating as expected.&lt;/p&gt;&lt;p&gt;To put a finer point on this, during the November 2, 2023, incident the following services had at least six hours of control plane downtime, with several of them functionally degraded for days.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;API and Dashboard&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Zero Trust&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Magic Transit&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;SSL&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;SSL for SaaS&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Workers&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;KV&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Waiting Room&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Load Balancing&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Zero Trust Gateway&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Access&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Pages&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Stream&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Images&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;During the March 26, 2024, incident, all of these services were up and running within minutes of the power failure, and many of them did not experience any impact at all during the failover.&lt;/p&gt;&lt;p&gt;The data plane, which handles the traffic that Cloudflare customers pass through our data centers in over 300 cities worldwide, was not impacted.&lt;/p&gt;&lt;p&gt;Our Analytics platform, which provides a view into customer traffic, was impacted and wasn’t fully restored until later that day. This was expected behavior as the Analytics platform is reliant on the PDX01 data center. Just like the Control Plane work, we began building new Analytics capacity immediately after the November 2, 2023, incident. However, the scale of the work requires that it will take a bit more time to complete. We have been working as fast as we can to remove this dependency, and we expect to complete this work in the near future.&lt;/p&gt;&lt;p&gt;Once we had validated the functionality of our Control Plane services, we were faced yet again with the cold start of a very large data center. This activity took roughly 72 hours in November 2023, but this time around we were able to complete this in roughly 10 hours. There is still work to be done to make that even faster in the future, and we will continue to refine our procedures in case we have a similar incident in the future.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7cu18EGvfdwXuXIr81qHN8/eaa05db6a5944d0270ed685ce558b070/Incident-inspection.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;284\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;how-did-we-get-here\&quot;&gt;How did we get here?&lt;/h3&gt;\n            &lt;a href=\&quot;#how-did-we-get-here\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;As mentioned above, the power outage event from last November led us to introduce Code Orange, a process where we shift most or all engineering resources to addressing the issue at hand when there’s a significant event or crisis. Over the past five months, we shifted all non-critical engineering functions to focusing on ensuring high reliability of our control plane.&lt;/p&gt;&lt;p&gt;Teams across our engineering departments rallied to ensure our systems would be more resilient in the face of a similar failure in the future. Though the March 26, 2024, incident was unexpected, it was something we’d been preparing for.&lt;/p&gt;&lt;p&gt;The most obvious difference is the speed at which the control plane and APIs regained service. Without human intervention, the ability to log in and make changes to Cloudflare configuration was possible seven minutes after PDX01 was lost. This is due to our efforts to move all of our configuration databases to a Highly Available (HA) topology, and pre-provision enough capacity that we could absorb the capacity loss. More than 100 databases across over 20 different database clusters simultaneously failed out of the affected facility and restored service automatically. This was actually the culmination of over a year’s worth of work, and we make sure we prove our ability to failover properly with weekly tests.&lt;/p&gt;&lt;p&gt;Another significant improvement is the updates to our Logpush infrastructure. In November 2023, the loss of the PDX01 datacenter meant that we were unable to push logs to our customers. During Code Orange, we invested in making the Logpush infrastructure HA in Portland, and additionally created an active failover option in Amsterdam. Logpush took advantage of our massively expanded Kubernetes cluster that spans all of our Portland facilities and provides a seamless way for service owners to deploy HA compliant services that have resiliency baked in. In fact, during our February chaos exercise, we found a flaw in our Portland HA deployment, but customers were not impacted because the Amsterdam Logpush infrastructure took over successfully. During this event, we saw that the fixes we’d made since then worked, and we were able to push logs from the Portland region.&lt;/p&gt;&lt;p&gt;A number of other improvements in our Stream and Zero Trust products resulted in little to no impact to their operation. Our Stream products, which use a lot of compute resources to transcode videos, were able to seamlessly hand off to our Amsterdam facility to continue operations. Teams were given specific availability targets for the services and were provided several options to achieve those targets. Stream is a good example of a service that chose a different resiliency architecture but was able to seamlessly deliver their service during this outage. Zero Trust, which was also impacted in November 2023, has since moved the vast majority of its functionally to our hundreds of data centers, which kept working seamlessly throughout this event. Ultimately this is the strategy we are pushing all Cloudflare products to adopt as our data centers in &lt;a href=\&quot;https://www.cloudflare.com/network\&quot;&gt;over 300 cities worldwide&lt;/a&gt; provide the highest level of availability possible.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4hnYtkVM6JHuvAOD3HGNmq/239ae0443184a22761245b4458e15ead/image1-12.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1800\&quot; height=\&quot;320\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;what-happened-to-the-power-in-the-data-center\&quot;&gt;What happened to the power in the data center?&lt;/h3&gt;\n            &lt;a href=\&quot;#what-happened-to-the-power-in-the-data-center\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;On March 26, 2024, at 14:58 UTC, PDX01 experienced a total loss of power to Cloudflare’s physical infrastructure following a reportedly simultaneous failure of four Flexential-owned and operated switchboards serving all of Cloudflare’s cages. This meant both primary and redundant power paths were deactivated across the entire environment. During the Flexential investigation, engineers focused on a set of equipment known as Circuit Switch Boards, or CSBs. CSBs are likened to an electrical panel board, consisting of a main input circuit breaker and series of smaller output breakers. Flexential engineers reported that infrastructure upstream of the CSBs (power feed, generator, UPS &amp;amp; PDU/transformer) was not impacted and continued to act normally. Similarly, infrastructure downstream from the CSBs such as Remote Power Panels and connected switchgear was not impacted – thus implying the outage was isolated to the CSBs themselves.&lt;/p&gt;&lt;p&gt;Initial assessment of the root cause of Flexential’s CSB failures points to incorrectly set breaker coordination settings within the four CSBs as one contributing factor. Trip settings which are too restrictive can result in overly sensitive overcurrent protection and the potential nuisance tripping of devices. In our case, Flexential’s breaker settings within the four CSBs were reportedly too low in relation to the downstream provisioned power capacities. When one or more of these breakers tripped, a cascading failure of the remaining active CSB boards resulted, thus causing a total loss of power serving Cloudflare’s cage and others on the shared infrastructure. During the triage of the incident, we were told that the Flexential facilities team noticed the incorrect trip settings, reset the CSBs and adjusted them to the expected values, enabling our team to power up our servers in a staged and controlled fashion. We do not know when these settings were established – typically, these would be set/adjusted as part of a data center commissioning process and/or breaker coordination study before customer critical loads are installed.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3lJDAVlXMNrU7Eyp7PP0lF/db9a86dfa40f4ca85965d8af8b36c634/Incident-inspection-3.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;284\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;whats-next\&quot;&gt;What’s next?&lt;/h3&gt;\n            &lt;a href=\&quot;#whats-next\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Our top priority is completing the resilience program for our Analytics platform. Analytics aren’t simply pretty charts in a dashboard. When you want to check the status of attacks, activities a firewall is blocking, or even the status of Cloudflare Tunnels - you need analytics. We have evidence that the resiliency pattern we are adopting works as expected, so this remains our primary focus, and we will progress as quickly as possible.&lt;/p&gt;&lt;p&gt;There were some services that still required manual intervention to properly recover, and we have collected data and action items for each of them to ensure that further manual action is not required. We will continue to use production cut tests to prove all of these changes and enhancements provide the resiliency that our customers expect.&lt;/p&gt;&lt;p&gt;We will continue to work with Flexential on follow-up activities to expand our understanding of their operational and review procedures to the greatest extent possible. While this incident was limited to a single facility, we will turn this exercise into a process that ensures we have a similar view into all of our critical data center facilities.&lt;/p&gt;&lt;p&gt;Once again, we are very sorry for the impact to our customers, particularly those that rely on the Analytics engine who were unable to access that product feature during the incident. Our work over the past four months has yielded the results that we expected, and we will stay absolutely focused on completing the remaining body of work.&lt;/p&gt;&quot;],&quot;published_at&quot;:[0,&quot;2024-04-08T14:00:15.000+01:00&quot;],&quot;updated_at&quot;:[0,&quot;2024-10-09T23:28:01.244Z&quot;],&quot;feature_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4bbrEk2RMnve9baEwW0cXh/a6d37e60317c9f7a7a4c172b3287ffd7/major-data-center-power-failure-again-cloudflare-code-orange-tested.png&quot;],&quot;tags&quot;:[1,[[0,{&quot;id&quot;:[0,&quot;3cCNoJJ5uusKFBLYKFX1jB&quot;],&quot;name&quot;:[0,&quot;Post Mortem&quot;],&quot;slug&quot;:[0,&quot;post-mortem&quot;]}],[0,{&quot;id&quot;:[0,&quot;4yliZlpBPZpOwBDZzo1tTh&quot;],&quot;name&quot;:[0,&quot;Outage&quot;],&quot;slug&quot;:[0,&quot;outage&quot;]}]]],&quot;relatedTags&quot;:[0],&quot;authors&quot;:[1,[[0,{&quot;name&quot;:[0,&quot;Matthew Prince&quot;],&quot;slug&quot;:[0,&quot;matthew-prince&quot;],&quot;bio&quot;:[0,&quot;A little bit geek, wonk, and nerd. Repeat entrepreneur, recovering lawyer, and former ski instructor. Co-founder &amp; CEO of Cloudflare (NYSE: NET).&quot;],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1VD9WePJ1jvjFwuSRF0IfQ/5e4f7d5fd4825358b33b2ead623140d8/matthew-prince.jpeg&quot;],&quot;location&quot;:[0,&quot;San Francisco, CA&quot;],&quot;website&quot;:[0,null],&quot;twitter&quot;:[0,&quot;@eastdakota&quot;],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}],[0,{&quot;name&quot;:[0,&quot;John Graham-Cumming&quot;],&quot;slug&quot;:[0,&quot;john-graham-cumming&quot;],&quot;bio&quot;:[0,null],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5vGNsXzZrtSLn2X30pnpUY/6f350e7dd36058a6422f9199b452bb02/john-graham-cumming.jpg&quot;],&quot;location&quot;:[0,&quot;Lisbon, Portugal&quot;],&quot;website&quot;:[0,null],&quot;twitter&quot;:[0,null],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}],[0,{&quot;name&quot;:[0,&quot;Jeremy Hartman&quot;],&quot;slug&quot;:[0,&quot;jeremy-hartman&quot;],&quot;bio&quot;:[0,null],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1yTvNpd60qmjgY8fbItcDp/f964f6cd281c1693cee7b4a43a6e3845/jeremy-hartman.jpeg&quot;],&quot;location&quot;:[0,null],&quot;website&quot;:[0,null],&quot;twitter&quot;:[0,null],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}]]],&quot;meta_description&quot;:[0,&quot;Just four months after a complete power outage at a critical data center we were hit with the exact same scenario.  Here’s how we did this time, and what’s next.&quot;],&quot;primary_author&quot;:[0,{}],&quot;localeList&quot;:[0,{&quot;name&quot;:[0,&quot;Major data center power failure (again): Cloudflare Code Orange tested Config&quot;],&quot;enUS&quot;:[0,&quot;English for Locale&quot;],&quot;zhCN&quot;:[0,&quot;Translated for Locale&quot;],&quot;zhHansCN&quot;:[0,&quot;No Page for Locale&quot;],&quot;zhTW&quot;:[0,&quot;Translated for Locale&quot;],&quot;frFR&quot;:[0,&quot;Translated for Locale&quot;],&quot;deDE&quot;:[0,&quot;Translated for Locale&quot;],&quot;itIT&quot;:[0,&quot;No Page for Locale&quot;],&quot;jaJP&quot;:[0,&quot;Translated for Locale&quot;],&quot;koKR&quot;:[0,&quot;Translated for Locale&quot;],&quot;ptBR&quot;:[0,&quot;No Page for Locale&quot;],&quot;esLA&quot;:[0,&quot;No Page for Locale&quot;],&quot;esES&quot;:[0,&quot;Translated for Locale&quot;],&quot;enAU&quot;:[0,&quot;No Page for Locale&quot;],&quot;enCA&quot;:[0,&quot;No Page for Locale&quot;],&quot;enIN&quot;:[0,&quot;No Page for Locale&quot;],&quot;enGB&quot;:[0,&quot;No Page for Locale&quot;],&quot;idID&quot;:[0,&quot;No Page for Locale&quot;],&quot;ruRU&quot;:[0,&quot;No Page for Locale&quot;],&quot;svSE&quot;:[0,&quot;No Page for Locale&quot;],&quot;viVN&quot;:[0,&quot;No Page for Locale&quot;],&quot;plPL&quot;:[0,&quot;No Page for Locale&quot;],&quot;arAR&quot;:[0,&quot;No Page for Locale&quot;],&quot;nlNL&quot;:[0,&quot;No Page for Locale&quot;],&quot;thTH&quot;:[0,&quot;No Page for Locale&quot;],&quot;trTR&quot;:[0,&quot;No Page for Locale&quot;],&quot;heIL&quot;:[0,&quot;No Page for Locale&quot;],&quot;lvLV&quot;:[0,&quot;No Page for Locale&quot;],&quot;etEE&quot;:[0,&quot;No Page for Locale&quot;],&quot;ltLT&quot;:[0,&quot;No Page for Locale&quot;]}],&quot;url&quot;:[0,&quot;https://blog.cloudflare.com/major-data-center-power-failure-again-cloudflare-code-orange-tested&quot;],&quot;metadata&quot;:[0,{&quot;title&quot;:[0,&quot;Major data center power failure (again): Cloudflare Code Orange tested&quot;],&quot;description&quot;:[0,&quot;Just four months after a complete power outage at a critical data center we were hit with the exact same scenario.  Here’s how we did this time, and what’s next.&quot;],&quot;imgPreview&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5ARkdS88AEID6KoSFfQK4w/e5938547e4b3c6b6d98d48b0406a2400/major-data-center-power-failure-again-cloudflare-code-orange-tested-kT3ZCQ.png&quot;]}],&quot;publicly_index&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;4MdY6pvvO7WXFULICwzYan&quot;],&quot;title&quot;:[0,&quot;Undersea cable failures cause Internet disruptions for multiple African countries&quot;],&quot;slug&quot;:[0,&quot;undersea-cable-failures-cause-internet-disruptions-across-africa-march-14-2024&quot;],&quot;excerpt&quot;:[0,&quot;Internet connectivity in several African countries was disrupted on March 14, 2024, beginning at approximately 05:00 UTC. Based on published reports and social media posts from impacted network providers, the disruption is believed to be due to multiple undersea cable failures in the region&quot;],&quot;featured&quot;:[0,false],&quot;html&quot;:[0,&quot;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3QkLMie4vi6ZxephX6L3tA/edf8d697756cd9104298e134b29663b8/Undersea-Cable-1.png\&quot; alt=\&quot;Undersea cable failures cause Internet disruptions for multiple African countries\&quot; class=\&quot;kg-image\&quot; width=\&quot;1800\&quot; height=\&quot;1013\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;Internet connectivity in several African countries was disrupted today, March 14, 2024. Beginning at approximately 05:00 UTC, west and central African countries were most impacted, as was South Africa. Based on published reports and social media posts from impacted network providers, the disruption is believed to be due to multiple undersea cable failures in the region. From The Gambia to Côte d&amp;#39;Ivoire, including a major network in South Africa (Vodacom), a total of 13 African countries were impacted, based on our observations.&lt;/p&gt;&lt;p&gt;&lt;a href=\&quot;https://radar.cloudflare.com/\&quot;&gt;Cloudflare Radar&lt;/a&gt; data shows a pattern of disruptions from the north to the south of West Africa over time. It began south of Senegal, with The Gambia, Guinea, and Liberia experiencing disruptions around 05:00 UTC.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3YFXvOb0d6KPYkYfR9nSM4/057a8d333635f2dce5529218b9a37707/pasted-image-0--7--1.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3HUVR6zoCKJ8Sjh7bm6WmU/74a0f012935e98e528c87643ba81f8f1/pasted-image-0-8.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;In The Gambia and Guinea, the disruptions lasted about 30 minutes, while in Liberia, the disruption has lasted more than 12 hours.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6tS8dtneEcP9LomsRKKabu/e7b5094195652b87839c3a2dc921eb6a/pasted-image-0--1--4.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;Moving south, around 07:30 UTC, disruptions were observed in Côte d&amp;#39;Ivoire and Ghana.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4LIFIi2fOcsAG5hDmAyNH9/30c3fad0d070ce04d863775d22e6f05f/pasted-image-0--2--4.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7rEVVZKDouQZWQNWhxhgsD/9b792d5b18a5deced50943c3a821de7b/pasted-image-0--3--2.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;Niger, a landlocked nation in Central Africa, experienced a disruption at 09:15, lasting just over two hours.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3oPCZakLyOUmCMxfuByZ4N/a584eeec67a9a4a4cea4e6b7a98110e6/pasted-image-0--4--1.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;This was followed by disruptions starting around 10:30 UTC in Nigeria, Benin, Cameroon, and Togo. Namibia and Burkina Faso were also impacted. These disruptions were ongoing at the time of writing.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2ajkDyNdD2ACpibN0qPWZy/9d64fe9eefe789a4765247154039ea54/pasted-image-0--5--1.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/71bpPDkKhQjmZN5uRLci6P/39ddca37cec24f639d09d439143e2933/pasted-image-0--6--1.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2axJ1y6LkrTRJu9PeS6BjE/7451b3c623780d282bf95c4d361b3199/pasted-image-0--8-.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7yS9XMwBpuoMhZGA3qUfSV/5d2fea9e031c778c31320d80fb1a6cef/pasted-image-0--9-.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;At approximately the same time, a significant disruption was observed on Vodacom’s South African network (&lt;a href=\&quot;https://radar.cloudflare.com/as29975?dateStart=2024-03-14&amp;dateEnd=2024-03-14\&quot;&gt;AS29975&lt;/a&gt;). Traffic began to recover after 13:30 UTC, and appears to have reached close to normal levels by 16:00 UTC.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/14rQeLYajsW1eN3GoTJxsZ/782aac73476084ac448ffe5134fabf1a/pasted-image-0--10-.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;900\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;the-importance-of-submarine-cables\&quot;&gt;The importance of submarine cables&lt;/h3&gt;\n            &lt;a href=\&quot;#the-importance-of-submarine-cables\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;This series of disruptions serves as a reminder of how dependent the Internet is on &lt;a href=\&quot;https://en.wikipedia.org/wiki/Submarine_communications_cable\&quot;&gt;submarine cables&lt;/a&gt;, which are estimated to carry over &lt;a href=\&quot;https://blog.telegeography.com/2023-mythbusting-part-3\&quot;&gt;90% of intercontinental data traffic&lt;/a&gt;. Only a small percentage of general use is done via satellite networks. There are &lt;a href=\&quot;https://submarine-cable-map-2023.telegeography.com/\&quot;&gt;529 active submarine cables and 1,444 landings&lt;/a&gt; that are currently active or under construction, running to an estimated 1.3 million km around the globe.&lt;/p&gt;&lt;p&gt;We have written about submarine cable-related outages before, from &lt;a href=\&quot;/internet-is-back-in-tonga-after-38-days-of-outage/\&quot;&gt;Tonga&lt;/a&gt; to the &lt;a href=\&quot;/aae-1-smw5-cable-cuts\&quot;&gt;AAE-1 &amp;amp; SMW5 cable cuts of June 2022&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Reports from several local networks, including South Africa’s &lt;a href=\&quot;https://twitter.com/Vodacom/status/1768262584413679758\&quot;&gt;Vodacom&lt;/a&gt;, &lt;a href=\&quot;https://twitter.com/MTN180/status/1768280785084137753\&quot;&gt;MTN&lt;/a&gt; in Nigeria, and &lt;a href=\&quot;https://twitter.com/celtiisbj/status/1768276617967587731\&quot;&gt;Celtiis&lt;/a&gt; in Bénin, reference multiple submarine cable failures. Microsoft was more detailed, &lt;a href=\&quot;https://web.archive.org/web/20240314160638/https://azure.status.microsoft/en-us/status\&quot;&gt;stating on their Azure status page&lt;/a&gt; that “multiple fiber cables on the West Coast of Africa — WACS, MainOne, SAT3, ACE — have been impacted which reduced total capacity supporting our Regions in South Africa”. The company also explains that the recent cable cuts in the &lt;a href=\&quot;https://twitter.com/CloudflareRadar/status/1762447960074330340?s=20\&quot;&gt;Red Sea&lt;/a&gt; in combination with today’s cable issues, “has impacted all Africa capacity”.&lt;/p&gt;&lt;p&gt;In addition to the impacts to the Microsoft Azure cloud platform, the &lt;a href=\&quot;https://www.mainone.net/\&quot;&gt;website of MainOne&lt;/a&gt;, owners of the &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/mainone\&quot;&gt;MainOne submarine cable&lt;/a&gt;, was offline for several hours. DNS for mainone.net is handled by name servers located in MainOne’s address space. It appears that a portion of the IPv4 address space for AS37282 (MAINONE) stopped being announced between 07:30 and 15:00 UTC, and once this address space was being routed again, both the nameservers and website became reachable.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/01olDj3FyILdeLsZw02sLQ/ef15b5446afb397720b13758e605a599/pasted-image-0--11-.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1590\&quot; height=\&quot;786\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;This &lt;a href=\&quot;https://www.submarinecablemap.com/multiselect/submarine-cable?ids=mainone,africa-coast-to-europe-ace,sat-3wasc,west-africa-cable-system-wacs\&quot;&gt;map from TeleGeography&lt;/a&gt; highlights the impacted submarine cables: WACS (West Africa Cable System), MainOne, SAT-3/WASC, and ACE.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/58nfk6NRa0lXPQNLaEzP2Q/da50db105468246c042499c6a9fdb409/pasted-image-0--12-.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;1410\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;The disruptions are now being reported by &lt;a href=\&quot;https://www.reuters.com/world/africa/internet-disruption-hits-west-central-africa-netblocks-cloudflare-data-shows-2024-03-14/\&quot;&gt;news media outlets&lt;/a&gt;, including in &lt;a href=\&quot;https://subtelforum.com/south-africa-internet-hit-by-multiple-subsea-cable-breaks/\&quot;&gt;South Africa&lt;/a&gt;, where the emphasis is not only on the latest outage but also on the problem with the submarine cable operator &lt;a href=\&quot;https://www.itweb.co.za/article/seacom-confirms-cable-outage-in-red-sea/KPNG8v8NyDNM4mwD\&quot;&gt;Seacom&lt;/a&gt;. This operator experienced a service-impacting outage on its cable system in the Red Sea. On March 8, the company &lt;a href=\&quot;https://www.itweb.co.za/article/seacom-waits-for-permits-to-start-red-sea-cable-repairs/xA9POvNEyapqo4J8\&quot;&gt;stated&lt;/a&gt; that it is waiting for &lt;a href=\&quot;https://subtelforum.com/seacom-waits-for-permits-to-start-red-sea-cable-repairs/\&quot;&gt;permits&lt;/a&gt; to start repairing its broken submarine cable in the Red Sea.&lt;/p&gt;&lt;p&gt;We will keep monitoring the situation. Follow the &lt;a href=\&quot;https://radar.cloudflare.com/outage-center\&quot;&gt;Cloudflare Radar Outage Center&lt;/a&gt; for the latest updates, and follow us on social media at &lt;a href=\&quot;https://twitter.com/CloudflareRadar\&quot;&gt;@CloudflareRadar&lt;/a&gt; (X), &lt;a href=\&quot;https://noc.social/@cloudflareradar\&quot;&gt;https://noc.social/@cloudflareradar&lt;/a&gt; (Mastodon), and &lt;a href=\&quot;https://bsky.app/profile/radar.cloudflare.com\&quot;&gt;radar.cloudflare.com&lt;/a&gt; (Bluesky).&lt;/p&gt;&quot;],&quot;published_at&quot;:[0,&quot;2024-03-14T18:03:25.000+00:00&quot;],&quot;updated_at&quot;:[0,&quot;2024-10-09T23:27:41.918Z&quot;],&quot;feature_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/75Ddg30LW4eYyjXZbZaOYQ/d62d717e75b38ce8b6bf4c9a15553e6f/undersea-cable-failures-cause-internet-disruptions-across-africa-march-14-2024.png&quot;],&quot;tags&quot;:[1,[[0,{&quot;id&quot;:[0,&quot;5kZtWqjqa7aOUoZr8NFGwI&quot;],&quot;name&quot;:[0,&quot;Radar&quot;],&quot;slug&quot;:[0,&quot;cloudflare-radar&quot;]}],[0,{&quot;id&quot;:[0,&quot;4yliZlpBPZpOwBDZzo1tTh&quot;],&quot;name&quot;:[0,&quot;Outage&quot;],&quot;slug&quot;:[0,&quot;outage&quot;]}],[0,{&quot;id&quot;:[0,&quot;0kgHdg1ytbdWl5BNo6bEa&quot;],&quot;name&quot;:[0,&quot;Internet Traffic&quot;],&quot;slug&quot;:[0,&quot;internet-traffic&quot;]}],[0,{&quot;id&quot;:[0,&quot;3yArjf0gLKZy8ObEDxbNNi&quot;],&quot;name&quot;:[0,&quot;Trends&quot;],&quot;slug&quot;:[0,&quot;trends&quot;]}]]],&quot;relatedTags&quot;:[0],&quot;authors&quot;:[1,[[0,{&quot;name&quot;:[0,&quot;João Tomé&quot;],&quot;slug&quot;:[0,&quot;joao-tome&quot;],&quot;bio&quot;:[0,&quot;After years as a journalist covering technology, cinema, sports (soccer/football), and mobility (including hosting a TV show about it), I’m now telling data-driven and other stories at Cloudflare.&quot;],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/KOYiYhfI8O9WNWxB8IWk7/e1e24f4df878f45e812bdd4a893b026e/joao-tome.jpeg&quot;],&quot;location&quot;:[0,&quot;Lisbon, Portugal&quot;],&quot;website&quot;:[0,null],&quot;twitter&quot;:[0,&quot;@emot&quot;],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}],[0,{&quot;name&quot;:[0,&quot;David Belson&quot;],&quot;slug&quot;:[0,&quot;david-belson&quot;],&quot;bio&quot;:[0,null],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/en7vkXf6rLBm4F8IcNHXT/645022bf841fabff7732aa3be3949808/david-belson.jpeg&quot;],&quot;location&quot;:[0,null],&quot;website&quot;:[0,null],&quot;twitter&quot;:[0,&quot;@dbelson&quot;],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}]]],&quot;meta_description&quot;:[0,&quot;Internet connectivity in several African countries was disrupted on March 14, 2024, beginning at approximately 05:00 UTC. Based on published reports and social media posts from impacted network providers, the disruption is believed to be due to multiple undersea cable failures in the region. &quot;],&quot;primary_author&quot;:[0,{}],&quot;localeList&quot;:[0,{&quot;name&quot;:[0,&quot;Undersea cable failures cause Internet disruptions for multiple African countries Config&quot;],&quot;enUS&quot;:[0,&quot;English for Locale&quot;],&quot;zhCN&quot;:[0,&quot;No Page for Locale&quot;],&quot;zhHansCN&quot;:[0,&quot;No Page for Locale&quot;],&quot;zhTW&quot;:[0,&quot;No Page for Locale&quot;],&quot;frFR&quot;:[0,&quot;No Page for Locale&quot;],&quot;deDE&quot;:[0,&quot;No Page for Locale&quot;],&quot;itIT&quot;:[0,&quot;No Page for Locale&quot;],&quot;jaJP&quot;:[0,&quot;No Page for Locale&quot;],&quot;koKR&quot;:[0,&quot;No Page for Locale&quot;],&quot;ptBR&quot;:[0,&quot;No Page for Locale&quot;],&quot;esLA&quot;:[0,&quot;No Page for Locale&quot;],&quot;esES&quot;:[0,&quot;No Page for Locale&quot;],&quot;enAU&quot;:[0,&quot;No Page for Locale&quot;],&quot;enCA&quot;:[0,&quot;No Page for Locale&quot;],&quot;enIN&quot;:[0,&quot;No Page for Locale&quot;],&quot;enGB&quot;:[0,&quot;No Page for Locale&quot;],&quot;idID&quot;:[0,&quot;No Page for Locale&quot;],&quot;ruRU&quot;:[0,&quot;No Page for Locale&quot;],&quot;svSE&quot;:[0,&quot;No Page for Locale&quot;],&quot;viVN&quot;:[0,&quot;No Page for Locale&quot;],&quot;plPL&quot;:[0,&quot;No Page for Locale&quot;],&quot;arAR&quot;:[0,&quot;No Page for Locale&quot;],&quot;nlNL&quot;:[0,&quot;No Page for Locale&quot;],&quot;thTH&quot;:[0,&quot;No Page for Locale&quot;],&quot;trTR&quot;:[0,&quot;No Page for Locale&quot;],&quot;heIL&quot;:[0,&quot;No Page for Locale&quot;],&quot;lvLV&quot;:[0,&quot;No Page for Locale&quot;],&quot;etEE&quot;:[0,&quot;No Page for Locale&quot;],&quot;ltLT&quot;:[0,&quot;No Page for Locale&quot;]}],&quot;url&quot;:[0,&quot;https://blog.cloudflare.com/undersea-cable-failures-cause-internet-disruptions-across-africa-march-14-2024&quot;],&quot;metadata&quot;:[0,{&quot;title&quot;:[0,&quot;Undersea cable failures cause Internet disruptions for multiple African countries&quot;],&quot;description&quot;:[0,&quot;Internet connectivity in several African countries was disrupted on March 14, 2024, beginning at approximately 05:00 UTC. Based on published reports and social media posts from impacted network providers, the disruption is believed to be due to multiple undersea cable failures in the region. &quot;],&quot;imgPreview&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5oABP0gZN9JgPPxZGcMauM/472141b8b50c163c21a96bc422ca8eb8/undersea-cable-failures-cause-internet-disruptions-across-africa-march-14-2024-ItbVTP.png&quot;]}],&quot;publicly_index&quot;:[0,true]}],[0,{&quot;id&quot;:[0,&quot;3jPeETqqS2lSPcVevWFbub&quot;],&quot;title&quot;:[0,&quot;Q4 2023 Internet disruption summary&quot;],&quot;slug&quot;:[0,&quot;q4-2023-internet-disruption-summary&quot;],&quot;excerpt&quot;:[0,&quot;In this post, we review selected Internet disruptions observed by Cloudflare during the fourth quarter of 2023, supported by traffic graphs from Cloudflare Radar and other internal Cloudflare tools, and grouped by associated cause or common geography&quot;],&quot;featured&quot;:[0,false],&quot;html&quot;:[0,&quot;&lt;p&gt;&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/46eFEiFp8AtgmQcdps6Inx/29327b0a230c82cce34efc2118a2d974/image48-1.png\&quot; alt=\&quot;Q4 2023 Internet disruption summary\&quot; class=\&quot;kg-image\&quot; width=\&quot;1999\&quot; height=\&quot;1126\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;Cloudflare’s network spans more than 310 cities in over 120 countries, where we interconnect with over 13,000 network providers in order to provide a broad range of services to millions of customers. The breadth of both our network and our customer base provides us with a unique perspective on Internet resilience, enabling us to observe the impact of Internet disruptions.&lt;/p&gt;&lt;p&gt;During previous quarters, we tracked a number of government directed Internet shutdowns in Iraq, intended to prevent cheating on academic exams. We expected to do so again during the fourth quarter, but there turned out to be no need to, as &lt;a href=\&quot;#governmentdirected\&quot;&gt;discussed below&lt;/a&gt;. While we didn’t see that set of expected shutdowns, we did observe a number of other Internet outages and disruptions due to a number of commonly seen causes, including &lt;a href=\&quot;#fibercabletrouble\&quot;&gt;fiber/cable issues&lt;/a&gt;, &lt;a href=\&quot;#poweroutages\&quot;&gt;power outages&lt;/a&gt;, extreme &lt;a href=\&quot;#weather\&quot;&gt;weather&lt;/a&gt;, infrastructure &lt;a href=\&quot;#maintenance\&quot;&gt;maintenance&lt;/a&gt;, general &lt;a href=\&quot;#technicalproblems\&quot;&gt;technical problems&lt;/a&gt;, &lt;a href=\&quot;#cyberattacks\&quot;&gt;cyberattacks&lt;/a&gt;, and unfortunately, &lt;a href=\&quot;#militaryaction\&quot;&gt;military action&lt;/a&gt;. As we have noted in the past, this post is intended as a summary overview of observed disruptions, and is not an exhaustive or complete list of issues that have occurred during the quarter.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;h2 id=\&quot;governmentdirected\&quot;&gt;Government directed&lt;/h2&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;iraq\&quot;&gt;Iraq&lt;/h3&gt;\n            &lt;a href=\&quot;#iraq\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;In a slight departure from the usual subject of this blog post, this time we lead off with coverage of government directed Internet shutdowns that didn’t happen. &lt;a href=\&quot;https://radar.cloudflare.com/iq\&quot;&gt;Iraq&lt;/a&gt; has been a frequent subject of this series of posts, as they have historically implemented daily multi-hour Internet shutdowns during exam periods, intended to prevent cheating. Earlier this year, there was some hope that this practice might be ending, and in our &lt;a href=\&quot;/q2-2023-internet-disruption-summary/\&quot;&gt;Q2 2023 Internet disruption summary&lt;/a&gt; post, we noted “&lt;i&gt;In the weeks prior to the start of this year’s shutdowns, it was &lt;/i&gt;&lt;a href=\&quot;https://www.kurdistan24.net/en/story/31453-Iraq%E2%80%99s-communication-ministry-refuses-to-enforce-internet-blackout-for-final-exams\&quot;&gt;&lt;i&gt;reported&lt;/i&gt;&lt;/a&gt;&lt;i&gt; that the Iraqi Ministry of Communications had announced it had refused a request from the Ministry of Education to impose an Internet shutdown during the exams as part of efforts to prevent cheating. Unfortunately, this refusal was short-lived, with shutdowns ultimately starting two weeks later.&lt;/i&gt;” In addition to these second quarter shutdowns, they also occurred during the third quarter across multiple weeks in July, August, and September.&lt;/p&gt;&lt;p&gt;During the fourth quarter, the third round of 12th grade high school final exams was scheduled to begin on November 13 and end on November 21, taking place at 13:00 local time, as shown in the schedule below, which was &lt;a href=\&quot;https://www.facebook.com/photo.php?fbid=661695112830032&amp;set=pb.100069686486016.-2207520000&amp;type=3\&quot;&gt;published&lt;/a&gt; on the Iraqi Ministry of Education’s Facebook page.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card \&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/EU7icSaMHzAeCVQs5Bitq/c0ad971a6ceeadb81a4d5a94900ab133/image53.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1024\&quot; height=\&quot;708\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;p&gt;November 2023 exam schedule in Iraq&lt;/p&gt;&lt;p&gt;However, in looking at Internet traffic for Iraq during that period, it appears that the nationwide Internet shutdowns that would have normally taken place did not occur, as the graph shows a very consistent diurnal pattern with no evidence of disruptions to Internet connectivity like we have seen in the past. Additionally, other &lt;a href=\&quot;https://twitter.com/accessnow\&quot;&gt;civil society groups&lt;/a&gt;, &lt;a href=\&quot;https://twitter.com/IODA_live\&quot;&gt;academic researchers&lt;/a&gt;, and &lt;a href=\&quot;https://twitter.com/dougmadory\&quot;&gt;Internet analysts&lt;/a&gt; that also monitor these shutdowns did not report seeing any related drops in traffic. It is unclear whether a request for shutdowns was submitted by the Ministry of Education and again refused by the Ministry of Communications, or if no request was ever submitted for this round of exams. Regardless, we hope that Iraq continues to keep the Internet connected during future rounds of exams.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;h2 id=\&quot;militaryaction\&quot;&gt;Military action&lt;/h2&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;palestine\&quot;&gt;Palestine&lt;/h3&gt;\n            &lt;a href=\&quot;#palestine\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;On Saturday, October 7, 2023, attacks from the Palestinian group Hamas launched from the Gaza Strip against the south of Israel started a new &lt;a href=\&quot;https://en.wikipedia.org/wiki/October_2023_Gaza%E2%88%92Israel_conflict\&quot;&gt;conflict&lt;/a&gt; in the region, with Israel &lt;a href=\&quot;https://apnews.com/live/israel-hamas-war-live-updates#0000018b-0f83-d2a1-a1df-8fcb0a320000\&quot;&gt;officially declaring&lt;/a&gt; the next day that it was at war. This had an almost immediate impact on Internet traffic in both &lt;a href=\&quot;https://radar.cloudflare.com/il\&quot;&gt;Israel&lt;/a&gt; and &lt;a href=\&quot;https://radar.cloudflare.com/ps\&quot;&gt;Palestine&lt;/a&gt;, with traffic in the former showing ~170% growth as compared to the prior week, and ~100% growth in the latter as compared to the previous week. These trends are discussed in our October 9 blog post, &lt;a href=\&quot;/internet-traffic-patterns-in-israel-and-palestine-following-the-october-2023-attacks/\&quot;&gt;&lt;i&gt;Internet traffic patterns in Israel and Palestine following the October 2023 attacks&lt;/i&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;However, in the hours and days following the initial attacks, a number of Palestinian Internet providers saw traffic fall significantly, with many winding up largely or totally offline, potentially as a result of power outages caused by &lt;a href=\&quot;https://apnews.com/article/israel-palestinians-gaza-hamas-rockets-airstrikes-tel-aviv-11fb98655c256d54ecb5329284fc37d2\&quot;&gt;retaliatory Israeli airstrikes&lt;/a&gt;. Impacted networks included &lt;a href=\&quot;https://radar.cloudflare.com/as42314\&quot;&gt;AS42314 (fusion)&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as203905\&quot;&gt;AS203905 (DCC_North_ASN)&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as210974\&quot;&gt;AS210974 (AjyalFI)&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as60268\&quot;&gt;AS60268 (DIGITAL-COMMUNICATION-PALESTINE-ASN)&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as60353\&quot;&gt;AS60353 (DCC_RAFAH_ASN)&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as62027\&quot;&gt;AS62027 (DCC_Khanyouns_ASN)&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as57704\&quot;&gt;AS57704 (SPEED-CLICK-LTD)&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as199046\&quot;&gt;AS199046 (JETNET)&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/as213207\&quot;&gt;AS213207 (TechHub-HiNet)&lt;/a&gt;, as shown in the graphs below.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2023-10-04&amp;dateEnd=2023-10-11&amp;location=as213207&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;&lt;p&gt;In addition to the outages illustrated above, throughout October, November, and December, &lt;a href=\&quot;https://www.paltel.ps/en/home\&quot;&gt;Paltel (Palestine Telecommunications Company)&lt;/a&gt; posted a number of times on &lt;a href=\&quot;https://twitter.com/Paltelco\&quot;&gt;its official X account&lt;/a&gt; about disruptions to its landline, mobile, and Internet services, citing causes including &lt;a href=\&quot;https://twitter.com/Paltelco/status/1718007432494911717\&quot;&gt;fiber damage due to bombardment&lt;/a&gt; and &lt;a href=\&quot;https://twitter.com/Paltelco/status/1724727009673101574\&quot;&gt;fuel depletion&lt;/a&gt;. Posts were made on &lt;a href=\&quot;https://twitter.com/Paltelco/status/1718007432494911717\&quot;&gt;October 27&lt;/a&gt;, &lt;a href=\&quot;https://twitter.com/Paltelco/status/1719529153471320550\&quot;&gt;October 31&lt;/a&gt;, &lt;a href=\&quot;https://twitter.com/Paltelco/status/1725159705796821048\&quot;&gt;November 16&lt;/a&gt;, &lt;a href=\&quot;https://twitter.com/Paltelco/status/1731740390691066263\&quot;&gt;December 4&lt;/a&gt;, &lt;a href=\&quot;https://twitter.com/Paltelco/status/1735324896677216391\&quot;&gt;December 14&lt;/a&gt;, &lt;a href=\&quot;https://twitter.com/Paltelco/status/1737380988064272472\&quot;&gt;December 20&lt;/a&gt;, and &lt;a href=\&quot;https://twitter.com/Paltelco/status/1739668361837936669\&quot;&gt;December 26&lt;/a&gt;. The associated outages varied in length, some lasting for hours, while others lasted for multiple days — each outage is shaded in the graphs below, which show Paltel traffic within four Palestinian governorates in the Gaza Strip region.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/2GIWlojCibbJx9f1t7GKxe/67ca726673664f4da6f3386ef857770a/Dec---Oct---Palestine---Gaza.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;910\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3LgG6g0LuUPd6eV7OjXRvz/7de10b9e30e86312b6e9df9a122c1dd0/Dec---Oct---Palestine---Rafah.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;910\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6LPxqCpcM3KKwRdBICyTFu/57ef31df6cdbb2cc16de4443629ec8c0/Dec---Oct---Palestine---Khan-Yunis.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;910\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7o0kLqhbSeHw2XEtJJiBUv/375182eeb397c52cf94ce3217bcdd260/Dec---Oct---Palestine---Deir-al-Balah.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;910\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;!--kg-card-begin: html--&gt;&lt;h2 id=\&quot;fibercabletrouble\&quot;&gt;Fiber/cable trouble&lt;/h2&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;namibia\&quot;&gt;Namibia&lt;/h3&gt;\n            &lt;a href=\&quot;#namibia\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;On November 13, &lt;a href=\&quot;https://radar.cloudflare.com/as36996\&quot;&gt;Telecom Namibia (AS36996)&lt;/a&gt; &lt;a href=\&quot;https://twitter.com/TelecomNamibia/status/1723311216850796563\&quot;&gt;reported&lt;/a&gt; that it was experiencing interruptions to its fixed voice and data services in several areas, resulting from cable theft. The impact of these interruptions is shown in the figure below, with Internet traffic disrupted between 13:45 local time (11:45 UTC) on November 13 and 08:30 local time (06:30 UTC) on November 14. The disruption to connectivity due to cable theft was not an isolated incident, as the provider posted several additional notices on its &lt;a href=\&quot;https://twitter.com/TelecomNamibia\&quot;&gt;social media accounts&lt;/a&gt; in November and December about similar occurrences.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2023-11-12&amp;dateEnd=2023-11-14&amp;location=as36996&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;cuba\&quot;&gt;Cuba&lt;/h3&gt;\n            &lt;a href=\&quot;#cuba\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;A day later, on November 14, &lt;a href=\&quot;https://radar.cloudflare.com/as27725\&quot;&gt;ETECSA (AS27725)&lt;/a&gt; &lt;a href=\&quot;https://twitter.com/ETECSA_Cuba/status/1724442186282909760\&quot;&gt;posted&lt;/a&gt; a notice about a terrestrial fiber cut that disrupted Internet services. As the state-owned telecommunications provider in &lt;a href=\&quot;https://radar.cloudflare.com/cu\&quot;&gt;Cuba&lt;/a&gt;, the cut impacted Internet traffic nationwide, as well as at a network level, as seen in the graphs below. The disruption was relatively short-lived, occurring between 06:30 - 08:15 local time (11:30 - 13:15 UTC), with a &lt;a href=\&quot;https://twitter.com/ETECSA_Cuba/status/1724499677041594801\&quot;&gt;follow-up post&lt;/a&gt; announcing the re-establishment of Internet service.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2023-11-13&amp;dateEnd=2023-11-14&amp;location=AS27725&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;chad\&quot;&gt;Chad&lt;/h3&gt;\n            &lt;a href=\&quot;#chad\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;On December 7 &amp;amp; 8, a near-complete outage observed in &lt;a href=\&quot;https://radar.cloudflare.com/td\&quot;&gt;Chad&lt;/a&gt; was &lt;a href=\&quot;https://www.msn.com/fr-xl/actualite/other/tchad-connexion-internet-r%C3%A9tablie-apr%C3%A8s-des-heures-de-coupure/ar-AA1lcaMM\&quot;&gt;reportedly&lt;/a&gt; due to fiber optic cable cuts in neighboring countries. A published article cited &lt;a href=\&quot;https://radar.cloudflare.com/as328594\&quot;&gt;SudaChad&lt;/a&gt; as claiming that the outage seen in the graphs below was due to an issue with CAMTEL, a &lt;a href=\&quot;https://www.camertoday.com/camtel-and-sudachad-assess-relationship-pledge-further-commitment-for-better-results/\&quot;&gt;Cameroonian partner&lt;/a&gt;. It also cites &lt;a href=\&quot;https://moovafrica.td/\&quot;&gt;Moov Africa’s (formerly known as Millicom Chad)&lt;/a&gt; &lt;a href=\&quot;https://www.facebook.com/moovafrica.td/posts/pfbid0V63Pse2WEMqB5FsdkzAwwJppZLjwJry9MeYV8jUZZUNJZqu9WFG6fQfAURbMKop2l\&quot;&gt;apology&lt;/a&gt; to customers, which points at “&lt;i&gt;the fiber-optic cut in Cameroon and Sudan&lt;/i&gt;&amp;#39;&amp;#39; as the root cause. Since simultaneous cuts in fiber optic cables in Chad’s two neighboring countries would certainly be an unusual occurrence, it isn’t clear if such an event happened, though &lt;a href=\&quot;https://radar.cloudflare.com/routing/as328594\&quot;&gt;routing data for SudaChad&lt;/a&gt; shows that the network’s two upstream providers are &lt;a href=\&quot;https://radar.cloudflare.com/routing/as15706\&quot;&gt;AS15706 (Sudatel)&lt;/a&gt; in &lt;a href=\&quot;https://radar.cloudflare.com/sd\&quot;&gt;Sudan&lt;/a&gt; and &lt;a href=\&quot;https://radar.cloudflare.com/routing/as15964\&quot;&gt;AS15964 (CAMNET)&lt;/a&gt; in &lt;a href=\&quot;https://radar.cloudflare.com/cm\&quot;&gt;Cameroon&lt;/a&gt;. The three providers are also partners on the &lt;a href=\&quot;https://www.capacitymedia.com/article/29ysrmpai1ti3q95wj474/news/african-three-partner-on-cameroon-chad-sudan-terrestrial-upgrade\&quot;&gt;WE-AFRICA-NA terrestrial cable&lt;/a&gt;, which stretches from Port-Sudan on the Red Sea in Sudan to Kribi on the Atlantic Ocean in Cameroon via Chad, but it isn’t known whether that cable system was involved in this outage.&lt;/p&gt;&lt;p&gt;The disruption lasted approximately fourteen hours, from 20:00 local time on December 7 until 10:15 local time on December 8 (19:00 UTC on December 7 until 09:15 UTC on December 8), with the impact visible country-wide, as well as at SudaChad and several downstream network providers.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;h2 id=\&quot;cyberattacks\&quot;&gt;Cyberattacks&lt;/h2&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;ukraine\&quot;&gt;Ukraine&lt;/h3&gt;\n            &lt;a href=\&quot;#ukraine\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Ukrainian Internet provider Kyivstar &lt;a href=\&quot;https://twitter.com/TwiyKyivstar/status/1734527519972298888\&quot;&gt;announced&lt;/a&gt; on the morning of December 12 that they were the “target of a powerful hacker attack”. They noted that the attack caused a “technical failure” that resulted in mobile communication and Internet access becoming temporarily unavailable. Although &lt;a href=\&quot;https://radar.cloudflare.com/as15895\&quot;&gt;Kyivstar&lt;/a&gt; has been targeted by around &lt;a href=\&quot;https://www.barrons.com/news/ukraine-s-main-phone-operator-recovering-two-days-after-cyberattack-41ba9ee3\&quot;&gt;500 cyberattacks&lt;/a&gt; since Russia launched its invasion of Ukraine in February 2022, this was &lt;a href=\&quot;https://www.reuters.com/technology/cybersecurity/ukraines-kyivstar-restores-services-after-cyberattack-parent-veon-says-2023-12-19/\&quot;&gt;reportedly&lt;/a&gt; the largest attack to date. A &lt;a href=\&quot;https://therecord.media/russians-infiltrated-kyivstar-months-before\&quot;&gt;subsequent report&lt;/a&gt; referenced an interview with Illia Vitiuk, the head of the cybersecurity department at Ukraine’s security service (SBU), in which he claimed that “&lt;i&gt;the hackers attempted to penetrate Kyivstar in March 2023 or earlier, managed to get into the system at least as early as May, and likely gained full access to the network in November.&lt;/i&gt;”&lt;/p&gt;&lt;p&gt;Recovery took several days, with Kyivstar &lt;a href=\&quot;https://twitter.com/TwiyKyivstar/status/1735732558783033831\&quot;&gt;posting&lt;/a&gt; on December 15 that “the Internet is everywhere” but warning that connection speeds might be slightly reduced. These posts align with the traffic disruption shown in the figure below, which lasted from 06:30 local time (04:30 UTC) on December 12 until 14:00 local time (12:00 UTC) on December 15.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;h2 id=\&quot;poweroutages\&quot;&gt;Power outages&lt;/h2&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;brunei\&quot;&gt;Brunei&lt;/h3&gt;\n            &lt;a href=\&quot;#brunei\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;A major &lt;a href=\&quot;https://borneobulletin.com.bn/key-services-affected-by-power-outage/\&quot;&gt;power outage&lt;/a&gt; in &lt;a href=\&quot;https://radar.cloudflare.com/bn\&quot;&gt;Brunei&lt;/a&gt; on October 17 disrupted key services including mobile and fixed Internet connectivity. Starting around 11:30 local time (03:30 UTC), traffic was disrupted for approximately 13 hours, recovering to expected levels around just after midnight local time on October 18 (16:45 UTC). Two &lt;a href=\&quot;http://www.unn.com.bn/\&quot;&gt;Unified National Networks&lt;/a&gt; &lt;a href=\&quot;https://www.cloudflare.com/learning/network-layer/what-is-an-autonomous-system/\&quot;&gt;autonomous systems&lt;/a&gt; (&lt;a href=\&quot;https://radar.cloudflare.com/as10094\&quot;&gt;AS10094&lt;/a&gt; and &lt;a href=\&quot;https://radar.cloudflare.com/as131467\&quot;&gt;AS131467&lt;/a&gt;) saw lower traffic volumes during the power outage.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2023-10-16&amp;dateEnd=2023-10-17&amp;location=as131467&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;kenya\&quot;&gt;Kenya&lt;/h3&gt;\n            &lt;a href=\&quot;#kenya\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;A widespread power outage in &lt;a href=\&quot;https://radar.cloudflare.com/ke\&quot;&gt;Kenya&lt;/a&gt; on November 11 disrupted Internet connectivity across the county for approximately seven hours. An X &lt;a href=\&quot;https://twitter.com/KenyaPower_Care/status/1723395753173750170\&quot;&gt;post from Kenya Power&lt;/a&gt; at 20:30 local time (17:30 UTC) reported a partial power outage, stating “&lt;i&gt;We have lost power supply to parts of the country. Our engineers are working to restore supply to the affected areas.&lt;/i&gt;” Kenya Power kept customers informed of progress, posting updates at &lt;a href=\&quot;https://twitter.com/KenyaPower_Care/status/1723419016805392777\&quot;&gt;22:00&lt;/a&gt;, &lt;a href=\&quot;https://twitter.com/KenyaPower_Care/status/1723447354869596441\&quot;&gt;23:57&lt;/a&gt;, and the &lt;a href=\&quot;https://twitter.com/KenyaPower_Care/status/1723499883921826270\&quot;&gt;morning of November 12&lt;/a&gt;, with the final update reporting “&lt;i&gt;We have successfully restored normal power supply in all the areas that were affected by the partial outage.&lt;/i&gt;”&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2023-11-11&amp;dateEnd=2023-11-12&amp;location=ke&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;curacao\&quot;&gt;Curaçao&lt;/h3&gt;\n            &lt;a href=\&quot;#curacao\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;On November 14, a &lt;a href=\&quot;https://www.facebook.com/AqualectraUtilityCuracao/posts/pfbid02zDjsA6PNXrJbvNRnbPsCqmYp1ZkyeQ76T8Wm5ppW6Nw34uWnHgPjFD4H7F1Lp2Cdl?comment_id=653239830306646&amp;__cft__[0]=AZWpmwt39YsibkYuAxOzfgXMMpqxQJmoMRw7wP4MoF1xoeyjXm7zTBb7a5qZDlQVSdPRy3aRUqWXPtlZXp3ixvLhXibRz0e5Q-hUCyOh7OEaWxAUQIRXC66H0Vu4UoyAk-ovL89HVTjCLy9PxQ_TebGFwR3i8z5LuynvWizmPlFajA&amp;__tn__=R]-R\&quot;&gt;Facebook post from Aqualectra&lt;/a&gt;, the water and power company in &lt;a href=\&quot;https://radar.cloudflare.com/cw\&quot;&gt;Curaçao&lt;/a&gt;, stated in part, “&lt;i&gt;Around 14:00 this afternoon, a blackout occurred. Preliminary investigation indicates that one of the main cables responsible for transporting electricity between the substations at Nijlweg and Weis experienced a short circuit. It is important to emphasize that this is not due to a lack of production capacity.&lt;/i&gt;” The power outage resulted in a near complete loss of traffic at &lt;a href=\&quot;https://radar.cloudflare.com/traffic/as52233\&quot;&gt;Flow Curaçao (AS52233)&lt;/a&gt;, with significant disruptions also visible at &lt;a href=\&quot;https://radar.cloudflare.com/traffic/as11081\&quot;&gt;United Telecommunication Services (AS11081)&lt;/a&gt; and at a country level, as seen in the graphs below. The disruption lasted eight hours, from 14:00 until 22:00 local time (18:00 UTC on November 14 until 02:00 UTC on November 15).&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2023-11-14&amp;dateEnd=2023-11-15&amp;location=as11081&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;sri-lanka\&quot;&gt;Sri Lanka&lt;/h3&gt;\n            &lt;a href=\&quot;#sri-lanka\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;After stabilizing its electrical infrastructure in the wake of 2022’s problems with its electrical power grid, &lt;a href=\&quot;https://apnews.com/article/sri-lanka-crisis-power-outage-imf-ff6c24554d5dcf74160f11740148e3ee\&quot;&gt;the failure of a main transmission line&lt;/a&gt; caused an island-wide power outage in &lt;a href=\&quot;https://radar.cloudflare.com/lk\&quot;&gt;Sri Lanka&lt;/a&gt; on December 9, in turn disrupting Internet connectivity. Traffic from the island nation initially dropped by around 50% starting around 16:45 local time (11:15 UTC). &lt;a href=\&quot;https://www.adaderana.lk/news.php?nid=95513\&quot;&gt;Repairs took several hours&lt;/a&gt;, with the country’s Internet traffic returning to expected levels around 01:00 local time on December 10 (19:30 UTC).&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2023-12-08&amp;dateEnd=2023-12-10&amp;location=lk&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;panama\&quot;&gt;Panama&lt;/h3&gt;\n            &lt;a href=\&quot;#panama\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;On the morning of December 24, Panamanian electric distribution company &lt;a href=\&quot;https://www.ensa.com.pa/\&quot;&gt;ENSA&lt;/a&gt; &lt;a href=\&quot;https://twitter.com/ENSApanama/status/1738947871146123372\&quot;&gt;initially reported&lt;/a&gt; an event that affected electrical services to their customers. A &lt;a href=\&quot;https://twitter.com/ENSApanama/status/1738954995179848162\&quot;&gt;subsequent report&lt;/a&gt; posted just 30 minutes later provided additional details, pointing to an incident in the “National Interconnected System” that affected the electrical supply in a number of areas, but &lt;a href=\&quot;https://twitter.com/ENSApanama/status/1738987254234640746\&quot;&gt;within an hour&lt;/a&gt;, it had spread nationally. Although the initial regional power issues did not have a noticeable impact on &lt;a href=\&quot;https://radar.cloudflare.com/pa\&quot;&gt;Panama’s&lt;/a&gt; Internet traffic, the loss of traffic in the graph below aligns with the national growth of the power outage, occurring at 11:45 local time (16:45 UTC). Traffic returned to expected levels at around 15:00 local time (20:00 UTC), aligning with an &lt;a href=\&quot;https://twitter.com/ENSApanama/status/1739027796733681703\&quot;&gt;X post from ENSA&lt;/a&gt; stating that “&lt;i&gt;At 3:12pm the supply of electrical energy to all our clients has been normalized after an event at the Transmission level originating in the Panama 1 Substation of ETESA.&lt;/i&gt;”&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;h2 id=\&quot;weather\&quot;&gt;Weather&lt;/h2&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;ukraine\&quot;&gt;Ukraine&lt;/h3&gt;\n            &lt;a href=\&quot;#ukraine\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Internet disruptions in &lt;a href=\&quot;https://radar.cloudflare.com/ua\&quot;&gt;Ukraine&lt;/a&gt; due to the conflict there have been covered in &lt;a href=\&quot;/searchresults#q=%22internet%20disruption%22%20ukraine&amp;sort=date%20descending\&quot;&gt;multiple quarterly Internet disruption summary blog posts&lt;/a&gt; over the last two years. However, in November, connectivity in multiple areas of the country was disrupted by power outages caused by a major winter storm. Snow and high winds &lt;a href=\&quot;https://www.reuters.com/world/europe/winter-storm-causes-power-outages-road-closures-ukraine-2023-11-27/\&quot;&gt;knocked out power&lt;/a&gt; to hundreds of towns and villages, damaging electrical power infrastructure. The impact is visible in the graphs below as a drop in traffic occurring around 01:00 local time on November 27 (23:00 UTC on November 26), observed in regions including Donetsk, Kherson Oblast, and Luhansk. Traffic appeared to return to expected levels early in the morning local time on November 28.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3vH3c3G46L4nD6EEOVklAi/87fc0dcba92a7fa097628c30eb34b881/pasted-image-0-1.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;397\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5vblMILsQHpP7QejIiK4We/ddf24b10384fe004ccbbfa3ecd9a0ab7/pasted-image-0--1--1.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;409\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/4Uwzflw7gJFzYm1mxJ6zIL/2d20c3b393a74618da8ef1c5589bd314/pasted-image-0--2--1.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;1600\&quot; height=\&quot;409\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;mexico\&quot;&gt;Mexico&lt;/h3&gt;\n            &lt;a href=\&quot;#mexico\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;On October 25, &lt;a href=\&quot;https://en.wikipedia.org/wiki/Hurricane_Otis\&quot;&gt;Hurricane Otis&lt;/a&gt; made landfall near Acapulco, a popular tourist destination in &lt;a href=\&quot;https://radar.cloudflare.com/mx\&quot;&gt;Mexico&lt;/a&gt;. In addition to catastrophic structural damage, it was &lt;a href=\&quot;https://www.nesdis.noaa.gov/news/hurricane-otis-causes-catastrophic-damage-acapulco-mexico\&quot;&gt;reported&lt;/a&gt; that “&lt;i&gt;more than 10,000 utility poles were destroyed, knocking out power and internet/communications across the region, while numerous transmission lines, electrical substations, and a power plant were also heavily damaged.&lt;/i&gt;” This damage to electrical and communications infrastructure in the area resulted in significant disruption to Internet connectivity. As shown in the graph below, Internet traffic from Acapulco dropped by around 80% as Otis made landfall. Traffic started to show some growth in early November, but peak volumes remained relatively consistent, and well below pre-hurricane levels, through the end of the year. (Several large spikes are visible on December 26 &amp;amp; 30, but it isn’t clear what those are associated with.) Although Acapulco’s tourism industry &lt;a href=\&quot;https://bnnbreaking.com/world/mexico/acapulcos-resilience-from-hurricane-devastation-to-holiday-destination/\&quot;&gt;experienced a notable recovery&lt;/a&gt; heading into the end of the year, it appears that infrastructure recovery has not been quite as swift.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6RqwYAx8KEBBCRS5ehEYxE/181a383c698b18180088758f09ed3228/pasted-image-0--3--1.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;910\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;fire\&quot;&gt;Fire&lt;/h2&gt;\n            &lt;a href=\&quot;#fire\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          \n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;hawaii\&quot;&gt;Hawaii&lt;/h3&gt;\n            &lt;a href=\&quot;#hawaii\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Last quarter, we &lt;a href=\&quot;/q3-2023-internet-disruption-summary/#fire\&quot;&gt;reported&lt;/a&gt; on the impact of wildfires that started on August 7 in Hawaii, including killing nearly 100 people, as well as destroying homes, businesses, and infrastructure, causing power outages and disrupting Internet connectivity. One of the most impacted areas was the town of Lahaina, where Internet connectivity remained sparse for weeks after the fires began. Repair and restoration efforts continued throughout the fourth quarter, with traffic clearly growing throughout October, with peak levels in November and December approaching pre-fire levels.&lt;/p&gt;\n            &lt;figure class=\&quot;kg-card kg-image-card kg-width-wide\&quot;&gt;\n            \n            &lt;Image src=\&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1n3qqN1BbwojGibaAVCslA/1a8d15204ed25e23706dc080578fed86/Dec-31---United-States---Hawaii---Lahaina.png\&quot; alt=\&quot;\&quot; class=\&quot;kg-image\&quot; width=\&quot;910\&quot; height=\&quot;360\&quot; loading=\&quot;lazy\&quot;/&gt;\n            \n            &lt;/figure&gt;&lt;!--kg-card-begin: html--&gt;&lt;h2 id=\&quot;maintenance\&quot;&gt;Maintenance&lt;/h2&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;yemen\&quot;&gt;Yemen&lt;/h3&gt;\n            &lt;a href=\&quot;#yemen\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;Two maintenance-related Internet disruptions impacted Internet connectivity in &lt;a href=\&quot;https://radar.cloudflare.com/ye\&quot;&gt;Yemen&lt;/a&gt; in the fourth quarter. The first lasted over four hours during the morning of November 10, from 03:10 - 07:45 local time (00:10 - 04:45 UTC), and followed two other disruptions the prior day. The impact was visible at a country level, as well as at a network level on &lt;a href=\&quot;https://radar.cloudflare.com/as30873\&quot;&gt;PTC-YemenNet (AS30873)&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;An Associated Press &lt;a href=\&quot;https://apnews.com/article/yemen-internet-outage-israel-hamas-war-houthis-4255eccf371e558b7912ddcd94d706d7\&quot;&gt;article&lt;/a&gt; noted that in a statement to the state news agency, Yemen’s Public Telecom Corp. (PTC-YemenNet) blamed the outage on maintenance, apparently of the &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/falcon\&quot;&gt;FALCON submarine cable&lt;/a&gt;. The article also cited a &lt;a href=\&quot;https://subsea.gcxworld.com/clarification-yemen-internet-outage/\&quot;&gt;statement&lt;/a&gt; from &lt;a href=\&quot;https://subsea.gcxworld.com/\&quot;&gt;GCX&lt;/a&gt;, the operator of the FALCON cable, regarding scheduled maintenance to the cable system that had been in planning for the previous three months.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2023-11-09&amp;dateEnd=2023-11-10&amp;location=as30873&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;&lt;p&gt;The second maintenance-related disruption occurred on December 15 just before 23:00 local time (20:00 UTC). An X &lt;a href=\&quot;https://twitter.com/AlnomeirMosfer/status/1735770808545423518\&quot;&gt;post from Mosfer Alnomeir&lt;/a&gt;, the Minister of Telecommunication and Information Technology in Yemen, explained what happened: “&lt;i&gt;We note that half an hour ago there was an interruption in the Internet service that lasted approximately 30 minutes. This is while engineers carry out emergency replacement and upgrade work on some service equipment. Service was restored immediately. On behalf of the team, I say thank you for your understanding.&lt;/i&gt;” Once again, the impact was visible at both a country and network level.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;h2 id=\&quot;technicalproblems\&quot;&gt;Technical problems&lt;/h2&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;australia\&quot;&gt;Australia&lt;/h3&gt;\n            &lt;a href=\&quot;#australia\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;&amp;quot;Changes to routing information&amp;quot; after a &amp;quot;routine software upgrade&amp;quot; were &lt;a href=\&quot;https://www.reuters.com/business/media-telecom/singtel-owned-optus-says-massive-australia-outage-was-after-software-upgrade-2023-11-13/\&quot;&gt;reportedly&lt;/a&gt; responsible for a multi-hour Internet outage at Australian telecommunications provider &lt;a href=\&quot;https://radar.cloudflare.com/as4804\&quot;&gt;Optus (AS4804)&lt;/a&gt; on November 8 local time. Connectivity began to drop just after 04:00 Sydney time, with the outage lasting from 04:30 - 10:00 Sydney time (17:30 - 23:00 UTC on November 7). Traffic didn’t fully recover to expected levels until around 23:00 Sydney time (12:00 UTC).&lt;/p&gt;&lt;p&gt;The network issue &lt;a href=\&quot;https://www.reuters.com/business/media-telecom/australia-investigate-optus-internet-phone-outage-2023-11-08/\&quot;&gt;impacted&lt;/a&gt; more than 10 million customers, as well as hospitals and payment and transport systems, and drew comparisons to &lt;a href=\&quot;/cloudflares-view-of-the-rogers-communications-outage-in-canada\&quot;&gt;July 2023’s outage at Canadian provider Rogers Communications&lt;/a&gt;. Optus &lt;a href=\&quot;https://www.aph.gov.au/DocumentStore.ashx?id=2ed95079-023d-49d5-87fd-d9029740629b&amp;subId=750333\&quot;&gt;submitted a report&lt;/a&gt; to the Australian Senate Standing Committee on Environment and Communications that detailed the cause of the outage, noting “&lt;i&gt;It is now understood that the outage occurred due to approximately 90 PE routers automatically self-isolating in order to protect themselves from an overload of IP routing information. … This unexpected overload of IP routing information occurred after a software upgrade at one of the Singtel internet exchanges (known as STiX) in North America, one of Optus’ international networks. During the upgrade, the Optus network received changes in routing information from an alternate Singtel peering router. These routing changes were propagated through multiple layers of our IP Core network. As a result, at around 4:05am (AEDT), the pre-set safety limits on a significant number of Optus network routers were exceeded.&lt;/i&gt;” The report also detailed the recovery efforts and timelines for consumer Internet, DNS, and mobile services.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2023-11-07&amp;dateEnd=2023-11-08&amp;location=as4804&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;armenia\&quot;&gt;Armenia&lt;/h3&gt;\n            &lt;a href=\&quot;#armenia\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;&lt;a href=\&quot;https://www.facebook.com/telecomarmenia.am/posts/pfbid0KaB276aGQeDpsb2Q5fi9J3ybVdzPzqZ49aw1GyiHpAWCszXGEMntYLaitYBPPN8bl\&quot;&gt;Failure of international links&lt;/a&gt; caused a brief Internet disruption at &lt;a href=\&quot;https://radar.cloudflare.com/as12297\&quot;&gt;Telecom Armenia (AS12297)&lt;/a&gt; on November 11, similar to a &lt;a href=\&quot;https://tech.news.am/eng/news/317/internet-failures-in-armenia-due-to-outage-of-main-and-backup-communication-nodes-on-territory-of-georgia.html\&quot;&gt;disruption that occurred almost exactly a year earlier&lt;/a&gt;. As shown in the graph below, the disruption began just around 15:15 local time (11:15 UTC), with short periods where traffic dropped to zero. Traffic recovered to expected levels by 21:00 local time (17:00 UTC). As one of the largest telecommunications providers in the country, the service disruption was visible at a country level as well.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2023-11-11&amp;dateEnd=2023-11-12&amp;location=am&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;united-kingdom\&quot;&gt;United Kingdom&lt;/h3&gt;\n            &lt;a href=\&quot;#united-kingdom\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;A sizable drop in traffic was observed between 15:00 and 21:30 local time (15:00 - 21:30 UTC) on mobile and broadband Internet provider &lt;a href=\&quot;https://radar.cloudflare.com/as206067\&quot;&gt;Three UK (AS206067)&lt;/a&gt; on December 1, as seen in the graph below. Although the provider &lt;a href=\&quot;https://twitter.com/ThreeUK/status/1730600392029802858\&quot;&gt;acknowledged&lt;/a&gt; that customers were experiencing issues and provided several updates (&lt;a href=\&quot;https://twitter.com/ThreeUK/status/1730698310611058926\&quot;&gt;1&lt;/a&gt;, &lt;a href=\&quot;https://twitter.com/ThreeUK/status/1730891263837159762\&quot;&gt;2&lt;/a&gt;, &lt;a href=\&quot;https://twitter.com/ThreeUK/status/1730909430449873229\&quot;&gt;3&lt;/a&gt;, &lt;a href=\&quot;https://twitter.com/ThreeUK/status/1730983680196178156\&quot;&gt;4&lt;/a&gt;) on service restoration over the next day, it never disclosed any additional information on the cause of the disruption. However, a &lt;a href=\&quot;https://www.datacenterdynamics.com/en/news/three-blames-network-outage-on-technical-issue-at-one-of-its-data-centers/\&quot;&gt;published report&lt;/a&gt; stated that Three UK blamed technical issues at one of its data centers as the cause of the problem, which impacted more than 20,000 users.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2023-12-01&amp;dateEnd=2023-12-01&amp;location=as206067&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;egypt\&quot;&gt;Egypt&lt;/h3&gt;\n            &lt;a href=\&quot;#egypt\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;On December 5, &lt;a href=\&quot;https://radar.cloudflare.com/as8452\&quot;&gt;Telecom Egypt (AS8452)&lt;/a&gt; &lt;a href=\&quot;https://twitter.com/telecomegypt/status/1732073702605410364\&quot;&gt;posted&lt;/a&gt; on X that a technical malfunction affecting one of their main network devices was responsible for an Internet disruption that occurred on their network, which also impacted connectivity on several other network providers, including &lt;a href=\&quot;https://radar.cloudflare.com/as24863\&quot;&gt;LINKdotNET (AS24863)&lt;/a&gt;, &lt;a href=\&quot;https://radar.cloudflare.com/as24835\&quot;&gt;Vodafone Egypt (AS24835)&lt;/a&gt;, and &lt;a href=\&quot;https://radar.cloudflare.com/as36992\&quot;&gt;Etisalat (AS36992)&lt;/a&gt;, as well as traffic at a national level, as seen in the graphs below. Although &lt;a href=\&quot;https://pub468.ayam.news/115707\&quot;&gt;one news report claimed&lt;/a&gt; that the disruption, which occurred between 14:15 - 00:00 local time (12:15 - 22:00 UTC), was due to damage to the &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/flag-europe-asia-fea\&quot;&gt;FLAG&lt;/a&gt; and &lt;a href=\&quot;https://www.submarinecablemap.com/submarine-cable/seamewe-4\&quot;&gt;SeaMeWe-4&lt;/a&gt; submarine cables, a &lt;a href=\&quot;https://twitter.com/telecomegypt/status/1732300454711755192\&quot;&gt;subsequent post from Telecom Egypt&lt;/a&gt; about service restoration dispelled that claim, noting “&lt;i&gt;The company also confirms that there is no truth to what has been circulated on some social media sites about the presence of a break in one of the submarine cables.&lt;/i&gt;”&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2023-12-05&amp;dateEnd=2023-12-06&amp;location=as36992&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;tunisia\&quot;&gt;Tunisia&lt;/h3&gt;\n            &lt;a href=\&quot;#tunisia\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;A &lt;a href=\&quot;https://twitter.com/Lechatquirit/status/1736366153855811657\&quot;&gt;reported DNS server outage&lt;/a&gt; (albeit unconfirmed) at &lt;a href=\&quot;https://radar.cloudflare.com/tn\&quot;&gt;Tunisian&lt;/a&gt; Internet provider &lt;a href=\&quot;https://radar.cloudflare.com/as37705\&quot;&gt;Topnet (AS37705)&lt;/a&gt; caused a brief Internet disruption for the provider’s customers on December 17, also impacting traffic volumes at a national level. The incident lasted less than two hours, from 13:00 - 14:45 local time (12:00 - 13:45 UTC).&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2023-12-16&amp;dateEnd=2023-12-17&amp;location=as37705&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h3 id=\&quot;guinea\&quot;&gt;Guinea&lt;/h3&gt;\n            &lt;a href=\&quot;#guinea\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n        &lt;p&gt;An &lt;a href=\&quot;https://twitter.com/orangeguinee_gn/status/1738145903515517298\&quot;&gt;unspecified incident&lt;/a&gt; on the &lt;a href=\&quot;https://radar.cloudflare.com/as37461\&quot;&gt;Orange Guinée (AS37461)&lt;/a&gt; network impacted Internet connectivity, as well as telephone calls and text messages during the morning of December 22. The graph below shows a near-complete outage on the network between 09:15 - 11:30 local time (09:15 - 11:30 UTC). The provider &lt;a href=\&quot;https://twitter.com/orangeguinee_gn/status/1738181857324253552\&quot;&gt;posted a subsequent update&lt;/a&gt; regarding the restoration of calls, text messages, and Internet connectivity.&lt;/p&gt;&lt;!--kg-card-begin: html--&gt;&lt;iframe width=\&quot;800\&quot; height=\&quot;400\&quot; src=\&quot;https://radar.cloudflare.com/embed/TrafficTrendsXY?dateStart=2023-12-22&amp;dateEnd=2023-12-22&amp;location=as37461&amp;chartState=%7B%22showAnnotations%22%3Atrue%2C%22xy.hiddenSeries%22%3A%5B%5D%2C%22xy.previousVisible%22%3Atrue%7D\&quot; title=\&quot;Cloudflare Radar - Internet traffic trends\&quot; loading=\&quot;lazy\&quot;&gt;&lt;/iframe&gt;&lt;!--kg-card-end: html--&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;conclusion\&quot;&gt;Conclusion&lt;/h2&gt;\n            &lt;a href=\&quot;#conclusion\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;p&gt;Within the &lt;a href=\&quot;https://radar.cloudflare.com/year-in-review/2023#internet-outages\&quot;&gt;Cloudflare Radar 2023 Year in Review&lt;/a&gt;, we highlighted over 180 major Internet disruptions that were observed year-to-date through the end of November, though the actual number was likely closer to 200 by the end of the year. While that may seem like a lot, it is worth nothing that the actual number is even higher, as these posts are not exhaustive in their coverage of such events. For example, while we covered the Internet shutdown in Manipur, India that took place across multiple months in 2023, &lt;a href=\&quot;https://internetshutdowns.in/\&quot;&gt;internetshutdowns.in&lt;/a&gt; shows that over 90 more smaller localized shutdowns were put into place across the country.&lt;/p&gt;&lt;p&gt;In addition, 2024 is shaping up to be an important year for elections, with voting taking place in more than &lt;a href=\&quot;https://www.weforum.org/agenda/2023/12/2024-elections-around-world/\&quot;&gt;50 countries around the world&lt;/a&gt;. Unfortunately, some countries have taken to implementing Internet shutdowns or otherwise disrupting Internet connectivity during elections. The &lt;a href=\&quot;https://freedomonlinecoalition.com/joint-statement-internet-shutdowns-and-elections/\&quot;&gt;Freedom Online Coalition’s Joint Statement on Internet Shutdowns and Elections&lt;/a&gt; details the detrimental effects of such actions. The Cloudflare Radar team will be monitoring for election-related Internet shutdowns, sharing our observations on the &lt;a href=\&quot;https://radar.cloudflare.com/outage-center\&quot;&gt;Cloudflare Radar Outage Center&lt;/a&gt;, via social media, and in posts on &lt;a href=\&quot;/tag/cloudflare-radar/\&quot;&gt;blog.cloudflare.com&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Follow us on social media at &lt;a href=\&quot;https://twitter.com/CloudflareRadar\&quot;&gt;@CloudflareRadar&lt;/a&gt; (X), &lt;a href=\&quot;https://noc.social/@cloudflareradar\&quot;&gt;https://noc.social/@cloudflareradar&lt;/a&gt; (Mastodon), and &lt;a href=\&quot;https://bsky.app/profile/radar.cloudflare.com\&quot;&gt;radar.cloudflare.com&lt;/a&gt; (Bluesky), or contact us via email.&lt;/p&gt;\n          &lt;div class=\&quot;flex anchor relative\&quot;&gt;\n            &lt;h2 id=\&quot;watch-on-cloudflare-tv\&quot;&gt;Watch on Cloudflare TV&lt;/h2&gt;\n            &lt;a href=\&quot;#watch-on-cloudflare-tv\&quot; aria-hidden=\&quot;true\&quot; class=\&quot;relative sm:absolute sm:-left-5\&quot;&gt;\n              &lt;svg width=\&quot;16\&quot; height=\&quot;16\&quot; viewBox=\&quot;0 0 24 24\&quot;&gt;&lt;path fill=\&quot;currentcolor\&quot; d=\&quot;m12.11 15.39-3.88 3.88a2.52 2.52 0 0 1-3.5 0 2.47 2.47 0 0 1 0-3.5l3.88-3.88a1 1 0 0 0-1.42-1.42l-3.88 3.89a4.48 4.48 0 0 0 6.33 6.33l3.89-3.88a1 1 0 1 0-1.42-1.42Zm8.58-12.08a4.49 4.49 0 0 0-6.33 0l-3.89 3.88a1 1 0 0 0 1.42 1.42l3.88-3.88a2.52 2.52 0 0 1 3.5 0 2.47 2.47 0 0 1 0 3.5l-3.88 3.88a1 1 0 1 0 1.42 1.42l3.88-3.89a4.49 4.49 0 0 0 0-6.33ZM8.83 15.17a1 1 0 0 0 1.1.22 1 1 0 0 0 .32-.22l4.92-4.92a1 1 0 0 0-1.42-1.42l-4.92 4.92a1 1 0 0 0 0 1.42Z\&quot;&gt;&lt;/path&gt;&lt;/svg&gt;\n            &lt;/a&gt;\n          &lt;/div&gt;\n          &lt;!--kg-card-begin: html--&gt;&lt;div style=\&quot;position: relative; padding-top: 56.25%;\&quot;&gt;\n  &lt;iframe\n    src=\&quot;https://customer-rhnwzxvb3mg4wz3v.cloudflarestream.com/131f95227e4d18032279d72833c66df3/iframe?preload=true&amp;poster=https%3A%2F%2Fcustomer-rhnwzxvb3mg4wz3v.cloudflarestream.com%2F131f95227e4d18032279d72833c66df3%2Fthumbnails%2Fthumbnail.jpg%3Ftime%3D%26height%3D600\&quot;\n    style=\&quot;border: none; position: absolute; top: 0; left: 0; height: 100%; width: 100%;\&quot;\n    allow=\&quot;accelerometer; gyroscope; autoplay; encrypted-media; picture-in-picture;\&quot;\n    allowfullscreen=\&quot;true\&quot;\n  &gt;&lt;/iframe&gt;\n&lt;/div&gt;&lt;!--kg-card-end: html--&gt;&lt;p&gt;&lt;/p&gt;&quot;],&quot;published_at&quot;:[0,&quot;2024-01-22T14:00:27.000+00:00&quot;],&quot;updated_at&quot;:[0,&quot;2024-10-09T23:26:49.706Z&quot;],&quot;feature_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/1TwDV11YHLEaF6u6RtweA0/bad5c7a69ec01b8505c1959ff38a6a05/q4-2023-internet-disruption-summary.png&quot;],&quot;tags&quot;:[1,[[0,{&quot;id&quot;:[0,&quot;5kZtWqjqa7aOUoZr8NFGwI&quot;],&quot;name&quot;:[0,&quot;Radar&quot;],&quot;slug&quot;:[0,&quot;cloudflare-radar&quot;]}],[0,{&quot;id&quot;:[0,&quot;0kgHdg1ytbdWl5BNo6bEa&quot;],&quot;name&quot;:[0,&quot;Internet Traffic&quot;],&quot;slug&quot;:[0,&quot;internet-traffic&quot;]}],[0,{&quot;id&quot;:[0,&quot;4yliZlpBPZpOwBDZzo1tTh&quot;],&quot;name&quot;:[0,&quot;Outage&quot;],&quot;slug&quot;:[0,&quot;outage&quot;]}],[0,{&quot;id&quot;:[0,&quot;sBnaK06GQyzaHg5OdsV90&quot;],&quot;name&quot;:[0,&quot;Internet Shutdown&quot;],&quot;slug&quot;:[0,&quot;internet-shutdown&quot;]}],[0,{&quot;id&quot;:[0,&quot;5DD7GZ0oxjP3NGOaJMwyWq&quot;],&quot;name&quot;:[0,&quot;Internet Quality&quot;],&quot;slug&quot;:[0,&quot;internet-quality&quot;]}]]],&quot;relatedTags&quot;:[0],&quot;authors&quot;:[1,[[0,{&quot;name&quot;:[0,&quot;David Belson&quot;],&quot;slug&quot;:[0,&quot;david-belson&quot;],&quot;bio&quot;:[0,null],&quot;profile_image&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/en7vkXf6rLBm4F8IcNHXT/645022bf841fabff7732aa3be3949808/david-belson.jpeg&quot;],&quot;location&quot;:[0,null],&quot;website&quot;:[0,null],&quot;twitter&quot;:[0,&quot;@dbelson&quot;],&quot;facebook&quot;:[0,null],&quot;publiclyIndex&quot;:[0,true]}]]],&quot;meta_description&quot;:[0,&quot;In this post, we review selected Internet disruptions observed by Cloudflare during the fourth quarter of 2023, supported by traffic graphs from Cloudflare Radar and other internal Cloudflare tools, and grouped by associated cause or common geography.&quot;],&quot;primary_author&quot;:[0,{}],&quot;localeList&quot;:[0,{&quot;name&quot;:[0,&quot;Q4 2023 Internet disruption summary Config&quot;],&quot;enUS&quot;:[0,&quot;English for Locale&quot;],&quot;zhCN&quot;:[0,&quot;Translated for Locale&quot;],&quot;zhHansCN&quot;:[0,&quot;No Page for Locale&quot;],&quot;zhTW&quot;:[0,&quot;Translated for Locale&quot;],&quot;frFR&quot;:[0,&quot;Translated for Locale&quot;],&quot;deDE&quot;:[0,&quot;Translated for Locale&quot;],&quot;itIT&quot;:[0,&quot;No Page for Locale&quot;],&quot;jaJP&quot;:[0,&quot;Translated for Locale&quot;],&quot;koKR&quot;:[0,&quot;Translated for Locale&quot;],&quot;ptBR&quot;:[0,&quot;Translated for Locale&quot;],&quot;esLA&quot;:[0,&quot;No Page for Locale&quot;],&quot;esES&quot;:[0,&quot;Translated for Locale&quot;],&quot;enAU&quot;:[0,&quot;No Page for Locale&quot;],&quot;enCA&quot;:[0,&quot;No Page for Locale&quot;],&quot;enIN&quot;:[0,&quot;No Page for Locale&quot;],&quot;enGB&quot;:[0,&quot;No Page for Locale&quot;],&quot;idID&quot;:[0,&quot;No Page for Locale&quot;],&quot;ruRU&quot;:[0,&quot;No Page for Locale&quot;],&quot;svSE&quot;:[0,&quot;No Page for Locale&quot;],&quot;viVN&quot;:[0,&quot;No Page for Locale&quot;],&quot;plPL&quot;:[0,&quot;No Page for Locale&quot;],&quot;arAR&quot;:[0,&quot;No Page for Locale&quot;],&quot;nlNL&quot;:[0,&quot;No Page for Locale&quot;],&quot;thTH&quot;:[0,&quot;No Page for Locale&quot;],&quot;trTR&quot;:[0,&quot;No Page for Locale&quot;],&quot;heIL&quot;:[0,&quot;No Page for Locale&quot;],&quot;lvLV&quot;:[0,&quot;No Page for Locale&quot;],&quot;etEE&quot;:[0,&quot;No Page for Locale&quot;],&quot;ltLT&quot;:[0,&quot;No Page for Locale&quot;]}],&quot;url&quot;:[0,&quot;https://blog.cloudflare.com/q4-2023-internet-disruption-summary&quot;],&quot;metadata&quot;:[0,{&quot;title&quot;:[0,&quot;Q4 2023 Internet disruption summary&quot;],&quot;description&quot;:[0,&quot;In this post, we review selected Internet disruptions observed by Cloudflare during the fourth quarter of 2023, supported by traffic graphs from Cloudflare Radar and other internal Cloudflare tools, and grouped by associated cause or common geography.&quot;],&quot;imgPreview&quot;:[0,&quot;https://cf-assets.www.cloudflare.com/zkvhlag99gkb/5FCAjmpJ7LY4AS4u4beKL/d4448046b6416200d21c5624a7449428/q4-2023-internet-disruption-summary-uSTsCA.png&quot;]}],&quot;publicly_index&quot;:[0,true]}]]],&quot;translations&quot;:[0,{&quot;posts.by&quot;:[0,&quot;By&quot;],&quot;footer.gdpr&quot;:[0,&quot;GDPR&quot;],&quot;lang_blurb1&quot;:[0,&quot;This post is also available in {lang1}.&quot;],&quot;lang_blurb2&quot;:[0,&quot;This post is also available in {lang1} and {lang2}.&quot;],&quot;lang_blurb3&quot;:[0,&quot;This post is also available in {lang1}, {lang2} and {lang3}.&quot;],&quot;footer.press&quot;:[0,&quot;Press&quot;],&quot;header.title&quot;:[0,&quot;The Cloudflare Blog&quot;],&quot;search.clear&quot;:[0,&quot;Clear&quot;],&quot;search.filter&quot;:[0,&quot;Filter&quot;],&quot;search.source&quot;:[0,&quot;Source&quot;],&quot;footer.careers&quot;:[0,&quot;Careers&quot;],&quot;footer.company&quot;:[0,&quot;Company&quot;],&quot;footer.support&quot;:[0,&quot;Support&quot;],&quot;footer.the_net&quot;:[0,&quot;theNet&quot;],&quot;search.filters&quot;:[0,&quot;Filters&quot;],&quot;footer.our_team&quot;:[0,&quot;Our team&quot;],&quot;footer.webinars&quot;:[0,&quot;Webinars&quot;],&quot;page.more_posts&quot;:[0,&quot;More posts&quot;],&quot;posts.time_read&quot;:[0,&quot;{time} min read&quot;],&quot;search.language&quot;:[0,&quot;Language&quot;],&quot;footer.community&quot;:[0,&quot;Community&quot;],&quot;footer.resources&quot;:[0,&quot;Resources&quot;],&quot;footer.solutions&quot;:[0,&quot;Solutions&quot;],&quot;footer.trademark&quot;:[0,&quot;Trademark&quot;],&quot;header.subscribe&quot;:[0,&quot;Subscribe&quot;],&quot;footer.compliance&quot;:[0,&quot;Compliance&quot;],&quot;footer.free_plans&quot;:[0,&quot;Free plans&quot;],&quot;footer.impact_ESG&quot;:[0,&quot;Impact/ESG&quot;],&quot;posts.follow_on_X&quot;:[0,&quot;Follow on X&quot;],&quot;footer.help_center&quot;:[0,&quot;Help center&quot;],&quot;footer.network_map&quot;:[0,&quot;Network Map&quot;],&quot;header.please_wait&quot;:[0,&quot;Please Wait&quot;],&quot;page.related_posts&quot;:[0,&quot;Related posts&quot;],&quot;search.result_stat&quot;:[0,&quot;Results &lt;strong&gt;{search_range}&lt;/strong&gt; of &lt;strong&gt;{search_total}&lt;/strong&gt; for &lt;strong&gt;{search_keyword}&lt;/strong&gt;&quot;],&quot;footer.case_studies&quot;:[0,&quot;Case Studies&quot;],&quot;footer.connect_2024&quot;:[0,&quot;Connect 2024&quot;],&quot;footer.terms_of_use&quot;:[0,&quot;Terms of Use&quot;],&quot;footer.white_papers&quot;:[0,&quot;White Papers&quot;],&quot;footer.cloudflare_tv&quot;:[0,&quot;Cloudflare TV&quot;],&quot;footer.community_hub&quot;:[0,&quot;Community Hub&quot;],&quot;footer.compare_plans&quot;:[0,&quot;Compare plans&quot;],&quot;footer.contact_sales&quot;:[0,&quot;Contact Sales&quot;],&quot;header.contact_sales&quot;:[0,&quot;Contact Sales&quot;],&quot;header.email_address&quot;:[0,&quot;Email Address&quot;],&quot;page.error.not_found&quot;:[0,&quot;Page not found&quot;],&quot;footer.developer_docs&quot;:[0,&quot;Developer docs&quot;],&quot;footer.privacy_policy&quot;:[0,&quot;Privacy Policy&quot;],&quot;footer.request_a_demo&quot;:[0,&quot;Request a demo&quot;],&quot;page.continue_reading&quot;:[0,&quot;Continue reading&quot;],&quot;footer.analysts_report&quot;:[0,&quot;Analyst reports&quot;],&quot;footer.for_enterprises&quot;:[0,&quot;For enterprises&quot;],&quot;footer.getting_started&quot;:[0,&quot;Getting Started&quot;],&quot;footer.learning_center&quot;:[0,&quot;Learning Center&quot;],&quot;footer.project_galileo&quot;:[0,&quot;Project Galileo&quot;],&quot;pagination.newer_posts&quot;:[0,&quot;Newer Posts&quot;],&quot;pagination.older_posts&quot;:[0,&quot;Older Posts&quot;],&quot;posts.social_buttons.x&quot;:[0,&quot;Discuss on X&quot;],&quot;search.icon_aria_label&quot;:[0,&quot;Search&quot;],&quot;search.source_location&quot;:[0,&quot;Source/Location&quot;],&quot;footer.about_cloudflare&quot;:[0,&quot;About Cloudflare&quot;],&quot;footer.athenian_project&quot;:[0,&quot;Athenian Project&quot;],&quot;footer.become_a_partner&quot;:[0,&quot;Become a partner&quot;],&quot;footer.cloudflare_radar&quot;:[0,&quot;Cloudflare Radar&quot;],&quot;footer.network_services&quot;:[0,&quot;Network services&quot;],&quot;footer.trust_and_safety&quot;:[0,&quot;Trust &amp; Safety&quot;],&quot;header.get_started_free&quot;:[0,&quot;Get Started Free&quot;],&quot;page.search.placeholder&quot;:[0,&quot;Search Cloudflare&quot;],&quot;footer.cloudflare_status&quot;:[0,&quot;Cloudflare Status&quot;],&quot;footer.cookie_preference&quot;:[0,&quot;Cookie Preferences&quot;],&quot;header.valid_email_error&quot;:[0,&quot;Must be valid email.&quot;],&quot;search.result_stat_empty&quot;:[0,&quot;Results &lt;strong&gt;{search_range}&lt;/strong&gt; of &lt;strong&gt;{search_total}&lt;/strong&gt;&quot;],&quot;footer.connectivity_cloud&quot;:[0,&quot;Connectivity cloud&quot;],&quot;footer.developer_services&quot;:[0,&quot;Developer services&quot;],&quot;footer.investor_relations&quot;:[0,&quot;Investor relations&quot;],&quot;page.not_found.error_code&quot;:[0,&quot;Error Code: 404&quot;],&quot;search.autocomplete_title&quot;:[0,&quot;Insert a query. Press enter to send&quot;],&quot;footer.logos_and_press_kit&quot;:[0,&quot;Logos &amp; press kit&quot;],&quot;footer.application_services&quot;:[0,&quot;Application services&quot;],&quot;footer.get_a_recommendation&quot;:[0,&quot;Get a recommendation&quot;],&quot;posts.social_buttons.reddit&quot;:[0,&quot;Discuss on Reddit&quot;],&quot;footer.sse_and_sase_services&quot;:[0,&quot;SSE and SASE services&quot;],&quot;page.not_found.outdated_link&quot;:[0,&quot;You may have used an outdated link, or you may have typed the address incorrectly.&quot;],&quot;footer.report_security_issues&quot;:[0,&quot;Report Security Issues&quot;],&quot;page.error.error_message_page&quot;:[0,&quot;Sorry, we can&#39;t find the page you are looking for.&quot;],&quot;header.subscribe_notifications&quot;:[0,&quot;Subscribe to receive notifications of new posts:&quot;],&quot;footer.cloudflare_for_campaigns&quot;:[0,&quot;Cloudflare for Campaigns&quot;],&quot;header.subscription_confimation&quot;:[0,&quot;Subscription confirmed. Thank you for subscribing!&quot;],&quot;posts.social_buttons.hackernews&quot;:[0,&quot;Discuss on Hacker News&quot;],&quot;footer.diversity_equity_inclusion&quot;:[0,&quot;Diversity, equity &amp; inclusion&quot;],&quot;footer.critical_infrastructure_defense_project&quot;:[0,&quot;Critical Infrastructure Defense Project&quot;]}]}" ssr client="load" opts="{&quot;name&quot;:&quot;MorePosts&quot;,&quot;value&quot;:true}" await-children><div class="w-100 bt-l b--gray8"><h3 data-testid="more-posts-title" class="orange fw5 f4 ph3 mt4">MORE POSTS</h3></div><article data-testid="more-posts-article" class="w-100 w-100-m ph3 mb4"><p class="f3 fw5 gray1" data-iso-date="2024-11-20T13:30-08:00">November 20, 2024  9:30 PM</p><a href="/resilient-internet-connectivity-baltic-cable-cuts/" class="no-underline gray1 f4 fw5"><h6 class="gray1 f4 fw5 mt2">Resilient Internet connectivity in Europe mitigates impact from multiple cable cuts</h6></a><p class="gray1 lh-copy">Two recent cable cuts that occurred in the Baltic Sea resulted in little-to-no observable impact to the affected countries, in large part because of the significant redundancy and resilience of Internet infrastructure in Europe.
<!-- -->...</p><ul class="flex pl0 fw6 f2"><span>By<!-- --> </span><li class="list flex items-center"><div class="author-name-tooltip"><a href="/author/david-belson/" class="fw5 f2 black no-underline">David Belson</a></div></li></ul><div class="flex flex-row flex-wrap"><div><a href="/tag/cloudflare-radar/" class="no-underline f1 fw2 blue3 underline-hover">Radar</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/internet-traffic/" class="no-underline f1 fw2 blue3 underline-hover">Internet Traffic</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/traffic/" class="no-underline f1 fw2 blue3 underline-hover">Traffic</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/outage/" class="no-underline f1 fw2 blue3 underline-hover">Outage</a></div></div></article><article data-testid="more-posts-article" class="w-100 w-100-m ph3 mb4"><p class="f3 fw5 gray1" data-iso-date="2024-10-30T00:00+00:00">October 30, 2024  12:00 AM</p><a href="/cloudflare-perspective-of-the-october-30-2024-ovhcloud-outage/" class="no-underline gray1 f4 fw5"><h6 class="gray1 f4 fw5 mt2">Cloudflare’s perspective of the October 30, 2024, OVHcloud outage</h6></a><p class="gray1 lh-copy">On October 30, 2024, cloud hosting provider OVHcloud (AS16276) suffered a brief but significant outage. Within this post, we review Cloudflare’s perspective on this outage.<!-- -->...</p><ul class="flex pl0 fw6 f2"><span>By<!-- --> </span><li class="list flex items-center"><div class="author-name-tooltip"><a href="/author/bryton/" class="fw5 f2 black no-underline">Bryton Herdes</a></div></li><li class="list flex items-center"><div class="author-name-tooltip"><span class="fw5 f2 black no-underline">, </span><a href="/author/david-belson/" class="fw5 f2 black no-underline">David Belson</a></div></li><li class="list flex items-center"><div class="author-name-tooltip"><span class="fw5 f2 black no-underline">, </span><a href="/author/tanner/" class="fw5 f2 black no-underline">Tanner Ryan</a></div></li></ul><div class="flex flex-row flex-wrap"><div><a href="/tag/cloudflare-radar/" class="no-underline f1 fw2 blue3 underline-hover">Radar</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/trends/" class="no-underline f1 fw2 blue3 underline-hover">Trends</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/consumer-services/" class="no-underline f1 fw2 blue3 underline-hover">Consumer Services</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/outage/" class="no-underline f1 fw2 blue3 underline-hover">Outage</a></div></div></article><article data-testid="more-posts-article" class="w-100 w-100-m ph3 mb4"><p class="f3 fw5 gray1" data-iso-date="2024-10-29T13:05+00:00">October 29, 2024  1:05 PM</p><a href="/q3-2024-internet-disruption-summary/" class="no-underline gray1 f4 fw5"><h6 class="gray1 f4 fw5 mt2">Forced offline: the Q3 2024 Internet disruption summary</h6></a><p class="gray1 lh-copy">The third quarter of 2024 was particularly active, with quite a few significant Internet disruptions. Underlying causes included government-directed shutdowns, power outages, hurricane damage, terrestrial and submarine cable cuts, military action, and more.<!-- -->...</p><ul class="flex pl0 fw6 f2"><span>By<!-- --> </span><li class="list flex items-center"><div class="author-name-tooltip"><a href="/author/david-belson/" class="fw5 f2 black no-underline">David Belson</a></div></li></ul><div class="flex flex-row flex-wrap"><div><a href="/tag/cloudflare-radar/" class="no-underline f1 fw2 blue3 underline-hover">Radar</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/internet-quality/" class="no-underline f1 fw2 blue3 underline-hover">Internet Quality</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/internet-shutdown/" class="no-underline f1 fw2 blue3 underline-hover">Internet Shutdown</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/outage/" class="no-underline f1 fw2 blue3 underline-hover">Outage</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/internet-traffic/" class="no-underline f1 fw2 blue3 underline-hover">Internet Traffic</a></div></div></article><article data-testid="more-posts-article" class="w-100 w-100-m ph3 mb4"><p class="f3 fw5 gray1" data-iso-date="2024-09-30T17:32-07:00">October 01, 2024  12:32 AM</p><a href="/impact-of-verizons-september-30-outage-on-internet-traffic/" class="no-underline gray1 f4 fw5"><h6 class="gray1 f4 fw5 mt2">Impact of Verizon’s September 30 outage on Internet traffic</h6></a><p class="gray1 lh-copy">On Monday, September 30, customers on Verizon’s mobile network in multiple cities across the United States reported experiencing a loss of connectivity. HTTP request traffic data from Verizon’s mobile ASN (AS6167) showed nominal declines across impacted cities.
<!-- -->...</p><ul class="flex pl0 fw6 f2"><span>By<!-- --> </span><li class="list flex items-center"><div class="author-name-tooltip"><a href="/author/david-belson/" class="fw5 f2 black no-underline">David Belson</a></div></li></ul><div class="flex flex-row flex-wrap"><div><a href="/tag/cloudflare-radar/" class="no-underline f1 fw2 blue3 underline-hover">Radar</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/trends/" class="no-underline f1 fw2 blue3 underline-hover">Trends</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/consumer-services/" class="no-underline f1 fw2 blue3 underline-hover">Consumer Services</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/outage/" class="no-underline f1 fw2 blue3 underline-hover">Outage</a></div></div></article><article data-testid="more-posts-article" class="w-100 w-100-m ph3 mb4"><p class="f3 fw5 gray1" data-iso-date="2024-09-20T14:00+00:00">September 20, 2024  2:00 PM</p><a href="/cloudflare-incident-on-september-17-2024/" class="no-underline gray1 f4 fw5"><h6 class="gray1 f4 fw5 mt2">Cloudflare incident on September 17, 2024</h6></a><p class="gray1 lh-copy">On September 17, 2024, during planned routine maintenance, Cloudflare stopped announcing 15 IPv4 prefixes, affecting some Business plan websites for approximately one hour. During this time, IPv4 traffic for these customers would not have reached Cloudflare and users attempting t<!-- -->...</p><ul class="flex pl0 fw6 f2"><span>By<!-- --> </span><li class="list flex items-center"><div class="author-name-tooltip"><a href="/author/joe-abley/" class="fw5 f2 black no-underline">Joe Abley</a></div></li></ul><div class="flex flex-row flex-wrap"><div><a href="/tag/outage/" class="no-underline f1 fw2 blue3 underline-hover">Outage</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/ipv4/" class="no-underline f1 fw2 blue3 underline-hover">IPv4</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/cdn/" class="no-underline f1 fw2 blue3 underline-hover">CDN</a></div></div></article><article data-testid="more-posts-article" class="w-100 w-100-m ph3 mb4"><p class="f3 fw5 gray1" data-iso-date="2024-08-01T15:21+00:00">August 01, 2024  3:21 PM</p><a href="/a-recent-spate-of-internet-disruptions-july-2024/" class="no-underline gray1 f4 fw5"><h6 class="gray1 f4 fw5 mt2">A recent spate of Internet disruptions</h6></a><p class="gray1 lh-copy">Cloudflare Radar is constantly monitoring the Internet for widespread disruptions. Here we examine several recent noteworthy disruptions detected in the first month of Q3, including traffic anomalies observed in Bangladesh, Syria, Pakistan, and Venezuela.<!-- -->...</p><ul class="flex pl0 fw6 f2"><span>By<!-- --> </span><li class="list flex items-center"><div class="author-name-tooltip"><a href="/author/david-belson/" class="fw5 f2 black no-underline">David Belson</a></div></li></ul><div class="flex flex-row flex-wrap"><div><a href="/tag/internet-shutdown/" class="no-underline f1 fw2 blue3 underline-hover">Internet Shutdown</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/cloudflare-radar/" class="no-underline f1 fw2 blue3 underline-hover">Radar</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/internet-traffic/" class="no-underline f1 fw2 blue3 underline-hover">Internet Traffic</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/outage/" class="no-underline f1 fw2 blue3 underline-hover">Outage</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/internet-shutdown/" class="no-underline f1 fw2 blue3 underline-hover">Internet Shutdown</a></div></div></article><article data-testid="more-posts-article" class="w-100 w-100-m ph3 mb4"><p class="f3 fw5 gray1" data-iso-date="2024-07-16T14:00:01.000+01:00">July 16, 2024  1:00 PM</p><a href="/q2-2024-internet-disruption-summary/" class="no-underline gray1 f4 fw5"><h6 class="gray1 f4 fw5 mt2">Q2 2024 Internet disruption summary</h6></a><p class="gray1 lh-copy">Government directed shutdowns and cable cuts were both significant sources of Internet outages in Q2 2024. This post explores these disruptions, as well as others caused by power outages, maintenance, technical problems, military action, and unknown causes<!-- -->...</p><ul class="flex pl0 fw6 f2"><span>By<!-- --> </span><li class="list flex items-center"><div class="author-name-tooltip"><a href="/author/david-belson/" class="fw5 f2 black no-underline">David Belson</a></div></li></ul><div class="flex flex-row flex-wrap"><div><a href="/tag/cloudflare-radar/" class="no-underline f1 fw2 blue3 underline-hover">Radar</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/internet-traffic/" class="no-underline f1 fw2 blue3 underline-hover">Internet Traffic</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/internet-shutdown/" class="no-underline f1 fw2 blue3 underline-hover">Internet Shutdown</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/internet-quality/" class="no-underline f1 fw2 blue3 underline-hover">Internet Quality</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/outage/" class="no-underline f1 fw2 blue3 underline-hover">Outage</a></div></div></article><article data-testid="more-posts-article" class="w-100 w-100-m ph3 mb4"><p class="f3 fw5 gray1" data-iso-date="2024-07-04T14:00:50.000+01:00">July 04, 2024  1:00 PM</p><a href="/cloudflare-1111-incident-on-june-27-2024/" class="no-underline gray1 f4 fw5"><h6 class="gray1 f4 fw5 mt2">Cloudflare 1.1.1.1 incident on June 27, 2024</h6></a><p class="gray1 lh-copy">On June 27, 2024, a small number of users globally may have noticed that 1.1.1.1 was unreachable or degraded. The root cause was a mix of BGP (Border Gateway Protocol) hijacking and a route leak<!-- -->...</p><ul class="flex pl0 fw6 f2"><span>By<!-- --> </span><li class="list flex items-center"><div class="author-name-tooltip"><a href="/author/bryton/" class="fw5 f2 black no-underline">Bryton Herdes</a></div></li><li class="list flex items-center"><div class="author-name-tooltip"><span class="fw5 f2 black no-underline">, </span><a href="/author/mingwei/" class="fw5 f2 black no-underline">Mingwei Zhang</a></div></li><li class="list flex items-center"><div class="author-name-tooltip"><span class="fw5 f2 black no-underline">, </span><a href="/author/tanner/" class="fw5 f2 black no-underline">Tanner Ryan</a></div></li></ul><div class="flex flex-row flex-wrap"><div><a href="/tag/1-1-1-1/" class="no-underline f1 fw2 blue3 underline-hover">1.1.1.1</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/outage/" class="no-underline f1 fw2 blue3 underline-hover">Outage</a></div></div></article><article data-testid="more-posts-article" class="w-100 w-100-m ph3 mb4"><p class="f3 fw5 gray1" data-iso-date="2024-06-26T14:00:22.000+01:00">June 26, 2024  1:00 PM</p><a href="/cloudflare-incident-on-june-20-2024/" class="no-underline gray1 f4 fw5"><h6 class="gray1 f4 fw5 mt2">Cloudflare incident on June 20, 2024</h6></a><p class="gray1 lh-copy">A new DDoS rule resulted in an increase in error responses and latency for Cloudflare customers. Here’s how it went wrong, and what we’ve learned<!-- -->...</p><ul class="flex pl0 fw6 f2"><span>By<!-- --> </span><li class="list flex items-center"><div class="author-name-tooltip"><a href="/author/lloyd/" class="fw5 f2 black no-underline">Lloyd Wallis</a></div></li><li class="list flex items-center"><div class="author-name-tooltip"><span class="fw5 f2 black no-underline">, </span><a href="/author/julien-desgats/" class="fw5 f2 black no-underline">Julien Desgats</a></div></li><li class="list flex items-center"><div class="author-name-tooltip"><span class="fw5 f2 black no-underline">, </span><a href="/author/manish/" class="fw5 f2 black no-underline">Manish Arora</a></div></li></ul><div class="flex flex-row flex-wrap"><div><a href="/tag/post-mortem/" class="no-underline f1 fw2 blue3 underline-hover">Post Mortem</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/outage/" class="no-underline f1 fw2 blue3 underline-hover">Outage</a></div></div></article><article data-testid="more-posts-article" class="w-100 w-100-m ph3 mb4"><p class="f3 fw5 gray1" data-iso-date="2024-06-21T14:00:02.000+01:00">June 21, 2024  1:00 PM</p><a href="/syria-iraq-algeria-exam-internet-shutdown/" class="no-underline gray1 f4 fw5"><h6 class="gray1 f4 fw5 mt2">Exam-ining recent Internet shutdowns in Syria, Iraq, and Algeria</h6></a><p class="gray1 lh-copy">Similar to actions taken over the last several years, governments in Syria, Iraq, and Algeria have again disrupted Internet connectivity nationwide in an attempt to prevent cheating on exams. We investigate how these disruptions were implemented, and their impact<!-- -->...</p><ul class="flex pl0 fw6 f2"><span>By<!-- --> </span><li class="list flex items-center"><div class="author-name-tooltip"><a href="/author/david-belson/" class="fw5 f2 black no-underline">David Belson</a></div></li></ul><div class="flex flex-row flex-wrap"><div><a href="/tag/cloudflare-radar/" class="no-underline f1 fw2 blue3 underline-hover">Radar</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/internet-traffic/" class="no-underline f1 fw2 blue3 underline-hover">Internet Traffic</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/outage/" class="no-underline f1 fw2 blue3 underline-hover">Outage</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/internet-shutdown/" class="no-underline f1 fw2 blue3 underline-hover">Internet Shutdown</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/bgp/" class="no-underline f1 fw2 blue3 underline-hover">BGP</a></div></div></article><article data-testid="more-posts-article" class="w-100 w-100-m ph3 mb4"><p class="f3 fw5 gray1" data-iso-date="2024-05-13T23:37:25.000+01:00">May 13, 2024  10:37 PM</p><a href="/east-african-internet-connectivity-again-impacted-by-submarine-cable-cuts/" class="no-underline gray1 f4 fw5"><h6 class="gray1 f4 fw5 mt2">East African Internet connectivity again impacted by submarine cable cuts</h6></a><p class="gray1 lh-copy">On Sunday, May 12, issues with the EASSy and Seacom submarine cables again disrupted connectivity to East Africa, impacting a number of countries previously affected by a set of cable cuts that occurred nearly three months earlier<!-- -->...</p><ul class="flex pl0 fw6 f2"><span>By<!-- --> </span><li class="list flex items-center"><div class="author-name-tooltip"><a href="/author/david-belson/" class="fw5 f2 black no-underline">David Belson</a></div></li></ul><div class="flex flex-row flex-wrap"><div><a href="/tag/cloudflare-radar/" class="no-underline f1 fw2 blue3 underline-hover">Radar</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/internet-traffic/" class="no-underline f1 fw2 blue3 underline-hover">Internet Traffic</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/outage/" class="no-underline f1 fw2 blue3 underline-hover">Outage</a></div></div></article><article data-testid="more-posts-article" class="w-100 w-100-m ph3 mb4"><p class="f3 fw5 gray1" data-iso-date="2024-04-29T14:00:09.000+01:00">April 29, 2024  1:00 PM</p><a href="/q1-2024-internet-disruption-summary/" class="no-underline gray1 f4 fw5"><h6 class="gray1 f4 fw5 mt2">Q1 2024 Internet disruption summary</h6></a><p class="gray1 lh-copy">The first quarter of 2024 kicked off with quite a few Internet disruptions. Perhaps most interestingly, RPKI, DNS, and DNSSEC issues were among the technical problems that disrupted connectivity for subscribers across multiple network providers<!-- -->...</p><ul class="flex pl0 fw6 f2"><span>By<!-- --> </span><li class="list flex items-center"><div class="author-name-tooltip"><a href="/author/david-belson/" class="fw5 f2 black no-underline">David Belson</a></div></li></ul><div class="flex flex-row flex-wrap"><div><a href="/tag/cloudflare-radar/" class="no-underline f1 fw2 blue3 underline-hover">Radar</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/internet-traffic/" class="no-underline f1 fw2 blue3 underline-hover">Internet Traffic</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/outage/" class="no-underline f1 fw2 blue3 underline-hover">Outage</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/internet-shutdown/" class="no-underline f1 fw2 blue3 underline-hover">Internet Shutdown</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/internet-quality/" class="no-underline f1 fw2 blue3 underline-hover">Internet Quality</a></div></div></article><article data-testid="more-posts-article" class="w-100 w-100-m ph3 mb4"><p class="f3 fw5 gray1" data-iso-date="2024-04-08T14:00:15.000+01:00">April 08, 2024  1:00 PM</p><a href="/major-data-center-power-failure-again-cloudflare-code-orange-tested/" class="no-underline gray1 f4 fw5"><h6 class="gray1 f4 fw5 mt2">Major data center power failure (again): Cloudflare Code Orange tested</h6></a><p class="gray1 lh-copy">Just four months after a complete power outage at a critical data center we were hit with the exact same scenario.  Here’s how we did this time, and what’s next<!-- -->...</p><ul class="flex pl0 fw6 f2"><span>By<!-- --> </span><li class="list flex items-center"><div class="author-name-tooltip"><a href="/author/matthew-prince/" class="fw5 f2 black no-underline">Matthew Prince</a></div></li><li class="list flex items-center"><div class="author-name-tooltip"><span class="fw5 f2 black no-underline">, </span><a href="/author/john-graham-cumming/" class="fw5 f2 black no-underline">John Graham-Cumming</a></div></li><li class="list flex items-center"><div class="author-name-tooltip"><span class="fw5 f2 black no-underline">, </span><a href="/author/jeremy-hartman/" class="fw5 f2 black no-underline">Jeremy Hartman</a></div></li></ul><div class="flex flex-row flex-wrap"><div><a href="/tag/post-mortem/" class="no-underline f1 fw2 blue3 underline-hover">Post Mortem</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/outage/" class="no-underline f1 fw2 blue3 underline-hover">Outage</a></div></div></article><article data-testid="more-posts-article" class="w-100 w-100-m ph3 mb4"><p class="f3 fw5 gray1" data-iso-date="2024-03-14T18:03:25.000+00:00">March 14, 2024  6:03 PM</p><a href="/undersea-cable-failures-cause-internet-disruptions-across-africa-march-14-2024/" class="no-underline gray1 f4 fw5"><h6 class="gray1 f4 fw5 mt2">Undersea cable failures cause Internet disruptions for multiple African countries</h6></a><p class="gray1 lh-copy">Internet connectivity in several African countries was disrupted on March 14, 2024, beginning at approximately 05:00 UTC. Based on published reports and social media posts from impacted network providers, the disruption is believed to be due to multiple undersea cable failures in<!-- -->...</p><ul class="flex pl0 fw6 f2"><span>By<!-- --> </span><li class="list flex items-center"><div class="author-name-tooltip"><a href="/author/joao-tome/" class="fw5 f2 black no-underline">João Tomé</a></div></li><li class="list flex items-center"><div class="author-name-tooltip"><span class="fw5 f2 black no-underline">, </span><a href="/author/david-belson/" class="fw5 f2 black no-underline">David Belson</a></div></li></ul><div class="flex flex-row flex-wrap"><div><a href="/tag/cloudflare-radar/" class="no-underline f1 fw2 blue3 underline-hover">Radar</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/outage/" class="no-underline f1 fw2 blue3 underline-hover">Outage</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/internet-traffic/" class="no-underline f1 fw2 blue3 underline-hover">Internet Traffic</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/trends/" class="no-underline f1 fw2 blue3 underline-hover">Trends</a></div></div></article><article data-testid="more-posts-article" class="w-100 w-100-m ph3 mb4"><p class="f3 fw5 gray1" data-iso-date="2024-01-22T14:00:27.000+00:00">January 22, 2024  2:00 PM</p><a href="/q4-2023-internet-disruption-summary/" class="no-underline gray1 f4 fw5"><h6 class="gray1 f4 fw5 mt2">Q4 2023 Internet disruption summary</h6></a><p class="gray1 lh-copy">In this post, we review selected Internet disruptions observed by Cloudflare during the fourth quarter of 2023, supported by traffic graphs from Cloudflare Radar and other internal Cloudflare tools, and grouped by associated cause or common geography<!-- -->...</p><ul class="flex pl0 fw6 f2"><span>By<!-- --> </span><li class="list flex items-center"><div class="author-name-tooltip"><a href="/author/david-belson/" class="fw5 f2 black no-underline">David Belson</a></div></li></ul><div class="flex flex-row flex-wrap"><div><a href="/tag/cloudflare-radar/" class="no-underline f1 fw2 blue3 underline-hover">Radar</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/internet-traffic/" class="no-underline f1 fw2 blue3 underline-hover">Internet Traffic</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/outage/" class="no-underline f1 fw2 blue3 underline-hover">Outage</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/internet-shutdown/" class="no-underline f1 fw2 blue3 underline-hover">Internet Shutdown</a></div><div><span class="f1 fw2 blue3 no-underline underline-hover">, </span><a href="/tag/internet-quality/" class="no-underline f1 fw2 blue3 underline-hover">Internet Quality</a></div></div></article><!--astro:end--></astro-island> <div class="pagination mw-100 center mv5 ph3 w-100 tc"><div class="center w-50-l w-100"><div class="flex items-center justify-center justify-around-m "><ul class="flex list ml3" style="padding-inline-start:inherit"><li class="gray"><a class="no-underline  underline-hover  dib-m dib-l mr1 gray3 " href="/tag/outage/">1</a></li><li class=""><a class="no-underline  underline-hover  dib-m dib-l mr1 blue3" href="/tag/outage/page/2/">2</a></li><li class="ml">…</li><li><a class="no-underline  underline-hover dib-m dib-l mr3 blue3" href="/tag/outage/page/4/">4</a></li></ul><span><a class="no-underline blue3 underline-hover" data-testid="pagination-toggle-next" href="/tag/outage/page/2/" rel="prev"><span class="underline-hover dn dib-m dib-l">Older Posts</span> →</a></span></div></div></div> </main>  <footer class="pt4 pb4 pl1 pr1 main-footer"><div class="mw8 center dn db-l ph3"><div class="flex flex-row justify-between"><div class="main-footer__menu-group"><ul id="getting-started-menu" class="list pl0"><li class="pt1 pb1 f1 main-footer__menu-group__header js-toggle-footer-group" data-submenu="getting-started-menu">Getting Started<i class="icon-caret-down"></i></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/plans/free/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="free-plans" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Free plans</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/enterprise/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="enterprise" class="f1 blue3 no-underline underline-hover" rel="noreferrer">For enterprises</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/plans/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="compare-plans" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Compare plans</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/about-your-website/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="get-a-recommendation" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Get a recommendation</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/plans/enterprise/demo/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="request-a-demo" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Request a demo</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/plans/enterprise/contact/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="contact-sales" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Contact Sales</a></li></ul></div><div class="main-footer__menu-group"><ul id="company-menu" class="list pl0"><li class="pt1 pb1 f1" data-submenu="company-menu">Resources<i class="icon-caret-down"></i></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/learning/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="learning-center" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Learning Center</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/analysts/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="analysts-report" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Analyst reports</a></li><li class="pt1 pb1"><a href="https://radar.cloudflare.com/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="overview" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Cloudflare Radar</a></li><li class="pt1 pb1"><a href="https://cloudflare.tv/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="tv" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Cloudflare TV</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/case-studies/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="case-studies" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Case Studies</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/resource-hub/?resourcetype=Webinar" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="webinars" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Webinars</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/resource-hub/?resourcetype=Whitepaper" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="white-papers" class="f1 blue3 no-underline underline-hover" rel="noreferrer">White Papers</a></li><li class="pt1 pb1"><a href="https://developers.cloudflare.com" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="developer-docs" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Developer docs</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/the-net/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="theNet" class="f1 blue3 no-underline underline-hover" rel="noreferrer">theNet</a></li></ul></div><div class="main-footer__menu-group"><ul id="sales-menu" class="list pl0"><li class="pt1 pb1 f1 main-footer__menu-group__header js-toggle-footer-group" data-submenu="sales-menu">Solutions<i class="icon-caret-down"></i></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/connectivity-cloud/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="connectivity-cloud" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Connectivity cloud</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/zero-trust/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="zero-trust" class="f1 blue3 no-underline underline-hover" rel="noreferrer">SSE and SASE services</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/application-services/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="application-services" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Application services</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/network-services/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="network-services" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Network services</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/developer-platform/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="developer-services" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Developer services</a></li></ul></div><div class="main-footer__menu-group"><ul id="community-menu" class="list pl0"><li class="pt1 pb1 f1 main-footer__menu-group__header js-toggle-footer-group" data-submenu="community-menu">Community<i class="icon-caret-down"></i></li><li class="pt1 pb1"><a href="https://community.cloudflare.com" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="community_hub" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Community Hub</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/galileo/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="galileo" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Project Galileo</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/athenian/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="athenian" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Athenian Project</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/campaigns/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="cloudflare-for-campaigns" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Cloudflare for Campaigns</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/partners/technology-partners/cidp/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="critical-infrastructure-defense-project" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Critical Infrastructure Defense Project</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/connect2024/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="connect-2024" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Connect 2024</a></li></ul></div><div class="main-footer__menu-group"><ul id="support-menu" class="list pl0"><li class="pt1 pb1 f1 main-footer__menu-group__header js-toggle-footer-group" data-submenu="support-menu">Support<i class="icon-caret-down"></i></li><li class="pt1 pb1"><a href="https://support.cloudflare.com" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="help-center" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Help center</a></li><li class="pt1 pb1"><a href="https://www.cloudflarestatus.com" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="status" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Cloudflare Status</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/compliance/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="compliance" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Compliance</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/gdpr/introduction/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="gdpr" class="f1 blue3 no-underline underline-hover" rel="noreferrer">GDPR</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/trust-hub/abuse-approach/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="trust-and-safety" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Trust &amp; Safety</a></li></ul></div><div class="main-footer__menu-group"><ul id="company-menu" class="list pl0"><li class="pt1 pb1 f1 main-footer__menu-group__header js-toggle-footer-group" data-submenu="company-menu">Company<i class="icon-caret-down"></i></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/about-overview/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="overview" class="f1 blue3 no-underline underline-hover" rel="noreferrer">About Cloudflare</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/people/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="our_team" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Our team</a></li><li class="pt1 pb1"><a href="https://cloudflare.net/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="investor-relations" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Investor relations</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/press/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="press" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Press</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/careers/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="careers" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Careers</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/diversity-equity-and-inclusion/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="diversity-equity-inclusion" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Diversity, equity &amp; inclusion</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/impact/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="impact-ESG" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Impact/ESG</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/network/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="network_map" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Network Map</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/press-kit/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="press-kit" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Logos &amp; press kit</a></li><li class="pt1 pb1"><a href="https://www.cloudflare.com/partners/" target="_blank" data-tracking-category="footer" data-tracking-action="click" data-tracking-label="partners" class="f1 blue3 no-underline underline-hover" rel="noreferrer">Become a partner</a></li></ul></div></div></div><div class="mw8 center ph3"><div class="flex flex-row flex-wrap justify-center md:justify-between items-center pt4"><div class="flex flex-row space-x-4 items-start w-25-l pb4 pb0-l"><a target="_blank" rel="noreferrer" href="https://www.facebook.com/Cloudflare/" class="w-8"><img class="w-8" src="https://www.cloudflare.com/img/footer/facebook.svg" alt="facebook"/></a><a target=" _blank" rel="noreferrer" href="https://x.com/Cloudflare" class="w-8"><img class="w-8" src="https://www.cloudflare.com/img/footer/twitter.svg" alt="X"/></a><a target="_blank" rel="noreferrer" href="https://www.linkedin.com/company/cloudflare" class="w-8"><img class="w-8" src="https://www.cloudflare.com/img/footer/linkedin.svg" alt="linkedin"/></a><a target="_blank" rel="noreferrer" href="https://www.youtube.com/cloudflare" class="w-8"><img class="w-8" src="https://www.cloudflare.com/img/footer/youtube.svg" alt="youtube"/></a><a target="_blank" rel="noreferrer" href="https://www.instagram.com/cloudflare" class="w-8"><img class="w-8" src="https://www.cloudflare.com/img/footer/instagram.svg" alt="instagram"/></a></div><div class="w-70-l tr-l tl-ns"><div><span class="main-footer__copyright f1">© <!-- -->2025<!-- --> Cloudflare, Inc.<!-- --> </span><span class="main-footer__copyright f1">|</span><a href="https://www.cloudflare.com/privacypolicy/" target="_blank" class="main-footer__copyright f1 no-underline underline-hover" rel="noreferrer"> <!-- -->Privacy Policy<!-- --> </a><span class="main-footer__copyright f1">|</span><a href="https://www.cloudflare.com/website-terms/" target="_blank" class="main-footer__copyright f1 no-underline underline-hover" rel="noreferrer"> <!-- -->Terms of Use<!-- --> </a><span class="main-footer__copyright f1">|</span><a href="https://www.cloudflare.com/disclosure/" target="_blank" class="main-footer__copyright f1 no-underline underline-hover" rel="noreferrer"> <!-- -->Report Security Issues<!-- --> </a><span class="main-footer__copyright f1">|</span><img class="mw2 ph1" src="/images/privacy-options.svg" alt="Privacy Options"/><a href="#cookie-settings" id="ot-sdk-btn" class="ot-sdk-show-settings main-footer__copyright f1 no-underline underline-hover"><span class="brandGray5">Cookie Preferences</span> </a><span class="main-footer__copyright f1">|</span><a href="https://www.cloudflare.com/trademark/" target="_blank" class="main-footer__copyright f1 no-underline underline-hover" rel="noreferrer"> <!-- -->Trademark<!-- --> </a></div></div></div></div></footer></html>